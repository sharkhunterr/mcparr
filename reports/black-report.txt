--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/base.py	2025-12-31 13:30:51.550007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/base.py	2025-12-31 13:41:32.876651+00:00
@@ -17,21 +17,22 @@
     def __init__(
         self,
         success: bool,
         message: Optional[str] = None,
         response_time_ms: Optional[float] = None,
-        details: Optional[Dict[str, Any]] = None
+        details: Optional[Dict[str, Any]] = None,
     ):
         self.success = success
         self.message = message
         self.response_time_ms = response_time_ms
         self.details = details or {}
         self.tested_at = datetime.utcnow()
 
 
 class ServiceCapability(Enum):
     """Capabilities that a service adapter can provide."""
+
     USER_MANAGEMENT = "user_management"
     MEDIA_CONTENT = "media_content"
     TICKET_SYSTEM = "ticket_system"
     MONITORING = "monitoring"
     AUTHENTICATION = "authentication"
@@ -39,16 +40,11 @@
 
 
 class BaseServiceAdapter(ABC):
     """Base class for all service adapters."""
 
-    def __init__(
-        self,
-        service_config: 'ServiceConfig',
-        timeout: int = 30,
-        verify_ssl: bool = True
-    ):
+    def __init__(self, service_config: "ServiceConfig", timeout: int = 30, verify_ssl: bool = True):
         """Initialize the adapter.
 
         Args:
             service_config: Service configuration object
             timeout: HTTP request timeout in seconds
@@ -78,11 +74,11 @@
             self._client = httpx.AsyncClient(
                 base_url=self.base_url,
                 headers=headers,
                 timeout=self.timeout,
                 verify=self.verify_ssl,
-                follow_redirects=True
+                follow_redirects=True,
             )
 
     async def close(self):
         """Close the HTTP client."""
         if self._client:
@@ -92,11 +88,11 @@
     @property
     def base_url(self) -> str:
         """Get the base URL for the service."""
         url = self.service_config.base_url
         if self.service_config.port:
-            if ':' not in url.split('://', 1)[1]:  # No port specified
+            if ":" not in url.split("://", 1)[1]:  # No port specified
                 url = f"{url}:{self.service_config.port}"
         return url
 
     @property
     @abstractmethod
@@ -123,16 +119,11 @@
     @abstractmethod
     async def get_service_info(self) -> Dict[str, Any]:
         """Get basic service information."""
         pass
 
-    async def _make_request(
-        self,
-        method: str,
-        endpoint: str,
-        **kwargs
-    ) -> httpx.Response:
+    async def _make_request(self, method: str, endpoint: str, **kwargs) -> httpx.Response:
         """Make an HTTP request to the service.
 
         Args:
             method: HTTP method (GET, POST, etc.)
             endpoint: API endpoint (will be appended to base_url)
@@ -164,21 +155,15 @@
         except httpx.RequestError as e:
             self.logger.error(f"Request failed: {method} {endpoint} - {e}")
             raise
         except httpx.HTTPStatusError as e:
             self.logger.error(
-                f"HTTP error: {method} {endpoint} - "
-                f"{e.response.status_code} {e.response.text}"
+                f"HTTP error: {method} {endpoint} - " f"{e.response.status_code} {e.response.text}"
             )
             raise
 
-    async def _safe_request(
-        self,
-        method: str,
-        endpoint: str,
-        **kwargs
-    ) -> Optional[Dict[str, Any]]:
+    async def _safe_request(self, method: str, endpoint: str, **kwargs) -> Optional[Dict[str, Any]]:
         """Make a safe HTTP request that returns None on error.
 
         Useful for optional operations where failures shouldn't crash the adapter.
         """
         try:
@@ -206,11 +191,11 @@
 
         # Basic validation
         if not self.service_config.base_url:
             errors.append("Base URL is required")
 
-        if not self.service_config.base_url.startswith(('http://', 'https://')):
+        if not self.service_config.base_url.startswith(("http://", "https://")):
             errors.append("Base URL must start with http:// or https://")
 
         return errors
 
 
@@ -289,10 +274,11 @@
 
         if not username or not password:
             return {}
 
         import base64
+
         credentials = base64.b64encode(f"{username}:{password}".encode()).decode()
         return {"Authorization": f"Basic {credentials}"}
 
     async def validate_auth(self) -> bool:
         """Validate basic authentication."""
@@ -309,21 +295,25 @@
 
 
 # Exception classes for adapters
 class AdapterError(Exception):
     """Base exception for adapter errors."""
+
     pass
 
 
 class ConnectionError(AdapterError):
     """Connection-related error."""
+
     pass
 
 
 class AuthenticationError(AdapterError):
     """Authentication-related error."""
+
     pass
 
 
 class ConfigurationError(AdapterError):
     """Configuration-related error."""
+
     pass
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/base.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/deluge.py	2025-12-31 13:30:51.554007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/deluge.py	2025-12-31 13:41:32.935062+00:00
@@ -26,13 +26,11 @@
     def service_type(self) -> str:
         return "deluge"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.API_ACCESS]
 
     def _get_next_request_id(self) -> int:
         """Get next JSON-RPC request ID."""
         self._request_id += 1
         return self._request_id
@@ -46,13 +44,13 @@
                 response = await client.post(
                     f"{self.base_url}/json",
                     json={
                         "method": "auth.login",
                         "params": [password],
-                        "id": self._get_next_request_id()
+                        "id": self._get_next_request_id(),
                     },
-                    headers={"Content-Type": "application/json"}
+                    headers={"Content-Type": "application/json"},
                 )
 
                 if response.status_code == 200:
                     data = response.json()
                     if data.get("result"):
@@ -77,16 +75,12 @@
         cookies = {"_session_id": self._session_cookie} if self._session_cookie else {}
 
         async with httpx.AsyncClient(timeout=30.0, cookies=cookies) as client:
             response = await client.post(
                 f"{self.base_url}/json",
-                json={
-                    "method": method,
-                    "params": params,
-                    "id": self._get_next_request_id()
-                },
-                headers={"Content-Type": "application/json"}
+                json={"method": method, "params": params, "id": self._get_next_request_id()},
+                headers={"Content-Type": "application/json"},
             )
 
             if response.status_code == 200:
                 data = response.json()
                 if data.get("error"):
@@ -109,27 +103,24 @@
 
                 return ConnectionTestResult(
                     success=True,
                     message="Successfully connected to Deluge",
                     response_time_ms=response_time,
-                    details={
-                        "status": "connected",
-                        "host_info": info
-                    }
+                    details={"status": "connected", "host_info": info},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check password",
-                    details={"status": "auth_failed"}
+                    details={"status": "auth_failed"},
                 )
 
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Deluge service information."""
         try:
@@ -140,75 +131,77 @@
                 "service": "deluge",
                 "version": version,
                 "download_location": config.get("download_location") if config else None,
                 "max_download_speed": config.get("max_download_speed") if config else None,
                 "max_upload_speed": config.get("max_upload_speed") if config else None,
-                "status": "online"
+                "status": "online",
             }
         except Exception as e:
-            return {
-                "service": "deluge",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+            return {"service": "deluge", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_torrents(self) -> List[Dict[str, Any]]:
         """Get list of torrents."""
         try:
             # Get torrent list with specific fields
             fields = [
-                "name", "state", "progress", "download_payload_rate",
-                "upload_payload_rate", "eta", "total_size", "total_done",
-                "ratio", "num_seeds", "num_peers", "time_added"
+                "name",
+                "state",
+                "progress",
+                "download_payload_rate",
+                "upload_payload_rate",
+                "eta",
+                "total_size",
+                "total_done",
+                "ratio",
+                "num_seeds",
+                "num_peers",
+                "time_added",
             ]
 
             torrents = await self._rpc_call("core.get_torrents_status", [{}, fields])
 
             result = []
             for torrent_id, data in (torrents or {}).items():
-                result.append({
-                    "id": torrent_id,
-                    "name": data.get("name"),
-                    "state": data.get("state"),
-                    "progress": round(data.get("progress", 0), 2),
-                    "download_speed": data.get("download_payload_rate", 0),
-                    "upload_speed": data.get("upload_payload_rate", 0),
-                    "eta": data.get("eta"),
-                    "total_size": data.get("total_size", 0),
-                    "total_done": data.get("total_done", 0),
-                    "ratio": round(data.get("ratio", 0), 2),
-                    "seeds": data.get("num_seeds", 0),
-                    "peers": data.get("num_peers", 0),
-                    "added": data.get("time_added")
-                })
+                result.append(
+                    {
+                        "id": torrent_id,
+                        "name": data.get("name"),
+                        "state": data.get("state"),
+                        "progress": round(data.get("progress", 0), 2),
+                        "download_speed": data.get("download_payload_rate", 0),
+                        "upload_speed": data.get("upload_payload_rate", 0),
+                        "eta": data.get("eta"),
+                        "total_size": data.get("total_size", 0),
+                        "total_done": data.get("total_done", 0),
+                        "ratio": round(data.get("ratio", 0), 2),
+                        "seeds": data.get("num_seeds", 0),
+                        "peers": data.get("num_peers", 0),
+                        "added": data.get("time_added"),
+                    }
+                )
 
             return result
         except Exception as e:
             self.logger.error(f"Failed to get torrents: {e}")
             return []
 
-    async def add_torrent(self, magnet_or_url: str, options: Optional[Dict] = None) -> Dict[str, Any]:
+    async def add_torrent(
+        self, magnet_or_url: str, options: Optional[Dict] = None
+    ) -> Dict[str, Any]:
         """Add a torrent by magnet link or URL."""
         try:
             if options is None:
                 options = {}
 
             if magnet_or_url.startswith("magnet:"):
                 result = await self._rpc_call("core.add_torrent_magnet", [magnet_or_url, options])
             else:
                 result = await self._rpc_call("core.add_torrent_url", [magnet_or_url, options])
 
-            return {
-                "success": True,
-                "torrent_id": result
-            }
-        except Exception as e:
-            return {
-                "success": False,
-                "error": str(e)
-            }
+            return {"success": True, "torrent_id": result}
+        except Exception as e:
+            return {"success": False, "error": str(e)}
 
     async def pause_torrent(self, torrent_id: str) -> bool:
         """Pause a torrent."""
         try:
             await self._rpc_call("core.pause_torrent", [[torrent_id]])
@@ -237,13 +230,13 @@
 
     async def get_statistics(self) -> Dict[str, Any]:
         """Get Deluge statistics."""
         try:
             torrents = await self.get_torrents()
-            session_status = await self._rpc_call("core.get_session_status", [[
-                "download_rate", "upload_rate", "dht_nodes"
-            ]])
+            session_status = await self._rpc_call(
+                "core.get_session_status", [["download_rate", "upload_rate", "dht_nodes"]]
+            )
 
             downloading = sum(1 for t in torrents if t.get("state") == "Downloading")
             seeding = sum(1 for t in torrents if t.get("state") == "Seeding")
             paused = sum(1 for t in torrents if t.get("state") == "Paused")
             total_size = sum(t.get("total_size", 0) for t in torrents)
@@ -254,11 +247,11 @@
                 "seeding": seeding,
                 "paused": paused,
                 "download_rate": session_status.get("download_rate", 0) if session_status else 0,
                 "upload_rate": session_status.get("upload_rate", 0) if session_status else 0,
                 "dht_nodes": session_status.get("dht_nodes", 0) if session_status else 0,
-                "total_size_gb": round(total_size / (1024**3), 2)
+                "total_size_gb": round(total_size / (1024**3), 2),
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_torrents": 0,
@@ -266,7 +259,7 @@
                 "seeding": 0,
                 "paused": 0,
                 "download_rate": 0,
                 "upload_rate": 0,
                 "dht_nodes": 0,
-                "total_size_gb": 0
+                "total_size_gb": 0,
             }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/deluge.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/authentik.py	2025-12-31 13:30:51.569007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/authentik.py	2025-12-31 13:41:33.016710+00:00
@@ -15,10 +15,11 @@
 )
 
 
 class UserStatus(Enum):
     """User status in Authentik."""
+
     ACTIVE = "active"
     INACTIVE = "inactive"
 
 
 class AuthentikAdapter(TokenAuthAdapter):
@@ -31,11 +32,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.AUTHENTICATION,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "authentik_token"
@@ -43,11 +44,11 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Authentik token header."""
         return {
             "Authorization": f"Bearer {token}",
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Authentik."""
         start_time = datetime.utcnow()
@@ -71,51 +72,51 @@
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "user_pk": user_data.get("pk"),
                         "username": user_data.get("username"),
-                        "is_superuser": user_data.get("is_superuser", False)
-                    }
+                        "is_superuser": user_data.get("is_superuser", False),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Authentik",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             elif e.response.status_code == 403:
                 return ConnectionTestResult(
                     success=False,
                     message="Access denied - insufficient permissions",
-                    details={"status": "access_denied", "status_code": 403}
+                    details={"status": "access_denied", "status_code": 403},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Authentik service information."""
         try:
@@ -140,13 +141,13 @@
                     "name": user_data.get("name"),
                     "email": user_data.get("email"),
                     "is_superuser": user_data.get("is_superuser", False),
                     "is_staff": user_data.get("is_staff", False),
                     "is_active": user_data.get("is_active", True),
-                    "groups": user_data.get("groups", [])
-                },
-                "system_info": system_data if system_data else {}
+                    "groups": user_data.get("groups", []),
+                },
+                "system_info": system_data if system_data else {},
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Authentik token")
@@ -157,11 +158,11 @@
     async def get_users(
         self,
         page: int = 1,
         page_size: int = 20,
         search: Optional[str] = None,
-        is_active: Optional[bool] = None
+        is_active: Optional[bool] = None,
     ) -> Dict[str, Any]:
         """Get users from Authentik."""
         try:
             params = {"page": str(page), "page_size": str(page_size)}
 
@@ -174,35 +175,37 @@
             data = response.json()
 
             # Process users
             users = []
             for user in data.get("results", []):
-                users.append({
-                    "pk": user.get("pk"),
-                    "username": user.get("username"),
-                    "name": user.get("name"),
-                    "email": user.get("email"),
-                    "is_active": user.get("is_active"),
-                    "is_superuser": user.get("is_superuser"),
-                    "is_staff": user.get("is_staff"),
-                    "date_joined": user.get("date_joined"),
-                    "last_login": user.get("last_login"),
-                    "groups": user.get("groups", []),
-                    "avatar": user.get("avatar"),
-                    "attributes": user.get("attributes", {})
-                })
+                users.append(
+                    {
+                        "pk": user.get("pk"),
+                        "username": user.get("username"),
+                        "name": user.get("name"),
+                        "email": user.get("email"),
+                        "is_active": user.get("is_active"),
+                        "is_superuser": user.get("is_superuser"),
+                        "is_staff": user.get("is_staff"),
+                        "date_joined": user.get("date_joined"),
+                        "last_login": user.get("last_login"),
+                        "groups": user.get("groups", []),
+                        "avatar": user.get("avatar"),
+                        "attributes": user.get("attributes", {}),
+                    }
+                )
 
             return {
                 "users": users,
                 "pagination": {
                     "page": page,
                     "page_size": page_size,
                     "count": data.get("pagination", {}).get("count", len(users)),
                     "total_pages": data.get("pagination", {}).get("num_pages", 1),
                     "next": data.get("pagination", {}).get("next"),
-                    "previous": data.get("pagination", {}).get("previous")
-                }
+                    "previous": data.get("pagination", {}).get("previous"),
+                },
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get users: {e}")
             return {"users": [], "pagination": {"page": page, "page_size": page_size, "count": 0}}
@@ -229,27 +232,29 @@
 
         except Exception as e:
             self.logger.error(f"Failed to create user: {e}")
             return None
 
-    async def update_user(self, user_pk: int, user_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
+    async def update_user(
+        self, user_pk: int, user_data: Dict[str, Any]
+    ) -> Optional[Dict[str, Any]]:
         """Update a user."""
         try:
-            response = await self._make_request("PATCH", f"/api/v3/core/users/{user_pk}/", json=user_data)
+            response = await self._make_request(
+                "PATCH", f"/api/v3/core/users/{user_pk}/", json=user_data
+            )
             return response.json()
 
         except Exception as e:
             self.logger.error(f"Failed to update user {user_pk}: {e}")
             return None
 
     async def deactivate_user(self, user_pk: int) -> bool:
         """Deactivate a user."""
         try:
             response = await self._make_request(
-                "PATCH",
-                f"/api/v3/core/users/{user_pk}/",
-                json={"is_active": False}
+                "PATCH", f"/api/v3/core/users/{user_pk}/", json={"is_active": False}
             )
             return response.status_code == 200
 
         except Exception as e:
             self.logger.error(f"Failed to deactivate user {user_pk}: {e}")
@@ -262,28 +267,30 @@
             response = await self._make_request("GET", "/api/v3/core/groups/", params=params)
             data = response.json()
 
             groups = []
             for group in data.get("results", []):
-                groups.append({
-                    "pk": group.get("pk"),
-                    "name": group.get("name"),
-                    "is_superuser": group.get("is_superuser"),
-                    "parent": group.get("parent"),
-                    "users_obj": group.get("users_obj", []),
-                    "attributes": group.get("attributes", {}),
-                    "num_pk": group.get("num_pk")
-                })
+                groups.append(
+                    {
+                        "pk": group.get("pk"),
+                        "name": group.get("name"),
+                        "is_superuser": group.get("is_superuser"),
+                        "parent": group.get("parent"),
+                        "users_obj": group.get("users_obj", []),
+                        "attributes": group.get("attributes", {}),
+                        "num_pk": group.get("num_pk"),
+                    }
+                )
 
             return {
                 "groups": groups,
                 "pagination": {
                     "page": page,
                     "page_size": page_size,
                     "count": data.get("pagination", {}).get("count", len(groups)),
-                    "total_pages": data.get("pagination", {}).get("num_pages", 1)
-                }
+                    "total_pages": data.get("pagination", {}).get("num_pages", 1),
+                },
             }
 
         except Exception as e:
             self.logger.warning(f"Failed to get groups: {e}")
             return {"groups": [], "pagination": {"page": page, "page_size": page_size, "count": 0}}
@@ -295,44 +302,49 @@
             response = await self._make_request("GET", "/api/v3/core/applications/", params=params)
             data = response.json()
 
             applications = []
             for app in data.get("results", []):
-                applications.append({
-                    "pk": app.get("pk"),
-                    "name": app.get("name"),
-                    "slug": app.get("slug"),
-                    "provider": app.get("provider"),
-                    "provider_obj": app.get("provider_obj", {}),
-                    "launch_url": app.get("launch_url"),
-                    "open_in_new_tab": app.get("open_in_new_tab"),
-                    "meta_icon": app.get("meta_icon"),
-                    "meta_description": app.get("meta_description"),
-                    "policy_engine_mode": app.get("policy_engine_mode"),
-                    "group": app.get("group")
-                })
+                applications.append(
+                    {
+                        "pk": app.get("pk"),
+                        "name": app.get("name"),
+                        "slug": app.get("slug"),
+                        "provider": app.get("provider"),
+                        "provider_obj": app.get("provider_obj", {}),
+                        "launch_url": app.get("launch_url"),
+                        "open_in_new_tab": app.get("open_in_new_tab"),
+                        "meta_icon": app.get("meta_icon"),
+                        "meta_description": app.get("meta_description"),
+                        "policy_engine_mode": app.get("policy_engine_mode"),
+                        "group": app.get("group"),
+                    }
+                )
 
             return {
                 "applications": applications,
                 "pagination": {
                     "page": page,
                     "page_size": page_size,
                     "count": data.get("pagination", {}).get("count", len(applications)),
-                    "total_pages": data.get("pagination", {}).get("num_pages", 1)
-                }
+                    "total_pages": data.get("pagination", {}).get("num_pages", 1),
+                },
             }
 
         except Exception as e:
             self.logger.warning(f"Failed to get applications: {e}")
-            return {"applications": [], "pagination": {"page": page, "page_size": page_size, "count": 0}}
+            return {
+                "applications": [],
+                "pagination": {"page": page, "page_size": page_size, "count": 0},
+            }
 
     async def get_events(
         self,
         page: int = 1,
         page_size: int = 20,
         action: Optional[str] = None,
-        username: Optional[str] = None
+        username: Optional[str] = None,
     ) -> Dict[str, Any]:
         """Get audit events from Authentik."""
         try:
             params = {"page": str(page), "page_size": str(page_size), "ordering": "-created"}
 
@@ -344,30 +356,32 @@
             response = await self._make_request("GET", "/api/v3/events/events/", params=params)
             data = response.json()
 
             events = []
             for event in data.get("results", []):
-                events.append({
-                    "pk": event.get("pk"),
-                    "user": event.get("user", {}),
-                    "action": event.get("action"),
-                    "result": event.get("result"),
-                    "created": event.get("created"),
-                    "client_ip": event.get("client_ip"),
-                    "context": event.get("context", {}),
-                    "app": event.get("app"),
-                    "tenant": event.get("tenant", {})
-                })
+                events.append(
+                    {
+                        "pk": event.get("pk"),
+                        "user": event.get("user", {}),
+                        "action": event.get("action"),
+                        "result": event.get("result"),
+                        "created": event.get("created"),
+                        "client_ip": event.get("client_ip"),
+                        "context": event.get("context", {}),
+                        "app": event.get("app"),
+                        "tenant": event.get("tenant", {}),
+                    }
+                )
 
             return {
                 "events": events,
                 "pagination": {
                     "page": page,
                     "page_size": page_size,
                     "count": data.get("pagination", {}).get("count", len(events)),
-                    "total_pages": data.get("pagination", {}).get("num_pages", 1)
-                }
+                    "total_pages": data.get("pagination", {}).get("num_pages", 1),
+                },
             }
 
         except Exception as e:
             self.logger.warning(f"Failed to get events: {e}")
             return {"events": [], "pagination": {"page": page, "page_size": page_size, "count": 0}}
@@ -383,11 +397,11 @@
                 {
                     "pk": user.get("pk"),
                     "username": user.get("username"),
                     "name": user.get("name"),
                     "email": user.get("email"),
-                    "is_active": user.get("is_active")
+                    "is_active": user.get("is_active"),
                 }
                 for user in data.get("results", [])
             ]
 
         except Exception as e:
@@ -424,13 +438,19 @@
                 "total_groups": total_groups,
                 "total_applications": total_applications,
                 "recent_events_count": len(recent_events),
                 "recent_events": recent_events[:5],
                 "user_activity": {
-                    "logins_today": sum(1 for event in recent_events if event.get("action") == "login" and "today" in event.get("created", "")),
-                    "failed_logins": sum(1 for event in recent_events if event.get("action") == "login_failed")
-                }
+                    "logins_today": sum(
+                        1
+                        for event in recent_events
+                        if event.get("action") == "login" and "today" in event.get("created", "")
+                    ),
+                    "failed_logins": sum(
+                        1 for event in recent_events if event.get("action") == "login_failed"
+                    ),
+                },
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
@@ -439,11 +459,11 @@
                 "inactive_users": 0,
                 "total_groups": 0,
                 "total_applications": 0,
                 "recent_events_count": 0,
                 "recent_events": [],
-                "user_activity": {"logins_today": 0, "failed_logins": 0}
+                "user_activity": {"logins_today": 0, "failed_logins": 0},
             }
 
     def validate_config(self) -> List[str]:
         """Validate Authentik-specific configuration."""
         errors = super().validate_config()
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/authentik.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/jackett.py	2025-12-31 13:30:51.561007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/jackett.py	2025-12-31 13:41:33.058334+00:00
@@ -19,24 +19,19 @@
     def service_type(self) -> str:
         return "jackett"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.API_ACCESS]
 
     @property
     def token_config_key(self) -> str:
         return "jackett_api_key"
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Jackett API key - uses query parameter instead of header."""
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     async def _ensure_client(self):
         """Ensure HTTP client is initialized with cookie support for Jackett."""
         if self._client is None:
             headers = self.get_auth_headers()
@@ -45,99 +40,96 @@
                 base_url=self.base_url,
                 headers=headers,
                 timeout=self.timeout,
                 verify=self.verify_ssl,
                 follow_redirects=True,
-                cookies=httpx.Cookies()  # Enable cookie jar
+                cookies=httpx.Cookies(),  # Enable cookie jar
             )
 
     async def _make_request(
         self,
         method: str,
         endpoint: str,
         params: Optional[Dict[str, Any]] = None,
         json: Optional[Dict[str, Any]] = None,
-        timeout: float = 30.0
+        timeout: float = 30.0,
     ):
         """Override to add API key to query params for Jackett."""
         if params is None:
             params = {}
 
         # Get API key from config
         api_key = self.get_config_value("api_key") or self.service_config.api_key
         if api_key:
             params["apikey"] = api_key
 
-        return await super()._make_request(method, endpoint, params=params, json=json, timeout=timeout)
+        return await super()._make_request(
+            method, endpoint, params=params, json=json, timeout=timeout
+        )
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Jackett using Torznab API (more reliable than management API)."""
         start_time = datetime.utcnow()
 
         try:
             # Use Torznab API which doesn't require cookie auth
             # t=caps returns capabilities of all indexers
             response = await self._make_request(
-                "GET",
-                "/api/v2.0/indexers/all/results/torznab/api",
-                params={"t": "caps"}
+                "GET", "/api/v2.0/indexers/all/results/torznab/api", params={"t": "caps"}
             )
             end_time = datetime.utcnow()
             response_time = int((end_time - start_time).total_seconds() * 1000)
 
             # Response is XML, check if it contains Jackett server info
             content = response.text
-            if "<server title=\"Jackett\"" in content or "<caps>" in content:
+            if '<server title="Jackett"' in content or "<caps>" in content:
                 return ConnectionTestResult(
                     success=True,
                     message="Successfully connected to Jackett (Torznab API)",
                     response_time_ms=response_time,
-                    details={
-                        "status": "connected",
-                        "api_type": "torznab"
-                    }
+                    details={"status": "connected", "api_type": "torznab"},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Jackett",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             # Check if response contains "Cookies required"
             if "Cookies required" in e.response.text:
                 return ConnectionTestResult(
                     success=False,
                     message="Jackett requires cookie authentication - management API not accessible",
-                    details={"status": "cookies_required", "status_code": e.response.status_code}
+                    details={"status": "cookies_required", "status_code": e.response.status_code},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             error_str = str(e)
             # Check for cookies error in exception message
             if "Cookies required" in error_str:
                 return ConnectionTestResult(
                     success=False,
                     message="Jackett requires cookie authentication - try using Torznab API directly",
-                    details={"status": "cookies_required", "error": error_str}
+                    details={"status": "cookies_required", "error": error_str},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {error_str}",
-                details={"status": "connection_failed", "error": error_str}
+                details={"status": "connection_failed", "error": error_str},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Jackett service information."""
         try:
@@ -147,19 +139,14 @@
             return {
                 "service": "jackett",
                 "version": data.get("app_version"),
                 "port": data.get("port"),
                 "blackhole_dir": data.get("blackholedir"),
-                "status": "online"
+                "status": "online",
             }
         except Exception as e:
-            return {
-                "service": "jackett",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+            return {"service": "jackett", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_indexers(self) -> List[Dict[str, Any]]:
         """Get list of configured indexers.
 
         Note: The management API (/api/v2.0/indexers) requires cookie authentication.
@@ -186,11 +173,11 @@
                     "configured": indexer.get("configured", False),
                     "site_link": indexer.get("site_link"),
                     "language": indexer.get("language"),
                     "last_error": indexer.get("last_error"),
                     "potatoenabled": indexer.get("potatoenabled", False),
-                    "caps": indexer.get("caps", [])
+                    "caps": indexer.get("caps", []),
                 }
                 for indexer in indexers
                 if indexer.get("configured", False)
             ]
         except Exception as e:
@@ -202,11 +189,11 @@
         try:
             # Perform a broad search to discover configured indexers
             response = await self._make_request(
                 "GET",
                 "/api/v2.0/indexers/all/results",
-                params={"Query": "test"}  # Simple query to trigger all indexers
+                params={"Query": "test"},  # Simple query to trigger all indexers
             )
             data = response.json()
 
             # Extract unique trackers from results
             trackers = {}
@@ -223,11 +210,11 @@
                         "configured": True,
                         "site_link": None,
                         "language": None,
                         "last_error": None,
                         "potatoenabled": False,
-                        "caps": []
+                        "caps": [],
                     }
 
             return list(trackers.values())
         except Exception as e:
             self.logger.error(f"Failed to get indexers from search: {e}")
@@ -236,22 +223,29 @@
     async def get_configured_indexers(self) -> List[Dict[str, Any]]:
         """Get only configured/enabled indexers."""
         indexers = await self.get_indexers()
         return [i for i in indexers if i.get("configured")]
 
-    async def search(self, query: str, indexers: Optional[List[str]] = None, categories: Optional[List[int]] = None) -> List[Dict[str, Any]]:
+    async def search(
+        self,
+        query: str,
+        indexers: Optional[List[str]] = None,
+        categories: Optional[List[int]] = None,
+    ) -> List[Dict[str, Any]]:
         """Search across indexers."""
         try:
             params = {"Query": query}
 
             if indexers:
                 params["Tracker[]"] = indexers
 
             if categories:
                 params["Category[]"] = categories
 
-            response = await self._make_request("GET", "/api/v2.0/indexers/all/results", params=params)
+            response = await self._make_request(
+                "GET", "/api/v2.0/indexers/all/results", params=params
+            )
             data = response.json()
 
             return [
                 {
                     "title": result.get("Title"),
@@ -263,11 +257,11 @@
                     "tracker": result.get("Tracker"),
                     "seeders": result.get("Seeders"),
                     "peers": result.get("Peers"),
                     "gain": result.get("Gain"),
                     "minimum_ratio": result.get("MinimumRatio"),
-                    "minimum_seed_time": result.get("MinimumSeedTime")
+                    "minimum_seed_time": result.get("MinimumSeedTime"),
                 }
                 for result in data.get("Results", [])[:50]
             ]
         except Exception as e:
             self.logger.error(f"Failed to search: {e}")
@@ -275,21 +269,13 @@
 
     async def test_indexer(self, indexer_id: str) -> Dict[str, Any]:
         """Test a specific indexer."""
         try:
             await self._make_request("GET", f"/api/v2.0/indexers/{indexer_id}/test", timeout=60.0)
-            return {
-                "success": True,
-                "indexer_id": indexer_id,
-                "message": "Indexer test passed"
-            }
-        except Exception as e:
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": str(e)
-            }
+            return {"success": True, "indexer_id": indexer_id, "message": "Indexer test passed"}
+        except Exception as e:
+            return {"success": False, "indexer_id": indexer_id, "error": str(e)}
 
     async def test_all_indexers(self) -> Dict[str, Any]:
         """Test all configured indexers."""
         indexers = await self.get_configured_indexers()
 
@@ -302,11 +288,11 @@
         success_count = sum(1 for r in results if r.get("success"))
         return {
             "total_tested": len(results),
             "success_count": success_count,
             "failed_count": len(results) - success_count,
-            "results": results
+            "results": results,
         }
 
     async def get_statistics(self) -> Dict[str, Any]:
         """Get Jackett statistics."""
         try:
@@ -316,16 +302,16 @@
             return {
                 "total_indexers": len(indexers),
                 "configured_indexers": len(configured),
                 "indexers_with_errors": sum(1 for i in configured if i.get("last_error")),
                 "public_indexers": sum(1 for i in configured if i.get("type") == "public"),
-                "private_indexers": sum(1 for i in configured if i.get("type") == "private")
+                "private_indexers": sum(1 for i in configured if i.get("type") == "private"),
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_indexers": 0,
                 "configured_indexers": 0,
                 "indexers_with_errors": 0,
                 "public_indexers": 0,
-                "private_indexers": 0
+                "private_indexers": 0,
             }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/jackett.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/ollama.py	2025-12-31 13:30:51.551007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/ollama.py	2025-12-31 13:41:33.105769+00:00
@@ -30,20 +30,15 @@
     def service_type(self) -> str:
         return "ollama"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.API_ACCESS]
 
     def get_auth_headers(self) -> Dict[str, str]:
         """Ollama doesn't require authentication headers."""
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     def validate_config(self) -> List[str]:
         """Validate Ollama configuration."""
         errors = []
         if not self.service_config.base_url:
@@ -78,46 +73,43 @@
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "version": data.get("version"),
                         "model_count": model_count,
-                        "models": models
-                    }
+                        "models": models,
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Ollama",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Ollama service information."""
-        info = {
-            "service_type": self.service_type,
-            "base_url": self.base_url
-        }
+        info = {"service_type": self.service_type, "base_url": self.base_url}
 
         try:
             # Get version
             version_response = await self._safe_request("GET", "/api/version")
             if version_response:
@@ -130,11 +122,11 @@
                 info["models"] = [
                     {
                         "name": m.get("name"),
                         "size": m.get("size", 0),
                         "modified_at": m.get("modified_at"),
-                        "details": m.get("details", {})
+                        "details": m.get("details", {}),
                     }
                     for m in models
                 ]
                 info["model_count"] = len(models)
                 info["total_size"] = sum(m.get("size", 0) for m in models)
@@ -151,15 +143,11 @@
 
         return info
 
     async def get_statistics(self) -> Dict[str, Any]:
         """Get Ollama statistics."""
-        stats = {
-            "models": [],
-            "running_models": [],
-            "total_size_bytes": 0
-        }
+        stats = {"models": [], "running_models": [], "total_size_bytes": 0}
 
         try:
             # Get models
             models_response = await self._safe_request("GET", "/api/tags")
             if models_response and "models" in models_response:
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/audiobookshelf.py	2025-12-31 13:30:51.512007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/audiobookshelf.py	2025-12-31 13:41:33.105855+00:00
@@ -25,11 +25,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MEDIA_CONTENT,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "audiobookshelf_api_token"
@@ -37,46 +37,37 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Audiobookshelf Bearer token header."""
         return {
             "Authorization": f"Bearer {token}",
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     def _get_auth_header(self) -> Dict[str, str]:
         """Get auth header with Bearer token."""
         # Try API token from service_config.api_key first, then config
         api_token = self.service_config.api_key or self.get_config_value("api_key")
         if api_token:
             return self._format_token_header(api_token)
 
         # No auth configured
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     async def _make_request(
         self,
         method: str,
         endpoint: str,
         params: Optional[Dict[str, Any]] = None,
         json: Optional[Dict[str, Any]] = None,
-        timeout: float = 30.0
+        timeout: float = 30.0,
     ):
         """Make HTTP request to Audiobookshelf API."""
         url = f"{self.base_url.rstrip('/')}{endpoint}"
         headers = self._get_auth_header()
 
         async with httpx.AsyncClient(timeout=timeout) as client:
-            response = await client.request(
-                method,
-                url,
-                params=params,
-                json=json,
-                headers=headers
-            )
+            response = await client.request(method, url, params=params, json=json, headers=headers)
             response.raise_for_status()
             return response
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Audiobookshelf."""
@@ -102,47 +93,47 @@
                         response_time_ms=response_time,
                         details={
                             "status": "connected",
                             "user": me_data.get("username"),
                             "user_type": me_data.get("type"),
-                            "is_active": me_data.get("isActive", False)
-                        }
+                            "is_active": me_data.get("isActive", False),
+                        },
                     )
                 except httpx.HTTPStatusError as e:
                     if e.response.status_code == 401:
                         return ConnectionTestResult(
                             success=False,
                             message="Server reachable but authentication failed - check API token",
                             response_time_ms=response_time,
-                            details={"status": "auth_failed", "status_code": 401}
+                            details={"status": "auth_failed", "status_code": 401},
                         )
                     raise
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Audiobookshelf",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Audiobookshelf service information."""
         try:
@@ -159,18 +150,18 @@
                 "version": status.get("serverVersion", "unknown"),
                 "user": me.get("username"),
                 "user_type": me.get("type"),
                 "is_admin": me.get("type") == "root" or me.get("type") == "admin",
                 "auth_methods": status.get("authMethods", []),
-                "status": "online"
+                "status": "online",
             }
         except Exception as e:
             return {
                 "service": "audiobookshelf",
                 "version": "unknown",
                 "status": "error",
-                "error": str(e)
+                "error": str(e),
             }
 
     async def get_libraries(self) -> List[Dict[str, Any]]:
         """Get list of libraries."""
         try:
@@ -186,12 +177,12 @@
                     "folders": [f.get("fullPath") for f in lib.get("folders", [])],
                     "icon": lib.get("icon"),
                     "provider": lib.get("provider"),
                     "settings": {
                         "cover_aspect_ratio": lib.get("settings", {}).get("coverAspectRatio"),
-                        "disable_watcher": lib.get("settings", {}).get("disableWatcher", False)
-                    }
+                        "disable_watcher": lib.get("settings", {}).get("disableWatcher", False),
+                    },
                 }
                 for lib in libraries
             ]
         except Exception as e:
             self.logger.error(f"Failed to get libraries: {e}")
@@ -201,26 +192,20 @@
         self,
         library_id: str,
         limit: int = 50,
         page: int = 0,
         sort: str = "media.metadata.title",
-        filter_type: Optional[str] = None
+        filter_type: Optional[str] = None,
     ) -> Dict[str, Any]:
         """Get items from a library."""
         try:
-            params = {
-                "limit": limit,
-                "page": page,
-                "sort": sort
-            }
+            params = {"limit": limit, "page": page, "sort": sort}
             if filter_type:
                 params["filter"] = filter_type
 
             response = await self._make_request(
-                "GET",
-                f"/api/libraries/{library_id}/items",
-                params=params
+                "GET", f"/api/libraries/{library_id}/items", params=params
             )
             data = response.json()
 
             return {
                 "total": data.get("total", 0),
@@ -235,14 +220,14 @@
                         "series": item.get("media", {}).get("metadata", {}).get("seriesName"),
                         "duration": item.get("media", {}).get("duration", 0),
                         "num_chapters": len(item.get("media", {}).get("chapters", [])),
                         "num_audio_files": item.get("media", {}).get("numAudioFiles", 0),
                         "added_at": item.get("addedAt"),
-                        "updated_at": item.get("updatedAt")
+                        "updated_at": item.get("updatedAt"),
                     }
                     for item in data.get("results", [])
-                ]
+                ],
             }
         except Exception as e:
             self.logger.error(f"Failed to get library items: {e}")
             return {"total": 0, "page": 0, "items_per_page": limit, "items": []}
 
@@ -277,67 +262,73 @@
                 "chapters": [
                     {
                         "id": ch.get("id"),
                         "title": ch.get("title"),
                         "start": ch.get("start"),
-                        "end": ch.get("end")
+                        "end": ch.get("end"),
                     }
                     for ch in media.get("chapters", [])
                 ],
                 "added_at": item.get("addedAt"),
-                "updated_at": item.get("updatedAt")
+                "updated_at": item.get("updatedAt"),
             }
         except Exception as e:
             self.logger.error(f"Failed to get item: {e}")
             return None
 
     async def search(self, library_id: str, query: str, limit: int = 25) -> Dict[str, Any]:
         """Search for items in a library."""
         try:
             response = await self._make_request(
-                "GET",
-                f"/api/libraries/{library_id}/search",
-                params={"q": query, "limit": limit}
+                "GET", f"/api/libraries/{library_id}/search", params={"q": query, "limit": limit}
             )
             data = response.json()
 
             return {
                 "book": [
                     {
                         "id": item.get("libraryItem", {}).get("id"),
-                        "title": item.get("libraryItem", {}).get("media", {}).get("metadata", {}).get("title"),
-                        "author": item.get("libraryItem", {}).get("media", {}).get("metadata", {}).get("authorName"),
+                        "title": item.get("libraryItem", {})
+                        .get("media", {})
+                        .get("metadata", {})
+                        .get("title"),
+                        "author": item.get("libraryItem", {})
+                        .get("media", {})
+                        .get("metadata", {})
+                        .get("authorName"),
                         "match_key": item.get("matchKey"),
-                        "match_text": item.get("matchText")
+                        "match_text": item.get("matchText"),
                     }
                     for item in data.get("book", [])
                 ],
                 "podcast": [
                     {
                         "id": item.get("libraryItem", {}).get("id"),
-                        "title": item.get("libraryItem", {}).get("media", {}).get("metadata", {}).get("title"),
-                        "author": item.get("libraryItem", {}).get("media", {}).get("metadata", {}).get("author"),
+                        "title": item.get("libraryItem", {})
+                        .get("media", {})
+                        .get("metadata", {})
+                        .get("title"),
+                        "author": item.get("libraryItem", {})
+                        .get("media", {})
+                        .get("metadata", {})
+                        .get("author"),
                         "match_key": item.get("matchKey"),
-                        "match_text": item.get("matchText")
+                        "match_text": item.get("matchText"),
                     }
                     for item in data.get("podcast", [])
                 ],
                 "authors": [
-                    {
-                        "id": a.get("id"),
-                        "name": a.get("name")
-                    }
-                    for a in data.get("authors", [])
+                    {"id": a.get("id"), "name": a.get("name")} for a in data.get("authors", [])
                 ],
                 "series": [
                     {
                         "id": s.get("series", {}).get("id"),
                         "name": s.get("series", {}).get("name"),
-                        "num_books": len(s.get("books", []))
+                        "num_books": len(s.get("books", [])),
                     }
                     for s in data.get("series", [])
-                ]
+                ],
             }
         except Exception as e:
             self.logger.error(f"Failed to search: {e}")
             return {"book": [], "podcast": [], "authors": [], "series": []}
 
@@ -356,22 +347,26 @@
                     "type": user.get("type"),  # "root", "admin", "user", "guest"
                     "is_active": user.get("isActive", False),
                     "is_locked": user.get("isLocked", False),
                     "created_at": user.get("createdAt"),
                     "libraries_allowed": user.get("librariesAccessible", []),
-                    "permissions": user.get("permissions", {})
+                    "permissions": user.get("permissions", {}),
                 }
                 for user in users
             ]
         except Exception as e:
             self.logger.error(f"Failed to get users: {e}")
             return []
 
     async def get_listening_sessions(self, user_id: Optional[str] = None) -> List[Dict[str, Any]]:
         """Get listening sessions."""
         try:
-            endpoint = f"/api/users/{user_id}/listening-sessions" if user_id else "/api/me/listening-sessions"
+            endpoint = (
+                f"/api/users/{user_id}/listening-sessions"
+                if user_id
+                else "/api/me/listening-sessions"
+            )
             response = await self._make_request("GET", endpoint)
             data = response.json()
             sessions = data.get("sessions", [])
 
             return [
@@ -383,46 +378,50 @@
                     "display_author": session.get("displayAuthor"),
                     "duration": session.get("duration"),
                     "play_method": session.get("playMethod"),
                     "device_info": session.get("deviceInfo", {}),
                     "started_at": session.get("startedAt"),
-                    "updated_at": session.get("updatedAt")
+                    "updated_at": session.get("updatedAt"),
                 }
                 for session in sessions
             ]
         except Exception as e:
             self.logger.error(f"Failed to get listening sessions: {e}")
             return []
 
     async def get_listening_stats(self, user_id: Optional[str] = None) -> Dict[str, Any]:
         """Get listening statistics for a user."""
         try:
-            endpoint = f"/api/users/{user_id}/listening-stats" if user_id else "/api/me/listening-stats"
+            endpoint = (
+                f"/api/users/{user_id}/listening-stats" if user_id else "/api/me/listening-stats"
+            )
             response = await self._make_request("GET", endpoint)
             data = response.json()
 
             return {
                 "total_time": data.get("totalTime", 0),
                 "items": [
                     {
                         "id": item.get("id"),
                         "media_metadata": item.get("mediaMetadata", {}),
                         "min_since_update": item.get("minSinceUpdate"),
-                        "recently_listened": item.get("recentlyListened")
+                        "recently_listened": item.get("recentlyListened"),
                     }
                     for item in data.get("items", [])
                 ],
                 "days": data.get("days", {}),
                 "day_of_week": data.get("dayOfWeek", {}),
                 "today": data.get("today", 0),
-                "recent_sessions": data.get("recentSessions", [])
+                "recent_sessions": data.get("recentSessions", []),
             }
         except Exception as e:
             self.logger.error(f"Failed to get listening stats: {e}")
             return {"total_time": 0, "items": [], "days": {}, "day_of_week": {}, "today": 0}
 
-    async def get_media_progress(self, library_item_id: str, episode_id: Optional[str] = None) -> Optional[Dict[str, Any]]:
+    async def get_media_progress(
+        self, library_item_id: str, episode_id: Optional[str] = None
+    ) -> Optional[Dict[str, Any]]:
         """Get media progress for a library item."""
         try:
             if episode_id:
                 endpoint = f"/api/me/progress/{library_item_id}/{episode_id}"
             else:
@@ -440,11 +439,11 @@
                 "current_time": progress.get("currentTime", 0),
                 "is_finished": progress.get("isFinished", False),
                 "hide_from_continue_listening": progress.get("hideFromContinueListening", False),
                 "started_at": progress.get("startedAt"),
                 "finished_at": progress.get("finishedAt"),
-                "last_update": progress.get("lastUpdate")
+                "last_update": progress.get("lastUpdate"),
             }
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 404:
                 return None  # No progress for this item
             raise
@@ -477,17 +476,17 @@
                 "total_libraries": len(libraries),
                 "total_books": total_books,
                 "total_podcasts": total_podcasts,
                 "total_duration_hours": round(total_duration / 3600, 2),
                 "listening_time_hours": round(listening_stats.get("total_time", 0) / 3600, 2),
-                "listened_today_hours": round(listening_stats.get("today", 0) / 3600, 2)
+                "listened_today_hours": round(listening_stats.get("today", 0) / 3600, 2),
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_libraries": 0,
                 "total_books": 0,
                 "total_podcasts": 0,
                 "total_duration_hours": 0,
                 "listening_time_hours": 0,
-                "listened_today_hours": 0
-            }
+                "listened_today_hours": 0,
+            }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/ollama.py
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/audiobookshelf.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/komga.py	2025-12-31 13:30:51.475007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/komga.py	2025-12-31 13:41:33.144139+00:00
@@ -26,11 +26,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MEDIA_CONTENT,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "komga_api_key"
@@ -38,58 +38,57 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Komga API key header."""
         return {
             "X-API-Key": token,
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     def _get_auth_header(self) -> Dict[str, str]:
         """Get auth header - tries API key first, then falls back to basic auth."""
         # Try API key first - check service_config.api_key first, then config
         api_key = self.service_config.api_key or self.get_config_value("api_key")
         if api_key:
             return self._format_token_header(api_key)
 
         # Fall back to basic auth
-        username = getattr(self.service_config, 'username', None) or self.get_config_value("username") or ""
-        password = getattr(self.service_config, 'password', None) or self.get_config_value("password") or ""
+        username = (
+            getattr(self.service_config, "username", None)
+            or self.get_config_value("username")
+            or ""
+        )
+        password = (
+            getattr(self.service_config, "password", None)
+            or self.get_config_value("password")
+            or ""
+        )
 
         if username and password:
             credentials = base64.b64encode(f"{username}:{password}".encode()).decode()
             return {
                 "Authorization": f"Basic {credentials}",
                 "Content-Type": "application/json",
-                "Accept": "application/json"
+                "Accept": "application/json",
             }
 
         # No auth configured
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     async def _make_request(
         self,
         method: str,
         endpoint: str,
         params: Optional[Dict[str, Any]] = None,
         json: Optional[Dict[str, Any]] = None,
-        timeout: float = 30.0
+        timeout: float = 30.0,
     ):
         """Make HTTP request to Komga API."""
         url = f"{self.base_url.rstrip('/')}{endpoint}"
         headers = self._get_auth_header()
 
         async with httpx.AsyncClient(timeout=timeout) as client:
-            response = await client.request(
-                method,
-                url,
-                params=params,
-                json=json,
-                headers=headers
-            )
+            response = await client.request(method, url, params=params, json=json, headers=headers)
             response.raise_for_status()
             return response
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Komga."""
@@ -108,38 +107,38 @@
                     message="Successfully connected to Komga",
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "user": data.get("email"),
-                        "roles": data.get("roles", [])
-                    }
+                        "roles": data.get("roles", []),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Komga",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key or credentials",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Komga service information."""
         try:
@@ -154,19 +153,14 @@
             return {
                 "service": "komga",
                 "version": info.get("build", {}).get("version", "unknown"),
                 "user": user.get("email"),
                 "is_admin": "ADMIN" in user.get("roles", []),
-                "status": "online"
-            }
-        except Exception as e:
-            return {
-                "service": "komga",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+                "status": "online",
+            }
+        except Exception as e:
+            return {"service": "komga", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_libraries(self) -> List[Dict[str, Any]]:
         """Get list of libraries."""
         try:
             response = await self._make_request("GET", "/api/v1/libraries")
@@ -175,19 +169,21 @@
             return [
                 {
                     "id": lib.get("id"),
                     "name": lib.get("name"),
                     "root": lib.get("root"),
-                    "unavailable_date": lib.get("unavailableDate")
+                    "unavailable_date": lib.get("unavailableDate"),
                 }
                 for lib in libraries
             ]
         except Exception as e:
             self.logger.error(f"Failed to get libraries: {e}")
             return []
 
-    async def get_series(self, library_id: Optional[str] = None, limit: int = 50) -> List[Dict[str, Any]]:
+    async def get_series(
+        self, library_id: Optional[str] = None, limit: int = 50
+    ) -> List[Dict[str, Any]]:
         """Get list of series."""
         try:
             params = {"size": limit, "sort": "metadata.titleSort,asc"}
             if library_id:
                 params["library_id"] = library_id
@@ -203,19 +199,21 @@
                     "books_count": series.get("booksCount", 0),
                     "books_read_count": series.get("booksReadCount", 0),
                     "books_unread_count": series.get("booksUnreadCount", 0),
                     "status": series.get("metadata", {}).get("status"),
                     "publisher": series.get("metadata", {}).get("publisher"),
-                    "genres": series.get("metadata", {}).get("genres", [])
+                    "genres": series.get("metadata", {}).get("genres", []),
                 }
                 for series in data.get("content", [])
             ]
         except Exception as e:
             self.logger.error(f"Failed to get series: {e}")
             return []
 
-    async def get_books(self, series_id: Optional[str] = None, limit: int = 50) -> List[Dict[str, Any]]:
+    async def get_books(
+        self, series_id: Optional[str] = None, limit: int = 50
+    ) -> List[Dict[str, Any]]:
         """Get list of books."""
         try:
             endpoint = f"/api/v1/series/{series_id}/books" if series_id else "/api/v1/books"
             params = {"size": limit}
 
@@ -229,11 +227,11 @@
                     "series_id": book.get("seriesId"),
                     "number": book.get("metadata", {}).get("number"),
                     "pages_count": book.get("media", {}).get("pagesCount", 0),
                     "size_bytes": book.get("sizeBytes", 0),
                     "read_progress": book.get("readProgress", {}).get("page", 0),
-                    "completed": book.get("readProgress", {}).get("completed", False)
+                    "completed": book.get("readProgress", {}).get("completed", False),
                 }
                 for book in data.get("content", [])
             ]
         except Exception as e:
             self.logger.error(f"Failed to get books: {e}")
@@ -248,22 +246,22 @@
             return {
                 "series": [
                     {
                         "id": s.get("id"),
                         "name": s.get("metadata", {}).get("title", s.get("name")),
-                        "books_count": s.get("booksCount", 0)
+                        "books_count": s.get("booksCount", 0),
                     }
                     for s in data.get("series", {}).get("content", [])[:10]
                 ],
                 "books": [
                     {
                         "id": b.get("id"),
                         "name": b.get("metadata", {}).get("title", b.get("name")),
-                        "series_id": b.get("seriesId")
+                        "series_id": b.get("seriesId"),
                     }
                     for b in data.get("books", {}).get("content", [])[:10]
-                ]
+                ],
             }
         except Exception as e:
             self.logger.error(f"Failed to search: {e}")
             return {"series": [], "books": []}
 
@@ -278,11 +276,11 @@
                     "id": user.get("id"),
                     "email": user.get("email"),
                     "username": user.get("email"),
                     "name": user.get("email").split("@")[0] if user.get("email") else "Unknown",
                     "roles": user.get("roles", []),
-                    "shared_libraries_ids": user.get("sharedLibrariesIds", [])
+                    "shared_libraries_ids": user.get("sharedLibrariesIds", []),
                 }
                 for user in users
             ]
         except Exception as e:
             self.logger.error(f"Failed to get users: {e}")
@@ -302,17 +300,19 @@
                 "total_libraries": len(libraries),
                 "total_series": len(series),
                 "total_books": total_books,
                 "books_read": total_read,
                 "books_unread": total_unread,
-                "completion_rate": round(total_read / total_books * 100, 2) if total_books > 0 else 0
+                "completion_rate": round(total_read / total_books * 100, 2)
+                if total_books > 0
+                else 0,
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_libraries": 0,
                 "total_series": 0,
                 "total_books": 0,
                 "books_read": 0,
                 "books_unread": 0,
-                "completion_rate": 0
-            }
+                "completion_rate": 0,
+            }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/komga.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/openwebui.py	2025-12-31 13:30:51.477007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/openwebui.py	2025-12-31 13:41:33.247799+00:00
@@ -38,11 +38,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.USER_MANAGEMENT,
             ServiceCapability.API_ACCESS,
-            ServiceCapability.AUTHENTICATION
+            ServiceCapability.AUTHENTICATION,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "openwebui_token"
@@ -50,11 +50,11 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Open WebUI token header."""
         return {
             "Authorization": f"Bearer {token}",
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Open WebUI."""
         start_time = datetime.utcnow()
@@ -76,51 +76,51 @@
                     details={
                         "status": "connected",
                         "user_id": data.get("id"),
                         "email": data.get("email"),
                         "name": data.get("name"),
-                        "role": data.get("role")
-                    }
+                        "role": data.get("role"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Open WebUI",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             elif e.response.status_code == 403:
                 return ConnectionTestResult(
                     success=False,
                     message="Access denied - insufficient permissions",
-                    details={"status": "access_denied", "status_code": 403}
+                    details={"status": "access_denied", "status_code": 403},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Open WebUI service information."""
         try:
@@ -140,28 +140,26 @@
                 "current_user": {
                     "id": user_data.get("id"),
                     "email": user_data.get("email"),
                     "name": user_data.get("name"),
                     "role": user_data.get("role"),
-                    "profile_image_url": user_data.get("profile_image_url")
+                    "profile_image_url": user_data.get("profile_image_url"),
                 },
-                "models_available": len(models_data) if models_data and isinstance(models_data, list) else 0,
-                "config": config_data if config_data else {}
+                "models_available": len(models_data)
+                if models_data and isinstance(models_data, list)
+                else 0,
+                "config": config_data if config_data else {},
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Open WebUI token")
             raise AdapterError(f"HTTP error: {e.response.status_code}")
         except Exception as e:
             raise AdapterError(f"Failed to get service info: {str(e)}")
 
-    async def get_users(
-        self,
-        skip: int = 0,
-        limit: int = 50
-    ) -> Dict[str, Any]:
+    async def get_users(self, skip: int = 0, limit: int = 50) -> Dict[str, Any]:
         """
         Get users from Open WebUI.
 
         Note: Requires admin privileges.
         """
@@ -172,34 +170,33 @@
 
             # Normalize user data
             users = []
             # Handle both list and dict response formats
             raw_users = users_data
-            if isinstance(users_data, dict) and 'users' in users_data:
-                raw_users = users_data['users']
+            if isinstance(users_data, dict) and "users" in users_data:
+                raw_users = users_data["users"]
 
             if isinstance(raw_users, list):
                 for user in raw_users:
-                    users.append({
-                        "id": user.get("id"),
-                        "email": user.get("email"),
-                        "name": user.get("name"),
-                        "username": user.get("email", "").split("@")[0] if user.get("email") else user.get("name"),
-                        "role": user.get("role"),
-                        "profile_image_url": user.get("profile_image_url"),
-                        "created_at": user.get("created_at"),
-                        "last_active_at": user.get("last_active_at"),
-                        # Keep raw data for reference
-                        "_raw": user
-                    })
-
-            return {
-                "users": users,
-                "count": len(users),
-                "skip": skip,
-                "limit": limit
-            }
+                    users.append(
+                        {
+                            "id": user.get("id"),
+                            "email": user.get("email"),
+                            "name": user.get("name"),
+                            "username": user.get("email", "").split("@")[0]
+                            if user.get("email")
+                            else user.get("name"),
+                            "role": user.get("role"),
+                            "profile_image_url": user.get("profile_image_url"),
+                            "created_at": user.get("created_at"),
+                            "last_active_at": user.get("last_active_at"),
+                            # Keep raw data for reference
+                            "_raw": user,
+                        }
+                    )
+
+            return {"users": users, "count": len(users), "skip": skip, "limit": limit}
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 403:
                 self.logger.warning("Access denied - admin privileges required to list users")
                 return {"users": [], "count": 0, "error": "Admin privileges required"}
@@ -216,15 +213,17 @@
 
             return {
                 "id": user.get("id"),
                 "email": user.get("email"),
                 "name": user.get("name"),
-                "username": user.get("email", "").split("@")[0] if user.get("email") else user.get("name"),
+                "username": user.get("email", "").split("@")[0]
+                if user.get("email")
+                else user.get("name"),
                 "role": user.get("role"),
                 "profile_image_url": user.get("profile_image_url"),
                 "created_at": user.get("created_at"),
-                "last_active_at": user.get("last_active_at")
+                "last_active_at": user.get("last_active_at"),
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 404:
                 return None
@@ -242,11 +241,11 @@
             return {
                 "id": user.get("id"),
                 "email": user.get("email"),
                 "name": user.get("name"),
                 "role": user.get("role"),
-                "profile_image_url": user.get("profile_image_url")
+                "profile_image_url": user.get("profile_image_url"),
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get current user: {e}")
             raise
@@ -262,59 +261,52 @@
                     {
                         "id": model.get("id"),
                         "name": model.get("name"),
                         "owned_by": model.get("owned_by"),
                         "created": model.get("created"),
-                        "object": model.get("object")
+                        "object": model.get("object"),
                     }
                     for model in models_data
                 ]
             elif isinstance(models_data, dict) and "data" in models_data:
                 return [
                     {
                         "id": model.get("id"),
                         "name": model.get("name", model.get("id")),
                         "owned_by": model.get("owned_by"),
                         "created": model.get("created"),
-                        "object": model.get("object")
+                        "object": model.get("object"),
                     }
                     for model in models_data.get("data", [])
                 ]
             return []
 
         except Exception as e:
             self.logger.warning(f"Failed to get models: {e}")
             return []
 
-    async def get_chats(
-        self,
-        skip: int = 0,
-        limit: int = 50
-    ) -> Dict[str, Any]:
+    async def get_chats(self, skip: int = 0, limit: int = 50) -> Dict[str, Any]:
         """Get chat history for current user."""
         try:
             params = {"skip": str(skip), "limit": str(limit)}
             response = await self._make_request("GET", "/api/v1/chats/", params=params)
             chats_data = response.json()
 
             chats = []
             if isinstance(chats_data, list):
                 for chat in chats_data:
-                    chats.append({
-                        "id": chat.get("id"),
-                        "title": chat.get("title"),
-                        "created_at": chat.get("created_at"),
-                        "updated_at": chat.get("updated_at"),
-                        "models": chat.get("models", [])
-                    })
-
-            return {
-                "chats": chats,
-                "count": len(chats),
-                "skip": skip,
-                "limit": limit
-            }
+                    chats.append(
+                        {
+                            "id": chat.get("id"),
+                            "title": chat.get("title"),
+                            "created_at": chat.get("created_at"),
+                            "updated_at": chat.get("updated_at"),
+                            "models": chat.get("models", []),
+                        }
+                    )
+
+            return {"chats": chats, "count": len(chats), "skip": skip, "limit": limit}
 
         except Exception as e:
             self.logger.warning(f"Failed to get chats: {e}")
             return {"chats": [], "count": 0, "error": str(e)}
 
@@ -352,22 +344,22 @@
                 "total_users": total_users,
                 "total_models": len(models),
                 "models": [m.get("id") for m in models[:10]],  # First 10 model IDs
                 "user_chats_count": chats_data.get("count", 0),
                 "version": service_info.get("version", "unknown"),
-                "current_user": service_info.get("current_user", {})
+                "current_user": service_info.get("current_user", {}),
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_users": "N/A",
                 "total_models": 0,
                 "models": [],
                 "user_chats_count": 0,
                 "version": "unknown",
-                "error": str(e)
+                "error": str(e),
             }
 
     async def search_users(self, query: str) -> List[Dict[str, Any]]:
         """Search for users by email or name."""
         try:
@@ -376,11 +368,12 @@
             users_data = await self.get_users(limit=100)
             users = users_data.get("users", [])
 
             query_lower = query.lower()
             matching_users = [
-                user for user in users
+                user
+                for user in users
                 if query_lower in (user.get("email") or "").lower()
                 or query_lower in (user.get("name") or "").lower()
                 or query_lower in (user.get("username") or "").lower()
             ]
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/openwebui.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/prowlarr.py	2025-12-31 13:30:51.543007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/prowlarr.py	2025-12-31 13:41:33.290031+00:00
@@ -19,24 +19,22 @@
     def service_type(self) -> str:
         return "prowlarr"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.API_ACCESS]
 
     @property
     def token_config_key(self) -> str:
         return "prowlarr_api_key"
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Prowlarr API key header."""
         return {
             "X-Api-Key": token,
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Prowlarr."""
         start_time = datetime.utcnow()
@@ -55,38 +53,38 @@
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "version": data.get("version"),
                         "app_name": data.get("appName", "Prowlarr"),
-                        "branch": data.get("branch")
-                    }
+                        "branch": data.get("branch"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Prowlarr",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Prowlarr service information."""
         try:
@@ -97,19 +95,14 @@
                 "service": "prowlarr",
                 "version": data.get("version"),
                 "app_name": data.get("appName", "Prowlarr"),
                 "branch": data.get("branch"),
                 "build_time": data.get("buildTime"),
-                "status": "online"
-            }
-        except Exception as e:
-            return {
-                "service": "prowlarr",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+                "status": "online",
+            }
+        except Exception as e:
+            return {"service": "prowlarr", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_indexers(self) -> List[Dict[str, Any]]:
         """Get list of configured indexers."""
         try:
             response = await self._make_request("GET", "/api/v1/indexer")
@@ -122,11 +115,11 @@
                     "protocol": indexer.get("protocol"),
                     "privacy": indexer.get("privacy"),
                     "enable": indexer.get("enable", False),
                     "priority": indexer.get("priority", 25),
                     "supports_rss": indexer.get("supportsRss", False),
-                    "supports_search": indexer.get("supportsSearch", False)
+                    "supports_search": indexer.get("supportsSearch", False),
                 }
                 for indexer in indexers
             ]
         except Exception as e:
             self.logger.error(f"Failed to get indexers: {e}")
@@ -143,19 +136,21 @@
                     "indexer_id": stat.get("indexerId"),
                     "indexer_name": stat.get("indexerName"),
                     "average_response_time": stat.get("averageResponseTime"),
                     "number_of_queries": stat.get("numberOfQueries"),
                     "number_of_grabs": stat.get("numberOfGrabs"),
-                    "number_of_failures": stat.get("numberOfFailures")
+                    "number_of_failures": stat.get("numberOfFailures"),
                 }
                 for stat in stats.get("indexers", [])
             ]
         except Exception as e:
             self.logger.error(f"Failed to get indexer stats: {e}")
             return []
 
-    async def search(self, query: str, categories: Optional[List[int]] = None, limit: int = 50) -> List[Dict[str, Any]]:
+    async def search(
+        self, query: str, categories: Optional[List[int]] = None, limit: int = 50
+    ) -> List[Dict[str, Any]]:
         """Search across all indexers."""
         try:
             params = {"query": query}
             if categories:
                 params["categories"] = ",".join(map(str, categories))
@@ -171,11 +166,11 @@
                     "size": result.get("size", 0),
                     "age_days": result.get("age", 0),
                     "seeders": result.get("seeders"),
                     "leechers": result.get("leechers"),
                     "categories": result.get("categories", []),
-                    "download_url": result.get("downloadUrl")
+                    "download_url": result.get("downloadUrl"),
                 }
                 for result in results[:limit]
             ]
         except Exception as e:
             self.logger.error(f"Failed to search: {e}")
@@ -191,11 +186,11 @@
                 {
                     "id": app.get("id"),
                     "name": app.get("name"),
                     "sync_level": app.get("syncLevel"),
                     "implementation": app.get("implementation"),
-                    "config_contract": app.get("configContract")
+                    "config_contract": app.get("configContract"),
                 }
                 for app in apps
             ]
         except Exception as e:
             self.logger.error(f"Failed to get applications: {e}")
@@ -218,22 +213,24 @@
                 "enabled_indexers": enabled_indexers,
                 "connected_apps": len(apps),
                 "total_queries": total_queries,
                 "total_grabs": total_grabs,
                 "total_failures": total_failures,
-                "success_rate": round((total_queries - total_failures) / total_queries * 100, 2) if total_queries > 0 else 100
+                "success_rate": round((total_queries - total_failures) / total_queries * 100, 2)
+                if total_queries > 0
+                else 100,
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_indexers": 0,
                 "enabled_indexers": 0,
                 "connected_apps": 0,
                 "total_queries": 0,
                 "total_grabs": 0,
                 "total_failures": 0,
-                "success_rate": 0
+                "success_rate": 0,
             }
 
     async def test_indexer(self, indexer_id: int) -> Dict[str, Any]:
         """Test a specific indexer by ID."""
         try:
@@ -242,21 +239,18 @@
             indexer_config = response.json()
             indexer_name = indexer_config.get("name", f"Indexer {indexer_id}")
 
             # Then test it
             await self._make_request(
-                "POST",
-                "/api/v1/indexer/test",
-                json=indexer_config,
-                timeout=60.0
+                "POST", "/api/v1/indexer/test", json=indexer_config, timeout=60.0
             )
 
             return {
                 "success": True,
                 "indexer_id": indexer_id,
                 "indexer_name": indexer_name,
-                "message": "Indexer test passed"
+                "message": "Indexer test passed",
             }
         except httpx.HTTPStatusError as e:
             error_msg = "Test failed"
             try:
                 error_data = e.response.json()
@@ -265,21 +259,13 @@
                 elif isinstance(error_data, dict):
                     error_msg = error_data.get("message", str(e))
             except Exception:
                 error_msg = str(e)
 
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": error_msg
-            }
-        except Exception as e:
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": str(e)
-            }
+            return {"success": False, "indexer_id": indexer_id, "error": error_msg}
+        except Exception as e:
+            return {"success": False, "indexer_id": indexer_id, "error": str(e)}
 
     async def test_all_indexers(self) -> Dict[str, Any]:
         """Test all enabled indexers."""
         indexers = await self.get_indexers()
         enabled_indexers = [i for i in indexers if i.get("enable")]
@@ -293,7 +279,7 @@
         success_count = sum(1 for r in results if r.get("success"))
         return {
             "total_tested": len(results),
             "success_count": success_count,
             "failed_count": len(results) - success_count,
-            "results": results
+            "results": results,
         }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/prowlarr.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/plex.py	2025-12-31 13:30:51.506007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/plex.py	2025-12-31 13:41:33.331439+00:00
@@ -24,11 +24,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MEDIA_CONTENT,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "plex_token"
@@ -47,14 +47,11 @@
 
         return self._format_token_header(token)
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Plex token header."""
-        return {
-            "X-Plex-Token": token,
-            "Accept": "application/json"
-        }
+        return {"X-Plex-Token": token, "Accept": "application/json"}
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Plex server."""
         start_time = datetime.utcnow()
 
@@ -69,44 +66,44 @@
             if "MediaContainer" in response.text:
                 return ConnectionTestResult(
                     success=True,
                     message="Successfully connected to Plex server",
                     response_time_ms=response_time,
-                    details={"status": "connected", "server_type": "plex"}
+                    details={"status": "connected", "server_type": "plex"},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Plex",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check Plex token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Plex server information."""
         try:
@@ -124,11 +121,11 @@
                 "platform": container.get("platform", "unknown"),
                 "server_name": container.get("friendlyName", "Plex Server"),
                 "machine_identifier": container.get("machineIdentifier"),
                 "updated_at": container.get("updatedAt"),
                 "multiuser": container.get("multiuser", False),
-                "my_plex": container.get("myPlex", False)
+                "my_plex": container.get("myPlex", False),
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Plex token")
@@ -147,20 +144,22 @@
 
             directories = data["MediaContainer"].get("Directory", [])
             libraries = []
 
             for directory in directories:
-                libraries.append({
-                    "key": directory.get("key"),
-                    "title": directory.get("title"),
-                    "type": directory.get("type"),
-                    "agent": directory.get("agent"),
-                    "language": directory.get("language"),
-                    "refreshing": directory.get("refreshing", False),
-                    "created_at": directory.get("createdAt"),
-                    "updated_at": directory.get("updatedAt")
-                })
+                libraries.append(
+                    {
+                        "key": directory.get("key"),
+                        "title": directory.get("title"),
+                        "type": directory.get("type"),
+                        "agent": directory.get("agent"),
+                        "language": directory.get("language"),
+                        "refreshing": directory.get("refreshing", False),
+                        "created_at": directory.get("createdAt"),
+                        "updated_at": directory.get("updatedAt"),
+                    }
+                )
 
             return libraries
 
         except Exception as e:
             self.logger.error(f"Failed to get libraries: {e}")
@@ -178,19 +177,21 @@
 
             accounts = data["MediaContainer"].get("Account", [])
             users = []
 
             for account in accounts:
-                users.append({
-                    "id": account.get("id"),
-                    "name": account.get("name"),
-                    "email": account.get("email"),
-                    "thumb": account.get("thumb"),
-                    "home": account.get("home", False),
-                    "admin": account.get("admin", False),
-                    "guest": account.get("guest", False)
-                })
+                users.append(
+                    {
+                        "id": account.get("id"),
+                        "name": account.get("name"),
+                        "email": account.get("email"),
+                        "thumb": account.get("thumb"),
+                        "home": account.get("home", False),
+                        "admin": account.get("admin", False),
+                        "guest": account.get("guest", False),
+                    }
+                )
 
             return users
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 404:
@@ -215,59 +216,68 @@
 
             for session in sessions:
                 user_info = session.get("User", [{}])[0] if session.get("User") else {}
                 player_info = session.get("Player", {})
 
-                active_sessions.append({
-                    "session_key": session.get("sessionKey"),
-                    "user_id": user_info.get("id"),
-                    "username": user_info.get("title"),
-                    "title": session.get("title"),
-                    "type": session.get("type"),
-                    "state": session.get("Player", {}).get("state"),
-                    "player": player_info.get("title"),
-                    "platform": player_info.get("platform"),
-                    "progress": session.get("viewOffset", 0),
-                    "duration": session.get("duration", 0)
-                })
+                active_sessions.append(
+                    {
+                        "session_key": session.get("sessionKey"),
+                        "user_id": user_info.get("id"),
+                        "username": user_info.get("title"),
+                        "title": session.get("title"),
+                        "type": session.get("type"),
+                        "state": session.get("Player", {}).get("state"),
+                        "player": player_info.get("title"),
+                        "platform": player_info.get("platform"),
+                        "progress": session.get("viewOffset", 0),
+                        "duration": session.get("duration", 0),
+                    }
+                )
 
             return active_sessions
 
         except Exception as e:
             self.logger.warning(f"Failed to get sessions: {e}")
             return []
 
-    async def get_recently_added(self, limit: int = 10, library_name: Optional[str] = None) -> List[Dict[str, Any]]:
+    async def get_recently_added(
+        self, limit: int = 10, library_name: Optional[str] = None
+    ) -> List[Dict[str, Any]]:
         """Get recently added content.
 
         Args:
             limit: Maximum number of items to return
             library_name: Optional library name to filter by (e.g., 'Movies', 'TV Shows')
         """
         try:
             # If library_name is specified, get items from that specific library
             if library_name:
                 libraries = await self.get_libraries()
-                library = next((lib for lib in libraries if lib.get("title", "").lower() == library_name.lower()), None)
+                library = next(
+                    (
+                        lib
+                        for lib in libraries
+                        if lib.get("title", "").lower() == library_name.lower()
+                    ),
+                    None,
+                )
                 if library:
                     response = await self._make_request(
                         "GET",
                         f"/library/sections/{library['key']}/recentlyAdded",
-                        params={"X-Plex-Container-Size": str(limit)}
+                        params={"X-Plex-Container-Size": str(limit)},
                     )
                 else:
                     # Library not found, fall back to global recently added
                     response = await self._make_request(
                         "GET",
                         "/library/recentlyAdded",
-                        params={"X-Plex-Container-Size": str(limit)}
+                        params={"X-Plex-Container-Size": str(limit)},
                     )
             else:
                 response = await self._make_request(
-                    "GET",
-                    "/library/recentlyAdded",
-                    params={"X-Plex-Container-Size": str(limit)}
+                    "GET", "/library/recentlyAdded", params={"X-Plex-Container-Size": str(limit)}
                 )
 
             data = response.json()
 
             if "MediaContainer" not in data:
@@ -275,23 +285,25 @@
 
             metadata = data["MediaContainer"].get("Metadata", [])
             recent_items = []
 
             for item in metadata:
-                recent_items.append({
-                    "key": item.get("key"),
-                    "title": item.get("title"),
-                    "type": item.get("type"),
-                    "year": item.get("year"),
-                    "rating": item.get("rating"),
-                    "duration": item.get("duration"),
-                    "addedAt": item.get("addedAt"),
-                    "updated_at": item.get("updatedAt"),
-                    "thumb": item.get("thumb"),
-                    "art": item.get("art"),
-                    "librarySectionTitle": item.get("librarySectionTitle")
-                })
+                recent_items.append(
+                    {
+                        "key": item.get("key"),
+                        "title": item.get("title"),
+                        "type": item.get("type"),
+                        "year": item.get("year"),
+                        "rating": item.get("rating"),
+                        "duration": item.get("duration"),
+                        "addedAt": item.get("addedAt"),
+                        "updated_at": item.get("updatedAt"),
+                        "thumb": item.get("thumb"),
+                        "art": item.get("art"),
+                        "librarySectionTitle": item.get("librarySectionTitle"),
+                    }
+                )
 
             return recent_items
 
         except Exception as e:
             self.logger.warning(f"Failed to get recently added: {e}")
@@ -299,40 +311,42 @@
 
     async def search_content(self, query: str, limit: int = 20) -> List[Dict[str, Any]]:
         """Search for content in Plex."""
         try:
             response = await self._make_request(
-                "GET",
-                "/search",
-                params={"query": query, "limit": str(limit)}
+                "GET", "/search", params={"query": query, "limit": str(limit)}
             )
             data = response.json()
 
             if "MediaContainer" not in data:
                 return []
 
             metadata = data["MediaContainer"].get("Metadata", [])
             search_results = []
 
             for item in metadata:
-                search_results.append({
-                    "key": item.get("key"),
-                    "title": item.get("title"),
-                    "type": item.get("type"),
-                    "year": item.get("year"),
-                    "score": item.get("score"),
-                    "library_section_title": item.get("librarySectionTitle"),
-                    "thumb": item.get("thumb")
-                })
+                search_results.append(
+                    {
+                        "key": item.get("key"),
+                        "title": item.get("title"),
+                        "type": item.get("type"),
+                        "year": item.get("year"),
+                        "score": item.get("score"),
+                        "library_section_title": item.get("librarySectionTitle"),
+                        "thumb": item.get("thumb"),
+                    }
+                )
 
             return search_results
 
         except Exception as e:
             self.logger.warning(f"Failed to search content: {e}")
             return []
 
-    async def search(self, query: str, media_type: Optional[str] = None, limit: int = 20) -> List[Dict[str, Any]]:
+    async def search(
+        self, query: str, media_type: Optional[str] = None, limit: int = 20
+    ) -> List[Dict[str, Any]]:
         """Search for content in Plex with optional media type filter.
 
         Args:
             query: Search query
             media_type: Optional filter (movie, show, episode, artist, album, track)
@@ -346,11 +360,11 @@
                     "movie": 1,
                     "show": 2,
                     "episode": 4,
                     "artist": 8,
                     "album": 9,
-                    "track": 10
+                    "track": 10,
                 }
                 if media_type in type_map:
                     params["type"] = str(type_map[media_type])
 
             response = await self._make_request("GET", "/search", params=params)
@@ -361,27 +375,29 @@
 
             metadata = data["MediaContainer"].get("Metadata", [])
             search_results = []
 
             for item in metadata:
-                search_results.append({
-                    "key": item.get("key"),
-                    "title": item.get("title"),
-                    "type": item.get("type"),
-                    "year": item.get("year"),
-                    "summary": item.get("summary"),
-                    "rating": item.get("rating"),
-                    "duration": item.get("duration"),
-                    "contentRating": item.get("contentRating"),
-                    "librarySectionTitle": item.get("librarySectionTitle"),
-                    "thumb": item.get("thumb"),
-                    "Genre": [g.get("tag") for g in item.get("Genre", [])],
-                    "Director": [d.get("tag") for d in item.get("Director", [])],
-                    "Role": [r.get("tag") for r in item.get("Role", [])],
-                    "studio": item.get("studio"),
-                    "addedAt": item.get("addedAt")
-                })
+                search_results.append(
+                    {
+                        "key": item.get("key"),
+                        "title": item.get("title"),
+                        "type": item.get("type"),
+                        "year": item.get("year"),
+                        "summary": item.get("summary"),
+                        "rating": item.get("rating"),
+                        "duration": item.get("duration"),
+                        "contentRating": item.get("contentRating"),
+                        "librarySectionTitle": item.get("librarySectionTitle"),
+                        "thumb": item.get("thumb"),
+                        "Genre": [g.get("tag") for g in item.get("Genre", [])],
+                        "Director": [d.get("tag") for d in item.get("Director", [])],
+                        "Role": [r.get("tag") for r in item.get("Role", [])],
+                        "studio": item.get("studio"),
+                        "addedAt": item.get("addedAt"),
+                    }
+                )
 
             return search_results
 
         except Exception as e:
             self.logger.warning(f"Failed to search: {e}")
@@ -393,35 +409,35 @@
         Args:
             limit: Maximum items to return
         """
         try:
             response = await self._make_request(
-                "GET",
-                "/library/onDeck",
-                params={"X-Plex-Container-Size": str(limit)}
+                "GET", "/library/onDeck", params={"X-Plex-Container-Size": str(limit)}
             )
             data = response.json()
 
             if "MediaContainer" not in data:
                 return []
 
             metadata = data["MediaContainer"].get("Metadata", [])
             on_deck_items = []
 
             for item in metadata:
-                on_deck_items.append({
-                    "key": item.get("key"),
-                    "title": item.get("title"),
-                    "grandparentTitle": item.get("grandparentTitle"),  # Show name for episodes
-                    "type": item.get("type"),
-                    "year": item.get("year"),
-                    "viewOffset": item.get("viewOffset", 0),
-                    "duration": item.get("duration", 0),
-                    "thumb": item.get("thumb"),
-                    "art": item.get("art"),
-                    "librarySectionTitle": item.get("librarySectionTitle")
-                })
+                on_deck_items.append(
+                    {
+                        "key": item.get("key"),
+                        "title": item.get("title"),
+                        "grandparentTitle": item.get("grandparentTitle"),  # Show name for episodes
+                        "type": item.get("type"),
+                        "year": item.get("year"),
+                        "viewOffset": item.get("viewOffset", 0),
+                        "duration": item.get("duration", 0),
+                        "thumb": item.get("thumb"),
+                        "art": item.get("art"),
+                        "librarySectionTitle": item.get("librarySectionTitle"),
+                    }
+                )
 
             return on_deck_items
 
         except Exception as e:
             self.logger.warning(f"Failed to get on deck: {e}")
@@ -455,11 +471,11 @@
                     "summary": setting.get("summary"),
                     "type": setting.get("type"),
                     "default": setting.get("default"),
                     "value": setting.get("value"),
                     "hidden": setting.get("hidden", False),
-                    "advanced": setting.get("advanced", False)
+                    "advanced": setting.get("advanced", False),
                 }
 
             return preferences
 
         except Exception as e:
@@ -486,17 +502,17 @@
                 "libraries_count": len(libraries),
                 "active_sessions": len(sessions),
                 "recent_additions": len(recent),
                 "libraries": libraries,
                 "sessions": sessions[:5],  # Limit for overview
-                "recent_items": recent
+                "recent_items": recent,
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "error": str(e),
                 "server_info": {},
                 "libraries_count": 0,
                 "active_sessions": 0,
-                "recent_additions": 0
+                "recent_additions": 0,
             }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/plex.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/overseerr.py	2025-12-31 13:30:51.550007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/overseerr.py	2025-12-31 13:41:33.369153+00:00
@@ -15,18 +15,20 @@
 )
 
 
 class RequestStatus(Enum):
     """Overseerr request status."""
+
     PENDING = 1
     APPROVED = 2
     DECLINED = 3
     AVAILABLE = 4
 
 
 class MediaType(Enum):
     """Media type."""
+
     MOVIE = "movie"
     TV = "tv"
 
 
 class OverseerrAdapter(TokenAuthAdapter):
@@ -39,11 +41,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MEDIA_CONTENT,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "overseerr_api_key"
@@ -51,11 +53,11 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Overseerr API key header."""
         return {
             "X-Api-Key": token,
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Overseerr."""
         start_time = datetime.utcnow()
@@ -75,51 +77,51 @@
                     message="Successfully connected to Overseerr",
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "version": data.get("version"),
-                        "commit_tag": data.get("commitTag")
-                    }
+                        "commit_tag": data.get("commitTag"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Overseerr",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             elif e.response.status_code == 403:
                 return ConnectionTestResult(
                     success=False,
                     message="Access denied - insufficient permissions",
-                    details={"status": "access_denied", "status_code": 403}
+                    details={"status": "access_denied", "status_code": 403},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Overseerr service information."""
         try:
@@ -134,13 +136,15 @@
                 "service": "overseerr",
                 "version": status_data.get("version"),
                 "commit_tag": status_data.get("commitTag"),
                 "build_id": status_data.get("buildId"),
                 "repository": status_data.get("repository"),
-                "application_title": settings_data.get("applicationTitle", "Overseerr") if settings_data else "Overseerr",
+                "application_title": settings_data.get("applicationTitle", "Overseerr")
+                if settings_data
+                else "Overseerr",
                 "application_url": settings_data.get("applicationUrl") if settings_data else None,
-                "trust_proxy": settings_data.get("trustProxy", False) if settings_data else False
+                "trust_proxy": settings_data.get("trustProxy", False) if settings_data else False,
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Overseerr API key")
@@ -162,14 +166,11 @@
         except Exception as e:
             self.logger.debug(f"Failed to get media title for {media_type}/{tmdb_id}: {e}")
         return None
 
     async def get_requests(
-        self,
-        take: int = 20,
-        skip: int = 0,
-        status: Optional[RequestStatus] = None
+        self, take: int = 20, skip: int = 0, status: Optional[RequestStatus] = None
     ) -> Dict[str, Any]:
         """Get media requests."""
         try:
             params = {"take": str(take), "skip": str(skip)}
             if status:
@@ -197,21 +198,21 @@
                     "updated_at": request.get("updatedAt"),
                     "requested_by": request.get("requestedBy", {}).get("displayName"),
                     "requested_by_id": request.get("requestedBy", {}).get("id"),
                     "media_info": {
                         **self._extract_media_info(media),
-                        "title": title  # Add title from TMDB lookup
-                    }
+                        "title": title,  # Add title from TMDB lookup
+                    },
                 }
 
                 # Add seasons for TV shows
                 if request.get("seasons"):
                     processed_request["seasons"] = [
                         {
                             "id": season.get("id"),
                             "season_number": season.get("seasonNumber"),
-                            "status": season.get("status")
+                            "status": season.get("status"),
                         }
                         for season in request.get("seasons", [])
                     ]
 
                 requests.append(processed_request)
@@ -220,12 +221,12 @@
                 "results": requests,
                 "page_info": {
                     "pages": data.get("pageInfo", {}).get("pages", 1),
                     "page_size": data.get("pageInfo", {}).get("pageSize", take),
                     "results": data.get("pageInfo", {}).get("results", len(requests)),
-                    "page": data.get("pageInfo", {}).get("page", 1)
-                }
+                    "page": data.get("pageInfo", {}).get("page", 1),
+                },
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get requests: {e}")
             return {"results": [], "page_info": {}}
@@ -236,29 +237,35 @@
             response = await self._make_request("GET", "/api/v1/user")
             data = response.json()
 
             users = []
             for user in data.get("results", []):
-                display_name = user.get("displayName") or user.get("username") or user.get("email", "").split("@")[0]
-                users.append({
-                    "id": user.get("id"),
-                    "email": user.get("email"),
-                    "display_name": display_name,
-                    "friendly_name": display_name,  # Alias for matching
-                    "username": user.get("username") or display_name,
-                    "name": display_name,  # Alias for matching
-                    "user_type": user.get("userType"),
-                    "permissions": user.get("permissions"),
-                    "avatar": user.get("avatar"),
-                    "created_at": user.get("createdAt"),
-                    "updated_at": user.get("updatedAt"),
-                    "request_count": user.get("requestCount", 0),
-                    "movie_quota_limit": user.get("movieQuotaLimit"),
-                    "movie_quota_days": user.get("movieQuotaDays"),
-                    "tv_quota_limit": user.get("tvQuotaLimit"),
-                    "tv_quota_days": user.get("tvQuotaDays")
-                })
+                display_name = (
+                    user.get("displayName")
+                    or user.get("username")
+                    or user.get("email", "").split("@")[0]
+                )
+                users.append(
+                    {
+                        "id": user.get("id"),
+                        "email": user.get("email"),
+                        "display_name": display_name,
+                        "friendly_name": display_name,  # Alias for matching
+                        "username": user.get("username") or display_name,
+                        "name": display_name,  # Alias for matching
+                        "user_type": user.get("userType"),
+                        "permissions": user.get("permissions"),
+                        "avatar": user.get("avatar"),
+                        "created_at": user.get("createdAt"),
+                        "updated_at": user.get("updatedAt"),
+                        "request_count": user.get("requestCount", 0),
+                        "movie_quota_limit": user.get("movieQuotaLimit"),
+                        "movie_quota_days": user.get("movieQuotaDays"),
+                        "tv_quota_limit": user.get("tvQuotaLimit"),
+                        "tv_quota_days": user.get("tvQuotaDays"),
+                    }
+                )
 
             return users
 
         except Exception as e:
             self.logger.warning(f"Failed to get users: {e}")
@@ -279,14 +286,11 @@
             return None
 
     async def approve_request(self, request_id: int) -> bool:
         """Approve a media request."""
         try:
-            response = await self._make_request(
-                "POST",
-                f"/api/v1/request/{request_id}/approve"
-            )
+            response = await self._make_request("POST", f"/api/v1/request/{request_id}/approve")
             return response.status_code == 200
 
         except Exception as e:
             self.logger.error(f"Failed to approve request {request_id}: {e}")
             return False
@@ -297,21 +301,21 @@
             data = {}
             if reason:
                 data["reason"] = reason
 
             response = await self._make_request(
-                "POST",
-                f"/api/v1/request/{request_id}/decline",
-                json=data
+                "POST", f"/api/v1/request/{request_id}/decline", json=data
             )
             return response.status_code == 200
 
         except Exception as e:
             self.logger.error(f"Failed to decline request {request_id}: {e}")
             return False
 
-    async def search_media(self, query: str, media_type: Optional[MediaType] = None) -> List[Dict[str, Any]]:
+    async def search_media(
+        self, query: str, media_type: Optional[MediaType] = None
+    ) -> List[Dict[str, Any]]:
         """Search for media in Overseerr."""
         try:
             endpoint = "/api/v1/search"
             if media_type:
                 endpoint = f"/api/v1/search/{media_type.value}"
@@ -320,22 +324,24 @@
             response = await self._make_request("GET", endpoint, params=params)
             data = response.json()
 
             search_results = []
             for result in data.get("results", []):
-                search_results.append({
-                    "id": result.get("id"),
-                    "media_type": result.get("mediaType"),
-                    "title": result.get("title") or result.get("name"),
-                    "overview": result.get("overview"),
-                    "release_date": result.get("releaseDate") or result.get("firstAirDate"),
-                    "poster_path": result.get("posterPath"),
-                    "backdrop_path": result.get("backdropPath"),
-                    "vote_average": result.get("voteAverage"),
-                    "genre_ids": result.get("genreIds", []),
-                    "media_info": result.get("mediaInfo")
-                })
+                search_results.append(
+                    {
+                        "id": result.get("id"),
+                        "media_type": result.get("mediaType"),
+                        "title": result.get("title") or result.get("name"),
+                        "overview": result.get("overview"),
+                        "release_date": result.get("releaseDate") or result.get("firstAirDate"),
+                        "poster_path": result.get("posterPath"),
+                        "backdrop_path": result.get("backdropPath"),
+                        "vote_average": result.get("voteAverage"),
+                        "genre_ids": result.get("genreIds", []),
+                        "media_info": result.get("mediaInfo"),
+                    }
+                )
 
             return search_results
 
         except Exception as e:
             self.logger.warning(f"Failed to search media: {e}")
@@ -350,22 +356,37 @@
             # Get users count
             users = await self.get_users()
 
             # Calculate statistics
             total_requests = len(requests_data.get("results", []))
-            pending_count = sum(1 for r in requests_data.get("results", []) if r.get("status") == RequestStatus.PENDING.value)
-            approved_count = sum(1 for r in requests_data.get("results", []) if r.get("status") == RequestStatus.APPROVED.value)
-            available_count = sum(1 for r in requests_data.get("results", []) if r.get("status") == RequestStatus.AVAILABLE.value)
+            pending_count = sum(
+                1
+                for r in requests_data.get("results", [])
+                if r.get("status") == RequestStatus.PENDING.value
+            )
+            approved_count = sum(
+                1
+                for r in requests_data.get("results", [])
+                if r.get("status") == RequestStatus.APPROVED.value
+            )
+            available_count = sum(
+                1
+                for r in requests_data.get("results", [])
+                if r.get("status") == RequestStatus.AVAILABLE.value
+            )
 
             return {
                 "total_requests": total_requests,
                 "pending_requests": pending_count,
                 "approved_requests": approved_count,
                 "available_requests": available_count,
-                "declined_requests": total_requests - pending_count - approved_count - available_count,
+                "declined_requests": total_requests
+                - pending_count
+                - approved_count
+                - available_count,
                 "total_users": len(users),
-                "recent_requests": requests_data.get("results", [])[:10]
+                "recent_requests": requests_data.get("results", [])[:10],
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
@@ -373,20 +394,20 @@
                 "pending_requests": 0,
                 "approved_requests": 0,
                 "available_requests": 0,
                 "declined_requests": 0,
                 "total_users": 0,
-                "recent_requests": []
+                "recent_requests": [],
             }
 
     def _get_status_name(self, status: int) -> str:
         """Get human-readable status name."""
         status_map = {
             RequestStatus.PENDING.value: "Pending",
             RequestStatus.APPROVED.value: "Approved",
             RequestStatus.DECLINED.value: "Declined",
-            RequestStatus.AVAILABLE.value: "Available"
+            RequestStatus.AVAILABLE.value: "Available",
         }
         return status_map.get(status, "Unknown")
 
     def _extract_media_info(self, media: Dict[str, Any]) -> Dict[str, Any]:
         """Extract relevant media information."""
@@ -399,11 +420,11 @@
             "tmdb_id": media.get("tmdbId"),
             "imdb_id": media.get("imdbId"),
             "tvdb_id": media.get("tvdbId"),
             "status": media.get("status"),
             "created_at": media.get("createdAt"),
-            "updated_at": media.get("updatedAt")
+            "updated_at": media.get("updatedAt"),
         }
 
     def validate_config(self) -> List[str]:
         """Validate Overseerr-specific configuration."""
         errors = super().validate_config()
@@ -412,15 +433,11 @@
         if not self.get_config_value(self.token_config_key):
             errors.append("Overseerr API key is required")
 
         return errors
 
-    async def get_trending(
-        self,
-        media_type: str = "all",
-        limit: int = 10
-    ) -> List[Dict[str, Any]]:
+    async def get_trending(self, media_type: str = "all", limit: int = 10) -> List[Dict[str, Any]]:
         """Get trending movies and TV shows."""
         try:
             results = []
 
             # Fetch trending movies
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/overseerr.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/radarr.py	2025-12-31 13:30:51.471007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/radarr.py	2025-12-31 13:41:33.450870+00:00
@@ -15,25 +15,22 @@
     def service_type(self) -> str:
         return "radarr"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.MEDIA_CONTENT,
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.MEDIA_CONTENT, ServiceCapability.API_ACCESS]
 
     @property
     def token_config_key(self) -> str:
         return "radarr_api_key"
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Radarr API key header."""
         return {
             "X-Api-Key": token,
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Radarr."""
         start_time = datetime.utcnow()
@@ -52,38 +49,38 @@
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "version": data.get("version"),
                         "app_name": data.get("appName", "Radarr"),
-                        "branch": data.get("branch")
-                    }
+                        "branch": data.get("branch"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Radarr",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Radarr service information."""
         try:
@@ -95,19 +92,14 @@
                 "version": data.get("version"),
                 "app_name": data.get("appName", "Radarr"),
                 "branch": data.get("branch"),
                 "build_time": data.get("buildTime"),
                 "runtime_version": data.get("runtimeVersion"),
-                "status": "online"
+                "status": "online",
             }
         except Exception as e:
-            return {
-                "service": "radarr",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+            return {"service": "radarr", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_movies(self, limit: int = 50) -> List[Dict[str, Any]]:
         """Get list of movies in Radarr."""
         try:
             response = await self._make_request("GET", "/api/v3/movie")
@@ -123,11 +115,11 @@
                     "has_file": movie.get("hasFile", False),
                     "monitored": movie.get("monitored", False),
                     "status": movie.get("status"),
                     "quality_profile_id": movie.get("qualityProfileId"),
                     "path": movie.get("path"),
-                    "size_on_disk": movie.get("sizeOnDisk", 0)
+                    "size_on_disk": movie.get("sizeOnDisk", 0),
                 }
                 for movie in movies[:limit]
             ]
         except Exception as e:
             self.logger.error(f"Failed to get movies: {e}")
@@ -135,24 +127,22 @@
 
     async def search_movie(self, query: str) -> List[Dict[str, Any]]:
         """Search for movies to add."""
         try:
             response = await self._make_request(
-                "GET",
-                "/api/v3/movie/lookup",
-                params={"term": query}
+                "GET", "/api/v3/movie/lookup", params={"term": query}
             )
             results = response.json()
 
             return [
                 {
                     "title": movie.get("title"),
                     "year": movie.get("year"),
                     "tmdb_id": movie.get("tmdbId"),
                     "imdb_id": movie.get("imdbId"),
                     "overview": movie.get("overview", "")[:200],
-                    "in_library": movie.get("id") is not None
+                    "in_library": movie.get("id") is not None,
                 }
                 for movie in results[:20]
             ]
         except Exception as e:
             self.logger.error(f"Failed to search movies: {e}")
@@ -167,13 +157,15 @@
             return [
                 {
                     "id": item.get("id"),
                     "title": item.get("title"),
                     "status": item.get("status"),
-                    "progress": item.get("sizeleft", 0) / item.get("size", 1) * 100 if item.get("size") else 0,
+                    "progress": item.get("sizeleft", 0) / item.get("size", 1) * 100
+                    if item.get("size")
+                    else 0,
                     "download_client": item.get("downloadClient"),
-                    "estimated_completion": item.get("estimatedCompletionTime")
+                    "estimated_completion": item.get("estimatedCompletionTime"),
                 }
                 for item in data.get("records", [])
             ]
         except Exception as e:
             self.logger.error(f"Failed to get queue: {e}")
@@ -181,30 +173,28 @@
 
     async def get_calendar(self, days: int = 7) -> List[Dict[str, Any]]:
         """Get upcoming movies."""
         try:
             from datetime import timedelta
+
             start = datetime.utcnow()
             end = start + timedelta(days=days)
 
             response = await self._make_request(
                 "GET",
                 "/api/v3/calendar",
-                params={
-                    "start": start.isoformat(),
-                    "end": end.isoformat()
-                }
+                params={"start": start.isoformat(), "end": end.isoformat()},
             )
             movies = response.json()
 
             return [
                 {
                     "id": movie.get("id"),
                     "title": movie.get("title"),
                     "year": movie.get("year"),
                     "release_date": movie.get("inCinemas") or movie.get("physicalRelease"),
-                    "has_file": movie.get("hasFile", False)
+                    "has_file": movie.get("hasFile", False),
                 }
                 for movie in movies
             ]
         except Exception as e:
             self.logger.error(f"Failed to get calendar: {e}")
@@ -225,21 +215,21 @@
                 "total_movies": total_movies,
                 "movies_with_files": movies_with_files,
                 "monitored_movies": monitored,
                 "missing_movies": monitored - movies_with_files,
                 "queue_count": len(queue),
-                "total_size_gb": round(total_size / (1024**3), 2)
+                "total_size_gb": round(total_size / (1024**3), 2),
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_movies": 0,
                 "movies_with_files": 0,
                 "monitored_movies": 0,
                 "missing_movies": 0,
                 "queue_count": 0,
-                "total_size_gb": 0
+                "total_size_gb": 0,
             }
 
     async def get_indexers(self) -> List[Dict[str, Any]]:
         """Get list of configured indexers in Radarr."""
         try:
@@ -254,11 +244,11 @@
                     "enable": indexer.get("enable", False),
                     "priority": indexer.get("priority", 25),
                     "supports_rss": indexer.get("supportsRss", False),
                     "supports_search": indexer.get("supportsSearch", False),
                     "implementation": indexer.get("implementation"),
-                    "config_contract": indexer.get("configContract")
+                    "config_contract": indexer.get("configContract"),
                 }
                 for indexer in indexers
             ]
         except Exception as e:
             self.logger.error(f"Failed to get indexers: {e}")
@@ -272,21 +262,18 @@
             indexer_config = response.json()
             indexer_name = indexer_config.get("name", f"Indexer {indexer_id}")
 
             # Then test it
             await self._make_request(
-                "POST",
-                "/api/v3/indexer/test",
-                json=indexer_config,
-                timeout=60.0
+                "POST", "/api/v3/indexer/test", json=indexer_config, timeout=60.0
             )
 
             return {
                 "success": True,
                 "indexer_id": indexer_id,
                 "indexer_name": indexer_name,
-                "message": "Indexer test passed"
+                "message": "Indexer test passed",
             }
         except httpx.HTTPStatusError as e:
             error_msg = "Test failed"
             try:
                 error_data = e.response.json()
@@ -295,21 +282,13 @@
                 elif isinstance(error_data, dict):
                     error_msg = error_data.get("message", str(e))
             except Exception:
                 error_msg = str(e)
 
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": error_msg
-            }
-        except Exception as e:
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": str(e)
-            }
+            return {"success": False, "indexer_id": indexer_id, "error": error_msg}
+        except Exception as e:
+            return {"success": False, "indexer_id": indexer_id, "error": str(e)}
 
     async def test_all_indexers(self) -> Dict[str, Any]:
         """Test all enabled indexers."""
         indexers = await self.get_indexers()
         enabled_indexers = [i for i in indexers if i.get("enable")]
@@ -323,7 +302,7 @@
         success_count = sum(1 for r in results if r.get("success"))
         return {
             "total_tested": len(results),
             "success_count": success_count,
             "failed_count": len(results) - success_count,
-            "results": results
+            "results": results,
         }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/radarr.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/romm.py	2025-12-31 13:30:51.553007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/romm.py	2025-12-31 13:41:33.458230+00:00
@@ -31,11 +31,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MEDIA_CONTENT,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "romm_api_key"
@@ -43,58 +43,57 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format RomM auth header (Bearer token)."""
         return {
             "Authorization": f"Bearer {token}",
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     def _get_auth_header(self) -> Dict[str, str]:
         """Get auth header - tries Bearer token first, then falls back to Basic Auth."""
         # Try Bearer token first (from api_key field)
         api_key = self.service_config.api_key or self.get_config_value("api_key")
         if api_key:
             return self._format_token_header(api_key)
 
         # Fall back to Basic Auth
-        username = getattr(self.service_config, 'username', None) or self.get_config_value("username") or ""
-        password = getattr(self.service_config, 'password', None) or self.get_config_value("password") or ""
+        username = (
+            getattr(self.service_config, "username", None)
+            or self.get_config_value("username")
+            or ""
+        )
+        password = (
+            getattr(self.service_config, "password", None)
+            or self.get_config_value("password")
+            or ""
+        )
 
         if username and password:
             credentials = base64.b64encode(f"{username}:{password}".encode()).decode()
             return {
                 "Authorization": f"Basic {credentials}",
                 "Content-Type": "application/json",
-                "Accept": "application/json"
+                "Accept": "application/json",
             }
 
         # No auth configured
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     async def _make_request(
         self,
         method: str,
         endpoint: str,
         params: Optional[Dict[str, Any]] = None,
         json: Optional[Dict[str, Any]] = None,
-        timeout: float = 30.0
+        timeout: float = 30.0,
     ):
         """Make HTTP request to RomM API."""
         url = f"{self.base_url.rstrip('/')}{endpoint}"
         headers = self._get_auth_header()
 
         async with httpx.AsyncClient(timeout=timeout) as client:
-            response = await client.request(
-                method,
-                url,
-                params=params,
-                json=json,
-                headers=headers
-            )
+            response = await client.request(method, url, params=params, json=json, headers=headers)
             response.raise_for_status()
             return response
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to RomM."""
@@ -109,53 +108,41 @@
 
             return ConnectionTestResult(
                 success=True,
                 message="Successfully connected to RomM",
                 response_time_ms=response_time,
-                details={
-                    "status": "connected",
-                    "response": data
-                }
+                details={"status": "connected", "response": data},
             )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get RomM service information."""
         try:
             response = await self._make_request("GET", "/api/heartbeat")
             data = response.json()
 
-            return {
-                "service": "romm",
-                "status": "online",
-                "heartbeat": data
-            }
-        except Exception as e:
-            return {
-                "service": "romm",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+            return {"service": "romm", "status": "online", "heartbeat": data}
+        except Exception as e:
+            return {"service": "romm", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_platforms(self) -> List[Dict[str, Any]]:
         """Get list of gaming platforms."""
         try:
             response = await self._make_request("GET", "/api/platforms")
@@ -166,19 +153,21 @@
                     "id": platform.get("id"),
                     "slug": platform.get("slug"),
                     "name": platform.get("name"),
                     "igdb_id": platform.get("igdb_id"),
                     "rom_count": platform.get("rom_count", 0),
-                    "logo_path": platform.get("logo_path")
+                    "logo_path": platform.get("logo_path"),
                 }
                 for platform in platforms
             ]
         except Exception as e:
             self.logger.error(f"Failed to get platforms: {e}")
             return []
 
-    async def get_roms(self, platform_id: Optional[int] = None, limit: int = 50) -> List[Dict[str, Any]]:
+    async def get_roms(
+        self, platform_id: Optional[int] = None, limit: int = 50
+    ) -> List[Dict[str, Any]]:
         """Get list of ROMs."""
         try:
             endpoint = f"/api/platforms/{platform_id}/roms" if platform_id else "/api/roms"
             params = {"limit": limit}
 
@@ -193,11 +182,11 @@
                     "file_size": rom.get("file_size", 0),
                     "platform_id": rom.get("platform_id"),
                     "platform_slug": rom.get("platform_slug"),
                     "igdb_id": rom.get("igdb_id"),
                     "summary": rom.get("summary", "")[:200] if rom.get("summary") else None,
-                    "path": rom.get("path")
+                    "path": rom.get("path"),
                 }
                 for rom in (roms if isinstance(roms, list) else roms.get("items", []))[:limit]
             ]
         except Exception as e:
             self.logger.error(f"Failed to get ROMs: {e}")
@@ -212,11 +201,11 @@
             return [
                 {
                     "id": rom.get("id"),
                     "name": rom.get("name"),
                     "platform_slug": rom.get("platform_slug"),
-                    "file_size": rom.get("file_size", 0)
+                    "file_size": rom.get("file_size", 0),
                 }
                 for rom in (roms if isinstance(roms, list) else roms.get("items", []))[:20]
             ]
         except Exception as e:
             self.logger.error(f"Failed to search ROMs: {e}")
@@ -232,11 +221,11 @@
                 {
                     "id": col.get("id"),
                     "name": col.get("name"),
                     "description": col.get("description"),
                     "rom_count": col.get("rom_count", 0),
-                    "is_public": col.get("is_public", False)
+                    "is_public": col.get("is_public", False),
                 }
                 for col in collections
             ]
         except Exception as e:
             self.logger.error(f"Failed to get collections: {e}")
@@ -253,11 +242,11 @@
                     "id": user.get("id"),
                     "username": user.get("username"),
                     "email": user.get("email"),
                     "name": user.get("username"),
                     "role": user.get("role"),
-                    "enabled": user.get("enabled", True)
+                    "enabled": user.get("enabled", True),
                 }
                 for user in users
             ]
         except Exception as e:
             self.logger.error(f"Failed to get users: {e}")
@@ -273,15 +262,13 @@
             return {
                 "total_platforms": len(platforms),
                 "total_roms": total_roms,
                 "platforms": [
                     {"name": p.get("name"), "roms": p.get("rom_count", 0)}
-                    for p in sorted(platforms, key=lambda x: x.get("rom_count", 0), reverse=True)[:10]
-                ]
+                    for p in sorted(platforms, key=lambda x: x.get("rom_count", 0), reverse=True)[
+                        :10
+                    ]
+                ],
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
-            return {
-                "total_platforms": 0,
-                "total_roms": 0,
-                "platforms": []
-            }
+            return {"total_platforms": 0, "total_roms": 0, "platforms": []}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/romm.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/sonarr.py	2025-12-31 13:30:51.535007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/sonarr.py	2025-12-31 13:41:33.534920+00:00
@@ -15,25 +15,22 @@
     def service_type(self) -> str:
         return "sonarr"
 
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
-        return [
-            ServiceCapability.MEDIA_CONTENT,
-            ServiceCapability.API_ACCESS
-        ]
+        return [ServiceCapability.MEDIA_CONTENT, ServiceCapability.API_ACCESS]
 
     @property
     def token_config_key(self) -> str:
         return "sonarr_api_key"
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Sonarr API key header."""
         return {
             "X-Api-Key": token,
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Sonarr."""
         start_time = datetime.utcnow()
@@ -52,38 +49,38 @@
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "version": data.get("version"),
                         "app_name": data.get("appName", "Sonarr"),
-                        "branch": data.get("branch")
-                    }
+                        "branch": data.get("branch"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Sonarr",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Sonarr service information."""
         try:
@@ -95,19 +92,14 @@
                 "version": data.get("version"),
                 "app_name": data.get("appName", "Sonarr"),
                 "branch": data.get("branch"),
                 "build_time": data.get("buildTime"),
                 "runtime_version": data.get("runtimeVersion"),
-                "status": "online"
+                "status": "online",
             }
         except Exception as e:
-            return {
-                "service": "sonarr",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+            return {"service": "sonarr", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_series(self, limit: int = 50) -> List[Dict[str, Any]]:
         """Get list of TV series in Sonarr."""
         try:
             response = await self._make_request("GET", "/api/v3/series")
@@ -125,11 +117,11 @@
                     "season_count": series.get("seasonCount", 0),
                     "episode_count": series.get("episodeCount", 0),
                     "episode_file_count": series.get("episodeFileCount", 0),
                     "path": series.get("path"),
                     "size_on_disk": series.get("sizeOnDisk", 0),
-                    "network": series.get("network")
+                    "network": series.get("network"),
                 }
                 for series in series_list[:limit]
             ]
         except Exception as e:
             self.logger.error(f"Failed to get series: {e}")
@@ -137,13 +129,11 @@
 
     async def search_series(self, query: str) -> List[Dict[str, Any]]:
         """Search for series to add."""
         try:
             response = await self._make_request(
-                "GET",
-                "/api/v3/series/lookup",
-                params={"term": query}
+                "GET", "/api/v3/series/lookup", params={"term": query}
             )
             results = response.json()
 
             return [
                 {
@@ -152,11 +142,11 @@
                     "tvdb_id": series.get("tvdbId"),
                     "imdb_id": series.get("imdbId"),
                     "overview": series.get("overview", "")[:200],
                     "network": series.get("network"),
                     "season_count": series.get("seasonCount", 0),
-                    "in_library": series.get("id") is not None
+                    "in_library": series.get("id") is not None,
                 }
                 for series in results[:20]
             ]
         except Exception as e:
             self.logger.error(f"Failed to search series: {e}")
@@ -175,13 +165,15 @@
                     "series_title": item.get("series", {}).get("title"),
                     "episode_title": item.get("episode", {}).get("title"),
                     "season": item.get("episode", {}).get("seasonNumber"),
                     "episode": item.get("episode", {}).get("episodeNumber"),
                     "status": item.get("status"),
-                    "progress": (1 - item.get("sizeleft", 0) / item.get("size", 1)) * 100 if item.get("size") else 0,
+                    "progress": (1 - item.get("sizeleft", 0) / item.get("size", 1)) * 100
+                    if item.get("size")
+                    else 0,
                     "download_client": item.get("downloadClient"),
-                    "estimated_completion": item.get("estimatedCompletionTime")
+                    "estimated_completion": item.get("estimatedCompletionTime"),
                 }
                 for item in data.get("records", [])
             ]
         except Exception as e:
             self.logger.error(f"Failed to get queue: {e}")
@@ -189,20 +181,18 @@
 
     async def get_calendar(self, days: int = 7) -> List[Dict[str, Any]]:
         """Get upcoming episodes."""
         try:
             from datetime import timedelta
+
             start = datetime.utcnow()
             end = start + timedelta(days=days)
 
             response = await self._make_request(
                 "GET",
                 "/api/v3/calendar",
-                params={
-                    "start": start.isoformat(),
-                    "end": end.isoformat()
-                }
+                params={"start": start.isoformat(), "end": end.isoformat()},
             )
             episodes = response.json()
 
             return [
                 {
@@ -211,11 +201,11 @@
                     "series_title": ep.get("series", {}).get("title"),
                     "title": ep.get("title"),
                     "season": ep.get("seasonNumber"),
                     "episode": ep.get("episodeNumber"),
                     "air_date": ep.get("airDateUtc"),
-                    "has_file": ep.get("hasFile", False)
+                    "has_file": ep.get("hasFile", False),
                 }
                 for ep in episodes
             ]
         except Exception as e:
             self.logger.error(f"Failed to get calendar: {e}")
@@ -238,22 +228,22 @@
                 "monitored_series": monitored,
                 "total_episodes": total_episodes,
                 "episodes_with_files": total_files,
                 "missing_episodes": total_episodes - total_files,
                 "queue_count": len(queue),
-                "total_size_gb": round(total_size / (1024**3), 2)
+                "total_size_gb": round(total_size / (1024**3), 2),
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_series": 0,
                 "monitored_series": 0,
                 "total_episodes": 0,
                 "episodes_with_files": 0,
                 "missing_episodes": 0,
                 "queue_count": 0,
-                "total_size_gb": 0
+                "total_size_gb": 0,
             }
 
     async def get_indexers(self) -> List[Dict[str, Any]]:
         """Get list of configured indexers in Sonarr."""
         try:
@@ -268,11 +258,11 @@
                     "enable": indexer.get("enable", False),
                     "priority": indexer.get("priority", 25),
                     "supports_rss": indexer.get("supportsRss", False),
                     "supports_search": indexer.get("supportsSearch", False),
                     "implementation": indexer.get("implementation"),
-                    "config_contract": indexer.get("configContract")
+                    "config_contract": indexer.get("configContract"),
                 }
                 for indexer in indexers
             ]
         except Exception as e:
             self.logger.error(f"Failed to get indexers: {e}")
@@ -286,21 +276,18 @@
             indexer_config = response.json()
             indexer_name = indexer_config.get("name", f"Indexer {indexer_id}")
 
             # Then test it
             await self._make_request(
-                "POST",
-                "/api/v3/indexer/test",
-                json=indexer_config,
-                timeout=60.0
+                "POST", "/api/v3/indexer/test", json=indexer_config, timeout=60.0
             )
 
             return {
                 "success": True,
                 "indexer_id": indexer_id,
                 "indexer_name": indexer_name,
-                "message": "Indexer test passed"
+                "message": "Indexer test passed",
             }
         except httpx.HTTPStatusError as e:
             error_msg = "Test failed"
             try:
                 error_data = e.response.json()
@@ -309,21 +296,13 @@
                 elif isinstance(error_data, dict):
                     error_msg = error_data.get("message", str(e))
             except Exception:
                 error_msg = str(e)
 
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": error_msg
-            }
-        except Exception as e:
-            return {
-                "success": False,
-                "indexer_id": indexer_id,
-                "error": str(e)
-            }
+            return {"success": False, "indexer_id": indexer_id, "error": error_msg}
+        except Exception as e:
+            return {"success": False, "indexer_id": indexer_id, "error": str(e)}
 
     async def test_all_indexers(self) -> Dict[str, Any]:
         """Test all enabled indexers."""
         indexers = await self.get_indexers()
         enabled_indexers = [i for i in indexers if i.get("enable")]
@@ -337,7 +316,7 @@
         success_count = sum(1 for r in results if r.get("success"))
         return {
             "total_tested": len(results),
             "success_count": success_count,
             "failed_count": len(results) - success_count,
-            "results": results
+            "results": results,
         }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/sonarr.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/config/settings.py	2025-12-31 13:30:51.462007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/config/settings.py	2025-12-31 13:41:33.614033+00:00
@@ -9,13 +9,11 @@
 
 class Settings(BaseSettings):
     """Application settings."""
 
     model_config = SettingsConfigDict(
-        env_file=".env",
-        env_file_encoding="utf-8",
-        case_sensitive=True
+        env_file=".env", env_file_encoding="utf-8", case_sensitive=True
     )
 
     # Application
     app_name: str = Field(default="MCParr AI Gateway", alias="APP_NAME")
     app_env: str = Field(default="development", alias="APP_ENV")
@@ -28,11 +26,11 @@
     mcp_port: int = Field(default=8001, alias="MCP_PORT")
 
     # Database
     database_url: str = Field(
         default="sqlite+aiosqlite:////home/jeremie/Documents/Dev/ia-homelab/ia-homelab/backend/data/mcparr.db",
-        alias="DATABASE_URL"
+        alias="DATABASE_URL",
     )
 
     # Redis (optional)
     redis_url: str = Field(default="redis://localhost:6379", alias="REDIS_URL")
     cache_ttl: int = Field(default=300, alias="CACHE_TTL")
@@ -44,23 +42,17 @@
             "http://localhost:5173",
             "http://localhost:5174",
             "http://192.168.1.21:5173",
             "http://192.168.1.21:5174",
         ],
-        alias="CORS_ORIGINS"
+        alias="CORS_ORIGINS",
     )
 
     # Security
-    secret_key: str = Field(
-        default="dev-secret-key-change-in-production",
-        alias="SECRET_KEY"
-    )
+    secret_key: str = Field(default="dev-secret-key-change-in-production", alias="SECRET_KEY")
     algorithm: str = Field(default="HS256", alias="ALGORITHM")
-    access_token_expire_minutes: int = Field(
-        default=30,
-        alias="ACCESS_TOKEN_EXPIRE_MINUTES"
-    )
+    access_token_expire_minutes: int = Field(default=30, alias="ACCESS_TOKEN_EXPIRE_MINUTES")
 
     # External Services
     plex_url: str = Field(default="", alias="PLEX_URL")
     plex_token: str = Field(default="", alias="PLEX_TOKEN")
 
@@ -81,22 +73,21 @@
 
     ollama_url: str = Field(default="http://localhost:11434", alias="OLLAMA_URL")
     ollama_model: str = Field(default="llama2", alias="OLLAMA_MODEL")
 
     # Training Worker (GPU fine-tuning)
-    training_worker_url: str = Field(default="http://192.168.1.60:8088", alias="TRAINING_WORKER_URL")
+    training_worker_url: str = Field(
+        default="http://192.168.1.60:8088", alias="TRAINING_WORKER_URL"
+    )
     training_worker_api_key: str = Field(default="", alias="TRAINING_WORKER_API_KEY")
 
     # Monitoring
     enable_metrics: bool = Field(default=True, alias="ENABLE_METRICS")
     metrics_port: int = Field(default=9090, alias="METRICS_PORT")
 
     # Docker
-    docker_socket: str = Field(
-        default="/var/run/docker.sock",
-        alias="DOCKER_SOCKET"
-    )
+    docker_socket: str = Field(default="/var/run/docker.sock", alias="DOCKER_SOCKET")
 
     # Alerts
     alert_email_enabled: bool = Field(default=False, alias="ALERT_EMAIL_ENABLED")
     alert_email_host: str = Field(default="", alias="ALERT_EMAIL_HOST")
     alert_email_port: int = Field(default=587, alias="ALERT_EMAIL_PORT")
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/config/settings.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/wikijs.py	2025-12-31 13:30:51.557007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/wikijs.py	2025-12-31 13:41:33.655689+00:00
@@ -42,38 +42,29 @@
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format WikiJS Bearer token header."""
         return {
             "Authorization": f"Bearer {token}",
             "Content-Type": "application/json",
-            "Accept": "application/json"
+            "Accept": "application/json",
         }
 
     def _get_auth_header(self) -> Dict[str, str]:
         """Get auth header with Bearer token."""
         api_token = self.service_config.api_key or self.get_config_value("api_key")
         if api_token:
             return self._format_token_header(api_token)
 
-        return {
-            "Content-Type": "application/json",
-            "Accept": "application/json"
-        }
+        return {"Content-Type": "application/json", "Accept": "application/json"}
 
     async def _graphql_request(
-        self,
-        query: str,
-        variables: Optional[Dict[str, Any]] = None,
-        timeout: float = 30.0
+        self, query: str, variables: Optional[Dict[str, Any]] = None, timeout: float = 30.0
     ) -> Dict[str, Any]:
         """Make GraphQL request to WikiJS API."""
         url = f"{self.base_url.rstrip('/')}/graphql"
         headers = self._get_auth_header()
 
-        payload = {
-            "query": query,
-            "variables": variables or {}
-        }
+        payload = {"query": query, "variables": variables or {}}
 
         async with httpx.AsyncClient(timeout=timeout) as client:
             response = await client.post(url, json=payload, headers=headers)
             response.raise_for_status()
             result = response.json()
@@ -115,37 +106,35 @@
                 response_time_ms=response_time,
                 details={
                     "status": "connected",
                     "version": system_info.get("currentVersion"),
                     "hostname": system_info.get("hostname"),
-                    "os": system_info.get("operatingSystem")
-                }
+                    "os": system_info.get("operatingSystem"),
+                },
             )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             return ConnectionTestResult(
                 success=False,
                 message=f"HTTP error: {e.response.status_code}",
-                details={"status": "http_error", "status_code": e.response.status_code}
+                details={"status": "http_error", "status_code": e.response.status_code},
             )
         except AdapterError as e:
             return ConnectionTestResult(
-                success=False,
-                message=str(e),
-                details={"status": "api_error"}
+                success=False, message=str(e), details={"status": "api_error"}
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get WikiJS service information."""
         try:
@@ -185,19 +174,14 @@
                 "os": system_info.get("operatingSystem"),
                 "platform": system_info.get("platform"),
                 "node_version": system_info.get("nodeVersion"),
                 "site_title": site_config.get("title"),
                 "site_description": site_config.get("description"),
-                "status": "online"
-            }
-        except Exception as e:
-            return {
-                "service": "wikijs",
-                "version": "unknown",
-                "status": "error",
-                "error": str(e)
-            }
+                "status": "online",
+            }
+        except Exception as e:
+            return {"service": "wikijs", "version": "unknown", "status": "error", "error": str(e)}
 
     async def get_users(self) -> List[Dict[str, Any]]:
         """Get list of users."""
         try:
             query = """
@@ -227,24 +211,21 @@
                     "name": user.get("name"),
                     "provider": user.get("providerKey"),
                     "is_system": user.get("isSystem", False),
                     "is_active": user.get("isActive", True),
                     "created_at": user.get("createdAt"),
-                    "last_login": user.get("lastLoginAt")
+                    "last_login": user.get("lastLoginAt"),
                 }
                 for user in users
                 if not user.get("isSystem", False)  # Exclude system users
             ]
         except Exception as e:
             self.logger.error(f"Failed to get users: {e}")
             return []
 
     async def get_pages(
-        self,
-        limit: int = 50,
-        order_by: str = "UPDATED",
-        locale: str = "en"
+        self, limit: int = 50, order_by: str = "UPDATED", locale: str = "en"
     ) -> List[Dict[str, Any]]:
         """Get list of wiki pages."""
         try:
             # WikiJS 2.x schema - PageListItem has limited fields
             query = """
@@ -262,15 +243,11 @@
                         tags
                     }
                 }
             }
             """
-            variables = {
-                "limit": limit,
-                "orderBy": order_by,
-                "locale": locale
-            }
+            variables = {"limit": limit, "orderBy": order_by, "locale": locale}
             data = await self._graphql_request(query, variables)
             pages = data.get("pages", {}).get("list", [])
 
             return [
                 {
@@ -280,11 +257,11 @@
                     "description": page.get("description"),
                     "locale": page.get("locale"),
                     "is_published": page.get("isPublished", True),
                     "tags": page.get("tags", []),  # tags is already a string array
                     "created_at": page.get("createdAt"),
-                    "updated_at": page.get("updatedAt")
+                    "updated_at": page.get("updatedAt"),
                 }
                 for page in pages
             ]
         except Exception as e:
             self.logger.error(f"Failed to get pages: {e}")
@@ -335,21 +312,17 @@
                 "is_published": page.get("isPublished", True),
                 "is_private": page.get("isPrivate", False),
                 "tags": [t.get("tag") for t in page.get("tags", [])],
                 "toc": page.get("toc"),
                 "created_at": page.get("createdAt"),
-                "updated_at": page.get("updatedAt")
+                "updated_at": page.get("updatedAt"),
             }
         except Exception as e:
             self.logger.error(f"Failed to get page {page_id}: {e}")
             return None
 
-    async def search(
-        self,
-        query: str,
-        locale: str = "en"
-    ) -> List[Dict[str, Any]]:
+    async def search(self, query: str, locale: str = "en") -> List[Dict[str, Any]]:
         """Search wiki content."""
         try:
             gql_query = """
             query($query: String!, $locale: String) {
                 pages {
@@ -377,14 +350,14 @@
                     {
                         "id": r.get("id"),
                         "path": r.get("path"),
                         "title": r.get("title"),
                         "description": r.get("description"),
-                        "locale": r.get("locale")
+                        "locale": r.get("locale"),
                     }
                     for r in search_results.get("results", [])
-                ]
+                ],
             }
         except Exception as e:
             self.logger.error(f"Failed to search: {e}")
             return {"total": 0, "suggestions": [], "results": []}
 
@@ -437,11 +410,11 @@
                     "path": item.get("path"),
                     "title": item.get("title"),
                     "is_private": item.get("isPrivate", False),
                     "is_folder": item.get("isFolder", False),
                     "depth": item.get("depth", 0),
-                    "page_id": item.get("pageId")
+                    "page_id": item.get("pageId"),
                 }
                 for item in tree
             ]
         except Exception as e:
             self.logger.error(f"Failed to get page tree: {e}")
@@ -470,11 +443,11 @@
                 {
                     "id": tag.get("id"),
                     "tag": tag.get("tag"),
                     "title": tag.get("title"),
                     "created_at": tag.get("createdAt"),
-                    "updated_at": tag.get("updatedAt")
+                    "updated_at": tag.get("updatedAt"),
                 }
                 for tag in tags
             ]
         except Exception as e:
             self.logger.error(f"Failed to get tags: {e}")
@@ -511,21 +484,21 @@
                 "total_pages": len(pages),
                 "total_users": len(users),
                 "total_tags": len(tags),
                 "active_users": len([u for u in users if u.get("is_active")]),
                 "published_pages": len([p for p in pages if p.get("isPublished")]),
-                "pages_by_locale": locales
+                "pages_by_locale": locales,
             }
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
                 "total_pages": 0,
                 "total_users": 0,
                 "total_tags": 0,
                 "active_users": 0,
                 "published_pages": 0,
-                "pages_by_locale": {}
+                "pages_by_locale": {},
             }
 
     async def create_page(
         self,
         path: str,
@@ -533,11 +506,11 @@
         content: str,
         description: str = "",
         locale: str = "en",
         is_published: bool = True,
         is_private: bool = False,
-        tags: Optional[List[str]] = None
+        tags: Optional[List[str]] = None,
     ) -> Dict[str, Any]:
         """Create a new wiki page."""
         try:
             mutation = """
             mutation(
@@ -584,11 +557,11 @@
                 "isPrivate": is_private,
                 "isPublished": is_published,
                 "locale": locale,
                 "path": path,
                 "tags": tags or [],
-                "title": title
+                "title": title,
             }
             data = await self._graphql_request(mutation, variables)
             result = data.get("pages", {}).get("create", {})
             response = result.get("responseResult", {})
 
@@ -597,17 +570,17 @@
                 return {
                     "success": True,
                     "page": {
                         "id": page.get("id"),
                         "path": page.get("path"),
-                        "title": page.get("title")
-                    }
+                        "title": page.get("title"),
+                    },
                 }
             else:
                 return {
                     "success": False,
                     "error": response.get("message", "Failed to create page"),
-                    "error_code": response.get("errorCode")
+                    "error_code": response.get("errorCode"),
                 }
         except Exception as e:
             self.logger.error(f"Failed to create page: {e}")
             return {"success": False, "error": str(e)}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/wikijs.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database/connection.py	2025-12-31 13:30:51.453007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database/connection.py	2025-12-31 13:41:33.663591+00:00
@@ -60,14 +60,11 @@
 database_manager: DatabaseManager = None
 
 
 def get_database_url() -> str:
     """Get database URL from environment."""
-    return os.getenv(
-        "DATABASE_URL",
-        "sqlite+aiosqlite:///./data/mcparr.db"
-    )
+    return os.getenv("DATABASE_URL", "sqlite+aiosqlite:///./data/mcparr.db")
 
 
 def init_database() -> DatabaseManager:
     """Initialize database manager."""
     global database_manager
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database/connection.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database.py	2025-12-31 13:30:51.453007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database.py	2025-12-31 13:41:33.674453+00:00
@@ -4,12 +4,13 @@
 
 from sqlalchemy import create_engine
 from sqlalchemy.orm import Session, sessionmaker
 
 # Create engine
-engine = create_engine('sqlite:///./data/mcparr.db', echo=False)
+engine = create_engine("sqlite:///./data/mcparr.db", echo=False)
 SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
+
 
 def get_db() -> Generator[Session, None, None]:
     """Get database session."""
     db = SessionLocal()
     try:
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/tautulli.py	2025-12-31 13:30:51.518007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/tautulli.py	2025-12-31 13:41:33.671686+00:00
@@ -24,30 +24,24 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.MONITORING,
             ServiceCapability.MEDIA_CONTENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "tautulli_api_key"
 
     def _format_token_header(self, token: str) -> Dict[str, str]:
         """Format Tautulli API key header."""
-        return {
-            "Accept": "application/json",
-            "Content-Type": "application/json"
-        }
+        return {"Accept": "application/json", "Content-Type": "application/json"}
 
     def get_auth_headers(self) -> Dict[str, str]:
         """Get authentication headers for Tautulli (uses query params, not headers)."""
-        return {
-            "Accept": "application/json",
-            "Content-Type": "application/json"
-        }
+        return {"Accept": "application/json", "Content-Type": "application/json"}
 
     def _get_auth_params(self) -> Dict[str, str]:
         """Get authentication parameters for Tautulli API."""
         # First try to get token from api_key field
         token = self.service_config.api_key
@@ -58,16 +52,11 @@
 
         if not token:
             return {}
         return {"apikey": token}
 
-    async def _make_request(
-        self,
-        method: str,
-        endpoint: str,
-        **kwargs
-    ) -> httpx.Response:
+    async def _make_request(self, method: str, endpoint: str, **kwargs) -> httpx.Response:
         """Override to add API key as query parameter."""
         # Add auth params to existing params
         params = kwargs.get("params", {})
         params.update(self._get_auth_params())
         kwargs["params"] = params
@@ -96,45 +85,48 @@
                     success=True,
                     message="Successfully connected to Tautulli",
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
-                        "message": data.get("response", {}).get("message", "")
-                    }
+                        "message": data.get("response", {}).get("message", ""),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but Tautulli returned an error",
                     response_time_ms=response_time,
-                    details={"status": "api_error", "error": data.get("response", {}).get("message")}
+                    details={
+                        "status": "api_error",
+                        "error": data.get("response", {}).get("message"),
+                    },
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check API key",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Tautulli service information."""
         try:
@@ -153,11 +145,11 @@
                 "plex_name": server_info.get("plex_name"),
                 "plex_version": server_info.get("plex_version"),
                 "plex_platform": server_info.get("plex_platform"),
                 "plex_machine_identifier": server_info.get("plex_machine_identifier"),
                 "update_available": server_info.get("update_available", False),
-                "update_version": server_info.get("update_version")
+                "update_version": server_info.get("update_version"),
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Tautulli API key")
@@ -177,50 +169,49 @@
             activity_data = data.get("response", {}).get("data", {})
             sessions = activity_data.get("sessions", [])
 
             processed_sessions = []
             for session in sessions:
-                processed_sessions.append({
-                    "session_key": session.get("session_key"),
-                    "user": session.get("user"),
-                    "friendly_name": session.get("friendly_name"),
-                    "title": session.get("title"),
-                    "parent_title": session.get("parent_title"),
-                    "grandparent_title": session.get("grandparent_title"),
-                    "media_type": session.get("media_type"),
-                    "state": session.get("state"),
-                    "progress_percent": session.get("progress_percent"),
-                    "duration": session.get("duration"),
-                    "view_offset": session.get("view_offset"),
-                    "player": session.get("player"),
-                    "platform": session.get("platform"),
-                    "product": session.get("product"),
-                    "quality_profile": session.get("quality_profile"),
-                    "bandwidth": session.get("bandwidth"),
-                    "location": session.get("location")
-                })
+                processed_sessions.append(
+                    {
+                        "session_key": session.get("session_key"),
+                        "user": session.get("user"),
+                        "friendly_name": session.get("friendly_name"),
+                        "title": session.get("title"),
+                        "parent_title": session.get("parent_title"),
+                        "grandparent_title": session.get("grandparent_title"),
+                        "media_type": session.get("media_type"),
+                        "state": session.get("state"),
+                        "progress_percent": session.get("progress_percent"),
+                        "duration": session.get("duration"),
+                        "view_offset": session.get("view_offset"),
+                        "player": session.get("player"),
+                        "platform": session.get("platform"),
+                        "product": session.get("product"),
+                        "quality_profile": session.get("quality_profile"),
+                        "bandwidth": session.get("bandwidth"),
+                        "location": session.get("location"),
+                    }
+                )
 
             return {
                 "sessions": processed_sessions,
                 "stream_count": activity_data.get("stream_count", 0),
                 "stream_count_direct_play": activity_data.get("stream_count_direct_play", 0),
                 "stream_count_direct_stream": activity_data.get("stream_count_direct_stream", 0),
                 "stream_count_transcode": activity_data.get("stream_count_transcode", 0),
                 "total_bandwidth": activity_data.get("total_bandwidth", 0),
                 "wan_bandwidth": activity_data.get("wan_bandwidth", 0),
-                "lan_bandwidth": activity_data.get("lan_bandwidth", 0)
+                "lan_bandwidth": activity_data.get("lan_bandwidth", 0),
             }
 
         except Exception as e:
             self.logger.warning(f"Failed to get activity: {e}")
             return {"sessions": [], "stream_count": 0}
 
     async def get_history(
-        self,
-        length: int = 25,
-        start: int = 0,
-        user: Optional[str] = None
+        self, length: int = 25, start: int = 0, user: Optional[str] = None
     ) -> Dict[str, Any]:
         """Get play history from Tautulli."""
         try:
             params = {"cmd": "get_history", "length": str(length), "start": str(start)}
             if user:
@@ -235,38 +226,40 @@
             history_data = data.get("response", {}).get("data", {})
             history_items = history_data.get("data", [])
 
             processed_history = []
             for item in history_items:
-                processed_history.append({
-                    "id": item.get("id"),
-                    "date": item.get("date"),
-                    "started": item.get("started"),
-                    "stopped": item.get("stopped"),
-                    "duration": item.get("duration"),
-                    "watched_status": item.get("watched_status"),
-                    "user": item.get("user"),
-                    "friendly_name": item.get("friendly_name"),
-                    "title": item.get("title"),
-                    "parent_title": item.get("parent_title"),
-                    "grandparent_title": item.get("grandparent_title"),
-                    "media_type": item.get("media_type"),
-                    "rating_key": item.get("rating_key"),
-                    "parent_rating_key": item.get("parent_rating_key"),
-                    "grandparent_rating_key": item.get("grandparent_rating_key"),
-                    "year": item.get("year"),
-                    "player": item.get("player"),
-                    "ip_address": item.get("ip_address"),
-                    "paused_counter": item.get("paused_counter"),
-                    "percent_complete": item.get("percent_complete")
-                })
+                processed_history.append(
+                    {
+                        "id": item.get("id"),
+                        "date": item.get("date"),
+                        "started": item.get("started"),
+                        "stopped": item.get("stopped"),
+                        "duration": item.get("duration"),
+                        "watched_status": item.get("watched_status"),
+                        "user": item.get("user"),
+                        "friendly_name": item.get("friendly_name"),
+                        "title": item.get("title"),
+                        "parent_title": item.get("parent_title"),
+                        "grandparent_title": item.get("grandparent_title"),
+                        "media_type": item.get("media_type"),
+                        "rating_key": item.get("rating_key"),
+                        "parent_rating_key": item.get("parent_rating_key"),
+                        "grandparent_rating_key": item.get("grandparent_rating_key"),
+                        "year": item.get("year"),
+                        "player": item.get("player"),
+                        "ip_address": item.get("ip_address"),
+                        "paused_counter": item.get("paused_counter"),
+                        "percent_complete": item.get("percent_complete"),
+                    }
+                )
 
             return {
                 "history": processed_history,
                 "total_duration": history_data.get("total_duration", 0),
                 "filtered_from_grouping": history_data.get("filtered_from_grouping", 0),
-                "total_plays": len(processed_history)
+                "total_plays": len(processed_history),
             }
 
         except Exception as e:
             self.logger.warning(f"Failed to get history: {e}")
             return {"history": [], "total_duration": 0}
@@ -282,32 +275,34 @@
 
             users_data = data.get("response", {}).get("data", [])
             users = []
 
             for user in users_data:
-                users.append({
-                    "user_id": user.get("user_id"),
-                    "username": user.get("username"),
-                    "friendly_name": user.get("friendly_name"),
-                    "email": user.get("email"),
-                    "thumb": user.get("thumb"),
-                    "is_active": user.get("is_active"),
-                    "is_admin": user.get("is_admin"),
-                    "is_home_user": user.get("is_home_user"),
-                    "is_allow_sync": user.get("is_allow_sync"),
-                    "is_restricted": user.get("is_restricted"),
-                    "do_notify": user.get("do_notify"),
-                    "keep_history": user.get("keep_history"),
-                    "allow_guest": user.get("allow_guest"),
-                    "server_token": user.get("server_token"),
-                    "shared_libraries": user.get("shared_libraries", []),
-                    "filter_all": user.get("filter_all"),
-                    "filter_movies": user.get("filter_movies"),
-                    "filter_tv": user.get("filter_tv"),
-                    "filter_music": user.get("filter_music"),
-                    "filter_photos": user.get("filter_photos")
-                })
+                users.append(
+                    {
+                        "user_id": user.get("user_id"),
+                        "username": user.get("username"),
+                        "friendly_name": user.get("friendly_name"),
+                        "email": user.get("email"),
+                        "thumb": user.get("thumb"),
+                        "is_active": user.get("is_active"),
+                        "is_admin": user.get("is_admin"),
+                        "is_home_user": user.get("is_home_user"),
+                        "is_allow_sync": user.get("is_allow_sync"),
+                        "is_restricted": user.get("is_restricted"),
+                        "do_notify": user.get("do_notify"),
+                        "keep_history": user.get("keep_history"),
+                        "allow_guest": user.get("allow_guest"),
+                        "server_token": user.get("server_token"),
+                        "shared_libraries": user.get("shared_libraries", []),
+                        "filter_all": user.get("filter_all"),
+                        "filter_movies": user.get("filter_movies"),
+                        "filter_tv": user.get("filter_tv"),
+                        "filter_music": user.get("filter_music"),
+                        "filter_photos": user.get("filter_photos"),
+                    }
+                )
 
             return users
 
         except Exception as e:
             self.logger.warning(f"Failed to get users: {e}")
@@ -324,26 +319,28 @@
 
             libraries_data = data.get("response", {}).get("data", [])
             libraries = []
 
             for library in libraries_data:
-                libraries.append({
-                    "section_id": library.get("section_id"),
-                    "section_name": library.get("section_name"),
-                    "section_type": library.get("section_type"),
-                    "agent": library.get("agent"),
-                    "thumb": library.get("thumb"),
-                    "art": library.get("art"),
-                    "count": library.get("count"),
-                    "parent_count": library.get("parent_count"),
-                    "child_count": library.get("child_count"),
-                    "is_active": library.get("is_active"),
-                    "do_notify": library.get("do_notify"),
-                    "do_notify_created": library.get("do_notify_created"),
-                    "keep_history": library.get("keep_history"),
-                    "deleted_section": library.get("deleted_section")
-                })
+                libraries.append(
+                    {
+                        "section_id": library.get("section_id"),
+                        "section_name": library.get("section_name"),
+                        "section_type": library.get("section_type"),
+                        "agent": library.get("agent"),
+                        "thumb": library.get("thumb"),
+                        "art": library.get("art"),
+                        "count": library.get("count"),
+                        "parent_count": library.get("parent_count"),
+                        "child_count": library.get("child_count"),
+                        "is_active": library.get("is_active"),
+                        "do_notify": library.get("do_notify"),
+                        "do_notify_created": library.get("do_notify_created"),
+                        "keep_history": library.get("keep_history"),
+                        "deleted_section": library.get("deleted_section"),
+                    }
+                )
 
             return libraries
 
         except Exception as e:
             self.logger.warning(f"Failed to get libraries: {e}")
@@ -377,11 +374,11 @@
                 "total_users": len(users),
                 "active_users": sum(1 for user in users if user.get("is_active")),
                 "libraries_count": len(libraries),
                 "home_stats": stats_data[:5] if isinstance(stats_data, list) else {},
                 "libraries": libraries,
-                "recent_sessions": activity.get("sessions", [])[:5]
+                "recent_sessions": activity.get("sessions", [])[:5],
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
@@ -390,11 +387,11 @@
                 "total_users": 0,
                 "active_users": 0,
                 "libraries_count": 0,
                 "home_stats": [],
                 "libraries": [],
-                "recent_sessions": []
+                "recent_sessions": [],
             }
 
     async def get_recently_added(self, count: int = 25) -> List[Dict[str, Any]]:
         """Get recently added items."""
         try:
@@ -407,23 +404,25 @@
 
             recently_added = data.get("response", {}).get("data", {}).get("recently_added", [])
             items = []
 
             for item in recently_added:
-                items.append({
-                    "added_at": item.get("added_at"),
-                    "title": item.get("title"),
-                    "parent_title": item.get("parent_title"),
-                    "grandparent_title": item.get("grandparent_title"),
-                    "media_type": item.get("media_type"),
-                    "year": item.get("year"),
-                    "rating": item.get("rating"),
-                    "section_id": item.get("section_id"),
-                    "library_name": item.get("library_name"),
-                    "thumb": item.get("thumb"),
-                    "art": item.get("art")
-                })
+                items.append(
+                    {
+                        "added_at": item.get("added_at"),
+                        "title": item.get("title"),
+                        "parent_title": item.get("parent_title"),
+                        "grandparent_title": item.get("grandparent_title"),
+                        "media_type": item.get("media_type"),
+                        "year": item.get("year"),
+                        "rating": item.get("rating"),
+                        "section_id": item.get("section_id"),
+                        "library_name": item.get("library_name"),
+                        "thumb": item.get("thumb"),
+                        "art": item.get("art"),
+                    }
+                )
 
             return items
 
         except Exception as e:
             self.logger.warning(f"Failed to get recently added: {e}")
@@ -433,11 +432,11 @@
         self,
         time_range: int = 30,
         stats_type: str = "plays",
         stats_count: int = 10,
         stat_id: Optional[str] = None,
-        user_id: Optional[int] = None
+        user_id: Optional[int] = None,
     ) -> List[Dict[str, Any]]:
         """Get homepage watch statistics.
 
         Args:
             time_range: Number of days to calculate statistics (default: 30)
@@ -462,11 +461,11 @@
         try:
             params = {
                 "cmd": "get_home_stats",
                 "time_range": str(time_range),
                 "stats_type": stats_type,
-                "stats_count": str(stats_count)
+                "stats_count": str(stats_count),
             }
 
             if stat_id:
                 params["stat_id"] = stat_id
 
@@ -485,13 +484,11 @@
         except Exception as e:
             self.logger.warning(f"Failed to get home stats: {e}")
             return []
 
     async def get_user_watch_time_stats(
-        self,
-        user_id: int,
-        query_days: Optional[List[int]] = None
+        self, user_id: int, query_days: Optional[List[int]] = None
     ) -> Dict[str, Any]:
         """Get a user's watch time statistics.
 
         Args:
             user_id: The user's Tautulli user_id
@@ -530,28 +527,21 @@
         except Exception as e:
             self.logger.warning(f"Failed to get user player stats: {e}")
             return []
 
     async def get_plays_by_date(
-        self,
-        time_range: int = 30,
-        y_axis: str = "plays",
-        user_id: Optional[int] = None
+        self, time_range: int = 30, y_axis: str = "plays", user_id: Optional[int] = None
     ) -> Dict[str, Any]:
         """Get play counts by date.
 
         Args:
             time_range: Number of days (default: 30)
             y_axis: 'plays' or 'duration'
             user_id: Optional user_id filter
         """
         try:
-            params = {
-                "cmd": "get_plays_by_date",
-                "time_range": str(time_range),
-                "y_axis": y_axis
-            }
+            params = {"cmd": "get_plays_by_date", "time_range": str(time_range), "y_axis": y_axis}
 
             if user_id:
                 params["user_id"] = str(user_id)
 
             response = await self._make_request("GET", "", params=params)
@@ -565,28 +555,21 @@
         except Exception as e:
             self.logger.warning(f"Failed to get plays by date: {e}")
             return {}
 
     async def get_plays_per_month(
-        self,
-        time_range: int = 12,
-        y_axis: str = "plays",
-        user_id: Optional[int] = None
+        self, time_range: int = 12, y_axis: str = "plays", user_id: Optional[int] = None
     ) -> Dict[str, Any]:
         """Get play counts per month.
 
         Args:
             time_range: Number of months (default: 12)
             y_axis: 'plays' or 'duration'
             user_id: Optional user_id filter
         """
         try:
-            params = {
-                "cmd": "get_plays_per_month",
-                "time_range": str(time_range),
-                "y_axis": y_axis
-            }
+            params = {"cmd": "get_plays_per_month", "time_range": str(time_range), "y_axis": y_axis}
 
             if user_id:
                 params["user_id"] = str(user_id)
 
             response = await self._make_request("GET", "", params=params)
@@ -600,20 +583,18 @@
         except Exception as e:
             self.logger.warning(f"Failed to get plays per month: {e}")
             return {}
 
     async def get_stream_type_by_top_10_users(
-        self,
-        time_range: int = 30,
-        y_axis: str = "plays"
+        self, time_range: int = 30, y_axis: str = "plays"
     ) -> Dict[str, Any]:
         """Get stream type breakdown for top 10 users."""
         try:
             params = {
                 "cmd": "get_stream_type_by_top_10_users",
                 "time_range": str(time_range),
-                "y_axis": y_axis
+                "y_axis": y_axis,
             }
 
             response = await self._make_request("GET", "", params=params)
             data = response.json()
 
@@ -644,12 +625,14 @@
 
     async def get_user_by_username(self, username: str) -> Optional[Dict[str, Any]]:
         """Get user details by username."""
         users = await self.get_users()
         for user in users:
-            if user.get("username", "").lower() == username.lower() or \
-               user.get("friendly_name", "").lower() == username.lower():
+            if (
+                user.get("username", "").lower() == username.lower()
+                or user.get("friendly_name", "").lower() == username.lower()
+            ):
                 return user
         return None
 
     def validate_config(self) -> List[str]:
         """Validate Tautulli-specific configuration."""
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/database.py
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/tautulli.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/zammad.py	2025-12-31 13:30:51.522007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/zammad.py	2025-12-31 13:41:33.674195+00:00
@@ -15,19 +15,21 @@
 )
 
 
 class TicketState(Enum):
     """Zammad ticket states."""
+
     NEW = "new"
     OPEN = "open"
     PENDING_REMINDER = "pending reminder"
     PENDING_CLOSE = "pending close"
     CLOSED = "closed"
 
 
 class TicketPriority(Enum):
     """Zammad ticket priorities."""
+
     LOW = "1 low"
     NORMAL = "2 normal"
     HIGH = "3 high"
 
 
@@ -41,11 +43,11 @@
     @property
     def supported_capabilities(self) -> List[ServiceCapability]:
         return [
             ServiceCapability.TICKET_SYSTEM,
             ServiceCapability.USER_MANAGEMENT,
-            ServiceCapability.API_ACCESS
+            ServiceCapability.API_ACCESS,
         ]
 
     @property
     def token_config_key(self) -> str:
         return "zammad_token"
@@ -58,23 +60,23 @@
         - Bearer: "Bearer {jwt_token}" (for OAuth/JWT)
 
         We detect format based on token structure.
         """
         # JWT tokens typically have 3 parts separated by dots
-        if token.count('.') == 2:
+        if token.count(".") == 2:
             # Looks like a JWT token
             return {
                 "Authorization": f"Bearer {token}",
                 "Content-Type": "application/json",
-                "Accept": "application/json"
+                "Accept": "application/json",
             }
         else:
             # Standard Zammad API token
             return {
                 "Authorization": f"Token token={token}",
                 "Content-Type": "application/json",
-                "Accept": "application/json"
+                "Accept": "application/json",
             }
 
     async def test_connection(self) -> ConnectionTestResult:
         """Test connection to Zammad."""
         start_time = datetime.utcnow()
@@ -94,51 +96,51 @@
                     message="Successfully connected to Zammad",
                     response_time_ms=response_time,
                     details={
                         "status": "connected",
                         "user_id": data.get("id"),
-                        "user_email": data.get("email")
-                    }
+                        "user_email": data.get("email"),
+                    },
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message="Connected but response doesn't appear to be from Zammad",
                     response_time_ms=response_time,
-                    details={"status": "invalid_response"}
+                    details={"status": "invalid_response"},
                 )
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 return ConnectionTestResult(
                     success=False,
                     message="Authentication failed - check token",
-                    details={"status": "auth_failed", "status_code": 401}
+                    details={"status": "auth_failed", "status_code": 401},
                 )
             elif e.response.status_code == 403:
                 return ConnectionTestResult(
                     success=False,
                     message="Access denied - insufficient permissions",
-                    details={"status": "access_denied", "status_code": 403}
+                    details={"status": "access_denied", "status_code": 403},
                 )
             else:
                 return ConnectionTestResult(
                     success=False,
                     message=f"HTTP error: {e.response.status_code}",
-                    details={"status": "http_error", "status_code": e.response.status_code}
+                    details={"status": "http_error", "status_code": e.response.status_code},
                 )
         except httpx.RequestError as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Connection failed: {str(e)}",
-                details={"status": "connection_failed", "error": str(e)}
+                details={"status": "connection_failed", "error": str(e)},
             )
         except Exception as e:
             return ConnectionTestResult(
                 success=False,
                 message=f"Unexpected error: {str(e)}",
-                details={"status": "unexpected_error", "error": str(e)}
+                details={"status": "unexpected_error", "error": str(e)},
             )
 
     async def get_service_info(self) -> Dict[str, Any]:
         """Get Zammad service information."""
         try:
@@ -155,13 +157,13 @@
                 "current_user": {
                     "id": user_data.get("id"),
                     "email": user_data.get("email"),
                     "firstname": user_data.get("firstname"),
                     "lastname": user_data.get("lastname"),
-                    "roles": user_data.get("roles", [])
+                    "roles": user_data.get("roles", []),
                 },
-                "api_version": "v1"
+                "api_version": "v1",
             }
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 401:
                 raise AuthenticationError("Invalid Zammad token")
@@ -183,14 +185,11 @@
         if isinstance(value, dict):
             return value.get("name")
         return None
 
     async def get_tickets(
-        self,
-        page: int = 1,
-        per_page: int = 25,
-        state: Optional[TicketState] = None
+        self, page: int = 1, per_page: int = 25, state: Optional[TicketState] = None
     ) -> Dict[str, Any]:
         """Get tickets from Zammad."""
         try:
             params = {"page": str(page), "per_page": str(per_page), "expand": "true"}
 
@@ -215,32 +214,32 @@
                     "customer_id": ticket.get("customer_id"),
                     "owner_id": ticket.get("owner_id"),
                     "created_at": ticket.get("created_at"),
                     "updated_at": ticket.get("updated_at"),
                     "close_at": ticket.get("close_at"),
-                    "article_count": ticket.get("article_count", 0)
+                    "article_count": ticket.get("article_count", 0),
                 }
                 processed_tickets.append(processed_ticket)
 
             return {
                 "tickets": processed_tickets,
-                "pagination": {
-                    "page": page,
-                    "per_page": per_page,
-                    "total": len(processed_tickets)
-                }
+                "pagination": {"page": page, "per_page": per_page, "total": len(processed_tickets)},
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get tickets: {e}")
             return {"tickets": [], "pagination": {"page": page, "per_page": per_page, "total": 0}}
 
-    async def get_ticket_by_id(self, ticket_id: int, expand: bool = True) -> Optional[Dict[str, Any]]:
+    async def get_ticket_by_id(
+        self, ticket_id: int, expand: bool = True
+    ) -> Optional[Dict[str, Any]]:
         """Get a specific ticket by ID."""
         try:
             params = {"expand": "true"} if expand else {}
-            response = await self._make_request("GET", f"/api/v1/tickets/{ticket_id}", params=params)
+            response = await self._make_request(
+                "GET", f"/api/v1/tickets/{ticket_id}", params=params
+            )
             return response.json()
 
         except httpx.HTTPStatusError as e:
             if e.response.status_code == 404:
                 return None
@@ -259,20 +258,24 @@
             error_body = ""
             try:
                 error_body = e.response.text
             except Exception:
                 pass
-            self.logger.error(f"Failed to create ticket: HTTP {e.response.status_code} - {error_body}")
+            self.logger.error(
+                f"Failed to create ticket: HTTP {e.response.status_code} - {error_body}"
+            )
             return None
         except Exception as e:
             self.logger.error(f"Failed to create ticket: {e}")
             return None
 
     async def update_ticket(self, ticket_id: int, ticket_data: Dict[str, Any]) -> bool:
         """Update a ticket."""
         try:
-            response = await self._make_request("PUT", f"/api/v1/tickets/{ticket_id}", json=ticket_data)
+            response = await self._make_request(
+                "PUT", f"/api/v1/tickets/{ticket_id}", json=ticket_data
+            )
             return response.status_code == 200
 
         except Exception as e:
             self.logger.error(f"Failed to update ticket {ticket_id}: {e}")
             return False
@@ -284,24 +287,26 @@
             response = await self._make_request("GET", "/api/v1/users", params=params)
             data = response.json()
 
             users = []
             for user in data if isinstance(data, list) else []:
-                users.append({
-                    "id": user.get("id"),
-                    "email": user.get("email"),
-                    "firstname": user.get("firstname"),
-                    "lastname": user.get("lastname"),
-                    "login": user.get("login"),
-                    "phone": user.get("phone"),
-                    "active": user.get("active"),
-                    "verified": user.get("verified"),
-                    "roles": user.get("roles", []),
-                    "groups": user.get("groups", []),
-                    "created_at": user.get("created_at"),
-                    "updated_at": user.get("updated_at")
-                })
+                users.append(
+                    {
+                        "id": user.get("id"),
+                        "email": user.get("email"),
+                        "firstname": user.get("firstname"),
+                        "lastname": user.get("lastname"),
+                        "login": user.get("login"),
+                        "phone": user.get("phone"),
+                        "active": user.get("active"),
+                        "verified": user.get("verified"),
+                        "roles": user.get("roles", []),
+                        "groups": user.get("groups", []),
+                        "created_at": user.get("created_at"),
+                        "updated_at": user.get("updated_at"),
+                    }
+                )
 
             return users
 
         except Exception as e:
             self.logger.warning(f"Failed to get users: {e}")
@@ -313,32 +318,36 @@
             response = await self._make_request("GET", "/api/v1/groups")
             data = response.json()
 
             groups = []
             for group in data if isinstance(data, list) else []:
-                groups.append({
-                    "id": group.get("id"),
-                    "name": group.get("name"),
-                    "assignment_timeout": group.get("assignment_timeout"),
-                    "follow_up_possible": group.get("follow_up_possible"),
-                    "follow_up_assignment": group.get("follow_up_assignment"),
-                    "active": group.get("active"),
-                    "note": group.get("note"),
-                    "created_at": group.get("created_at"),
-                    "updated_at": group.get("updated_at")
-                })
+                groups.append(
+                    {
+                        "id": group.get("id"),
+                        "name": group.get("name"),
+                        "assignment_timeout": group.get("assignment_timeout"),
+                        "follow_up_possible": group.get("follow_up_possible"),
+                        "follow_up_assignment": group.get("follow_up_assignment"),
+                        "active": group.get("active"),
+                        "note": group.get("note"),
+                        "created_at": group.get("created_at"),
+                        "updated_at": group.get("updated_at"),
+                    }
+                )
 
             return groups
 
         except Exception as e:
             self.logger.warning(f"Failed to get groups: {e}")
             return []
 
     async def get_ticket_articles(self, ticket_id: int) -> List[Dict[str, Any]]:
         """Get articles (comments) for a ticket."""
         try:
-            response = await self._make_request("GET", f"/api/v1/ticket_articles/by_ticket/{ticket_id}")
+            response = await self._make_request(
+                "GET", f"/api/v1/ticket_articles/by_ticket/{ticket_id}"
+            )
             data = response.json()
 
             articles = []
             for article in data if isinstance(data, list) else []:
                 # Handle type field - can be string or object
@@ -349,43 +358,49 @@
                 # Handle sender field - can be string or object
                 sender = article.get("sender")
                 if isinstance(sender, dict):
                     sender = sender.get("name")
 
-                articles.append({
-                    "id": article.get("id"),
-                    "ticket_id": article.get("ticket_id"),
-                    "type": article_type,
-                    "sender": sender,
-                    "from": article.get("from"),
-                    "to": article.get("to"),
-                    "subject": article.get("subject"),
-                    "body": article.get("body"),
-                    "content_type": article.get("content_type"),
-                    "internal": article.get("internal", False),
-                    "created_by_id": article.get("created_by_id"),
-                    "created_by": article.get("created_by"),
-                    "created_at": article.get("created_at"),
-                    "updated_at": article.get("updated_at")
-                })
+                articles.append(
+                    {
+                        "id": article.get("id"),
+                        "ticket_id": article.get("ticket_id"),
+                        "type": article_type,
+                        "sender": sender,
+                        "from": article.get("from"),
+                        "to": article.get("to"),
+                        "subject": article.get("subject"),
+                        "body": article.get("body"),
+                        "content_type": article.get("content_type"),
+                        "internal": article.get("internal", False),
+                        "created_by_id": article.get("created_by_id"),
+                        "created_by": article.get("created_by"),
+                        "created_at": article.get("created_at"),
+                        "updated_at": article.get("updated_at"),
+                    }
+                )
 
             return articles
 
         except Exception as e:
             self.logger.warning(f"Failed to get articles for ticket {ticket_id}: {e}")
             return []
 
-    async def create_article(self, ticket_id: int, body: str, internal: bool = False) -> Optional[Dict[str, Any]]:
+    async def create_article(
+        self, ticket_id: int, body: str, internal: bool = False
+    ) -> Optional[Dict[str, Any]]:
         """Create an article (comment) for a ticket."""
         try:
             article_data = {
                 "ticket_id": ticket_id,
                 "body": body,
                 "type": "note",
                 "internal": internal,
             }
-            response = await self._make_request("POST", "/api/v1/ticket_articles", json=article_data)
+            response = await self._make_request(
+                "POST", "/api/v1/ticket_articles", json=article_data
+            )
             return response.json()
 
         except Exception as e:
             self.logger.error(f"Failed to create article for ticket {ticket_id}: {e}")
             return None
@@ -444,11 +459,11 @@
                 "open_tickets": open_tickets,
                 "pending_tickets": pending_tickets,
                 "closed_tickets": closed_tickets,
                 "total_users": len(users),
                 "total_groups": len(groups),
-                "recent_tickets": tickets[:10]
+                "recent_tickets": tickets[:10],
             }
 
         except Exception as e:
             self.logger.error(f"Failed to get statistics: {e}")
             return {
@@ -457,11 +472,11 @@
                 "open_tickets": 0,
                 "pending_tickets": 0,
                 "closed_tickets": 0,
                 "total_users": 0,
                 "total_groups": 0,
-                "recent_tickets": []
+                "recent_tickets": [],
             }
 
     def validate_config(self) -> List[str]:
         """Validate Zammad-specific configuration."""
         errors = super().validate_config()
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/adapters/zammad.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/main.py	2025-12-31 13:30:51.487007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/main.py	2025-12-31 13:41:33.705107+00:00
@@ -26,27 +26,27 @@
     from src.database.connection import get_db_session
     from src.models import ServiceConfig
 
     configs = []
     async for session in get_db_session():
-        result = await session.execute(
-            select(ServiceConfig).where(ServiceConfig.enabled is True)
-        )
+        result = await session.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
         services = result.scalars().all()
 
         for service in services:
-            configs.append({
-                "id": str(service.id),
-                "name": service.name,
-                "service_type": service.service_type,
-                "base_url": service.base_url,
-                "port": service.port,
-                "api_key": service.api_key,
-                "username": service.username,
-                "password": service.password,
-                "config": service.config or {},
-            })
+            configs.append(
+                {
+                    "id": str(service.id),
+                    "name": service.name,
+                    "service_type": service.service_type,
+                    "base_url": service.base_url,
+                    "port": service.port,
+                    "api_key": service.api_key,
+                    "username": service.username,
+                    "password": service.password,
+                    "config": service.config or {},
+                }
+            )
 
     return configs
 
 
 async def main():
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/main.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/main.py	2025-12-31 13:30:51.484007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/main.py	2025-12-31 13:41:33.757218+00:00
@@ -15,15 +15,11 @@
 from src.middleware.logging import LoggingMiddleware, setup_logging
 from src.routers import health
 from src.services.log_service import log_service
 
 
-async def log_error_to_db(
-    request: Request,
-    exc: Exception,
-    status_code: int = 500
-) -> None:
+async def log_error_to_db(request: Request, exc: Exception, status_code: int = 500) -> None:
     """Log error to database for visibility in web UI."""
     try:
         db_manager = get_db_manager()
         async with db_manager.session_factory() as session:
             correlation_id = getattr(request.state, "correlation_id", None)
@@ -40,11 +36,11 @@
                 extra_data={
                     "method": request.method,
                     "path": str(request.url.path),
                     "query": str(request.url.query) if request.url.query else None,
                     "status_code": status_code,
-                }
+                },
             )
     except Exception as log_err:
         # Don't let logging errors break the response
         print(f"Failed to log error to DB: {log_err}")
 
@@ -87,14 +83,11 @@
         openapi_url="/openapi.json",
         lifespan=lifespan,
     )
 
     # Middleware setup
-    app.add_middleware(
-        TrustedHostMiddleware,
-        allowed_hosts=["*"]  # Local network trust model
-    )
+    app.add_middleware(TrustedHostMiddleware, allowed_hosts=["*"])  # Local network trust model
 
     app.add_middleware(
         CORSMiddleware,
         allow_origins=settings.cors_origins,
         allow_credentials=True,
@@ -114,12 +107,12 @@
         return JSONResponse(
             status_code=exc.status_code,
             content={
                 "error": exc.detail,
                 "status_code": exc.status_code,
-                "correlation_id": getattr(request.state, "correlation_id", "unknown")
-            }
+                "correlation_id": getattr(request.state, "correlation_id", "unknown"),
+            },
         )
 
     @app.exception_handler(Exception)
     async def general_exception_handler(request, exc):
         # Log unhandled exceptions to database
@@ -127,55 +120,64 @@
         return JSONResponse(
             status_code=500,
             content={
                 "error": "Internal server error",
                 "message": str(exc) if settings.debug else "An error occurred",
-                "correlation_id": getattr(request.state, "correlation_id", "unknown")
-            }
+                "correlation_id": getattr(request.state, "correlation_id", "unknown"),
+            },
         )
 
     # Include routers
     app.include_router(health.router, tags=["Health"])
 
     # Import and include other routers
     from src.routers import config, dashboard, services, system
+
     app.include_router(dashboard.router, tags=["Dashboard"])
     app.include_router(system.router, tags=["System"])
     app.include_router(config.router, tags=["Configuration"])
     app.include_router(services.router, tags=["Services"])
 
     # Users router
     from src.routers import users
+
     app.include_router(users.router, tags=["Users"])
 
     # Groups router
     from src.routers import groups
+
     app.include_router(groups.router, tags=["Groups"])
 
     # Observability routers
     from src.routers import alerts, logs
+
     app.include_router(logs.router, tags=["Logs"])
     app.include_router(alerts.router, tags=["Alerts"])
 
     # MCP router
     from src.routers import mcp
+
     app.include_router(mcp.router, tags=["MCP"])
 
     # Training router
     from src.routers import training
+
     app.include_router(training.router, tags=["Training"])
 
     # Workers router (GPU training workers)
     from src.routers import workers
+
     app.include_router(workers.router, tags=["Workers"])
 
     # OpenAPI Tools router for Open WebUI integration
     from src.routers import openapi_tools
+
     app.include_router(openapi_tools.router)
 
     # Backup/Restore router
     from src.routers import backup
+
     app.include_router(backup.router, tags=["Backup"])
 
     # WebSocket endpoints
     from src.websocket.logs import websocket_logs_endpoint
     from src.websocket.system import handle_system_websocket
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/main.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/audiobookshelf_tools.py	2025-12-31 13:30:51.492007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/audiobookshelf_tools.py	2025-12-31 13:41:33.858045+00:00
@@ -146,14 +146,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute an Audiobookshelf tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Audiobookshelf service not configured"
-            }
+            return {"success": False, "error": "Audiobookshelf service not configured"}
 
         try:
             from src.adapters.audiobookshelf import AudiobookshelfAdapter
 
             class ServiceConfigProxy:
@@ -197,50 +194,31 @@
 
     async def _get_libraries(self, adapter) -> dict:
         """Get libraries from Audiobookshelf."""
         libraries = await adapter.get_libraries()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(libraries),
-                "libraries": libraries
-            }
-        }
+        return {"success": True, "result": {"count": len(libraries), "libraries": libraries}}
 
     async def _get_library_items(self, adapter, arguments: dict) -> dict:
         """Get library items from Audiobookshelf."""
         library_id = arguments.get("library_id")
         limit = arguments.get("limit", 50)
         page = arguments.get("page", 0)
 
-        result = await adapter.get_library_items(
-            library_id=library_id,
-            limit=limit,
-            page=page
-        )
-
-        return {
-            "success": True,
-            "result": result
-        }
+        result = await adapter.get_library_items(library_id=library_id, limit=limit, page=page)
+
+        return {"success": True, "result": result}
 
     async def _get_item(self, adapter, arguments: dict) -> dict:
         """Get a specific item from Audiobookshelf."""
         item_id = arguments.get("item_id")
         item = await adapter.get_item(item_id)
 
         if item:
-            return {
-                "success": True,
-                "result": item
-            }
+            return {"success": True, "result": item}
         else:
-            return {
-                "success": False,
-                "error": f"Item not found: {item_id}"
-            }
+            return {"success": False, "error": f"Item not found: {item_id}"}
 
     async def _search(self, adapter, arguments: dict) -> dict:
         """Search in Audiobookshelf."""
         library_id = arguments.get("library_id")
         query = arguments.get("query")
@@ -255,63 +233,44 @@
                 "library_id": library_id,
                 "books_count": len(results.get("book", [])),
                 "podcasts_count": len(results.get("podcast", [])),
                 "authors_count": len(results.get("authors", [])),
                 "series_count": len(results.get("series", [])),
-                "results": results
-            }
+                "results": results,
+            },
         }
 
     async def _get_users(self, adapter) -> dict:
         """Get users from Audiobookshelf."""
         users = await adapter.get_users()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(users),
-                "users": users
-            }
-        }
+        return {"success": True, "result": {"count": len(users), "users": users}}
 
     async def _get_listening_stats(self, adapter, arguments: dict) -> dict:
         """Get listening statistics."""
         user_id = arguments.get("user_id")
         stats = await adapter.get_listening_stats(user_id=user_id)
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _get_media_progress(self, adapter, arguments: dict) -> dict:
         """Get media progress."""
         library_item_id = arguments.get("library_item_id")
         episode_id = arguments.get("episode_id")
 
         progress = await adapter.get_media_progress(
-            library_item_id=library_item_id,
-            episode_id=episode_id
+            library_item_id=library_item_id, episode_id=episode_id
         )
 
         if progress:
-            return {
-                "success": True,
-                "result": progress
-            }
+            return {"success": True, "result": progress}
         else:
             return {
                 "success": True,
-                "result": {
-                    "message": "No progress found for this item",
-                    "progress": 0
-                }
+                "result": {"message": "No progress found for this item", "progress": 0},
             }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/audiobookshelf_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/server.py	2025-12-31 13:30:51.486007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/server.py	2025-12-31 13:41:33.867696+00:00
@@ -126,13 +126,11 @@
         params.get("clientInfo", {})
 
         return {
             "protocolVersion": self.PROTOCOL_VERSION,
             "capabilities": {
-                "tools": {
-                    "listChanged": False  # We don't support dynamic tool changes
-                },
+                "tools": {"listChanged": False},  # We don't support dynamic tool changes
             },
             "serverInfo": {
                 "name": self.SERVER_NAME,
                 "version": self.SERVER_VERSION,
             },
@@ -182,22 +180,19 @@
         if result.get("success", False):
             return {
                 "content": [
                     {
                         "type": "text",
-                        "text": json.dumps(result.get("result", {}), indent=2, default=str)
+                        "text": json.dumps(result.get("result", {}), indent=2, default=str),
                     }
                 ],
                 "isError": False,
             }
         else:
             return {
                 "content": [
-                    {
-                        "type": "text",
-                        "text": f"Error: {result.get('error', 'Unknown error')}"
-                    }
+                    {"type": "text", "text": f"Error: {result.get('error', 'Unknown error')}"}
                 ],
                 "isError": True,
             }
 
     async def _log_request_start(
@@ -213,11 +208,13 @@
 
             async with self.db_session_factory() as session:
                 request = McpRequest(
                     session_id=self._session_id,
                     tool_name=tool_name,
-                    tool_category=McpToolCategory(category) if category in [e.value for e in McpToolCategory] else McpToolCategory.SYSTEM,
+                    tool_category=McpToolCategory(category)
+                    if category in [e.value for e in McpToolCategory]
+                    else McpToolCategory.SYSTEM,
                     input_params=arguments,
                     status=McpRequestStatus.PROCESSING,
                     is_mutation=is_mutation,
                     started_at=datetime.utcnow(),
                 )
@@ -251,11 +248,11 @@
                     if result.get("success", False):
                         request.mark_completed(result.get("result", {}))
                     else:
                         request.mark_failed(
                             error_message=result.get("error", "Unknown error"),
-                            error_type=result.get("error_type", "Error")
+                            error_type=result.get("error_type", "Error"),
                         )
                     request.duration_ms = duration_ms
                     await session.commit()
         except Exception as e:
             print(f"Failed to log MCP request completion: {e}", file=sys.stderr)
@@ -284,13 +281,11 @@
         import sys
 
         while True:
             try:
                 # Read line from stdin
-                line = await asyncio.get_event_loop().run_in_executor(
-                    None, sys.stdin.readline
-                )
+                line = await asyncio.get_event_loop().run_in_executor(None, sys.stdin.readline)
 
                 if not line:
                     break
 
                 line = line.strip()
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/server.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/base.py	2025-12-31 13:30:51.490007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/base.py	2025-12-31 13:41:33.887642+00:00
@@ -6,10 +6,11 @@
 
 
 @dataclass
 class ToolParameter:
     """Definition of a tool parameter."""
+
     name: str
     description: str
     type: str  # "string", "number", "boolean", "array", "object"
     required: bool = True
     enum: Optional[List[str]] = None
@@ -17,10 +18,11 @@
 
 
 @dataclass
 class ToolDefinition:
     """Complete definition of an MCP tool."""
+
     name: str
     description: str
     parameters: List[ToolParameter] = field(default_factory=list)
     category: str = "general"
     is_mutation: bool = False  # True if the tool modifies data
@@ -51,11 +53,11 @@
             "description": self.description,
             "inputSchema": {
                 "type": "object",
                 "properties": properties,
                 "required": required,
-            }
+            },
         }
 
 
 class BaseTool(ABC):
     """Base class for MCP tool implementations."""
@@ -132,19 +134,12 @@
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a tool by name with arguments."""
         tool = self.get_tool(tool_name)
         if not tool:
-            return {
-                "success": False,
-                "error": f"Unknown tool: {tool_name}"
-            }
+            return {"success": False, "error": f"Unknown tool: {tool_name}"}
 
         try:
             result = await tool.execute(tool_name, arguments)
             return result
         except Exception as e:
-            return {
-                "success": False,
-                "error": str(e),
-                "error_type": type(e).__name__
-            }
+            return {"success": False, "error": str(e), "error_type": type(e).__name__}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/base.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/deluge_tools.py	2025-12-31 13:30:51.486007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/deluge_tools.py	2025-12-31 13:41:33.943995+00:00
@@ -97,14 +97,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Deluge tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Deluge service not configured"
-            }
+            return {"success": False, "error": "Deluge service not configured"}
 
         try:
             from src.adapters.deluge import DelugeAdapter
 
             class ServiceConfigProxy:
@@ -142,52 +139,37 @@
 
     async def _get_torrents(self, adapter) -> dict:
         """Get torrents from Deluge."""
         torrents = await adapter.get_torrents()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(torrents),
-                "torrents": torrents
-            }
-        }
+        return {"success": True, "result": {"count": len(torrents), "torrents": torrents}}
 
     async def _add_torrent(self, adapter, arguments: dict) -> dict:
         """Add a torrent."""
         magnet_or_url = arguments.get("magnet_or_url")
         result = await adapter.add_torrent(magnet_or_url)
 
-        return {
-            "success": result.get("success", False),
-            "result": result
-        }
+        return {"success": result.get("success", False), "result": result}
 
     async def _pause_torrent(self, adapter, arguments: dict) -> dict:
         """Pause a torrent."""
         torrent_id = arguments.get("torrent_id")
         success = await adapter.pause_torrent(torrent_id)
 
         return {
             "success": success,
-            "result": {
-                "torrent_id": torrent_id,
-                "action": "paused" if success else "failed"
-            }
+            "result": {"torrent_id": torrent_id, "action": "paused" if success else "failed"},
         }
 
     async def _resume_torrent(self, adapter, arguments: dict) -> dict:
         """Resume a torrent."""
         torrent_id = arguments.get("torrent_id")
         success = await adapter.resume_torrent(torrent_id)
 
         return {
             "success": success,
-            "result": {
-                "torrent_id": torrent_id,
-                "action": "resumed" if success else "failed"
-            }
+            "result": {"torrent_id": torrent_id, "action": "resumed" if success else "failed"},
         }
 
     async def _remove_torrent(self, adapter, arguments: dict) -> dict:
         """Remove a torrent."""
         torrent_id = arguments.get("torrent_id")
@@ -197,17 +179,14 @@
         return {
             "success": success,
             "result": {
                 "torrent_id": torrent_id,
                 "action": "removed" if success else "failed",
-                "data_removed": remove_data if success else False
-            }
+                "data_removed": remove_data if success else False,
+            },
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/jackett_tools.py	2025-12-31 13:30:51.488007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/jackett_tools.py	2025-12-31 13:41:33.945059+00:00
@@ -88,14 +88,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Jackett tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Jackett service not configured"
-            }
+            return {"success": False, "error": "Jackett service not configured"}
 
         try:
             from src.adapters.jackett import JackettAdapter
 
             class ServiceConfigProxy:
@@ -135,17 +132,11 @@
         if configured_only:
             indexers = await adapter.get_configured_indexers()
         else:
             indexers = await adapter.get_indexers()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(indexers),
-                "indexers": indexers
-            }
-        }
+        return {"success": True, "result": {"count": len(indexers), "indexers": indexers}}
 
     async def _search(self, adapter, arguments: dict) -> dict:
         """Search across indexers."""
         query = arguments.get("query")
         indexers_str = arguments.get("indexers")
@@ -161,38 +152,25 @@
 
         results = await adapter.search(query, indexers=indexers, categories=categories)
 
         return {
             "success": True,
-            "result": {
-                "query": query,
-                "count": len(results),
-                "results": results
-            }
+            "result": {"query": query, "count": len(results), "results": results},
         }
 
     async def _test_indexer(self, adapter, arguments: dict) -> dict:
         """Test a specific indexer."""
         indexer_id = arguments.get("indexer_id")
         result = await adapter.test_indexer(indexer_id)
 
-        return {
-            "success": True,
-            "result": result
-        }
+        return {"success": True, "result": result}
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _test_all_indexers(self, adapter) -> dict:
         """Test all configured indexers."""
         result = await adapter.test_all_indexers()
-        return {
-            "success": True,
-            "result": result
-        }
+        return {"success": True, "result": result}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/deluge_tools.py
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/jackett_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/komga_tools.py	2025-12-31 13:30:51.501007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/komga_tools.py	2025-12-31 13:41:33.980659+00:00
@@ -97,14 +97,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Komga tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Komga service not configured"
-            }
+            return {"success": False, "error": "Komga service not configured"}
 
         try:
             from src.adapters.komga import KomgaAdapter
 
             class ServiceConfigProxy:
@@ -144,45 +141,27 @@
 
     async def _get_libraries(self, adapter) -> dict:
         """Get libraries from Komga."""
         libraries = await adapter.get_libraries()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(libraries),
-                "libraries": libraries
-            }
-        }
+        return {"success": True, "result": {"count": len(libraries), "libraries": libraries}}
 
     async def _get_series(self, adapter, arguments: dict) -> dict:
         """Get series from Komga."""
         library_id = arguments.get("library_id")
         limit = arguments.get("limit", 50)
         series = await adapter.get_series(library_id=library_id, limit=limit)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(series),
-                "series": series
-            }
-        }
+        return {"success": True, "result": {"count": len(series), "series": series}}
 
     async def _get_books(self, adapter, arguments: dict) -> dict:
         """Get books from Komga."""
         series_id = arguments.get("series_id")
         limit = arguments.get("limit", 50)
         books = await adapter.get_books(series_id=series_id, limit=limit)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(books),
-                "books": books
-            }
-        }
+        return {"success": True, "result": {"count": len(books), "books": books}}
 
     async def _search(self, adapter, arguments: dict) -> dict:
         """Search in Komga."""
         query = arguments.get("query")
         results = await adapter.search(query)
@@ -191,29 +170,20 @@
             "success": True,
             "result": {
                 "query": query,
                 "series_count": len(results.get("series", [])),
                 "books_count": len(results.get("books", [])),
-                "results": results
-            }
+                "results": results,
+            },
         }
 
     async def _get_users(self, adapter) -> dict:
         """Get users from Komga."""
         users = await adapter.get_users()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(users),
-                "users": users
-            }
-        }
+        return {"success": True, "result": {"count": len(users), "users": users}}
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/komga_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/authentik_tools.py	2025-12-31 13:30:51.504007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/authentik_tools.py	2025-12-31 13:41:34.004744+00:00
@@ -163,14 +163,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute an Authentik tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Authentik service not configured"
-            }
+            return {"success": False, "error": "Authentik service not configured"}
 
         try:
             from src.adapters.authentik import AuthentikAdapter
 
             class ServiceConfigProxy:
@@ -216,15 +213,11 @@
         """Get users from Authentik."""
         search = arguments.get("search")
         is_active = arguments.get("is_active")
         limit = arguments.get("limit", 20)
 
-        result = await adapter.get_users(
-            page_size=limit,
-            search=search,
-            is_active=is_active
-        )
+        result = await adapter.get_users(page_size=limit, search=search, is_active=is_active)
 
         return {
             "success": True,
             "result": {
                 "count": len(result.get("users", [])),
@@ -236,15 +229,18 @@
                         "name": user.get("name"),
                         "email": user.get("email"),
                         "is_active": user.get("is_active"),
                         "is_superuser": user.get("is_superuser"),
                         "last_login": user.get("last_login"),
-                        "groups": [g.get("name") if isinstance(g, dict) else g for g in user.get("groups", [])],
+                        "groups": [
+                            g.get("name") if isinstance(g, dict) else g
+                            for g in user.get("groups", [])
+                        ],
                     }
                     for user in result.get("users", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_user(self, adapter, arguments: dict) -> dict:
         """Get a specific user by ID."""
         user_pk = arguments.get("user_pk")
@@ -267,29 +263,22 @@
                 "is_staff": user.get("is_staff"),
                 "date_joined": user.get("date_joined"),
                 "last_login": user.get("last_login"),
                 "groups": user.get("groups", []),
                 "attributes": user.get("attributes", {}),
-            }
+            },
         }
 
     async def _search_users(self, adapter, arguments: dict) -> dict:
         """Search for users."""
         query = arguments.get("query")
         if not query:
             return {"success": False, "error": "query is required"}
 
         users = await adapter.search_users(query)
 
-        return {
-            "success": True,
-            "result": {
-                "query": query,
-                "count": len(users),
-                "users": users
-            }
-        }
+        return {"success": True, "result": {"query": query, "count": len(users), "users": users}}
 
     async def _get_groups(self, adapter, arguments: dict) -> dict:
         """Get groups from Authentik."""
         limit = arguments.get("limit", 20)
 
@@ -307,12 +296,12 @@
                         "is_superuser": group.get("is_superuser"),
                         "parent": group.get("parent"),
                         "user_count": len(group.get("users_obj", [])),
                     }
                     for group in result.get("groups", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_applications(self, adapter, arguments: dict) -> dict:
         """Get applications from Authentik."""
         limit = arguments.get("limit", 20)
@@ -332,25 +321,21 @@
                         "launch_url": app.get("launch_url"),
                         "description": app.get("meta_description"),
                         "group": app.get("group"),
                     }
                     for app in result.get("applications", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_events(self, adapter, arguments: dict) -> dict:
         """Get audit events from Authentik."""
         action = arguments.get("action")
         username = arguments.get("username")
         limit = arguments.get("limit", 20)
 
-        result = await adapter.get_events(
-            page_size=limit,
-            action=action,
-            username=username
-        )
+        result = await adapter.get_events(page_size=limit, action=action, username=username)
 
         return {
             "success": True,
             "result": {
                 "count": len(result.get("events", [])),
@@ -359,17 +344,19 @@
                     {
                         "pk": event.get("pk"),
                         "action": event.get("action"),
                         "result": event.get("result"),
                         "created": event.get("created"),
-                        "user": event.get("user", {}).get("username") if isinstance(event.get("user"), dict) else event.get("user"),
+                        "user": event.get("user", {}).get("username")
+                        if isinstance(event.get("user"), dict)
+                        else event.get("user"),
                         "client_ip": event.get("client_ip"),
                         "app": event.get("app"),
                     }
                     for event in result.get("events", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get Authentik statistics."""
         stats = await adapter.get_statistics()
@@ -389,16 +376,18 @@
                     "failed_logins": stats.get("user_activity", {}).get("failed_logins", 0),
                 },
                 "recent_events": [
                     {
                         "action": event.get("action"),
-                        "user": event.get("user", {}).get("username") if isinstance(event.get("user"), dict) else None,
+                        "user": event.get("user", {}).get("username")
+                        if isinstance(event.get("user"), dict)
+                        else None,
                         "created": event.get("created"),
                     }
                     for event in stats.get("recent_events", [])[:5]
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_server_info(self, adapter) -> dict:
         """Get Authentik server information."""
         info = await adapter.get_service_info()
@@ -409,11 +398,11 @@
                 "service": info.get("service"),
                 "version": info.get("version"),
                 "version_latest": info.get("version_latest"),
                 "outdated": info.get("outdated", False),
                 "current_user": info.get("current_user", {}),
-            }
+            },
         }
 
     async def _deactivate_user(self, adapter, arguments: dict) -> dict:
         """Deactivate a user account."""
         user_pk = arguments.get("user_pk")
@@ -430,11 +419,11 @@
                 "success": True,
                 "result": {
                     "message": f"User '{user.get('username')}' is already inactive",
                     "user_pk": user_pk,
                     "was_active": False,
-                }
+                },
             }
 
         success = await adapter.deactivate_user(int(user_pk))
 
         if success:
@@ -442,12 +431,9 @@
                 "success": True,
                 "result": {
                     "message": f"User '{user.get('username')}' has been deactivated",
                     "user_pk": user_pk,
                     "username": user.get("username"),
-                }
+                },
             }
         else:
-            return {
-                "success": False,
-                "error": f"Failed to deactivate user {user_pk}"
-            }
+            return {"success": False, "error": f"Failed to deactivate user {user_pk}"}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/authentik_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/openwebui_tools.py	2025-12-31 13:30:51.470972+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/openwebui_tools.py	2025-12-31 13:41:34.049442+00:00
@@ -85,14 +85,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute an Open WebUI tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Open WebUI service not configured"
-            }
+            return {"success": False, "error": "Open WebUI service not configured"}
 
         try:
             # Import adapter here to avoid circular imports
             from src.adapters.openwebui import OpenWebUIAdapter
 
@@ -138,23 +135,20 @@
             "result": {
                 "service": info.get("service"),
                 "version": info.get("version"),
                 "models_available": info.get("models_available"),
                 "current_user": info.get("current_user"),
-            }
+            },
         }
 
     async def _get_users(self, adapter, arguments: dict) -> dict:
         """Get Open WebUI users."""
         limit = arguments.get("limit", 50)
         result = await adapter.get_users(limit=limit)
 
         if "error" in result:
-            return {
-                "success": False,
-                "error": result.get("error", "Failed to get users")
-            }
+            return {"success": False, "error": result.get("error", "Failed to get users")}
 
         return {
             "success": True,
             "result": {
                 "count": result.get("count", 0),
@@ -166,12 +160,12 @@
                         "role": user.get("role"),
                         "created_at": user.get("created_at"),
                         "last_active_at": user.get("last_active_at"),
                     }
                     for user in result.get("users", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_models(self, adapter) -> dict:
         """Get available AI models."""
         models = await adapter.get_models()
@@ -184,34 +178,28 @@
                         "id": model.get("id"),
                         "name": model.get("name"),
                         "owned_by": model.get("owned_by"),
                     }
                     for model in models
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_chats(self, adapter, arguments: dict) -> dict:
         """Get chat history."""
         limit = arguments.get("limit", 20)
         result = await adapter.get_chats(limit=limit)
 
         return {
             "success": True,
-            "result": {
-                "count": result.get("count", 0),
-                "chats": result.get("chats", [])
-            }
+            "result": {"count": result.get("count", 0), "chats": result.get("chats", [])},
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get Open WebUI statistics."""
         stats = await adapter.get_statistics()
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _search_users(self, adapter, arguments: dict) -> dict:
         """Search for users."""
         query = arguments.get("query", "")
         if not query:
@@ -230,8 +218,8 @@
                         "email": user.get("email"),
                         "name": user.get("name"),
                         "role": user.get("role"),
                     }
                     for user in users
-                ]
-            }
-        }
+                ],
+            },
+        }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/openwebui_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/prowlarr_tools.py	2025-12-31 13:30:51.497007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/prowlarr_tools.py	2025-12-31 13:41:34.103090+00:00
@@ -97,14 +97,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Prowlarr tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Prowlarr service not configured"
-            }
+            return {"success": False, "error": "Prowlarr service not configured"}
 
         try:
             from src.adapters.prowlarr import ProwlarrAdapter
 
             class ServiceConfigProxy:
@@ -144,17 +141,11 @@
 
     async def _get_indexers(self, adapter) -> dict:
         """Get indexers from Prowlarr."""
         indexers = await adapter.get_indexers()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(indexers),
-                "indexers": indexers
-            }
-        }
+        return {"success": True, "result": {"count": len(indexers), "indexers": indexers}}
 
     async def _search(self, adapter, arguments: dict) -> dict:
         """Search across indexers."""
         query = arguments.get("query")
         categories_str = arguments.get("categories")
@@ -166,61 +157,39 @@
 
         results = await adapter.search(query, categories=categories, limit=limit)
 
         return {
             "success": True,
-            "result": {
-                "query": query,
-                "count": len(results),
-                "results": results
-            }
+            "result": {"query": query, "count": len(results), "results": results},
         }
 
     async def _get_indexer_stats(self, adapter) -> dict:
         """Get indexer statistics."""
         stats = await adapter.get_indexer_stats()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _get_applications(self, adapter) -> dict:
         """Get connected applications."""
         apps = await adapter.get_applications()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(apps),
-                "applications": apps
-            }
-        }
+        return {"success": True, "result": {"count": len(apps), "applications": apps}}
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _test_indexer(self, adapter, arguments: dict) -> dict:
         """Test a specific indexer."""
         indexer_id = arguments.get("indexer_id")
         if not indexer_id:
             return {"success": False, "error": "indexer_id is required"}
 
         result = await adapter.test_indexer(int(indexer_id))
-        return {
-            "success": result.get("success", False),
-            "result": result
-        }
+        return {"success": result.get("success", False), "result": result}
 
     async def _test_all_indexers(self, adapter) -> dict:
         """Test all enabled indexers."""
         result = await adapter.test_all_indexers()
-        return {
-            "success": True,
-            "result": result
-        }
+        return {"success": True, "result": result}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/prowlarr_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/overseerr_tools.py	2025-12-31 13:30:51.507007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/overseerr_tools.py	2025-12-31 13:41:34.146776+00:00
@@ -149,14 +149,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute an Overseerr tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Overseerr service not configured"
-            }
+            return {"success": False, "error": "Overseerr service not configured"}
 
         try:
             from src.adapters.overseerr import OverseerrAdapter
 
             # Create a mock ServiceConfig object for the adapter
@@ -216,18 +213,26 @@
                 "count": len(results),
                 "items": [
                     {
                         "title": item.get("title") or item.get("name"),
                         "type": "movie" if item.get("mediaType") == "movie" else "tv",
-                        "year": item.get("releaseDate", "")[:4] if item.get("releaseDate") else item.get("firstAirDate", "")[:4] if item.get("firstAirDate") else None,
-                        "overview": (item.get("overview", "")[:200] + "...") if item.get("overview") and len(item.get("overview", "")) > 200 else item.get("overview"),
+                        "year": item.get("releaseDate", "")[:4]
+                        if item.get("releaseDate")
+                        else item.get("firstAirDate", "")[:4]
+                        if item.get("firstAirDate")
+                        else None,
+                        "overview": (item.get("overview", "")[:200] + "...")
+                        if item.get("overview") and len(item.get("overview", "")) > 200
+                        else item.get("overview"),
                         "tmdb_id": item.get("id"),
-                        "status": item.get("mediaInfo", {}).get("status") if item.get("mediaInfo") else "not_requested",
+                        "status": item.get("mediaInfo", {}).get("status")
+                        if item.get("mediaInfo")
+                        else "not_requested",
                     }
                     for item in results[:10]
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_requests(self, adapter, arguments: dict) -> dict:
         """Get media requests."""
         status = arguments.get("status")
@@ -250,12 +255,12 @@
                         "status": req.get("status_name"),
                         "requested_by": req.get("requested_by"),
                         "requested_at": req.get("created_at"),
                     }
                     for req in requests_list
-                ]
-            }
+                ],
+            },
         }
 
     async def _request_media(self, adapter, arguments: dict) -> dict:
         """Request new media."""
         from src.adapters.overseerr import MediaType
@@ -269,47 +274,36 @@
 
         # First search for the media
         results = await adapter.search_media(title, media_type=media_type)
 
         if not results:
-            return {
-                "success": False,
-                "error": f"No {media_type} found with title '{title}'"
-            }
+            return {"success": False, "error": f"No {media_type} found with title '{title}'"}
 
         media = results[0]
         tmdb_id = media.get("id")
 
         # Check if already available or requested
         media_info = media.get("mediaInfo")
         if media_info:
             status = media_info.get("status")
             if status == 5:  # Available
-                return {
-                    "success": False,
-                    "error": f"'{title}' is already available in the library"
-                }
+                return {"success": False, "error": f"'{title}' is already available in the library"}
             elif status in [2, 3, 4]:  # Pending, Processing, Partially Available
-                return {
-                    "success": False,
-                    "error": f"'{title}' has already been requested"
-                }
+                return {"success": False, "error": f"'{title}' has already been requested"}
 
         # Create the request
         result = await adapter.request_media(
-            tmdb_id=tmdb_id,
-            media_type=media_type,
-            seasons=seasons if media_type == "tv" else None
+            tmdb_id=tmdb_id, media_type=media_type, seasons=seasons if media_type == "tv" else None
         )
 
         return {
             "success": True,
             "result": {
                 "message": f"Successfully requested '{title}'",
                 "request_id": result.get("id"),
                 "status": "pending",
-            }
+            },
         }
 
     async def _get_trending(self, adapter, arguments: dict) -> dict:
         """Get trending media."""
         media_type = arguments.get("media_type", "all")
@@ -322,17 +316,25 @@
             "result": {
                 "trending": [
                     {
                         "title": item.get("title") or item.get("name"),
                         "type": "movie" if item.get("mediaType") == "movie" else "tv",
-                        "year": item.get("releaseDate", "")[:4] if item.get("releaseDate") else item.get("firstAirDate", "")[:4] if item.get("firstAirDate") else None,
-                        "overview": (item.get("overview", "")[:150] + "...") if item.get("overview") and len(item.get("overview", "")) > 150 else item.get("overview"),
-                        "available": item.get("mediaInfo", {}).get("status") == 5 if item.get("mediaInfo") else False,
+                        "year": item.get("releaseDate", "")[:4]
+                        if item.get("releaseDate")
+                        else item.get("firstAirDate", "")[:4]
+                        if item.get("firstAirDate")
+                        else None,
+                        "overview": (item.get("overview", "")[:150] + "...")
+                        if item.get("overview") and len(item.get("overview", "")) > 150
+                        else item.get("overview"),
+                        "available": item.get("mediaInfo", {}).get("status") == 5
+                        if item.get("mediaInfo")
+                        else False,
                     }
                     for item in items
                 ]
-            }
+            },
         }
 
     async def _check_availability(self, adapter, arguments: dict) -> dict:
         """Check media availability."""
         title = arguments.get("title")
@@ -342,22 +344,25 @@
 
         # Filter by year if provided
         if year:
             filtered = []
             for item in results:
-                item_year = item.get("releaseDate", "")[:4] if item.get("releaseDate") else item.get("firstAirDate", "")[:4] if item.get("firstAirDate") else None
+                item_year = (
+                    item.get("releaseDate", "")[:4]
+                    if item.get("releaseDate")
+                    else item.get("firstAirDate", "")[:4]
+                    if item.get("firstAirDate")
+                    else None
+                )
                 if item_year and int(item_year) == year:
                     filtered.append(item)
             results = filtered or results  # Fall back to unfiltered if no year match
 
         if not results:
             return {
                 "success": True,
-                "result": {
-                    "found": False,
-                    "message": f"No media found with title '{title}'"
-                }
+                "result": {"found": False, "message": f"No media found with title '{title}'"},
             }
 
         media = results[0]
         media_info = media.get("mediaInfo")
 
@@ -377,15 +382,19 @@
             "success": True,
             "result": {
                 "found": True,
                 "title": media.get("title") or media.get("name"),
                 "type": "movie" if media.get("mediaType") == "movie" else "tv",
-                "year": media.get("releaseDate", "")[:4] if media.get("releaseDate") else media.get("firstAirDate", "")[:4] if media.get("firstAirDate") else None,
+                "year": media.get("releaseDate", "")[:4]
+                if media.get("releaseDate")
+                else media.get("firstAirDate", "")[:4]
+                if media.get("firstAirDate")
+                else None,
                 "status": status,
                 "available": status == "available",
                 "can_request": status == "not_requested",
-            }
+            },
         }
 
     async def _get_users(self, adapter) -> dict:
         """Get Overseerr users."""
         users = await adapter.get_users()
@@ -402,12 +411,12 @@
                         "user_type": user.get("user_type"),
                         "request_count": user.get("request_count", 0),
                         "created_at": user.get("created_at"),
                     }
                     for user in users
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get Overseerr statistics."""
         stats = await adapter.get_statistics()
@@ -419,7 +428,7 @@
                 "pending_requests": stats.get("pending_requests", 0),
                 "approved_requests": stats.get("approved_requests", 0),
                 "available_requests": stats.get("available_requests", 0),
                 "declined_requests": stats.get("declined_requests", 0),
                 "total_users": stats.get("total_users", 0),
-            }
-        }
+            },
+        }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/overseerr_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/plex_tools.py	2025-12-31 13:30:51.468007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/plex_tools.py	2025-12-31 13:41:34.153114+00:00
@@ -118,14 +118,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Plex tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Plex service not configured"
-            }
+            return {"success": False, "error": "Plex service not configured"}
 
         try:
             # Import adapter here to avoid circular imports
             from src.adapters.plex import PlexAdapter
 
@@ -176,11 +173,11 @@
                         "key": lib.get("key"),
                         "count": lib.get("count", 0),
                     }
                     for lib in libraries
                 ]
-            }
+            },
         }
 
     async def _search_media(self, adapter, arguments: dict) -> dict:
         """Search for media in Plex."""
         query = arguments.get("query")
@@ -197,17 +194,21 @@
                 "items": [
                     {
                         "title": item.get("title"),
                         "type": item.get("type"),
                         "year": item.get("year"),
-                        "summary": item.get("summary", "")[:200] + "..." if item.get("summary") and len(item.get("summary", "")) > 200 else item.get("summary"),
+                        "summary": item.get("summary", "")[:200] + "..."
+                        if item.get("summary") and len(item.get("summary", "")) > 200
+                        else item.get("summary"),
                         "rating": item.get("rating"),
-                        "duration_minutes": item.get("duration", 0) // 60000 if item.get("duration") else None,
+                        "duration_minutes": item.get("duration", 0) // 60000
+                        if item.get("duration")
+                        else None,
                     }
                     for item in results[:limit]
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_recently_added(self, adapter, arguments: dict) -> dict:
         """Get recently added media."""
         library_name = arguments.get("library_name")
@@ -226,12 +227,12 @@
                         "year": item.get("year"),
                         "added_at": item.get("addedAt"),
                         "library": item.get("librarySectionTitle"),
                     }
                     for item in items
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_on_deck(self, adapter, arguments: dict) -> dict:
         """Get on deck items."""
         limit = arguments.get("limit", 10)
@@ -247,15 +248,19 @@
                         "title": item.get("title"),
                         "grandparent_title": item.get("grandparentTitle"),  # Show name for episodes
                         "type": item.get("type"),
                         "view_offset": item.get("viewOffset"),
                         "duration": item.get("duration"),
-                        "progress_percent": round((item.get("viewOffset", 0) / item.get("duration", 1)) * 100) if item.get("duration") else 0,
+                        "progress_percent": round(
+                            (item.get("viewOffset", 0) / item.get("duration", 1)) * 100
+                        )
+                        if item.get("duration")
+                        else 0,
                     }
                     for item in items
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_media_details(self, adapter, arguments: dict) -> dict:
         """Get details for a specific media item."""
         title = arguments.get("title")
@@ -269,11 +274,12 @@
             results = [r for r in results if r.get("year") == year]
 
         if not results:
             return {
                 "success": False,
-                "error": f"No media found with title '{title}'" + (f" and year {year}" if year else "")
+                "error": f"No media found with title '{title}'"
+                + (f" and year {year}" if year else ""),
             }
 
         item = results[0]
 
         return {
@@ -283,17 +289,19 @@
                 "type": item.get("type"),
                 "year": item.get("year"),
                 "summary": item.get("summary"),
                 "rating": item.get("rating"),
                 "content_rating": item.get("contentRating"),
-                "duration_minutes": item.get("duration", 0) // 60000 if item.get("duration") else None,
+                "duration_minutes": item.get("duration", 0) // 60000
+                if item.get("duration")
+                else None,
                 "genres": item.get("Genre", []),
                 "directors": item.get("Director", []),
                 "actors": item.get("Role", [])[:5],  # Limit actors
                 "studio": item.get("studio"),
                 "added_at": item.get("addedAt"),
-            }
+            },
         }
 
     async def _get_active_sessions(self, adapter) -> dict:
         """Get active streaming sessions."""
         sessions = await adapter.get_sessions()
@@ -308,11 +316,15 @@
                         "title": session.get("title"),
                         "grandparent_title": session.get("grandparentTitle"),
                         "type": session.get("type"),
                         "player": session.get("Player", {}).get("title"),
                         "state": session.get("Player", {}).get("state"),
-                        "progress_percent": round((session.get("viewOffset", 0) / session.get("duration", 1)) * 100) if session.get("duration") else 0,
+                        "progress_percent": round(
+                            (session.get("viewOffset", 0) / session.get("duration", 1)) * 100
+                        )
+                        if session.get("duration")
+                        else 0,
                     }
                     for session in sessions
-                ]
-            }
-        }
+                ],
+            },
+        }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/plex_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/romm_tools.py	2025-12-31 13:30:51.464007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/romm_tools.py	2025-12-31 13:41:34.186740+00:00
@@ -83,14 +83,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a RomM tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "RomM service not configured"
-            }
+            return {"success": False, "error": "RomM service not configured"}
 
         try:
             from src.adapters.romm import RommAdapter
 
             class ServiceConfigProxy:
@@ -130,73 +127,42 @@
 
     async def _get_platforms(self, adapter) -> dict:
         """Get platforms from RomM."""
         platforms = await adapter.get_platforms()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(platforms),
-                "platforms": platforms
-            }
-        }
+        return {"success": True, "result": {"count": len(platforms), "platforms": platforms}}
 
     async def _get_roms(self, adapter, arguments: dict) -> dict:
         """Get ROMs from RomM."""
         platform_id = arguments.get("platform_id")
         limit = arguments.get("limit", 50)
         roms = await adapter.get_roms(platform_id=platform_id, limit=limit)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(roms),
-                "roms": roms
-            }
-        }
+        return {"success": True, "result": {"count": len(roms), "roms": roms}}
 
     async def _search_roms(self, adapter, arguments: dict) -> dict:
         """Search for ROMs."""
         query = arguments.get("query")
         results = await adapter.search_roms(query)
 
         return {
             "success": True,
-            "result": {
-                "query": query,
-                "count": len(results),
-                "results": results
-            }
+            "result": {"query": query, "count": len(results), "results": results},
         }
 
     async def _get_collections(self, adapter) -> dict:
         """Get collections from RomM."""
         collections = await adapter.get_collections()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(collections),
-                "collections": collections
-            }
-        }
+        return {"success": True, "result": {"count": len(collections), "collections": collections}}
 
     async def _get_users(self, adapter) -> dict:
         """Get users from RomM."""
         users = await adapter.get_users()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(users),
-                "users": users
-            }
-        }
+        return {"success": True, "result": {"count": len(users), "users": users}}
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/romm_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/radarr_tools.py	2025-12-31 13:30:51.472007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/radarr_tools.py	2025-12-31 13:41:34.219952+00:00
@@ -108,14 +108,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Radarr tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Radarr service not configured"
-            }
+            return {"success": False, "error": "Radarr service not configured"}
 
         try:
             from src.adapters.radarr import RadarrAdapter
 
             class ServiceConfigProxy:
@@ -158,94 +155,65 @@
     async def _get_movies(self, adapter, arguments: dict) -> dict:
         """Get movies from Radarr."""
         limit = arguments.get("limit", 50)
         movies = await adapter.get_movies(limit=limit)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(movies),
-                "movies": movies
-            }
-        }
+        return {"success": True, "result": {"count": len(movies), "movies": movies}}
 
     async def _search_movie(self, adapter, arguments: dict) -> dict:
         """Search for a movie."""
         query = arguments.get("query")
         results = await adapter.search_movie(query)
 
         return {
             "success": True,
-            "result": {
-                "query": query,
-                "count": len(results),
-                "results": results
-            }
+            "result": {"query": query, "count": len(results), "results": results},
         }
 
     async def _get_queue(self, adapter) -> dict:
         """Get download queue."""
         queue = await adapter.get_queue()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(queue),
-                "queue": queue
-            }
-        }
+        return {"success": True, "result": {"count": len(queue), "queue": queue}}
 
     async def _get_calendar(self, adapter, arguments: dict) -> dict:
         """Get calendar."""
         days = arguments.get("days", 7)
         calendar = await adapter.get_calendar(days=days)
 
         return {
             "success": True,
-            "result": {
-                "days": days,
-                "count": len(calendar),
-                "upcoming": calendar
-            }
+            "result": {"days": days, "count": len(calendar), "upcoming": calendar},
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _get_indexers(self, adapter) -> dict:
         """Get list of indexers."""
         indexers = await adapter.get_indexers()
 
         return {
             "success": True,
             "result": {
                 "count": len(indexers),
                 "enabled_count": sum(1 for i in indexers if i.get("enable")),
-                "indexers": indexers
-            }
+                "indexers": indexers,
+            },
         }
 
     async def _test_indexer(self, adapter, arguments: dict) -> dict:
         """Test a specific indexer."""
         indexer_id = arguments.get("indexer_id")
         if not indexer_id:
             return {"success": False, "error": "indexer_id is required"}
 
         result = await adapter.test_indexer(int(indexer_id))
-        return {
-            "success": result.get("success", False),
-            "result": result
-        }
+        return {"success": result.get("success", False), "result": result}
 
     async def _test_all_indexers(self, adapter) -> dict:
         """Test all enabled indexers."""
         result = await adapter.test_all_indexers()
-        return {
-            "success": True,
-            "result": result
-        }
+        return {"success": True, "result": result}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/radarr_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/sonarr_tools.py	2025-12-31 13:30:51.496007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/sonarr_tools.py	2025-12-31 13:41:34.321213+00:00
@@ -108,14 +108,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Sonarr tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Sonarr service not configured"
-            }
+            return {"success": False, "error": "Sonarr service not configured"}
 
         try:
             from src.adapters.sonarr import SonarrAdapter
 
             class ServiceConfigProxy:
@@ -158,94 +155,65 @@
     async def _get_series(self, adapter, arguments: dict) -> dict:
         """Get series from Sonarr."""
         limit = arguments.get("limit", 50)
         series = await adapter.get_series(limit=limit)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(series),
-                "series": series
-            }
-        }
+        return {"success": True, "result": {"count": len(series), "series": series}}
 
     async def _search_series(self, adapter, arguments: dict) -> dict:
         """Search for a series."""
         query = arguments.get("query")
         results = await adapter.search_series(query)
 
         return {
             "success": True,
-            "result": {
-                "query": query,
-                "count": len(results),
-                "results": results
-            }
+            "result": {"query": query, "count": len(results), "results": results},
         }
 
     async def _get_queue(self, adapter) -> dict:
         """Get download queue."""
         queue = await adapter.get_queue()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(queue),
-                "queue": queue
-            }
-        }
+        return {"success": True, "result": {"count": len(queue), "queue": queue}}
 
     async def _get_calendar(self, adapter, arguments: dict) -> dict:
         """Get calendar."""
         days = arguments.get("days", 7)
         calendar = await adapter.get_calendar(days=days)
 
         return {
             "success": True,
-            "result": {
-                "days": days,
-                "count": len(calendar),
-                "upcoming": calendar
-            }
+            "result": {"days": days, "count": len(calendar), "upcoming": calendar},
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _get_indexers(self, adapter) -> dict:
         """Get list of indexers."""
         indexers = await adapter.get_indexers()
 
         return {
             "success": True,
             "result": {
                 "count": len(indexers),
                 "enabled_count": sum(1 for i in indexers if i.get("enable")),
-                "indexers": indexers
-            }
+                "indexers": indexers,
+            },
         }
 
     async def _test_indexer(self, adapter, arguments: dict) -> dict:
         """Test a specific indexer."""
         indexer_id = arguments.get("indexer_id")
         if not indexer_id:
             return {"success": False, "error": "indexer_id is required"}
 
         result = await adapter.test_indexer(int(indexer_id))
-        return {
-            "success": result.get("success", False),
-            "result": result
-        }
+        return {"success": result.get("success", False), "result": result}
 
     async def _test_all_indexers(self, adapter) -> dict:
         """Test all enabled indexers."""
         result = await adapter.test_all_indexers()
-        return {
-            "success": True,
-            "result": result
-        }
+        return {"success": True, "result": result}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/sonarr_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/wikijs_tools.py	2025-12-31 13:30:51.499007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/wikijs_tools.py	2025-12-31 13:41:34.362759+00:00
@@ -169,14 +169,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a WikiJS tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "WikiJS service not configured"
-            }
+            return {"success": False, "error": "WikiJS service not configured"}
 
         try:
             from src.adapters.wikijs import WikiJSAdapter
 
             class ServiceConfigProxy:
@@ -223,18 +220,11 @@
         limit = arguments.get("limit", 50)
         locale = arguments.get("locale", "en")
 
         pages = await adapter.get_pages(limit=limit, locale=locale)
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(pages),
-                "locale": locale,
-                "pages": pages
-            }
-        }
+        return {"success": True, "result": {"count": len(pages), "locale": locale, "pages": pages}}
 
     async def _get_page(self, adapter, arguments: dict) -> dict:
         """Get a specific page from WikiJS."""
         page_id = arguments.get("page_id")
 
@@ -242,19 +232,13 @@
             return {"success": False, "error": "page_id is required"}
 
         page = await adapter.get_page(int(page_id))
 
         if page:
-            return {
-                "success": True,
-                "result": page
-            }
+            return {"success": True, "result": page}
         else:
-            return {
-                "success": False,
-                "error": f"Page not found: {page_id}"
-            }
+            return {"success": False, "error": f"Page not found: {page_id}"}
 
     async def _search(self, adapter, arguments: dict) -> dict:
         """Search in WikiJS."""
         query = arguments.get("query")
         locale = arguments.get("locale", "en")
@@ -269,12 +253,12 @@
             "result": {
                 "query": query,
                 "locale": locale,
                 "total": results.get("total", 0),
                 "suggestions": results.get("suggestions", []),
-                "results": results.get("results", [])
-            }
+                "results": results.get("results", []),
+            },
         }
 
     async def _get_page_tree(self, adapter, arguments: dict) -> dict:
         """Get page tree from WikiJS."""
         parent_id = int(arguments.get("parent_id", 0))
@@ -282,50 +266,30 @@
 
         tree = await adapter.get_page_tree(parent_id=parent_id, locale=locale)
 
         return {
             "success": True,
-            "result": {
-                "parent_id": parent_id,
-                "locale": locale,
-                "count": len(tree),
-                "tree": tree
-            }
+            "result": {"parent_id": parent_id, "locale": locale, "count": len(tree), "tree": tree},
         }
 
     async def _get_tags(self, adapter) -> dict:
         """Get tags from WikiJS."""
         tags = await adapter.get_tags()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(tags),
-                "tags": tags
-            }
-        }
+        return {"success": True, "result": {"count": len(tags), "tags": tags}}
 
     async def _get_users(self, adapter) -> dict:
         """Get users from WikiJS."""
         users = await adapter.get_users()
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(users),
-                "users": users
-            }
-        }
+        return {"success": True, "result": {"count": len(users), "users": users}}
 
     async def _get_statistics(self, adapter) -> dict:
         """Get statistics from WikiJS."""
         stats = await adapter.get_statistics()
 
-        return {
-            "success": True,
-            "result": stats
-        }
+        return {"success": True, "result": stats}
 
     async def _create_page(self, adapter, arguments: dict) -> dict:
         """Create a page in WikiJS."""
         path = arguments.get("path")
         title = arguments.get("title")
@@ -344,13 +308,13 @@
             path=path,
             title=title,
             content=content,
             description=description,
             locale=locale,
-            tags=tags
+            tags=tags,
         )
 
         return {
             "success": result.get("success", False),
             "result": result if result.get("success") else None,
-            "error": result.get("error") if not result.get("success") else None
+            "error": result.get("error") if not result.get("success") else None,
         }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/wikijs_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/correlation_id.py	2025-12-31 13:30:51.454007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/correlation_id.py	2025-12-31 13:41:34.383952+00:00
@@ -9,21 +9,19 @@
 
 class CorrelationIdMiddleware(BaseHTTPMiddleware):
     """Middleware to add correlation ID to each request."""
 
     async def dispatch(
-        self,
-        request: Request,
-        call_next: Callable[[Request], Response]
+        self, request: Request, call_next: Callable[[Request], Response]
     ) -> Response:
         """Add correlation ID to request state and response headers."""
 
         # Get or generate correlation ID
         correlation_id = (
-            request.headers.get("X-Correlation-ID") or
-            request.headers.get("X-Request-ID") or
-            str(uuid.uuid4())
+            request.headers.get("X-Correlation-ID")
+            or request.headers.get("X-Request-ID")
+            or str(uuid.uuid4())
         )
 
         # Add to request state
         request.state.correlation_id = correlation_id
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/correlation_id.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/logging.py	2025-12-31 13:30:51.456007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/logging.py	2025-12-31 13:41:34.450769+00:00
@@ -70,30 +70,30 @@
     request_id: Optional[str] = None,
     extra_data: Optional[dict] = None,
     duration_ms: Optional[float] = None,
 ):
     """Queue a log entry for database persistence."""
-    _log_queue.append({
-        "level": level,
-        "message": message,
-        "source": source,
-        "component": component,
-        "correlation_id": correlation_id,
-        "request_id": request_id,
-        "extra_data": extra_data or {},
-        "duration_ms": int(duration_ms) if duration_ms else None,
-        "logged_at": datetime.utcnow(),
-    })
+    _log_queue.append(
+        {
+            "level": level,
+            "message": message,
+            "source": source,
+            "component": component,
+            "correlation_id": correlation_id,
+            "request_id": request_id,
+            "extra_data": extra_data or {},
+            "duration_ms": int(duration_ms) if duration_ms else None,
+            "logged_at": datetime.utcnow(),
+        }
+    )
 
 
 class LoggingMiddleware(BaseHTTPMiddleware):
     """Middleware to log HTTP requests and responses."""
 
     async def dispatch(
-        self,
-        request: Request,
-        call_next: Callable[[Request], Response]
+        self, request: Request, call_next: Callable[[Request], Response]
     ) -> Response:
         """Log request and response details."""
         # Start log persistence task if not running
         start_log_persistence()
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/middleware/logging.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/system_tools.py	2025-12-31 13:30:51.481659+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/system_tools.py	2025-12-31 13:41:34.457102+00:00
@@ -162,11 +162,11 @@
         import psutil
 
         # Get basic system health
         cpu_percent = psutil.cpu_percent(interval=0.1)
         memory = psutil.virtual_memory()
-        disk = psutil.disk_usage('/')
+        disk = psutil.disk_usage("/")
 
         health_status = "healthy"
         issues = []
 
         if cpu_percent > 90:
@@ -191,11 +191,11 @@
                 result = await session.execute(
                     select(ServiceConfig).where(ServiceConfig.enabled is True)
                 )
                 services = result.scalars().all()
                 for svc in services:
-                    status = svc.status.value if hasattr(svc.status, 'value') else str(svc.status)
+                    status = svc.status.value if hasattr(svc.status, "value") else str(svc.status)
                     if status == "active":
                         service_status["active"] += 1
                     elif status == "error":
                         service_status["error"] += 1
                         if health_status == "healthy":
@@ -215,22 +215,22 @@
                     "cpu_usage": f"{cpu_percent}%",
                     "memory_usage": f"{memory.percent}%",
                     "disk_usage": f"{disk.percent}%",
                 },
                 "services": service_status,
-            }
+            },
         }
 
     async def _get_metrics(self) -> dict:
         """Get current system metrics."""
         import time
 
         import psutil
 
         cpu_percent = psutil.cpu_percent(interval=0.1)
         memory = psutil.virtual_memory()
-        disk = psutil.disk_usage('/')
+        disk = psutil.disk_usage("/")
         network = psutil.net_io_counters()
         boot_time = psutil.boot_time()
         uptime = time.time() - boot_time
 
         # Format uptime
@@ -263,11 +263,11 @@
                     "bytes_recv": network.bytes_recv,
                     "sent_gb": round(network.bytes_sent / (1024**3), 2),
                     "recv_gb": round(network.bytes_recv / (1024**3), 2),
                 },
                 "uptime": uptime_str,
-            }
+            },
         }
 
     async def _get_services(self, arguments: dict) -> dict:
         """Get list of configured services."""
         status_filter = arguments.get("status_filter", "all")
@@ -288,30 +288,38 @@
                 result = await session.execute(query.order_by(ServiceConfig.name))
                 services = result.scalars().all()
 
                 services_list = []
                 for svc in services:
-                    services_list.append({
-                        "id": str(svc.id),
-                        "name": svc.name,
-                        "type": svc.service_type.value if hasattr(svc.service_type, 'value') else str(svc.service_type),
-                        "status": svc.status.value if hasattr(svc.status, 'value') else str(svc.status),
-                        "enabled": svc.enabled,
-                        "url": svc.full_url,
-                        "version": svc.version,
-                        "last_test_at": svc.last_test_at.isoformat() if svc.last_test_at else None,
-                        "last_test_success": svc.last_test_success,
-                        "last_error": svc.last_error,
-                    })
+                    services_list.append(
+                        {
+                            "id": str(svc.id),
+                            "name": svc.name,
+                            "type": svc.service_type.value
+                            if hasattr(svc.service_type, "value")
+                            else str(svc.service_type),
+                            "status": svc.status.value
+                            if hasattr(svc.status, "value")
+                            else str(svc.status),
+                            "enabled": svc.enabled,
+                            "url": svc.full_url,
+                            "version": svc.version,
+                            "last_test_at": svc.last_test_at.isoformat()
+                            if svc.last_test_at
+                            else None,
+                            "last_test_success": svc.last_test_success,
+                            "last_error": svc.last_error,
+                        }
+                    )
 
                 return {
                     "success": True,
                     "result": {
                         "count": len(services_list),
                         "filter": status_filter,
                         "services": services_list,
-                    }
+                    },
                 }
 
         except Exception as e:
             return {"success": False, "error": f"Failed to get services: {str(e)}"}
 
@@ -348,11 +356,11 @@
                         "service": service_name,
                         "test_success": test_result.success,
                         "message": test_result.message,
                         "response_time_ms": test_result.response_time_ms,
                         "details": test_result.details,
-                    }
+                    },
                 }
 
         except Exception as e:
             return {"success": False, "error": f"Failed to test service: {str(e)}"}
 
@@ -376,21 +384,23 @@
                     limit=limit,
                 )
 
                 logs_list = []
                 for log in logs:
-                    logs_list.append({
-                        "id": str(log.id),
-                        "level": log.level,
-                        "message": log.message,
-                        "source": log.source,
-                        "component": log.component,
-                        "logged_at": log.logged_at.isoformat() if log.logged_at else None,
-                        "service_type": log.service_type,
-                        "exception_type": log.exception_type,
-                        "exception_message": log.exception_message,
-                    })
+                    logs_list.append(
+                        {
+                            "id": str(log.id),
+                            "level": log.level,
+                            "message": log.message,
+                            "source": log.source,
+                            "component": log.component,
+                            "logged_at": log.logged_at.isoformat() if log.logged_at else None,
+                            "service_type": log.service_type,
+                            "exception_type": log.exception_type,
+                            "exception_message": log.exception_message,
+                        }
+                    )
 
                 return {
                     "success": True,
                     "result": {
                         "count": len(logs_list),
@@ -399,11 +409,11 @@
                             "level": level,
                             "source": source,
                             "search": search,
                         },
                         "logs": logs_list,
-                    }
+                    },
                 }
 
         except Exception as e:
             return {"success": False, "error": f"Failed to get logs: {str(e)}"}
 
@@ -420,39 +430,49 @@
                 if active_only:
                     # Get active (unresolved) alerts
                     alerts = await alert_service.get_active_alerts(session)
                     alerts_list = []
                     for alert in alerts[:limit]:
-                        alerts_list.append({
-                            "id": str(alert.id),
-                            "alert_name": alert.alert_name,
-                            "severity": alert.severity,
-                            "triggered_at": alert.triggered_at.isoformat() if alert.triggered_at else None,
-                            "is_resolved": alert.is_resolved,
-                            "metric_value": alert.metric_value,
-                            "threshold_value": alert.threshold_value,
-                            "message": alert.message,
-                        })
+                        alerts_list.append(
+                            {
+                                "id": str(alert.id),
+                                "alert_name": alert.alert_name,
+                                "severity": alert.severity,
+                                "triggered_at": alert.triggered_at.isoformat()
+                                if alert.triggered_at
+                                else None,
+                                "is_resolved": alert.is_resolved,
+                                "metric_value": alert.metric_value,
+                                "threshold_value": alert.threshold_value,
+                                "message": alert.message,
+                            }
+                        )
                 else:
                     # Get recent alert history
                     history, total = await alert_service.get_alert_history(
                         session,
                         limit=limit,
                     )
                     alerts_list = []
                     for alert in history:
-                        alerts_list.append({
-                            "id": str(alert.id),
-                            "alert_name": alert.alert_name,
-                            "severity": alert.severity,
-                            "triggered_at": alert.triggered_at.isoformat() if alert.triggered_at else None,
-                            "resolved_at": alert.resolved_at.isoformat() if alert.resolved_at else None,
-                            "is_resolved": alert.is_resolved,
-                            "metric_value": alert.metric_value,
-                            "threshold_value": alert.threshold_value,
-                            "message": alert.message,
-                        })
+                        alerts_list.append(
+                            {
+                                "id": str(alert.id),
+                                "alert_name": alert.alert_name,
+                                "severity": alert.severity,
+                                "triggered_at": alert.triggered_at.isoformat()
+                                if alert.triggered_at
+                                else None,
+                                "resolved_at": alert.resolved_at.isoformat()
+                                if alert.resolved_at
+                                else None,
+                                "is_resolved": alert.is_resolved,
+                                "metric_value": alert.metric_value,
+                                "threshold_value": alert.threshold_value,
+                                "message": alert.message,
+                            }
+                        )
 
                 # Get stats
                 stats = await alert_service.get_alert_stats(session, hours=24)
 
                 return {
@@ -463,12 +483,12 @@
                         "alerts": alerts_list,
                         "stats": {
                             "total_triggered_24h": stats.get("total_triggered", 0),
                             "active_count": stats.get("active_count", 0),
                             "by_severity": stats.get("by_severity", {}),
-                        }
-                    }
+                        },
+                    },
                 }
 
         except Exception as e:
             return {"success": False, "error": f"Failed to get alerts: {str(e)}"}
 
@@ -484,13 +504,11 @@
             from src.database.connection import async_session_maker
             from src.models.user_mapping import UserMapping
 
             async with async_session_maker() as session:
                 # Query to get unique central users with their mappings count
-                query = select(UserMapping).options(
-                    selectinload(UserMapping.service_config)
-                )
+                query = select(UserMapping).options(selectinload(UserMapping.service_config))
 
                 if search:
                     query = query.where(
                         or_(
                             UserMapping.central_username.ilike(f"%{search}%"),
@@ -513,26 +531,36 @@
                             "central_user_id": user_id,
                             "central_username": mapping.central_username,
                             "central_email": mapping.central_email,
                             "mappings": [],
                         }
-                    users_dict[user_id]["mappings"].append({
-                        "service_name": mapping.service_config.name if mapping.service_config else "Unknown",
-                        "service_type": mapping.service_config.service_type.value if mapping.service_config else "unknown",
-                        "service_username": mapping.service_username,
-                        "status": mapping.status.value if hasattr(mapping.status, 'value') else str(mapping.status),
-                        "role": mapping.role.value if hasattr(mapping.role, 'value') else str(mapping.role),
-                    })
+                    users_dict[user_id]["mappings"].append(
+                        {
+                            "service_name": mapping.service_config.name
+                            if mapping.service_config
+                            else "Unknown",
+                            "service_type": mapping.service_config.service_type.value
+                            if mapping.service_config
+                            else "unknown",
+                            "service_username": mapping.service_username,
+                            "status": mapping.status.value
+                            if hasattr(mapping.status, "value")
+                            else str(mapping.status),
+                            "role": mapping.role.value
+                            if hasattr(mapping.role, "value")
+                            else str(mapping.role),
+                        }
+                    )
 
                 users_list = list(users_dict.values())[:limit]
 
                 return {
                     "success": True,
                     "result": {
                         "count": len(users_list),
                         "search": search,
                         "users": users_list,
-                    }
+                    },
                 }
 
         except Exception as e:
             return {"success": False, "error": f"Failed to get users: {str(e)}"}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/system_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/zammad_tools.py	2025-12-31 13:30:51.494007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/zammad_tools.py	2025-12-31 13:41:34.496257+00:00
@@ -169,14 +169,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Zammad tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Zammad service not configured"
-            }
+            return {"success": False, "error": "Zammad service not configured"}
 
         try:
             from src.adapters.zammad import ZammadAdapter
 
             # Create a mock ServiceConfig object for the adapter
@@ -221,17 +218,11 @@
 
         # Get tickets from adapter (uses per_page parameter)
         result = await adapter.get_tickets(per_page=limit)
         tickets = result.get("tickets", [])
 
-        return {
-            "success": True,
-            "result": {
-                "count": len(tickets),
-                "tickets": tickets
-            }
-        }
+        return {"success": True, "result": {"count": len(tickets), "tickets": tickets}}
 
     async def _get_ticket_details(self, adapter, arguments: dict) -> dict:
         """Get ticket details with articles."""
         ticket_id_or_number = arguments.get("ticket_id")
 
@@ -243,11 +234,11 @@
             ticket = await adapter.get_ticket_by_number(str(ticket_id_or_number))
 
         if ticket is None:
             return {
                 "success": False,
-                "error": f"Ticket {ticket_id_or_number} not found (searched by ID and number)"
+                "error": f"Ticket {ticket_id_or_number} not found (searched by ID and number)",
             }
 
         # Use the actual ticket ID for fetching articles
         actual_ticket_id = ticket.get("id")
         articles = await adapter.get_ticket_articles(actual_ticket_id)
@@ -277,12 +268,12 @@
                         "internal": article.get("internal", False),
                         "created_at": article.get("created_at"),
                         "from": article.get("from"),
                     }
                     for article in articles
-                ]
-            }
+                ],
+            },
         }
 
     async def _search_tickets(self, adapter, arguments: dict) -> dict:
         """Search for tickets."""
         query = arguments.get("query")
@@ -302,12 +293,12 @@
                         "title": ticket.get("title"),
                         "state": ticket.get("state"),
                         "created_at": ticket.get("created_at"),
                     }
                     for ticket in tickets
-                ]
-            }
+                ],
+            },
         }
 
     async def _create_ticket(self, adapter, arguments: dict) -> dict:
         """Create a new ticket."""
         title = arguments.get("title")
@@ -335,11 +326,11 @@
             "article": {
                 "subject": title,
                 "body": body,
                 "type": "note",
                 "internal": False,
-            }
+            },
         }
 
         # Add customer_id if available (required for ticket creation)
         if customer_id:
             ticket_data["customer_id"] = customer_id
@@ -347,20 +338,20 @@
         ticket = await adapter.create_ticket(ticket_data)
 
         if not ticket:
             return {
                 "success": False,
-                "error": "Failed to create ticket - check Zammad API logs for details"
+                "error": "Failed to create ticket - check Zammad API logs for details",
             }
 
         return {
             "success": True,
             "result": {
                 "message": f"Ticket #{ticket.get('number')} created successfully",
                 "ticket_id": ticket.get("id"),
                 "ticket_number": ticket.get("number"),
-            }
+            },
         }
 
     async def _add_comment(self, adapter, arguments: dict) -> dict:
         """Add a comment to a ticket."""
         ticket_id = arguments.get("ticket_id")
@@ -372,22 +363,19 @@
             body=comment,
             internal=internal,
         )
 
         if not article:
-            return {
-                "success": False,
-                "error": f"Failed to add comment to ticket #{ticket_id}"
-            }
+            return {"success": False, "error": f"Failed to add comment to ticket #{ticket_id}"}
 
         return {
             "success": True,
             "result": {
                 "message": f"Comment added to ticket #{ticket_id}",
                 "article_id": article.get("id"),
                 "internal": internal,
-            }
+            },
         }
 
     async def _update_ticket_status(self, adapter, arguments: dict) -> dict:
         """Update ticket status."""
         ticket_id = arguments.get("ticket_id")
@@ -403,22 +391,19 @@
         state_id = status_map.get(status.lower(), 2)
 
         success = await adapter.update_ticket(ticket_id, {"state_id": state_id})
 
         if not success:
-            return {
-                "success": False,
-                "error": f"Failed to update ticket #{ticket_id} status"
-            }
+            return {"success": False, "error": f"Failed to update ticket #{ticket_id} status"}
 
         return {
             "success": True,
             "result": {
                 "message": f"Ticket #{ticket_id} status updated to {status}",
                 "ticket_id": ticket_id,
                 "new_status": status,
-            }
+            },
         }
 
     async def _get_ticket_stats(self, adapter) -> dict:
         """Get ticket statistics."""
         stats = await adapter.get_statistics()
@@ -431,7 +416,7 @@
                 "pending_tickets": stats.get("pending_tickets", 0),
                 "closed_tickets": stats.get("closed_tickets", 0),
                 "total_tickets": stats.get("total_tickets", 0),
                 "total_users": stats.get("total_users", 0),
                 "total_groups": stats.get("total_groups", 0),
-            }
-        }
+            },
+        }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/zammad_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/base.py	2025-12-31 13:30:51.537007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/base.py	2025-12-31 13:41:34.528140+00:00
@@ -9,16 +9,18 @@
 from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
 
 
 class Base(DeclarativeBase):
     """Base class for all database models."""
+
     pass
 
 
 # Service Types
 class ServiceType(str, Enum):
     """Supported homelab service types."""
+
     PLEX = "plex"
     TAUTULLI = "tautulli"
     OVERSEERR = "overseerr"
     ZAMMAD = "zammad"
     AUTHENTIK = "authentik"
@@ -26,73 +28,82 @@
 
 
 # Status Types
 class TestStatus(str, Enum):
     """Service connection test status."""
+
     SUCCESS = "success"
     FAILED = "failed"
     PENDING = "pending"
 
 
 class TrainingStatus(str, Enum):
     """Training session status."""
+
     PENDING = "pending"
     RUNNING = "running"
     COMPLETED = "completed"
     FAILED = "failed"
     CANCELLED = "cancelled"
 
 
 class RequestStatus(str, Enum):
     """Request completion status."""
+
     SUCCESS = "success"
     ERROR = "error"
     TIMEOUT = "timeout"
 
 
 # User and Permission Types
 class UserRole(str, Enum):
     """User role in the system."""
+
     ADMIN = "admin"
     USER = "user"
 
 
 class LogLevel(str, Enum):
     """Log entry severity levels."""
+
     DEBUG = "debug"
     INFO = "info"
     WARNING = "warning"
     ERROR = "error"
     CRITICAL = "critical"
 
 
 # MCP Types
 class McpRequestType(str, Enum):
     """MCP request types."""
+
     TOOL_CALL = "tool_call"
     RESOURCE_REQUEST = "resource_request"
     PROMPT_REQUEST = "prompt_request"
 
 
 # Training Types
 class PromptDifficulty(str, Enum):
     """Training prompt difficulty levels."""
+
     BASIC = "basic"
     INTERMEDIATE = "intermediate"
     ADVANCED = "advanced"
 
 
 class PromptSource(str, Enum):
     """Training prompt sources."""
+
     MANUAL = "manual"
     IMPORTED = "imported"
     GENERATED = "generated"
 
 
 # Monitoring Types
 class MetricType(str, Enum):
     """System metric types."""
+
     CPU = "cpu"
     MEMORY = "memory"
     DISK = "disk"
     NETWORK = "network"
     DOCKER_CONTAINER = "docker_container"
@@ -100,45 +111,50 @@
     ERROR_RATE = "error_rate"
 
 
 class AlertSeverity(str, Enum):
     """Alert severity levels."""
+
     LOW = "low"
     MEDIUM = "medium"
     HIGH = "high"
     CRITICAL = "critical"
 
 
 class ThresholdOperator(str, Enum):
     """Alert threshold operators."""
+
     GT = "gt"
     LT = "lt"
     EQ = "eq"
     NE = "ne"
     GTE = "gte"
     LTE = "lte"
 
 
 class DestinationType(str, Enum):
     """Alert destination types."""
+
     EMAIL = "email"
     WEBHOOK = "webhook"
     SLACK = "slack"
 
 
 # Configuration Types
 class ConfigCategory(str, Enum):
     """Configuration setting categories."""
+
     GENERAL = "general"
     SERVICES = "services"
     TRAINING = "training"
     MONITORING = "monitoring"
     SECURITY = "security"
 
 
 class ValueType(str, Enum):
     """Configuration value types."""
+
     STRING = "string"
     INTEGER = "integer"
     FLOAT = "float"
     BOOLEAN = "boolean"
     JSON = "json"
@@ -146,43 +162,35 @@
 
 
 # Base model mixins
 class TimestampMixin:
     """Mixin for created_at and updated_at timestamps."""
-    created_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        default=datetime.utcnow,
-        nullable=False
-    )
+
+    created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, nullable=False)
     updated_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        default=datetime.utcnow,
-        onupdate=datetime.utcnow,
-        nullable=False
+        DateTime, default=datetime.utcnow, onupdate=datetime.utcnow, nullable=False
     )
 
 
 class UUIDMixin:
     """Mixin for UUID primary key (as string for SQLite compatibility)."""
+
     id: Mapped[str] = mapped_column(
-        String(36),
-        primary_key=True,
-        default=lambda: str(uuid4()),
-        nullable=False
+        String(36), primary_key=True, default=lambda: str(uuid4()), nullable=False
     )
 
 
 # Pydantic model helpers
 def to_dict(obj: Any) -> Dict[str, Any]:
     """Convert SQLAlchemy model to dictionary."""
-    if hasattr(obj, '__dict__'):
+    if hasattr(obj, "__dict__"):
         result = {}
         for key, value in obj.__dict__.items():
-            if not key.startswith('_'):
+            if not key.startswith("_"):
                 if isinstance(value, datetime):
                     result[key] = value.isoformat()
-                elif isinstance(value, (UUID, str)) and key == 'id':
+                elif isinstance(value, (UUID, str)) and key == "id":
                     result[key] = str(value)
                 elif isinstance(value, Enum):
                     result[key] = value.value
                 else:
                     result[key] = value
@@ -190,10 +198,9 @@
     return obj
 
 
 def from_dict(cls: type, data: Dict[str, Any]) -> Any:
     """Create model instance from dictionary."""
-    if hasattr(cls, '__annotations__'):
-        filtered_data = {k: v for k, v in data.items()
-                        if k in cls.__annotations__}
+    if hasattr(cls, "__annotations__"):
+        filtered_data = {k: v for k, v in data.items() if k in cls.__annotations__}
         return cls(**filtered_data)
     return cls(**data)
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/base.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/configuration.py	2025-12-31 13:30:51.533007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/configuration.py	2025-12-31 13:41:34.535773+00:00
@@ -11,55 +11,22 @@
 class ConfigurationSetting(Base, UUIDMixin, TimestampMixin):
     """System-wide configuration settings."""
 
     __tablename__ = "configuration_settings"
 
-    category: Mapped[ConfigCategory] = mapped_column(
-        String(50),
-        nullable=False,
-        index=True
+    category: Mapped[ConfigCategory] = mapped_column(String(50), nullable=False, index=True)
+    key: Mapped[str] = mapped_column(String(255), nullable=False, index=True)
+    value: Mapped[str] = mapped_column(Text, nullable=False)
+    value_type: Mapped[ValueType] = mapped_column(
+        String(20), nullable=False, default=ValueType.STRING
     )
-    key: Mapped[str] = mapped_column(
-        String(255),
-        nullable=False,
-        index=True
-    )
-    value: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
-    value_type: Mapped[ValueType] = mapped_column(
-        String(20),
-        nullable=False,
-        default=ValueType.STRING
-    )
-    default_value: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
-    description: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
-    is_sensitive: Mapped[bool] = mapped_column(
-        Boolean,
-        default=False,
-        nullable=False
-    )
-    validation_regex: Mapped[Optional[str]] = mapped_column(
-        String(500),
-        nullable=True
-    )
-    requires_restart: Mapped[bool] = mapped_column(
-        Boolean,
-        default=False,
-        nullable=False
-    )
-    updated_by: Mapped[Optional[str]] = mapped_column(
-        String(255),
-        nullable=True
-    )
+    default_value: Mapped[str] = mapped_column(Text, nullable=False)
+    description: Mapped[str] = mapped_column(Text, nullable=False)
+    is_sensitive: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
+    validation_regex: Mapped[Optional[str]] = mapped_column(String(500), nullable=True)
+    requires_restart: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
+    updated_by: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)
 
     def __repr__(self) -> str:
         return (
             f"<ConfigurationSetting(id={self.id}, "
             f"category={self.category}, "
@@ -84,11 +51,11 @@
             if self.value_type == ValueType.INTEGER:
                 int(value)
             elif self.value_type == ValueType.FLOAT:
                 float(value)
             elif self.value_type == ValueType.BOOLEAN:
-                if value.lower() not in ['true', 'false', '1', '0']:
+                if value.lower() not in ["true", "false", "1", "0"]:
                     return False
             elif self.value_type == ValueType.JSON:
                 json.loads(value)
             elif self.value_type == ValueType.ARRAY:
                 json.loads(value)
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/configuration.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/alert_config.py	2025-12-31 13:30:51.555007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/alert_config.py	2025-12-31 13:41:34.545069+00:00
@@ -26,96 +26,53 @@
     description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
     enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Alert type and severity
     severity: Mapped[str] = mapped_column(
-        String(20),
-        nullable=False,
-        default=AlertSeverity.MEDIUM.value
+        String(20), nullable=False, default=AlertSeverity.MEDIUM.value
     )
 
     metric_type: Mapped[str] = mapped_column(
-        String(50),
-        nullable=False,
-        default=MetricType.CPU.value
+        String(50), nullable=False, default=MetricType.CPU.value
     )
 
     # Threshold configuration
     threshold_operator: Mapped[str] = mapped_column(
-        String(10),
-        nullable=False,
-        default=ThresholdOperator.GT.value
+        String(10), nullable=False, default=ThresholdOperator.GT.value
     )
 
-    threshold_value: Mapped[float] = mapped_column(
-        Float,
-        nullable=False
-    )
+    threshold_value: Mapped[float] = mapped_column(Float, nullable=False)
 
     # Duration before triggering (in seconds)
-    duration_seconds: Mapped[int] = mapped_column(
-        Integer,
-        nullable=False,
-        default=60
-    )
+    duration_seconds: Mapped[int] = mapped_column(Integer, nullable=False, default=60)
 
     # Service-specific alert (optional)
-    service_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        nullable=True,
-        index=True
-    )
+    service_id: Mapped[Optional[str]] = mapped_column(String(36), nullable=True, index=True)
 
-    service_type: Mapped[Optional[str]] = mapped_column(
-        String(50),
-        nullable=True
-    )
+    service_type: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)
 
     # Notification settings
     notification_channels: Mapped[List[str]] = mapped_column(
-        JSON,
-        nullable=False,
-        default=list
+        JSON, nullable=False, default=list
     )  # List of destination types: ["email", "webhook", "slack"]
 
     notification_config: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        nullable=False,
-        default=dict
+        JSON, nullable=False, default=dict
     )  # Channel-specific config (emails, webhook URLs, etc.)
 
     # Cooldown to prevent alert spam
-    cooldown_minutes: Mapped[int] = mapped_column(
-        Integer,
-        nullable=False,
-        default=15
-    )
+    cooldown_minutes: Mapped[int] = mapped_column(Integer, nullable=False, default=15)
 
     # Alert state
-    last_triggered_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
+    last_triggered_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
 
-    trigger_count: Mapped[int] = mapped_column(
-        Integer,
-        nullable=False,
-        default=0
-    )
+    trigger_count: Mapped[int] = mapped_column(Integer, nullable=False, default=0)
 
-    is_firing: Mapped[bool] = mapped_column(
-        Boolean,
-        nullable=False,
-        default=False
-    )
+    is_firing: Mapped[bool] = mapped_column(Boolean, nullable=False, default=False)
 
     # Additional metadata
-    tags: Mapped[Dict[str, str]] = mapped_column(
-        JSON,
-        nullable=False,
-        default=dict
-    )
+    tags: Mapped[Dict[str, str]] = mapped_column(JSON, nullable=False, default=dict)
 
     def __repr__(self) -> str:
         return f"<AlertConfiguration {self.id[:8]} {self.name} [{self.severity}]>"
 
     def to_dict(self) -> Dict[str, Any]:
@@ -133,11 +90,13 @@
             "service_id": self.service_id,
             "service_type": self.service_type,
             "notification_channels": self.notification_channels,
             "notification_config": self.notification_config,
             "cooldown_minutes": self.cooldown_minutes,
-            "last_triggered_at": self.last_triggered_at.isoformat() if self.last_triggered_at else None,
+            "last_triggered_at": self.last_triggered_at.isoformat()
+            if self.last_triggered_at
+            else None,
             "trigger_count": self.trigger_count,
             "is_firing": self.is_firing,
             "tags": self.tags,
             "created_at": self.created_at.isoformat() if self.created_at else None,
             "updated_at": self.updated_at.isoformat() if self.updated_at else None,
@@ -168,57 +127,36 @@
     """History of triggered alerts."""
 
     __tablename__ = "alert_history"
 
     # Reference to alert configuration
-    alert_config_id: Mapped[str] = mapped_column(
-        String(36),
-        nullable=False,
-        index=True
-    )
+    alert_config_id: Mapped[str] = mapped_column(String(36), nullable=False, index=True)
 
     alert_name: Mapped[str] = mapped_column(String(100), nullable=False)
     severity: Mapped[str] = mapped_column(String(20), nullable=False)
 
     # Trigger details
     triggered_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        nullable=False,
-        default=datetime.utcnow
+        DateTime, nullable=False, default=datetime.utcnow
     )
 
-    resolved_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
+    resolved_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
 
-    is_resolved: Mapped[bool] = mapped_column(
-        Boolean,
-        nullable=False,
-        default=False
-    )
+    is_resolved: Mapped[bool] = mapped_column(Boolean, nullable=False, default=False)
 
     # Values at time of trigger
     metric_value: Mapped[float] = mapped_column(Float, nullable=False)
     threshold_value: Mapped[float] = mapped_column(Float, nullable=False)
 
     # Context
     service_id: Mapped[Optional[str]] = mapped_column(String(36), nullable=True)
     message: Mapped[str] = mapped_column(Text, nullable=False)
 
     # Notification status
-    notifications_sent: Mapped[bool] = mapped_column(
-        Boolean,
-        nullable=False,
-        default=False
-    )
+    notifications_sent: Mapped[bool] = mapped_column(Boolean, nullable=False, default=False)
 
-    notification_details: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        nullable=False,
-        default=dict
-    )
+    notification_details: Mapped[Dict[str, Any]] = mapped_column(JSON, nullable=False, default=dict)
 
     def __repr__(self) -> str:
         status = "resolved" if self.is_resolved else "firing"
         return f"<AlertHistory {self.id[:8]} {self.alert_name} [{status}]>"
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/alert_config.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/log_entry.py	2025-12-31 13:30:51.557007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/log_entry.py	2025-12-31 13:41:34.588856+00:00
@@ -14,102 +14,65 @@
 
     __tablename__ = "log_entries"
 
     # Log content
     level: Mapped[str] = mapped_column(
-        String(20),
-        nullable=False,
-        default=LogLevel.INFO.value,
-        index=True
+        String(20), nullable=False, default=LogLevel.INFO.value, index=True
     )
     message: Mapped[str] = mapped_column(Text, nullable=False)
 
     # Source identification
     source: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        index=True
+        String(100), nullable=False, index=True
     )  # e.g., "backend", "frontend", "plex", "tautulli"
 
     component: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True
+        String(100), nullable=True
     )  # e.g., "api", "websocket", "adapter", "service"
 
     # Request tracing
     correlation_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        nullable=True,
-        index=True
+        String(36), nullable=True, index=True
     )  # UUID for tracing requests across services
 
     request_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        nullable=True
+        String(36), nullable=True
     )  # Unique request identifier
 
     # User context
-    user_id: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True,
-        index=True
-    )
+    user_id: Mapped[Optional[str]] = mapped_column(String(100), nullable=True, index=True)
 
     # Service context
     service_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        nullable=True,
-        index=True
+        String(36), nullable=True, index=True
     )  # Related service config ID
 
-    service_type: Mapped[Optional[str]] = mapped_column(
-        String(50),
-        nullable=True
-    )
+    service_type: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)
 
     # Additional data
-    extra_data: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        nullable=False,
-        default=dict
-    )
+    extra_data: Mapped[Dict[str, Any]] = mapped_column(JSON, nullable=False, default=dict)
 
     # Exception info
-    exception_type: Mapped[Optional[str]] = mapped_column(
-        String(200),
-        nullable=True
-    )
+    exception_type: Mapped[Optional[str]] = mapped_column(String(200), nullable=True)
 
-    exception_message: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    exception_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
-    stack_trace: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    stack_trace: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Performance data
-    duration_ms: Mapped[Optional[int]] = mapped_column(
-        Integer,
-        nullable=True
-    )
+    duration_ms: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
 
     # Timestamp for when the log event occurred (may differ from created_at)
     logged_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        nullable=False,
-        default=datetime.utcnow,
-        index=True
+        DateTime, nullable=False, default=datetime.utcnow, index=True
     )
 
     # Indexes for common queries
     __table_args__ = (
-        Index('ix_log_entries_level_logged_at', 'level', 'logged_at'),
-        Index('ix_log_entries_source_logged_at', 'source', 'logged_at'),
-        Index('ix_log_entries_service_logged_at', 'service_id', 'logged_at'),
+        Index("ix_log_entries_level_logged_at", "level", "logged_at"),
+        Index("ix_log_entries_source_logged_at", "source", "logged_at"),
+        Index("ix_log_entries_service_logged_at", "service_id", "logged_at"),
     )
 
     def __repr__(self) -> str:
         return f"<LogEntry {self.id[:8]} [{self.level}] {self.source}: {self.message[:50]}>"
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/log_entry.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/group.py	2025-12-31 13:30:51.539007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/group.py	2025-12-31 13:41:34.681683+00:00
@@ -13,63 +13,34 @@
     """Group for organizing users and managing tool access permissions."""
 
     __tablename__ = "groups"
 
     # Group identity
-    name: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        unique=True,
-        index=True
-    )
-    description: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    name: Mapped[str] = mapped_column(String(100), nullable=False, unique=True, index=True)
+    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Display settings
     color: Mapped[Optional[str]] = mapped_column(
-        String(7),  # Hex color code #RRGGBB
-        nullable=True,
-        default="#6366f1"  # Indigo default
+        String(7), nullable=True, default="#6366f1"  # Hex color code #RRGGBB  # Indigo default
     )
-    icon: Mapped[Optional[str]] = mapped_column(
-        String(50),  # Icon name for frontend
-        nullable=True
-    )
+    icon: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)  # Icon name for frontend
 
     # Priority for permission resolution (higher = more priority)
-    priority: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
+    priority: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
 
     # System groups cannot be deleted
-    is_system: Mapped[bool] = mapped_column(
-        Boolean,
-        default=False,
-        nullable=False
-    )
+    is_system: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
 
     # Group status
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Relationships
     memberships: Mapped[List["GroupMembership"]] = relationship(
-        "GroupMembership",
-        back_populates="group",
-        cascade="all, delete-orphan"
+        "GroupMembership", back_populates="group", cascade="all, delete-orphan"
     )
     tool_permissions: Mapped[List["GroupToolPermission"]] = relationship(
-        "GroupToolPermission",
-        back_populates="group",
-        cascade="all, delete-orphan"
+        "GroupToolPermission", back_populates="group", cascade="all, delete-orphan"
     )
 
     def __repr__(self) -> str:
         return f"<Group(id={self.id}, name={self.name}, enabled={self.enabled})>"
 
@@ -89,100 +60,60 @@
 
     __tablename__ = "group_memberships"
 
     # Group reference
     group_id: Mapped[str] = mapped_column(
-        String(36),
-        ForeignKey("groups.id"),
-        nullable=False,
-        index=True
+        String(36), ForeignKey("groups.id"), nullable=False, index=True
     )
 
     # User reference (central_user_id from UserMapping)
-    central_user_id: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        index=True
-    )
+    central_user_id: Mapped[str] = mapped_column(String(100), nullable=False, index=True)
 
     # Membership status
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # When membership was granted
-    granted_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        default=datetime.utcnow,
-        nullable=False
-    )
+    granted_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow, nullable=False)
 
     # Who granted the membership (optional)
-    granted_by: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True
-    )
+    granted_by: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
 
     # Relationships
-    group: Mapped["Group"] = relationship(
-        "Group",
-        back_populates="memberships"
-    )
+    group: Mapped["Group"] = relationship("Group", back_populates="memberships")
 
     def __repr__(self) -> str:
-        return f"<GroupMembership(group_id={self.group_id}, central_user_id={self.central_user_id})>"
+        return (
+            f"<GroupMembership(group_id={self.group_id}, central_user_id={self.central_user_id})>"
+        )
 
 
 class GroupToolPermission(Base, UUIDMixin, TimestampMixin):
     """Permission linking groups to specific tools they can access."""
 
     __tablename__ = "group_tool_permissions"
 
     # Group reference
     group_id: Mapped[str] = mapped_column(
-        String(36),
-        ForeignKey("groups.id"),
-        nullable=False,
-        index=True
+        String(36), ForeignKey("groups.id"), nullable=False, index=True
     )
 
     # Tool identification
     # Can be specific tool name or "*" for all tools of a service
-    tool_name: Mapped[str] = mapped_column(
-        String(200),
-        nullable=False,
-        index=True
-    )
+    tool_name: Mapped[str] = mapped_column(String(200), nullable=False, index=True)
 
     # Optional service filter (if set, permission only applies to this service)
     # If None and tool_name is "*", means ALL tools from ALL services
-    service_type: Mapped[Optional[str]] = mapped_column(
-        String(50),
-        nullable=True,
-        index=True
-    )
+    service_type: Mapped[Optional[str]] = mapped_column(String(50), nullable=True, index=True)
 
     # Permission status
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Optional description for this permission
-    description: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Relationships
-    group: Mapped["Group"] = relationship(
-        "Group",
-        back_populates="tool_permissions"
-    )
+    group: Mapped["Group"] = relationship("Group", back_populates="tool_permissions")
 
     def __repr__(self) -> str:
         return f"<GroupToolPermission(group_id={self.group_id}, tool={self.tool_name}, service={self.service_type})>"
 
     def matches_tool(self, tool_name: str, service_type: Optional[str] = None) -> bool:
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/group.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/system_metrics.py	2025-12-31 13:30:51.558007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/system_metrics.py	2025-12-31 13:41:34.708817+00:00
@@ -13,51 +13,20 @@
     """System metrics for monitoring and performance tracking."""
 
     __tablename__ = "system_metrics"
 
     timestamp: Mapped[datetime] = mapped_column(
-        DateTime,
-        default=datetime.utcnow,
-        nullable=False,
-        index=True
+        DateTime, default=datetime.utcnow, nullable=False, index=True
     )
-    metric_type: Mapped[MetricType] = mapped_column(
-        String(50),
-        nullable=False,
-        index=True
-    )
-    metric_name: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False
-    )
-    value: Mapped[float] = mapped_column(
-        Float,
-        nullable=False
-    )
-    unit: Mapped[str] = mapped_column(
-        String(20),
-        nullable=False
-    )
-    hostname: Mapped[str] = mapped_column(
-        String(255),
-        nullable=False,
-        default="localhost"
-    )
-    component: Mapped[str] = mapped_column(
-        String(100),
-        nullable=True
-    )
-    labels: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
-    retention_days: Mapped[int] = mapped_column(
-        Integer,
-        default=30,
-        nullable=False
-    )
+    metric_type: Mapped[MetricType] = mapped_column(String(50), nullable=False, index=True)
+    metric_name: Mapped[str] = mapped_column(String(100), nullable=False)
+    value: Mapped[float] = mapped_column(Float, nullable=False)
+    unit: Mapped[str] = mapped_column(String(20), nullable=False)
+    hostname: Mapped[str] = mapped_column(String(255), nullable=False, default="localhost")
+    component: Mapped[str] = mapped_column(String(100), nullable=True)
+    labels: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
+    retention_days: Mapped[int] = mapped_column(Integer, default=30, nullable=False)
 
     def __repr__(self) -> str:
         return (
             f"<SystemMetric(id={self.id}, "
             f"metric_type={self.metric_type}, "
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/system_metrics.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/mcp_request.py	2025-12-31 13:30:51.550007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/mcp_request.py	2025-12-31 13:41:34.714576+00:00
@@ -10,25 +10,27 @@
 from .base import Base, TimestampMixin, UUIDMixin
 
 
 class McpRequestStatus(str, Enum):
     """Status of an MCP request."""
+
     PENDING = "pending"
     PROCESSING = "processing"
     COMPLETED = "completed"
     FAILED = "failed"
     CANCELLED = "cancelled"
 
 
 class McpToolCategory(str, Enum):
     """Category of MCP tools."""
-    MEDIA = "media"           # Plex, Tautulli
-    MONITORING = "monitoring" # Tautulli stats, metrics
-    REQUESTS = "requests"     # Overseerr
-    SUPPORT = "support"       # Zammad
-    SYSTEM = "system"         # System monitoring, logs
-    USERS = "users"           # User management
+
+    MEDIA = "media"  # Plex, Tautulli
+    MONITORING = "monitoring"  # Tautulli stats, metrics
+    REQUESTS = "requests"  # Overseerr
+    SUPPORT = "support"  # Zammad
+    SYSTEM = "system"  # System monitoring, logs
+    USERS = "users"  # User management
 
 
 class McpRequest(Base, UUIDMixin, TimestampMixin):
     """Model for tracking MCP requests from AI to homelab services."""
 
@@ -39,24 +41,20 @@
     session_id: Mapped[str] = mapped_column(String(100), nullable=True, index=True)
 
     # Tool information
     tool_name: Mapped[str] = mapped_column(String(100), nullable=False, index=True)
     tool_category: Mapped[McpToolCategory] = mapped_column(
-        String(20),
-        default=McpToolCategory.SYSTEM,
-        index=True
+        String(20), default=McpToolCategory.SYSTEM, index=True
     )
 
     # Request details
     input_params: Mapped[dict] = mapped_column(JSON, default=dict)
     output_result: Mapped[Optional[dict]] = mapped_column(JSON, nullable=True)
 
     # Status tracking
     status: Mapped[McpRequestStatus] = mapped_column(
-        String(20),
-        default=McpRequestStatus.PENDING,
-        index=True
+        String(20), default=McpRequestStatus.PENDING, index=True
     )
 
     # Timing
     started_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
     completed_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
@@ -66,13 +64,11 @@
     error_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
     error_type: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
 
     # Service reference (which homelab service was called)
     service_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        ForeignKey("service_configs.id", ondelete="SET NULL"),
-        nullable=True
+        String(36), ForeignKey("service_configs.id", ondelete="SET NULL"), nullable=True
     )
 
     # User context (who triggered the request via AI)
     user_id: Mapped[Optional[str]] = mapped_column(String(100), nullable=True, index=True)
     user_query: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
@@ -81,20 +77,22 @@
     ai_model: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
     ai_response_id: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
 
     # Audit flags
     is_sensitive: Mapped[bool] = mapped_column(Boolean, default=False)
-    is_mutation: Mapped[bool] = mapped_column(Boolean, default=False)  # True if request modifies data
+    is_mutation: Mapped[bool] = mapped_column(
+        Boolean, default=False
+    )  # True if request modifies data
 
     # Relationships
     service = relationship("ServiceConfig", foreign_keys=[service_id], lazy="selectin")
 
     # Indexes for common queries
     __table_args__ = (
-        Index('ix_mcp_requests_created_status', 'created_at', 'status'),
-        Index('ix_mcp_requests_tool_status', 'tool_name', 'status'),
-        Index('ix_mcp_requests_category_created', 'tool_category', 'created_at'),
+        Index("ix_mcp_requests_created_status", "created_at", "status"),
+        Index("ix_mcp_requests_tool_status", "tool_name", "status"),
+        Index("ix_mcp_requests_category_created", "tool_category", "created_at"),
     )
 
     def __repr__(self) -> str:
         return (
             f"<McpRequest(id={self.id}, "
@@ -108,14 +106,16 @@
         return {
             "id": str(self.id),
             "correlation_id": self.correlation_id,
             "session_id": self.session_id,
             "tool_name": self.tool_name,
-            "tool_category": self.tool_category.value if hasattr(self.tool_category, 'value') else self.tool_category,
+            "tool_category": self.tool_category.value
+            if hasattr(self.tool_category, "value")
+            else self.tool_category,
             "input_params": self.input_params,
             "output_result": self.output_result,
-            "status": self.status.value if hasattr(self.status, 'value') else self.status,
+            "status": self.status.value if hasattr(self.status, "value") else self.status,
             "started_at": self.started_at.isoformat() if self.started_at else None,
             "completed_at": self.completed_at.isoformat() if self.completed_at else None,
             "duration_ms": self.duration_ms,
             "error_message": self.error_message,
             "error_type": self.error_type,
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/mcp_request.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/service_config.py	2025-12-31 13:30:51.556007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/service_config.py	2025-12-31 13:41:34.761158+00:00
@@ -10,10 +10,11 @@
 from .base import Base, TimestampMixin, UUIDMixin
 
 
 class ServiceType(str, Enum):
     """Supported service types."""
+
     PLEX = "plex"
     OVERSEERR = "overseerr"
     ZAMMAD = "zammad"
     TAUTULLI = "tautulli"
     AUTHENTIK = "authentik"
@@ -32,10 +33,11 @@
     CUSTOM = "custom"
 
 
 class ServiceStatus(str, Enum):
     """Service connection status."""
+
     ACTIVE = "active"
     INACTIVE = "inactive"
     ERROR = "error"
     TESTING = "testing"
     UNKNOWN = "unknown"
@@ -45,111 +47,52 @@
     """Configuration for homelab services."""
 
     __tablename__ = "service_configs"
 
     # Basic service information
-    name: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        unique=True,
-        index=True
-    )
-    service_type: Mapped[ServiceType] = mapped_column(
-        String(50),
-        nullable=False,
-        index=True
-    )
-    description: Mapped[str] = mapped_column(
-        Text,
-        nullable=True
-    )
+    name: Mapped[str] = mapped_column(String(100), nullable=False, unique=True, index=True)
+    service_type: Mapped[ServiceType] = mapped_column(String(50), nullable=False, index=True)
+    description: Mapped[str] = mapped_column(Text, nullable=True)
 
     # Connection details
-    base_url: Mapped[str] = mapped_column(
-        String(255),
-        nullable=False
-    )
-    port: Mapped[Optional[int]] = mapped_column(
-        Integer,
-        nullable=True
-    )
+    base_url: Mapped[str] = mapped_column(String(255), nullable=False)
+    port: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
 
     # Authentication
     api_key: Mapped[Optional[str]] = mapped_column(
-        String(2000),  # JWT tokens can be long
-        nullable=True
+        String(2000), nullable=True  # JWT tokens can be long
     )
-    username: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True
-    )
-    password: Mapped[Optional[str]] = mapped_column(
-        String(255),
-        nullable=True
-    )
+    username: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
+    password: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)
 
     # Service-specific configuration
-    config: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    config: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Status and monitoring
     status: Mapped[ServiceStatus] = mapped_column(
-        String(20),
-        default=ServiceStatus.UNKNOWN,
-        nullable=False
+        String(20), default=ServiceStatus.UNKNOWN, nullable=False
     )
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Connection testing
-    last_test_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
-    last_test_success: Mapped[Optional[bool]] = mapped_column(
-        Boolean,
-        nullable=True
-    )
-    last_error: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    last_test_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
+    last_test_success: Mapped[Optional[bool]] = mapped_column(Boolean, nullable=True)
+    last_error: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Health monitoring
     health_check_interval: Mapped[int] = mapped_column(
-        Integer,
-        default=300,  # 5 minutes
-        nullable=False
+        Integer, default=300, nullable=False  # 5 minutes
     )
-    health_check_enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    health_check_enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Metadata
-    version: Mapped[Optional[str]] = mapped_column(
-        String(50),
-        nullable=True
-    )
-    tags: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    version: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)
+    tags: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Relationships
     user_mappings: Mapped[list["UserMapping"]] = relationship(
-        "UserMapping",
-        back_populates="service_config",
-        cascade="all, delete-orphan"
+        "UserMapping", back_populates="service_config", cascade="all, delete-orphan"
     )
 
     def __repr__(self) -> str:
         return (
             f"<ServiceConfig(id={self.id}, "
@@ -168,13 +111,11 @@
 
     @property
     def is_healthy(self) -> bool:
         """Check if service is healthy based on last test."""
         return (
-            self.status == ServiceStatus.ACTIVE and
-            self.last_test_success is True and
-            self.enabled
+            self.status == ServiceStatus.ACTIVE and self.last_test_success is True and self.enabled
         )
 
     def get_auth_headers(self) -> Dict[str, str]:
         """Get authentication headers for API calls."""
         headers = {}
@@ -212,41 +153,25 @@
     """History of service health check results for uptime tracking."""
 
     __tablename__ = "service_health_history"
 
     # Foreign key to service
-    service_id: Mapped[str] = mapped_column(
-        String(36),
-        nullable=False,
-        index=True
-    )
+    service_id: Mapped[str] = mapped_column(String(36), nullable=False, index=True)
 
     # Test timestamp
     tested_at: Mapped[datetime] = mapped_column(
-        DateTime,
-        default=datetime.utcnow,
-        nullable=False,
-        index=True
+        DateTime, default=datetime.utcnow, nullable=False, index=True
     )
 
     # Test result
-    success: Mapped[bool] = mapped_column(
-        Boolean,
-        nullable=False
-    )
+    success: Mapped[bool] = mapped_column(Boolean, nullable=False)
 
     # Response time in milliseconds
-    response_time_ms: Mapped[Optional[int]] = mapped_column(
-        Integer,
-        nullable=True
-    )
+    response_time_ms: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
 
     # Error message if failed
-    error_message: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    error_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     def __repr__(self) -> str:
         return (
             f"<ServiceHealthHistory(id={self.id}, "
             f"service_id={self.service_id}, "
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/service_config.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/tautulli_tools.py	2025-12-31 13:30:51.463098+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/tautulli_tools.py	2025-12-31 13:41:34.791125+00:00
@@ -318,14 +318,11 @@
         ]
 
     async def execute(self, tool_name: str, arguments: dict) -> dict:
         """Execute a Tautulli tool."""
         if not self.service_config:
-            return {
-                "success": False,
-                "error": "Tautulli service not configured"
-            }
+            return {"success": False, "error": "Tautulli service not configured"}
 
         try:
             # Import adapter here to avoid circular imports
             from src.adapters.tautulli import TautulliAdapter
 
@@ -403,12 +400,12 @@
                         "platform": session.get("platform"),
                         "quality": session.get("quality_profile"),
                         "location": session.get("location"),
                     }
                     for session in activity.get("sessions", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_history(self, adapter, arguments: dict) -> dict:
         """Get play history."""
         length = arguments.get("length", 25)
@@ -436,12 +433,12 @@
                         "percent_complete": item.get("percent_complete"),
                         "watched_status": item.get("watched_status"),
                         "player": item.get("player"),
                     }
                     for item in history_data.get("history", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_users(self, adapter) -> dict:
         """Get all users."""
         users = await adapter.get_users()
@@ -459,12 +456,12 @@
                         "is_admin": user.get("is_admin"),
                         "is_home_user": user.get("is_home_user"),
                         "shared_libraries": user.get("shared_libraries", []),
                     }
                     for user in users
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_libraries(self, adapter) -> dict:
         """Get library statistics."""
         libraries = await adapter.get_libraries()
@@ -481,12 +478,12 @@
                         "parent_count": lib.get("parent_count"),
                         "child_count": lib.get("child_count"),
                         "is_active": lib.get("is_active"),
                     }
                     for lib in libraries
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_statistics(self, adapter) -> dict:
         """Get comprehensive statistics."""
         stats = await adapter.get_statistics()
@@ -513,12 +510,12 @@
                         "user": session.get("friendly_name") or session.get("user"),
                         "title": self._format_title(session),
                         "state": session.get("state"),
                     }
                     for session in stats.get("recent_sessions", [])
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_recently_added(self, adapter, arguments: dict) -> dict:
         """Get recently added items."""
         count = arguments.get("count", 25)
@@ -537,12 +534,12 @@
                         "library": item.get("library_name"),
                         "added_at": item.get("added_at"),
                         "rating": item.get("rating"),
                     }
                     for item in items
-                ]
-            }
+                ],
+            },
         }
 
     async def _get_server_info(self, adapter) -> dict:
         """Get server information."""
         info = await adapter.get_service_info()
@@ -554,11 +551,11 @@
                 "plex_name": info.get("plex_name"),
                 "plex_version": info.get("plex_version"),
                 "plex_platform": info.get("plex_platform"),
                 "update_available": info.get("update_available", False),
                 "update_version": info.get("update_version"),
-            }
+            },
         }
 
     def _format_title(self, item: dict) -> str:
         """Format title including parent/grandparent for TV shows."""
         title = item.get("title", "")
@@ -605,14 +602,11 @@
         days = arguments.get("days", 30)
         stats_type = arguments.get("stats_type", "plays")
         limit = arguments.get("limit", 10)
 
         stats_data = await adapter.get_home_stats(
-            time_range=days,
-            stats_type=stats_type,
-            stats_count=limit,
-            stat_id="top_users"
+            time_range=days, stats_type=stats_type, stats_count=limit, stat_id="top_users"
         )
 
         rows = self._extract_stat_rows(stats_data, "top_users")
 
         users = []
@@ -630,15 +624,11 @@
                 user_data["total_duration"] = self._format_duration(duration)
             users.append(user_data)
 
         return {
             "success": True,
-            "result": {
-                "period_days": days,
-                "stats_type": stats_type,
-                "users": users
-            }
+            "result": {"period_days": days, "stats_type": stats_type, "users": users},
         }
 
     async def _get_top_movies(self, adapter, arguments: dict) -> dict:
         """Get top watched movies."""
         days = arguments.get("days", 30)
@@ -648,21 +638,18 @@
 
         user_id = None
         if username:
             user_id = await self._get_user_id_from_username(adapter, username)
             if user_id is None:
-                return {
-                    "success": False,
-                    "error": f"User '{username}' not found"
-                }
+                return {"success": False, "error": f"User '{username}' not found"}
 
         stats_data = await adapter.get_home_stats(
             time_range=days,
             stats_type=stats_type,
             stats_count=limit,
             stat_id="top_movies",
-            user_id=user_id
+            user_id=user_id,
         )
 
         rows = self._extract_stat_rows(stats_data, "top_movies")
 
         movies = []
@@ -679,15 +666,11 @@
                 duration = row.get("total_duration", 0)
                 movie_data["total_duration_seconds"] = duration
                 movie_data["total_duration"] = self._format_duration(duration)
             movies.append(movie_data)
 
-        result = {
-            "period_days": days,
-            "stats_type": stats_type,
-            "movies": movies
-        }
+        result = {"period_days": days, "stats_type": stats_type, "movies": movies}
         if username:
             result["filtered_by_user"] = username
 
         return {"success": True, "result": result}
 
@@ -700,21 +683,18 @@
 
         user_id = None
         if username:
             user_id = await self._get_user_id_from_username(adapter, username)
             if user_id is None:
-                return {
-                    "success": False,
-                    "error": f"User '{username}' not found"
-                }
+                return {"success": False, "error": f"User '{username}' not found"}
 
         stats_data = await adapter.get_home_stats(
             time_range=days,
             stats_type=stats_type,
             stats_count=limit,
             stat_id="top_tv",
-            user_id=user_id
+            user_id=user_id,
         )
 
         rows = self._extract_stat_rows(stats_data, "top_tv")
 
         shows = []
@@ -730,15 +710,11 @@
                 duration = row.get("total_duration", 0)
                 show_data["total_duration_seconds"] = duration
                 show_data["total_duration"] = self._format_duration(duration)
             shows.append(show_data)
 
-        result = {
-            "period_days": days,
-            "stats_type": stats_type,
-            "tv_shows": shows
-        }
+        result = {"period_days": days, "stats_type": stats_type, "tv_shows": shows}
         if username:
             result["filtered_by_user"] = username
 
         return {"success": True, "result": result}
 
@@ -751,21 +727,18 @@
 
         user_id = None
         if username:
             user_id = await self._get_user_id_from_username(adapter, username)
             if user_id is None:
-                return {
-                    "success": False,
-                    "error": f"User '{username}' not found"
-                }
+                return {"success": False, "error": f"User '{username}' not found"}
 
         stats_data = await adapter.get_home_stats(
             time_range=days,
             stats_type=stats_type,
             stats_count=limit,
             stat_id="top_music",
-            user_id=user_id
+            user_id=user_id,
         )
 
         rows = self._extract_stat_rows(stats_data, "top_music")
 
         music = []
@@ -783,15 +756,11 @@
                 duration = row.get("total_duration", 0)
                 music_data["total_duration_seconds"] = duration
                 music_data["total_duration"] = self._format_duration(duration)
             music.append(music_data)
 
-        result = {
-            "period_days": days,
-            "stats_type": stats_type,
-            "music": music
-        }
+        result = {"period_days": days, "stats_type": stats_type, "music": music}
         if username:
             result["filtered_by_user"] = username
 
         return {"success": True, "result": result}
 
@@ -800,14 +769,11 @@
         days = arguments.get("days", 30)
         stats_type = arguments.get("stats_type", "plays")
         limit = arguments.get("limit", 10)
 
         stats_data = await adapter.get_home_stats(
-            time_range=days,
-            stats_type=stats_type,
-            stats_count=limit,
-            stat_id="top_platforms"
+            time_range=days, stats_type=stats_type, stats_count=limit, stat_id="top_platforms"
         )
 
         rows = self._extract_stat_rows(stats_data, "top_platforms")
 
         platforms = []
@@ -824,15 +790,11 @@
                 platform_data["total_duration"] = self._format_duration(duration)
             platforms.append(platform_data)
 
         return {
             "success": True,
-            "result": {
-                "period_days": days,
-                "stats_type": stats_type,
-                "platforms": platforms
-            }
+            "result": {"period_days": days, "stats_type": stats_type, "platforms": platforms},
         }
 
     async def _get_user_stats(self, adapter, arguments: dict) -> dict:
         """Get detailed statistics for a specific user."""
         username = arguments.get("username")
@@ -872,44 +834,47 @@
                 total_time = stat.get("total_time", 0)
                 total_plays = stat.get("total_plays", 0)
                 if query_days == 1:
                     watch_time["last_24h"] = {
                         "plays": total_plays,
-                        "duration": self._format_duration(total_time)
+                        "duration": self._format_duration(total_time),
                     }
                 elif query_days == 7:
                     watch_time["last_7_days"] = {
                         "plays": total_plays,
-                        "duration": self._format_duration(total_time)
+                        "duration": self._format_duration(total_time),
                     }
                 elif query_days == 30:
                     watch_time["last_30_days"] = {
                         "plays": total_plays,
-                        "duration": self._format_duration(total_time)
+                        "duration": self._format_duration(total_time),
                     }
                 elif query_days == 0:
                     watch_time["all_time"] = {
                         "plays": total_plays,
-                        "duration": self._format_duration(total_time)
+                        "duration": self._format_duration(total_time),
                     }
 
         # Extract top content
         top_movies = [
             {"title": m.get("title"), "plays": m.get("total_plays", 0)}
             for m in self._extract_stat_rows(top_movies_data, "top_movies")[:5]
         ]
         top_shows = [
-            {"title": s.get("grandparent_title") or s.get("title"), "plays": s.get("total_plays", 0)}
+            {
+                "title": s.get("grandparent_title") or s.get("title"),
+                "plays": s.get("total_plays", 0),
+            }
             for s in self._extract_stat_rows(top_tv_data, "top_tv")[:5]
         ]
 
         # Process player stats
         devices = [
             {
                 "platform": p.get("platform"),
                 "player": p.get("player"),
-                "total_plays": p.get("total_plays", 0)
+                "total_plays": p.get("total_plays", 0),
             }
             for p in (player_stats[:5] if player_stats else [])
         ]
 
         return {
@@ -922,33 +887,33 @@
                     "is_active": user.get("is_active"),
                 },
                 "watch_time": watch_time,
                 f"top_movies_last_{days}_days": top_movies,
                 f"top_tv_shows_last_{days}_days": top_shows,
-                "devices": devices
-            }
+                "devices": devices,
+            },
         }
 
     async def _get_watch_stats_summary(self, adapter, arguments: dict) -> dict:
         """Get comprehensive watch statistics summary."""
         days = arguments.get("days", 30)
         stats_type = arguments.get("stats_type", "plays")
         limit = arguments.get("limit", 5)
 
         # Fetch all stats at once
         stats_data = await adapter.get_home_stats(
-            time_range=days,
-            stats_type=stats_type,
-            stats_count=limit
+            time_range=days, stats_type=stats_type, stats_count=limit
         )
 
         # Extract each category
         def extract_items(stat_id: str, title_key: str = "title") -> list:
             rows = self._extract_stat_rows(stats_data, stat_id)
             items = []
             for row in rows:
-                item = {"title": row.get(title_key) or row.get("grandparent_title") or row.get("title")}
+                item = {
+                    "title": row.get(title_key) or row.get("grandparent_title") or row.get("title")
+                }
                 if stats_type == "plays":
                     item["plays"] = row.get("total_plays", 0)
                 else:
                     item["duration"] = self._format_duration(row.get("total_duration", 0))
                 items.append(item)
@@ -979,8 +944,8 @@
                 "stats_type": stats_type,
                 "top_users": top_users,
                 "top_movies": extract_items("top_movies"),
                 "top_tv_shows": extract_items("top_tv", "grandparent_title"),
                 "top_music": extract_items("top_music", "grandparent_title"),
-                "top_platforms": top_platforms
-            }
-        }
+                "top_platforms": top_platforms,
+            },
+        }
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/mcp/tools/tautulli_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_worker.py	2025-12-31 13:30:51.561007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_worker.py	2025-12-31 13:41:34.810787+00:00
@@ -8,10 +8,11 @@
 from .base import Base, TimestampMixin, UUIDMixin
 
 
 class WorkerStatus(str, enum.Enum):
     """Worker status."""
+
     ONLINE = "online"
     OFFLINE = "offline"
     TRAINING = "training"
     ERROR = "error"
     UNKNOWN = "unknown"
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_worker.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_prompt.py	2025-12-31 13:30:51.535007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_prompt.py	2025-12-31 13:41:34.830117+00:00
@@ -14,42 +14,56 @@
 
 # Association table for many-to-many relationship between sessions and prompts
 session_prompt_association = Table(
     "session_prompt_association",
     Base.metadata,
-    Column("session_id", String(36), ForeignKey("training_sessions.id", ondelete="CASCADE"), primary_key=True),
-    Column("prompt_id", String(36), ForeignKey("training_prompts.id", ondelete="CASCADE"), primary_key=True),
+    Column(
+        "session_id",
+        String(36),
+        ForeignKey("training_sessions.id", ondelete="CASCADE"),
+        primary_key=True,
+    ),
+    Column(
+        "prompt_id",
+        String(36),
+        ForeignKey("training_prompts.id", ondelete="CASCADE"),
+        primary_key=True,
+    ),
     Column("added_at", DateTime, default=datetime.utcnow),
 )
 
 
 class PromptCategory(str, Enum):
     """Training prompt categories."""
+
     GENERAL = "general"
     MEDIA = "media"
     SUPPORT = "support"
     HOMELAB = "homelab"
     CUSTOM = "custom"
 
 
 class PromptDifficulty(str, Enum):
     """Training prompt difficulty levels."""
+
     BASIC = "basic"
     INTERMEDIATE = "intermediate"
     ADVANCED = "advanced"
 
 
 class PromptSource(str, Enum):
     """Training prompt sources."""
+
     MANUAL = "manual"
     IMPORTED = "imported"
     GENERATED = "generated"
     SYSTEM = "system"
 
 
 class PromptFormat(str, Enum):
     """Training data format."""
+
     CHAT = "chat"  # [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}]
     INSTRUCTION = "instruction"  # {"instruction": "...", "input": "...", "output": "..."}
     COMPLETION = "completion"  # {"prompt": "...", "completion": "..."}
     QA = "qa"  # {"question": "...", "answer": "..."}
 
@@ -58,154 +72,85 @@
     """Training prompt/example for model fine-tuning."""
 
     __tablename__ = "training_prompts"
 
     # Basic information
-    name: Mapped[str] = mapped_column(
-        String(200),
-        nullable=False,
-        index=True
-    )
-    description: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    name: Mapped[str] = mapped_column(String(200), nullable=False, index=True)
+    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Categorization
     category: Mapped[PromptCategory] = mapped_column(
-        String(50),
-        default=PromptCategory.GENERAL,
-        nullable=False,
-        index=True
+        String(50), default=PromptCategory.GENERAL, nullable=False, index=True
     )
     difficulty: Mapped[PromptDifficulty] = mapped_column(
-        String(20),
-        default=PromptDifficulty.BASIC,
-        nullable=False
+        String(20), default=PromptDifficulty.BASIC, nullable=False
     )
     source: Mapped[PromptSource] = mapped_column(
-        String(20),
-        default=PromptSource.MANUAL,
-        nullable=False
+        String(20), default=PromptSource.MANUAL, nullable=False
     )
     format: Mapped[PromptFormat] = mapped_column(
-        String(20),
-        default=PromptFormat.CHAT,
-        nullable=False
+        String(20), default=PromptFormat.CHAT, nullable=False
     )
 
     # Content - The actual training data
     # For CHAT format: [{"role": "user/assistant/system", "content": "..."}]
     # For INSTRUCTION: {"instruction": "...", "input": "...", "output": "..."}
     # For COMPLETION: {"prompt": "...", "completion": "..."}
-    content: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        nullable=False
-    )
+    content: Mapped[Dict[str, Any]] = mapped_column(JSON, nullable=False)
 
     # System prompt (optional, for chat format)
-    system_prompt: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    system_prompt: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # User input/question
-    user_input: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
+    user_input: Mapped[str] = mapped_column(Text, nullable=False)
 
     # Tool calling support - for prompts that involve function calling
     # tool_call contains the expected tool call: {"name": "tool_name", "arguments": {...}}
-    tool_call: Mapped[Optional[Dict[str, Any]]] = mapped_column(
-        JSON,
-        nullable=True
-    )
+    tool_call: Mapped[Optional[Dict[str, Any]]] = mapped_column(JSON, nullable=True)
 
     # tool_response contains an example response from the tool (realistic mock data)
-    tool_response: Mapped[Optional[Dict[str, Any]]] = mapped_column(
-        JSON,
-        nullable=True
-    )
+    tool_response: Mapped[Optional[Dict[str, Any]]] = mapped_column(JSON, nullable=True)
 
     # Final assistant response (after processing tool results if applicable)
-    assistant_response: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    assistant_response: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # DEPRECATED: Expected output/answer - replaced by assistant_response
     # Kept for backward compatibility
-    expected_output: Mapped[str] = mapped_column(
-        Text,
-        nullable=False,
-        default=""
-    )
+    expected_output: Mapped[str] = mapped_column(Text, nullable=False, default="")
 
     # Tags for filtering/grouping
-    tags: Mapped[List[str]] = mapped_column(
-        JSON,
-        default=list,
-        nullable=False
-    )
+    tags: Mapped[List[str]] = mapped_column(JSON, default=list, nullable=False)
 
     # Quality/validation
-    is_validated: Mapped[bool] = mapped_column(
-        Boolean,
-        default=False,
-        nullable=False
-    )
-    validation_score: Mapped[Optional[float]] = mapped_column(
-        nullable=True
-    )
-    validated_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
-    validated_by: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True
-    )
+    is_validated: Mapped[bool] = mapped_column(Boolean, default=False, nullable=False)
+    validation_score: Mapped[Optional[float]] = mapped_column(nullable=True)
+    validated_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
+    validated_by: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
 
     # Usage tracking
-    times_used: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
-    last_used_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
+    times_used: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
+    last_used_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
 
     # Status
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # DEPRECATED: session_id kept for backward compatibility, use sessions relationship instead
     session_id: Mapped[Optional[str]] = mapped_column(
         String(36),
         ForeignKey("training_sessions.id", ondelete="SET NULL"),
         nullable=True,
-        index=True
+        index=True,
     )
 
     # Many-to-many relationship with sessions (a prompt can be in multiple sessions)
     sessions: Mapped[List["TrainingSession"]] = relationship(
-        "TrainingSession",
-        secondary=session_prompt_association,
-        back_populates="prompts"
+        "TrainingSession", secondary=session_prompt_association, back_populates="prompts"
     )
 
     # DEPRECATED: kept for backward compatibility
     session: Mapped[Optional["TrainingSession"]] = relationship(
-        "TrainingSession",
-        foreign_keys=[session_id],
-        viewonly=True
+        "TrainingSession", foreign_keys=[session_id], viewonly=True
     )
 
     def __repr__(self) -> str:
         return (
             f"<TrainingPrompt(id={self.id}, "
@@ -236,45 +181,39 @@
 
             # If this is a tool calling prompt
             if self.tool_call and self.tool_response:
                 # Assistant makes a tool call
                 json_module.dumps(self.tool_call, ensure_ascii=False)
-                messages.append({
-                    "role": "assistant",
-                    "content": f'{{"name": "{self.tool_call.get("name", "")}", "parameters": {json_module.dumps(self.tool_call.get("arguments", {}), ensure_ascii=False)}}}'
-                })
+                messages.append(
+                    {
+                        "role": "assistant",
+                        "content": f'{{"name": "{self.tool_call.get("name", "")}", "parameters": {json_module.dumps(self.tool_call.get("arguments", {}), ensure_ascii=False)}}}',
+                    }
+                )
                 # Tool returns response
-                messages.append({
-                    "role": "tool",
-                    "content": json_module.dumps(self.tool_response, ensure_ascii=False)
-                })
+                messages.append(
+                    {
+                        "role": "tool",
+                        "content": json_module.dumps(self.tool_response, ensure_ascii=False),
+                    }
+                )
                 # Assistant provides final response based on tool result
                 messages.append({"role": "assistant", "content": final_response})
             else:
                 # Regular prompt without tool calling
                 messages.append({"role": "assistant", "content": final_response})
 
             return {"messages": messages}
 
         elif self.format == PromptFormat.INSTRUCTION:
-            return {
-                "instruction": self.user_input,
-                "input": "",
-                "output": final_response
-            }
+            return {"instruction": self.user_input, "input": "", "output": final_response}
 
         elif self.format == PromptFormat.COMPLETION:
-            return {
-                "prompt": self.user_input,
-                "completion": final_response
-            }
+            return {"prompt": self.user_input, "completion": final_response}
 
         elif self.format == PromptFormat.QA:
-            return {
-                "question": self.user_input,
-                "answer": final_response
-            }
+            return {"question": self.user_input, "answer": final_response}
 
         return self.content
 
     @property
     def has_tool_calling(self) -> bool:
@@ -300,75 +239,42 @@
     """Reusable prompt templates for creating training prompts."""
 
     __tablename__ = "prompt_templates"
 
     # Basic information
-    name: Mapped[str] = mapped_column(
-        String(200),
-        nullable=False,
-        unique=True,
-        index=True
-    )
-    description: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    name: Mapped[str] = mapped_column(String(200), nullable=False, unique=True, index=True)
+    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Template content
-    system_template: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
-    user_template: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
-    assistant_template: Mapped[str] = mapped_column(
-        Text,
-        nullable=False
-    )
+    system_template: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
+    user_template: Mapped[str] = mapped_column(Text, nullable=False)
+    assistant_template: Mapped[str] = mapped_column(Text, nullable=False)
 
     # Template variables
-    variables: Mapped[List[str]] = mapped_column(
-        JSON,
-        default=list,
-        nullable=False
-    )
+    variables: Mapped[List[str]] = mapped_column(JSON, default=list, nullable=False)
 
     # Categorization
     category: Mapped[PromptCategory] = mapped_column(
-        String(50),
-        default=PromptCategory.GENERAL,
-        nullable=False
+        String(50), default=PromptCategory.GENERAL, nullable=False
     )
     format: Mapped[PromptFormat] = mapped_column(
-        String(20),
-        default=PromptFormat.CHAT,
-        nullable=False
+        String(20), default=PromptFormat.CHAT, nullable=False
     )
 
     # Status
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Usage tracking
-    times_used: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
+    times_used: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
 
     def __repr__(self) -> str:
         return f"<PromptTemplate(id={self.id}, name={self.name})>"
 
     def render(self, **kwargs) -> Dict[str, str]:
         """Render template with provided variables."""
         result = {
             "user_input": self.user_template.format(**kwargs),
-            "expected_output": self.assistant_template.format(**kwargs)
+            "expected_output": self.assistant_template.format(**kwargs),
         }
         if self.system_template:
             result["system_prompt"] = self.system_template.format(**kwargs)
         return result
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_prompt.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_session.py	2025-12-31 13:30:51.543007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_session.py	2025-12-31 13:41:34.880347+00:00
@@ -13,10 +13,11 @@
     from .training_prompt import TrainingPrompt
 
 
 class TrainingStatus(str, Enum):
     """Training session status."""
+
     PENDING = "pending"
     PREPARING = "preparing"
     RUNNING = "running"
     PAUSED = "paused"
     COMPLETED = "completed"
@@ -24,10 +25,11 @@
     CANCELLED = "cancelled"
 
 
 class TrainingType(str, Enum):
     """Type of training/fine-tuning."""
+
     FINE_TUNE = "fine_tune"
     LORA = "lora"
     QLORA = "qlora"
     PROMPT_TUNE = "prompt_tune"
 
@@ -36,170 +38,84 @@
     """Training session for Ollama model fine-tuning."""
 
     __tablename__ = "training_sessions"
 
     # Basic information
-    name: Mapped[str] = mapped_column(
-        String(200),
-        nullable=False,
-        index=True
-    )
-    description: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    name: Mapped[str] = mapped_column(String(200), nullable=False, index=True)
+    description: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Model configuration
-    base_model: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        index=True
-    )
-    output_model: Mapped[Optional[str]] = mapped_column(
-        String(100),
-        nullable=True
-    )
+    base_model: Mapped[str] = mapped_column(String(100), nullable=False, index=True)
+    output_model: Mapped[Optional[str]] = mapped_column(String(100), nullable=True)
     training_type: Mapped[TrainingType] = mapped_column(
-        String(20),
-        default=TrainingType.FINE_TUNE,
-        nullable=False
+        String(20), default=TrainingType.FINE_TUNE, nullable=False
     )
     training_backend: Mapped[str] = mapped_column(
-        String(50),
-        default="ollama_modelfile",
-        nullable=False
+        String(50), default="ollama_modelfile", nullable=False
     )
 
     # Status tracking
     status: Mapped[TrainingStatus] = mapped_column(
-        String(20),
-        default=TrainingStatus.PENDING,
-        nullable=False,
-        index=True
-    )
-    error_message: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+        String(20), default=TrainingStatus.PENDING, nullable=False, index=True
+    )
+    error_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Progress metrics
-    current_epoch: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
-    total_epochs: Mapped[int] = mapped_column(
-        Integer,
-        default=1,
-        nullable=False
-    )
-    current_step: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
-    total_steps: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
-    progress_percent: Mapped[float] = mapped_column(
-        Float,
-        default=0.0,
-        nullable=False
-    )
+    current_epoch: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
+    total_epochs: Mapped[int] = mapped_column(Integer, default=1, nullable=False)
+    current_step: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
+    total_steps: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
+    progress_percent: Mapped[float] = mapped_column(Float, default=0.0, nullable=False)
 
     # Training metrics (updated in real-time)
-    loss: Mapped[Optional[float]] = mapped_column(
-        Float,
-        nullable=True
-    )
-    learning_rate: Mapped[Optional[float]] = mapped_column(
-        Float,
-        nullable=True
-    )
+    loss: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
+    learning_rate: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
     metrics_history: Mapped[List[Dict[str, Any]]] = mapped_column(
-        JSON,
-        default=list,
-        nullable=False
+        JSON, default=list, nullable=False
     )
 
     # Final session summary (populated on completion)
     session_summary: Mapped[Optional[Dict[str, Any]]] = mapped_column(
         JSON,
         nullable=True,
-        comment="Final summary with step durations, final metrics, and overall assessment"
+        comment="Final summary with step durations, final metrics, and overall assessment",
     )
 
     # Training logs (stored after training completes)
     training_logs: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True,
-        comment="Training logs captured from the worker"
+        Text, nullable=True, comment="Training logs captured from the worker"
     )
 
     # Hyperparameters
-    hyperparameters: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    hyperparameters: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Timing
-    started_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
-    completed_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
-    estimated_completion: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
+    started_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
+    completed_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
+    estimated_completion: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
 
     # Resource usage
-    gpu_memory_used: Mapped[Optional[float]] = mapped_column(
-        Float,
-        nullable=True
-    )
-    cpu_usage: Mapped[Optional[float]] = mapped_column(
-        Float,
-        nullable=True
-    )
+    gpu_memory_used: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
+    cpu_usage: Mapped[Optional[float]] = mapped_column(Float, nullable=True)
 
     # Data source
-    dataset_size: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
-    dataset_path: Mapped[Optional[str]] = mapped_column(
-        String(500),
-        nullable=True
-    )
+    dataset_size: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
+    dataset_path: Mapped[Optional[str]] = mapped_column(String(500), nullable=True)
 
     # Ollama service reference
     ollama_service_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        ForeignKey("service_configs.id", ondelete="SET NULL"),
-        nullable=True
+        String(36), ForeignKey("service_configs.id", ondelete="SET NULL"), nullable=True
     )
 
     # Training worker reference
     worker_id: Mapped[Optional[str]] = mapped_column(
-        String(36),
-        ForeignKey("training_workers.id", ondelete="SET NULL"),
-        nullable=True
+        String(36), ForeignKey("training_workers.id", ondelete="SET NULL"), nullable=True
     )
 
     # Many-to-many relationship with prompts (via association table)
     prompts: Mapped[List["TrainingPrompt"]] = relationship(
-        "TrainingPrompt",
-        secondary="session_prompt_association",
-        back_populates="sessions"
+        "TrainingPrompt", secondary="session_prompt_association", back_populates="sessions"
     )
 
     def __repr__(self) -> str:
         return (
             f"<TrainingSession(id={self.id}, "
@@ -225,20 +141,20 @@
     def is_completed(self) -> bool:
         """Check if training is finished (success or failure)."""
         return self.status in [
             TrainingStatus.COMPLETED,
             TrainingStatus.FAILED,
-            TrainingStatus.CANCELLED
+            TrainingStatus.CANCELLED,
         ]
 
     def update_progress(
         self,
         current_step: int,
         total_steps: int,
         current_epoch: int = None,
         loss: float = None,
-        learning_rate: float = None
+        learning_rate: float = None,
     ) -> None:
         """Update training progress."""
         self.current_step = current_step
         self.total_steps = total_steps
         if current_epoch is not None:
@@ -256,11 +172,11 @@
         metric_entry = {
             "timestamp": datetime.utcnow().isoformat(),
             "step": current_step,
             "epoch": self.current_epoch,
             "loss": loss,
-            "learning_rate": learning_rate
+            "learning_rate": learning_rate,
         }
         if self.metrics_history is None:
             self.metrics_history = []
         self.metrics_history.append(metric_entry)
 
@@ -295,34 +211,28 @@
             "name": self.name,
             "status": self.status.value if isinstance(self.status, Enum) else self.status,
             "base_model": self.base_model,
             "output_model": self.output_model,
             "training_backend": self.training_backend,
-
             # Timing
             "started_at": self.started_at.isoformat() if self.started_at else None,
             "completed_at": self.completed_at.isoformat() if self.completed_at else None,
             "duration_seconds": self.duration_seconds,
             "duration_formatted": self._format_duration(self.duration_seconds),
-
             # Progress
             "total_epochs": self.total_epochs,
             "total_steps": self.total_steps,
             "final_step": self.current_step,
             "progress_percent": self.progress_percent,
             "dataset_size": self.dataset_size,
-
             # Final metrics
             "final_loss": self.loss,
             "final_learning_rate": self.learning_rate,
-
             # Metrics analysis
             "metrics_analysis": self._analyze_metrics(),
-
             # Error info
             "error_message": self.error_message,
-
             # Assessment
             "assessment": self._assess_training(),
         }
 
         return summary
@@ -362,18 +272,22 @@
         }
 
         # Calculate loss improvement
         if analysis["initial_loss"] and analysis["final_loss"]:
             improvement = analysis["initial_loss"] - analysis["final_loss"]
-            improvement_pct = (improvement / analysis["initial_loss"]) * 100 if analysis["initial_loss"] > 0 else 0
+            improvement_pct = (
+                (improvement / analysis["initial_loss"]) * 100
+                if analysis["initial_loss"] > 0
+                else 0
+            )
             analysis["loss_improvement"] = improvement
             analysis["loss_improvement_percent"] = round(improvement_pct, 2)
 
         # Determine trend
         if len(losses) >= 3:
-            first_third = losses[:len(losses)//3]
-            last_third = losses[-len(losses)//3:]
+            first_third = losses[: len(losses) // 3]
+            last_third = losses[-len(losses) // 3 :]
             avg_first = sum(first_third) / len(first_third) if first_third else 0
             avg_last = sum(last_third) / len(last_third) if last_third else 0
 
             if avg_last < avg_first * 0.95:
                 analysis["trend"] = "decreasing"
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/training_session.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/user_mapping.py	2025-12-31 13:30:51.552007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/user_mapping.py	2025-12-31 13:41:34.884775+00:00
@@ -10,19 +10,21 @@
 from .base import Base, TimestampMixin, UUIDMixin
 
 
 class UserRole(str, Enum):
     """User roles across services."""
+
     ADMIN = "admin"
     USER = "user"
     MODERATOR = "moderator"
     VIEWER = "viewer"
     CUSTOM = "custom"
 
 
 class MappingStatus(str, Enum):
     """User mapping status."""
+
     ACTIVE = "active"
     INACTIVE = "inactive"
     PENDING = "pending"
     FAILED = "failed"
     SYNCING = "syncing"
@@ -32,110 +34,50 @@
     """User mapping between homelab services and central user management."""
 
     __tablename__ = "user_mappings"
 
     # Central user identity
-    central_user_id: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False,
-        index=True
-    )
-    central_username: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False
-    )
-    central_email: Mapped[Optional[str]] = mapped_column(
-        String(255),
-        nullable=True
-    )
+    central_user_id: Mapped[str] = mapped_column(String(100), nullable=False, index=True)
+    central_username: Mapped[str] = mapped_column(String(100), nullable=False)
+    central_email: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)
 
     # Service-specific mapping
     service_config_id: Mapped[str] = mapped_column(
-        String(36),
-        ForeignKey("service_configs.id"),
-        nullable=False,
-        index=True
+        String(36), ForeignKey("service_configs.id"), nullable=False, index=True
     )
-    service_user_id: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False
-    )
-    service_username: Mapped[str] = mapped_column(
-        String(100),
-        nullable=False
-    )
-    service_email: Mapped[Optional[str]] = mapped_column(
-        String(255),
-        nullable=True
-    )
+    service_user_id: Mapped[str] = mapped_column(String(100), nullable=False)
+    service_username: Mapped[str] = mapped_column(String(100), nullable=False)
+    service_email: Mapped[Optional[str]] = mapped_column(String(255), nullable=True)
 
     # Role and permissions
-    role: Mapped[UserRole] = mapped_column(
-        String(20),
-        default=UserRole.USER,
-        nullable=False
-    )
-    permissions: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    role: Mapped[UserRole] = mapped_column(String(20), default=UserRole.USER, nullable=False)
+    permissions: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Mapping status
     status: Mapped[MappingStatus] = mapped_column(
-        String(20),
-        default=MappingStatus.ACTIVE,
-        nullable=False
+        String(20), default=MappingStatus.ACTIVE, nullable=False
     )
-    enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
+    enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
 
     # Synchronization tracking
-    last_sync_at: Mapped[Optional[datetime]] = mapped_column(
-        DateTime,
-        nullable=True
-    )
-    last_sync_success: Mapped[Optional[bool]] = mapped_column(
-        Boolean,
-        nullable=True
-    )
-    last_sync_error: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
+    last_sync_at: Mapped[Optional[datetime]] = mapped_column(DateTime, nullable=True)
+    last_sync_success: Mapped[Optional[bool]] = mapped_column(Boolean, nullable=True)
+    last_sync_error: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
 
     # Service-specific metadata
-    service_metadata: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    service_metadata: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Sync settings
-    sync_enabled: Mapped[bool] = mapped_column(
-        Boolean,
-        default=True,
-        nullable=False
-    )
-    sync_attempts: Mapped[int] = mapped_column(
-        Integer,
-        default=0,
-        nullable=False
-    )
+    sync_enabled: Mapped[bool] = mapped_column(Boolean, default=True, nullable=False)
+    sync_attempts: Mapped[int] = mapped_column(Integer, default=0, nullable=False)
 
     # Relationships
     service_config: Mapped["ServiceConfig"] = relationship(
-        "ServiceConfig",
-        back_populates="user_mappings"
+        "ServiceConfig", back_populates="user_mappings"
     )
     sync_logs: Mapped[list["UserSync"]] = relationship(
-        "UserSync",
-        back_populates="user_mapping",
-        cascade="all, delete-orphan"
+        "UserSync", back_populates="user_mapping", cascade="all, delete-orphan"
     )
 
     def __repr__(self) -> str:
         return (
             f"<UserMapping(id={self.id}, "
@@ -147,13 +89,13 @@
 
     @property
     def is_active(self) -> bool:
         """Check if mapping is active and healthy."""
         return (
-            self.status == MappingStatus.ACTIVE and
-            self.enabled and
-            self.last_sync_success is not False
+            self.status == MappingStatus.ACTIVE
+            and self.enabled
+            and self.last_sync_success is not False
         )
 
     def update_sync_result(self, success: bool, error: Optional[str] = None) -> None:
         """Update synchronization result."""
         self.last_sync_at = datetime.utcnow()
@@ -182,41 +124,21 @@
         time_since_sync = (datetime.utcnow() - self.last_sync_at).total_seconds()
         return time_since_sync >= sync_frequency
 
     def get_service_permissions(self) -> Dict[str, Any]:
         """Get service-specific permissions."""
-        base_permissions = {
-            "read": True,
-            "write": False,
-            "admin": False
-        }
+        base_permissions = {"read": True, "write": False, "admin": False}
 
         # Override with role-based permissions
         if self.role == UserRole.ADMIN:
-            base_permissions.update({
-                "read": True,
-                "write": True,
-                "admin": True
-            })
+            base_permissions.update({"read": True, "write": True, "admin": True})
         elif self.role == UserRole.MODERATOR:
-            base_permissions.update({
-                "read": True,
-                "write": True,
-                "admin": False
-            })
+            base_permissions.update({"read": True, "write": True, "admin": False})
         elif self.role == UserRole.USER:
-            base_permissions.update({
-                "read": True,
-                "write": True,
-                "admin": False
-            })
+            base_permissions.update({"read": True, "write": True, "admin": False})
         elif self.role == UserRole.VIEWER:
-            base_permissions.update({
-                "read": True,
-                "write": False,
-                "admin": False
-            })
+            base_permissions.update({"read": True, "write": False, "admin": False})
 
         # Merge with custom permissions
         base_permissions.update(self.permissions)
         return base_permissions
 
@@ -229,46 +151,26 @@
     """User synchronization log for audit and troubleshooting."""
 
     __tablename__ = "user_syncs"
 
     user_mapping_id: Mapped[str] = mapped_column(
-        String(36),
-        ForeignKey("user_mappings.id"),
-        nullable=False,
-        index=True
+        String(36), ForeignKey("user_mappings.id"), nullable=False, index=True
     )
 
     # Sync details
     sync_type: Mapped[str] = mapped_column(
-        String(50),
-        nullable=False  # "create", "update", "delete", "check"
+        String(50), nullable=False  # "create", "update", "delete", "check"
     )
-    success: Mapped[bool] = mapped_column(
-        Boolean,
-        nullable=False
-    )
-    error_message: Mapped[Optional[str]] = mapped_column(
-        Text,
-        nullable=True
-    )
-    sync_duration_ms: Mapped[Optional[int]] = mapped_column(
-        Integer,
-        nullable=True
-    )
+    success: Mapped[bool] = mapped_column(Boolean, nullable=False)
+    error_message: Mapped[Optional[str]] = mapped_column(Text, nullable=True)
+    sync_duration_ms: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)
 
     # Changed data
-    changes: Mapped[Dict[str, Any]] = mapped_column(
-        JSON,
-        default=dict,
-        nullable=False
-    )
+    changes: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict, nullable=False)
 
     # Relationships
-    user_mapping: Mapped["UserMapping"] = relationship(
-        "UserMapping",
-        back_populates="sync_logs"
-    )
+    user_mapping: Mapped["UserMapping"] = relationship("UserMapping", back_populates="sync_logs")
 
     def __repr__(self) -> str:
         return (
             f"<UserSync(id={self.id}, "
             f"user_mapping_id={self.user_mapping_id}, "
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/models/user_mapping.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/dashboard.py	2025-12-31 13:30:51.517898+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/dashboard.py	2025-12-31 13:41:34.935212+00:00
@@ -16,41 +16,47 @@
 router = APIRouter(prefix="/api/v1/dashboard")
 
 
 class ServiceStats(BaseModel):
     """Service statistics."""
+
     total: int
     active: int
     failing: int
 
 
 class UserStats(BaseModel):
     """User statistics."""
+
     total: int
     active_sessions: int
 
 
 class TrainingStats(BaseModel):
     """Training statistics."""
+
     active_sessions: int
     completed_today: int
 
 
 class LogStats(BaseModel):
     """Log statistics."""
+
     recent_errors: int
     total_today: int
 
 
 class McpStats(BaseModel):
     """MCP statistics."""
+
     requests_today: int
     average_response_time: float
 
 
 class SystemStatus(BaseModel):
     """System status."""
+
     cpu_percent: float
     memory_used_mb: int
     memory_total_mb: int
     disk_used_gb: float
     disk_total_gb: float
@@ -58,30 +64,25 @@
     docker_containers: Dict[str, int]
 
 
 class DashboardOverview(BaseModel):
     """Dashboard overview response."""
+
     services: ServiceStats
     users: UserStats
     training: TrainingStats
     logs: LogStats
     mcp: McpStats
     system: SystemStatus
 
 
 @router.get("/overview", response_model=DashboardOverview)
-async def get_dashboard_overview(
-    db: AsyncSession = Depends(get_db_session)
-) -> DashboardOverview:
+async def get_dashboard_overview(db: AsyncSession = Depends(get_db_session)) -> DashboardOverview:
     """Get dashboard overview with system metrics and statistics."""
 
     logger.info(
-        "Dashboard overview requested",
-        extra={
-            "component": "dashboard",
-            "action": "get_overview"
-        }
+        "Dashboard overview requested", extra={"component": "dashboard", "action": "get_overview"}
     )
 
     # Get system monitor service
     system_monitor = SystemMonitorService()
 
@@ -98,51 +99,43 @@
     docker_info = await system_monitor.get_docker_status()
 
     # Build response
     overview = DashboardOverview(
         services=ServiceStats(
-            total=0,  # Would query service_configurations table
-            active=0,
-            failing=0
+            total=0, active=0, failing=0  # Would query service_configurations table
         ),
         users=UserStats(
-            total=0,  # Would query user_mappings table
-            active_sessions=1  # Current dashboard user
+            total=0, active_sessions=1  # Would query user_mappings table  # Current dashboard user
         ),
         training=TrainingStats(
-            active_sessions=0,  # Would query training_sessions table
-            completed_today=0
+            active_sessions=0, completed_today=0  # Would query training_sessions table
         ),
         logs=LogStats(
-            recent_errors=0,  # Would query log_entries table
-            total_today=50  # Mock data
+            recent_errors=0, total_today=50  # Would query log_entries table  # Mock data
         ),
-        mcp=McpStats(
-            requests_today=0,  # Would query mcp_requests table
-            average_response_time=0.0
-        ),
+        mcp=McpStats(requests_today=0, average_response_time=0.0),  # Would query mcp_requests table
         system=SystemStatus(
             cpu_percent=system_status.get("cpu_percent", 0.0),
             memory_used_mb=system_status.get("memory_used_mb", 0),
             memory_total_mb=system_status.get("memory_total_mb", 0),
             disk_used_gb=system_status.get("disk_used_gb", 0.0),
             disk_total_gb=system_status.get("disk_total_gb", 0.0),
             uptime_seconds=system_status.get("uptime_seconds", 0),
             docker_containers={
                 "running": docker_info.get("containers_running", 0),
-                "stopped": docker_info.get("containers_stopped", 0)
-            }
-        )
+                "stopped": docker_info.get("containers_stopped", 0),
+            },
+        ),
     )
 
     logger.info(
         "Dashboard overview generated",
         extra={
             "component": "dashboard",
             "action": "overview_generated",
             "services_total": overview.services.total,
             "system_cpu": overview.system.cpu_percent,
-            "system_memory_mb": overview.system.memory_used_mb
-        }
+            "system_memory_mb": overview.system.memory_used_mb,
+        },
     )
 
     return overview
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/dashboard.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/alerts.py	2025-12-31 13:30:51.520007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/alerts.py	2025-12-31 13:41:34.945885+00:00
@@ -14,10 +14,11 @@
 router = APIRouter(prefix="/api/alerts")
 
 
 class AlertConfigCreate(BaseModel):
     """Schema for creating an alert configuration."""
+
     name: str = Field(..., min_length=1, max_length=100)
     description: Optional[str] = None
     enabled: bool = True
     severity: str = AlertSeverity.MEDIUM.value
     metric_type: str = MetricType.CPU.value
@@ -32,10 +33,11 @@
     tags: dict = {}
 
 
 class AlertConfigUpdate(BaseModel):
     """Schema for updating an alert configuration."""
+
     name: Optional[str] = Field(None, min_length=1, max_length=100)
     description: Optional[str] = None
     enabled: Optional[bool] = None
     severity: Optional[str] = None
     metric_type: Optional[str] = None
@@ -50,10 +52,11 @@
     tags: Optional[dict] = None
 
 
 class AlertConfigResponse(BaseModel):
     """Schema for alert configuration response."""
+
     id: str
     name: str
     description: Optional[str]
     enabled: bool
     severity: str
@@ -74,18 +77,20 @@
     updated_at: datetime
 
 
 class AlertConfigListResponse(BaseModel):
     """Schema for paginated alert config list response."""
+
     items: List[AlertConfigResponse]
     total: int
     skip: int
     limit: int
 
 
 class AlertHistoryResponse(BaseModel):
     """Schema for alert history response."""
+
     id: str
     alert_config_id: str
     alert_name: str
     severity: str
     triggered_at: datetime
@@ -100,27 +105,30 @@
     created_at: datetime
 
 
 class AlertHistoryListResponse(BaseModel):
     """Schema for paginated alert history list response."""
+
     items: List[AlertHistoryResponse]
     total: int
     skip: int
     limit: int
 
 
 class AlertStatsResponse(BaseModel):
     """Schema for alert statistics response."""
+
     total_triggered: int
     active_count: int
     by_severity: dict
     mttr_seconds: float
     mttr_formatted: str
     period_hours: int
 
 
 # Alert Configurations endpoints
+
 
 @router.get("/configs", response_model=AlertConfigListResponse)
 async def list_alert_configs(
     enabled_only: bool = Query(False, description="Only show enabled alerts"),
     service_id: Optional[str] = Query(None, description="Filter by service ID"),
@@ -207,10 +215,11 @@
         raise HTTPException(status_code=404, detail="Alert configuration not found")
     return AlertConfigResponse(**config.to_dict())
 
 
 # Alert History endpoints
+
 
 @router.get("/history", response_model=AlertHistoryListResponse)
 async def list_alert_history(
     config_id: Optional[str] = Query(None, description="Filter by alert config ID"),
     severity: Optional[str] = Query(None, description="Filter by severity"),
@@ -256,14 +265,11 @@
     session: AsyncSession = Depends(get_db_session),
 ):
     """Manually resolve an alert."""
     history = await alert_service.resolve_alert(session, history_id, message)
     if not history:
-        raise HTTPException(
-            status_code=404,
-            detail="Alert not found or already resolved"
-        )
+        raise HTTPException(status_code=404, detail="Alert not found or already resolved")
     return AlertHistoryResponse(**history.to_dict())
 
 
 @router.get("/stats", response_model=AlertStatsResponse)
 async def get_alert_stats(
@@ -275,24 +281,21 @@
     return AlertStatsResponse(**stats)
 
 
 # Metadata endpoints
 
+
 @router.get("/severities")
 async def get_alert_severities():
     """Get all available alert severities."""
-    return {
-        "severities": [severity.value for severity in AlertSeverity]
-    }
+    return {"severities": [severity.value for severity in AlertSeverity]}
 
 
 @router.get("/metric-types")
 async def get_metric_types():
     """Get all available metric types."""
-    return {
-        "metric_types": [metric.value for metric in MetricType]
-    }
+    return {"metric_types": [metric.value for metric in MetricType]}
 
 
 @router.get("/operators")
 async def get_threshold_operators():
     """Get all available threshold operators."""
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/alerts.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/health.py	2025-12-31 13:30:51.507007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/health.py	2025-12-31 13:41:34.978106+00:00
@@ -9,18 +9,20 @@
 from src.config.settings import get_settings
 
 
 class HealthResponse(BaseModel):
     """Health check response model."""
+
     status: str
     timestamp: datetime
     version: str
     environment: str
 
 
 class DetailedHealthResponse(BaseModel):
     """Detailed health check response."""
+
     status: str
     timestamp: datetime
     version: str
     environment: str
     checks: Dict[str, Dict[str, Any]]
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/health.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/config.py	2025-12-31 13:30:51.523007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/config.py	2025-12-31 13:41:35.005348+00:00
@@ -17,10 +17,11 @@
 router = APIRouter(prefix="/api/v1/config")
 
 
 class ConfigurationSettingResponse(BaseModel):
     """Configuration setting response model."""
+
     id: str
     category: str
     key: str
     value: str
     value_type: str
@@ -42,47 +43,46 @@
             default_value=setting.default_value,
             description=setting.description,
             is_sensitive=setting.is_sensitive,
             requires_restart=setting.requires_restart,
             updated_at=setting.updated_at.isoformat(),
-            updated_by=setting.updated_by
+            updated_by=setting.updated_by,
         )
 
 
 class ConfigurationUpdateRequest(BaseModel):
     """Configuration update request."""
+
     updates: Dict[str, str]
 
 
 class ConfigurationResponse(BaseModel):
     """Configuration update response."""
+
     updated: int
     errors: List[Dict[str, str]]
     restart_required: bool
 
 
 class ConfigurationBackup(BaseModel):
     """Configuration backup model."""
+
     version: str
     created_at: str
     settings: List[Dict[str, Any]]
 
 
 @router.get("/", response_model=List[ConfigurationSettingResponse])
 async def get_configuration_settings(
     category: Optional[str] = Query(None, description="Filter by category"),
-    db: AsyncSession = Depends(get_db_session)
+    db: AsyncSession = Depends(get_db_session),
 ) -> List[ConfigurationSettingResponse]:
     """Get all configuration settings with optional category filter."""
 
     logger.info(
         "Configuration settings requested",
-        extra={
-            "component": "config",
-            "action": "list_settings",
-            "category": category
-        }
+        extra={"component": "config", "action": "list_settings", "category": category},
     )
 
     try:
         # Build query
         query = select(ConfigurationSetting)
@@ -100,45 +100,37 @@
             f"Retrieved {len(response)} configuration settings",
             extra={
                 "component": "config",
                 "action": "settings_retrieved",
                 "count": len(response),
-                "category": category
-            }
+                "category": category,
+            },
         )
 
         return response
 
     except Exception as e:
         logger.error(
             f"Failed to retrieve configuration settings: {str(e)}",
-            extra={
-                "component": "config",
-                "action": "list_settings_error",
-                "error": str(e)
-            }
-        )
-        raise HTTPException(
-            status_code=500,
-            detail="Failed to retrieve configuration settings"
-        )
+            extra={"component": "config", "action": "list_settings_error", "error": str(e)},
+        )
+        raise HTTPException(status_code=500, detail="Failed to retrieve configuration settings")
 
 
 @router.put("/", response_model=ConfigurationResponse)
 async def update_configuration_settings(
-    request: ConfigurationUpdateRequest,
-    db: AsyncSession = Depends(get_db_session)
+    request: ConfigurationUpdateRequest, db: AsyncSession = Depends(get_db_session)
 ) -> ConfigurationResponse:
     """Update multiple configuration settings."""
 
     logger.info(
         f"Configuration update requested for {len(request.updates)} settings",
         extra={
             "component": "config",
             "action": "update_settings",
-            "settings_count": len(request.updates)
-        }
+            "settings_count": len(request.updates),
+        },
     )
 
     updated_count = 0
     errors = []
     restart_required = False
@@ -150,22 +142,18 @@
                 query = select(ConfigurationSetting).where(ConfigurationSetting.key == key)
                 result = await db.execute(query)
                 setting = result.scalar_one_or_none()
 
                 if not setting:
-                    errors.append({
-                        "key": key,
-                        "message": f"Configuration setting '{key}' not found"
-                    })
+                    errors.append(
+                        {"key": key, "message": f"Configuration setting '{key}' not found"}
+                    )
                     continue
 
                 # Validate value
                 if not setting.validate_value(value):
-                    errors.append({
-                        "key": key,
-                        "message": f"Invalid value for setting '{key}'"
-                    })
+                    errors.append({"key": key, "message": f"Invalid value for setting '{key}'"})
                     continue
 
                 # Update setting
                 setting.value = value
                 setting.updated_by = "admin"  # Would get from auth context
@@ -178,79 +166,63 @@
                     f"Updated configuration setting: {key}",
                     extra={
                         "component": "config",
                         "action": "setting_updated",
                         "key": key,
-                        "requires_restart": setting.requires_restart
-                    }
+                        "requires_restart": setting.requires_restart,
+                    },
                 )
 
             except Exception as e:
-                errors.append({
-                    "key": key,
-                    "message": str(e)
-                })
+                errors.append({"key": key, "message": str(e)})
                 logger.error(
                     f"Failed to update setting {key}: {str(e)}",
                     extra={
                         "component": "config",
                         "action": "setting_update_error",
                         "key": key,
-                        "error": str(e)
-                    }
+                        "error": str(e),
+                    },
                 )
 
         # Commit changes
         await db.commit()
 
         response = ConfigurationResponse(
-            updated=updated_count,
-            errors=errors,
-            restart_required=restart_required
+            updated=updated_count, errors=errors, restart_required=restart_required
         )
 
         logger.info(
             f"Configuration update completed: {updated_count} updated, {len(errors)} errors",
             extra={
                 "component": "config",
                 "action": "update_completed",
                 "updated": updated_count,
                 "errors": len(errors),
-                "restart_required": restart_required
-            }
+                "restart_required": restart_required,
+            },
         )
 
         return response
 
     except Exception as e:
         await db.rollback()
         logger.error(
             f"Configuration update failed: {str(e)}",
-            extra={
-                "component": "config",
-                "action": "update_failed",
-                "error": str(e)
-            }
-        )
-        raise HTTPException(
-            status_code=500,
-            detail="Failed to update configuration settings"
-        )
+            extra={"component": "config", "action": "update_failed", "error": str(e)},
+        )
+        raise HTTPException(status_code=500, detail="Failed to update configuration settings")
 
 
 @router.get("/backup", response_model=ConfigurationBackup)
 async def export_configuration_backup(
-    db: AsyncSession = Depends(get_db_session)
+    db: AsyncSession = Depends(get_db_session),
 ) -> ConfigurationBackup:
     """Export complete configuration as backup."""
 
     logger.info(
-        "Configuration backup requested",
-        extra={
-            "component": "config",
-            "action": "backup_export"
-        }
+        "Configuration backup requested", extra={"component": "config", "action": "backup_export"}
     )
 
     try:
         # Get all settings
         query = select(ConfigurationSetting).order_by(
@@ -260,67 +232,59 @@
         settings = result.scalars().all()
 
         # Convert to backup format
         settings_data = []
         for setting in settings:
-            settings_data.append({
-                "category": setting.category,
-                "key": setting.key,
-                "value": setting.value,  # Full value for backup
-                "value_type": setting.value_type,
-                "default_value": setting.default_value,
-                "description": setting.description,
-                "is_sensitive": setting.is_sensitive,
-                "requires_restart": setting.requires_restart,
-            })
+            settings_data.append(
+                {
+                    "category": setting.category,
+                    "key": setting.key,
+                    "value": setting.value,  # Full value for backup
+                    "value_type": setting.value_type,
+                    "default_value": setting.default_value,
+                    "description": setting.description,
+                    "is_sensitive": setting.is_sensitive,
+                    "requires_restart": setting.requires_restart,
+                }
+            )
 
         backup = ConfigurationBackup(
-            version="1.0",
-            created_at=str(datetime.utcnow().isoformat()),
-            settings=settings_data
+            version="1.0", created_at=str(datetime.utcnow().isoformat()), settings=settings_data
         )
 
         logger.info(
             f"Configuration backup created with {len(settings_data)} settings",
             extra={
                 "component": "config",
                 "action": "backup_created",
-                "settings_count": len(settings_data)
-            }
+                "settings_count": len(settings_data),
+            },
         )
 
         return backup
 
     except Exception as e:
         logger.error(
             f"Configuration backup failed: {str(e)}",
-            extra={
-                "component": "config",
-                "action": "backup_failed",
-                "error": str(e)
-            }
-        )
-        raise HTTPException(
-            status_code=500,
-            detail="Failed to create configuration backup"
-        )
+            extra={"component": "config", "action": "backup_failed", "error": str(e)},
+        )
+        raise HTTPException(status_code=500, detail="Failed to create configuration backup")
 
 
 @router.post("/backup", response_model=ConfigurationResponse)
 async def restore_configuration_backup(
-    backup: ConfigurationBackup,
-    db: AsyncSession = Depends(get_db_session)
+    backup: ConfigurationBackup, db: AsyncSession = Depends(get_db_session)
 ) -> ConfigurationResponse:
     """Restore configuration from backup."""
 
     logger.info(
         f"Configuration restore requested with {len(backup.settings)} settings",
         extra={
             "component": "config",
             "action": "backup_restore",
-            "settings_count": len(backup.settings)
-        }
+            "settings_count": len(backup.settings),
+        },
     )
 
     updated_count = 0
     errors = []
     restart_required = False
@@ -342,44 +306,32 @@
                     if setting.requires_restart:
                         restart_required = True
                     updated_count += 1
 
             except Exception as e:
-                errors.append({
-                    "key": setting_data.get("key", "unknown"),
-                    "message": str(e)
-                })
+                errors.append({"key": setting_data.get("key", "unknown"), "message": str(e)})
 
         await db.commit()
 
         response = ConfigurationResponse(
-            updated=updated_count,
-            errors=errors,
-            restart_required=restart_required
+            updated=updated_count, errors=errors, restart_required=restart_required
         )
 
         logger.info(
             f"Configuration restore completed: {updated_count} restored",
             extra={
                 "component": "config",
                 "action": "restore_completed",
                 "updated": updated_count,
-                "errors": len(errors)
-            }
+                "errors": len(errors),
+            },
         )
 
         return response
 
     except Exception as e:
         await db.rollback()
         logger.error(
             f"Configuration restore failed: {str(e)}",
-            extra={
-                "component": "config",
-                "action": "restore_failed",
-                "error": str(e)
-            }
-        )
-        raise HTTPException(
-            status_code=500,
-            detail="Failed to restore configuration"
-        )
+            extra={"component": "config", "action": "restore_failed", "error": str(e)},
+        )
+        raise HTTPException(status_code=500, detail="Failed to restore configuration")
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/config.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/logs.py	2025-12-31 13:30:51.518007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/logs.py	2025-12-31 13:41:35.086496+00:00
@@ -16,10 +16,11 @@
 router = APIRouter(prefix="/api/logs")
 
 
 class LogEntryCreate(BaseModel):
     """Schema for creating a log entry."""
+
     level: str = Field(default=LogLevel.INFO.value)
     message: str
     source: str
     component: Optional[str] = None
     correlation_id: Optional[str] = None
@@ -34,10 +35,11 @@
     duration_ms: Optional[int] = None
 
 
 class LogEntryResponse(BaseModel):
     """Schema for log entry response."""
+
     id: str
     level: str
     message: str
     source: str
     component: Optional[str]
@@ -55,18 +57,20 @@
     created_at: datetime
 
 
 class LogListResponse(BaseModel):
     """Schema for paginated log list response."""
+
     items: List[LogEntryResponse]
     total: int
     skip: int
     limit: int
 
 
 class LogStatsResponse(BaseModel):
     """Schema for log statistics response."""
+
     total: int
     by_level: dict
     by_source: dict
     error_rate: float
     period_hours: int
@@ -152,13 +156,11 @@
 
 
 @router.get("/levels/available")
 async def get_log_levels():
     """Get all available log levels."""
-    return {
-        "levels": [level.value for level in LogLevel]
-    }
+    return {"levels": [level.value for level in LogLevel]}
 
 
 @router.get("/export")
 async def export_logs(
     format: ExportFormat = Query("json", description="Export format: json, csv, or text"),
@@ -191,13 +193,11 @@
     filename = log_exporter.get_filename(format)
 
     return Response(
         content=content,
         media_type=content_type,
-        headers={
-            "Content-Disposition": f'attachment; filename="{filename}"'
-        }
+        headers={"Content-Disposition": f'attachment; filename="{filename}"'},
     )
 
 
 @router.get("/{log_id}", response_model=LogEntryResponse)
 async def get_log(
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/logs.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/backup.py	2025-12-31 13:30:51.516007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/backup.py	2025-12-31 13:41:35.306503+00:00
@@ -23,65 +23,73 @@
 router = APIRouter(prefix="/api/backup", tags=["backup"])
 
 
 class ExportOptions(BaseModel):
     """Options for what to include in export."""
+
     services: bool = Field(default=True, description="Include service configurations")
     user_mappings: bool = Field(default=True, description="Include user mappings")
     groups: bool = Field(default=True, description="Include groups and permissions")
     site_config: bool = Field(default=True, description="Include site configuration")
     training_prompts: bool = Field(default=True, description="Include AI training prompts")
     prompt_templates: bool = Field(default=True, description="Include prompt templates")
-    training_workers: bool = Field(default=True, description="Include training worker configurations")
+    training_workers: bool = Field(
+        default=True, description="Include training worker configurations"
+    )
 
 
 class ExportResponse(BaseModel):
     """Complete export response."""
+
     version: str
     exported_at: str
     app_name: str = "mcparr-ai-gateway"
     options: ExportOptions
     data: Dict[str, Any]
     stats: Dict[str, int]
 
 
 class ImportOptions(BaseModel):
     """Options for what to import."""
+
     services: bool = Field(default=True, description="Import service configurations")
     user_mappings: bool = Field(default=True, description="Import user mappings")
     groups: bool = Field(default=True, description="Import groups and permissions")
     site_config: bool = Field(default=True, description="Import site configuration")
     training_prompts: bool = Field(default=True, description="Import AI training prompts")
     prompt_templates: bool = Field(default=True, description="Import prompt templates")
-    training_workers: bool = Field(default=True, description="Import training worker configurations")
-    merge_mode: bool = Field(default=False, description="Merge with existing data instead of replacing")
+    training_workers: bool = Field(
+        default=True, description="Import training worker configurations"
+    )
+    merge_mode: bool = Field(
+        default=False, description="Merge with existing data instead of replacing"
+    )
 
 
 class ImportRequest(BaseModel):
     """Import request with data and options."""
+
     version: str
     data: Dict[str, Any]
     options: ImportOptions = Field(default_factory=ImportOptions)
 
 
 class ImportResult(BaseModel):
     """Result of import operation."""
+
     success: bool
     imported: Dict[str, int]
     errors: List[Dict[str, str]]
     warnings: List[str]
 
 
 @router.post("/export", response_model=ExportResponse)
 async def export_configuration(
-    options: ExportOptions = ExportOptions(),
-    db: AsyncSession = Depends(get_db_session)
+    options: ExportOptions = ExportOptions(), db: AsyncSession = Depends(get_db_session)
 ) -> ExportResponse:
     """Export complete site configuration based on selected options."""
-    logger.info(
-        f"Configuration export requested with options: {options.model_dump()}"
-    )
+    logger.info(f"Configuration export requested with options: {options.model_dump()}")
 
     data = {}
     stats = {}
 
     try:
@@ -90,11 +98,13 @@
             result = await db.execute(select(ServiceConfig))
             services = result.scalars().all()
             data["services"] = [
                 {
                     "name": s.name,
-                    "service_type": s.service_type.value if hasattr(s.service_type, 'value') else str(s.service_type),
+                    "service_type": s.service_type.value
+                    if hasattr(s.service_type, "value")
+                    else str(s.service_type),
                     "base_url": s.base_url,
                     "api_key": s.api_key,  # Note: sensitive data included
                     "enabled": s.enabled,
                     "config": s.config or {},
                     "description": s.description,
@@ -117,28 +127,29 @@
             data["user_mappings"] = [
                 {
                     "central_user_id": m.central_user_id,
                     "central_username": m.central_username,
                     "central_email": m.central_email,
-                    "service_type": m.service_config.service_type.value if m.service_config and hasattr(m.service_config.service_type, 'value') else None,
+                    "service_type": m.service_config.service_type.value
+                    if m.service_config and hasattr(m.service_config.service_type, "value")
+                    else None,
                     "service_name": m.service_config.name if m.service_config else None,
                     "service_user_id": m.service_user_id,
                     "service_username": m.service_username,
                     "service_email": m.service_email,
-                    "role": m.role.value if hasattr(m.role, 'value') else str(m.role),
-                    "status": m.status.value if hasattr(m.status, 'value') else str(m.status),
+                    "role": m.role.value if hasattr(m.role, "value") else str(m.role),
+                    "status": m.status.value if hasattr(m.status, "value") else str(m.status),
                 }
                 for m in mappings
             ]
             stats["user_mappings"] = len(data["user_mappings"])
 
         # Export groups with memberships and permissions
         if options.groups:
             result = await db.execute(
                 select(Group).options(
-                    selectinload(Group.memberships),
-                    selectinload(Group.tool_permissions)
+                    selectinload(Group.memberships), selectinload(Group.tool_permissions)
                 )
             )
             groups = result.scalars().all()
             data["groups"] = [
                 {
@@ -196,14 +207,18 @@
             prompts = result.scalars().all()
             data["training_prompts"] = [
                 {
                     "name": p.name,
                     "description": p.description,
-                    "category": p.category.value if hasattr(p.category, 'value') else str(p.category),
-                    "difficulty": p.difficulty.value if hasattr(p.difficulty, 'value') else str(p.difficulty),
-                    "source": p.source.value if hasattr(p.source, 'value') else str(p.source),
-                    "format": p.format.value if hasattr(p.format, 'value') else str(p.format),
+                    "category": p.category.value
+                    if hasattr(p.category, "value")
+                    else str(p.category),
+                    "difficulty": p.difficulty.value
+                    if hasattr(p.difficulty, "value")
+                    else str(p.difficulty),
+                    "source": p.source.value if hasattr(p.source, "value") else str(p.source),
+                    "format": p.format.value if hasattr(p.format, "value") else str(p.format),
                     "content": p.content or {},
                     "system_prompt": p.system_prompt,
                     "user_input": p.user_input,
                     "expected_output": p.expected_output,
                     "tool_call": p.tool_call,
@@ -230,12 +245,14 @@
                     "description": t.description,
                     "system_template": t.system_template,
                     "user_template": t.user_template,
                     "assistant_template": t.assistant_template,
                     "variables": t.variables or [],
-                    "category": t.category.value if hasattr(t.category, 'value') else str(t.category),
-                    "format": t.format.value if hasattr(t.format, 'value') else str(t.format),
+                    "category": t.category.value
+                    if hasattr(t.category, "value")
+                    else str(t.category),
+                    "format": t.format.value if hasattr(t.format, "value") else str(t.format),
                     "enabled": t.enabled,
                     "times_used": t.times_used,
                 }
                 for t in templates
             ]
@@ -262,11 +279,11 @@
         response = ExportResponse(
             version="1.0",
             exported_at=datetime.utcnow().isoformat(),
             options=options,
             data=data,
-            stats=stats
+            stats=stats,
         )
 
         logger.info(f"Configuration export completed: {stats}")
 
         return response
@@ -276,12 +293,11 @@
         raise HTTPException(status_code=500, detail=f"Export failed: {str(e)}")
 
 
 @router.post("/import", response_model=ImportResult)
 async def import_configuration(
-    request: ImportRequest,
-    db: AsyncSession = Depends(get_db_session)
+    request: ImportRequest, db: AsyncSession = Depends(get_db_session)
 ) -> ImportResult:
     """Import configuration from backup file."""
     logger.info(f"Configuration import requested with options: {request.options.model_dump()}")
 
     imported = {}
@@ -306,14 +322,17 @@
                             for key, value in service_data.items():
                                 if key != "name" and hasattr(existing_service, key):
                                     setattr(existing_service, key, value)
                             count += 1
                         else:
-                            warnings.append(f"Service '{service_data['name']}' already exists, skipped")
+                            warnings.append(
+                                f"Service '{service_data['name']}' already exists, skipped"
+                            )
                     else:
                         # Create new service
                         from src.models.service_config import ServiceType
+
                         service = ServiceConfig(
                             name=service_data["name"],
                             service_type=ServiceType(service_data["service_type"]),
                             base_url=service_data["base_url"],
                             api_key=service_data.get("api_key"),
@@ -327,11 +346,17 @@
                             health_check_interval=service_data.get("health_check_interval", 300),
                         )
                         db.add(service)
                         count += 1
                 except Exception as e:
-                    errors.append({"type": "service", "name": service_data.get("name", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "service",
+                            "name": service_data.get("name", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["services"] = count
 
         # Import groups first (before user mappings since memberships reference users)
         if request.options.groups and "groups" in request.data:
@@ -375,11 +400,12 @@
                     for member_data in group_data.get("memberships", []):
                         try:
                             existing_member = await db.execute(
                                 select(GroupMembership).where(
                                     GroupMembership.group_id == group.id,
-                                    GroupMembership.central_user_id == member_data["central_user_id"]
+                                    GroupMembership.central_user_id
+                                    == member_data["central_user_id"],
                                 )
                             )
                             if not existing_member.scalar_one_or_none():
                                 membership = GroupMembership(
                                     group_id=group.id,
@@ -388,19 +414,21 @@
                                     granted_by=member_data.get("granted_by"),
                                 )
                                 db.add(membership)
                                 membership_count += 1
                         except Exception as e:
-                            errors.append({"type": "membership", "group": group_data["name"], "error": str(e)})
+                            errors.append(
+                                {"type": "membership", "group": group_data["name"], "error": str(e)}
+                            )
 
                     # Import tool permissions
                     for perm_data in group_data.get("tool_permissions", []):
                         try:
                             existing_perm = await db.execute(
                                 select(GroupToolPermission).where(
                                     GroupToolPermission.group_id == group.id,
-                                    GroupToolPermission.tool_name == perm_data["tool_name"]
+                                    GroupToolPermission.tool_name == perm_data["tool_name"],
                                 )
                             )
                             if not existing_perm.scalar_one_or_none():
                                 permission = GroupToolPermission(
                                     group_id=group.id,
@@ -410,14 +438,22 @@
                                     description=perm_data.get("description"),
                                 )
                                 db.add(permission)
                                 permission_count += 1
                         except Exception as e:
-                            errors.append({"type": "permission", "group": group_data["name"], "error": str(e)})
+                            errors.append(
+                                {"type": "permission", "group": group_data["name"], "error": str(e)}
+                            )
 
                 except Exception as e:
-                    errors.append({"type": "group", "name": group_data.get("name", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "group",
+                            "name": group_data.get("name", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["groups"] = group_count
             imported["memberships"] = membership_count
             imported["permissions"] = permission_count
 
@@ -427,27 +463,32 @@
             for mapping_data in request.data["user_mappings"]:
                 try:
                     # Find service by name
                     if mapping_data.get("service_name"):
                         service_result = await db.execute(
-                            select(ServiceConfig).where(ServiceConfig.name == mapping_data["service_name"])
+                            select(ServiceConfig).where(
+                                ServiceConfig.name == mapping_data["service_name"]
+                            )
                         )
                         service = service_result.scalar_one_or_none()
 
                         if not service:
-                            warnings.append(f"Service '{mapping_data['service_name']}' not found for mapping")
+                            warnings.append(
+                                f"Service '{mapping_data['service_name']}' not found for mapping"
+                            )
                             continue
 
                         # Check if mapping exists
                         existing = await db.execute(
                             select(UserMapping).where(
                                 UserMapping.central_user_id == mapping_data["central_user_id"],
-                                UserMapping.service_config_id == service.id
+                                UserMapping.service_config_id == service.id,
                             )
                         )
                         if not existing.scalar_one_or_none():
                             from src.models.user_mapping import MappingStatus, UserRole
+
                             mapping = UserMapping(
                                 central_user_id=mapping_data["central_user_id"],
                                 central_username=mapping_data.get("central_username"),
                                 central_email=mapping_data.get("central_email"),
                                 service_config_id=service.id,
@@ -458,30 +499,44 @@
                                 status=MappingStatus(mapping_data.get("status", "active")),
                             )
                             db.add(mapping)
                             count += 1
                 except Exception as e:
-                    errors.append({"type": "user_mapping", "user": mapping_data.get("central_user_id", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "user_mapping",
+                            "user": mapping_data.get("central_user_id", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["user_mappings"] = count
 
         # Import site config
         if request.options.site_config and "site_config" in request.data:
             count = 0
             for config_data in request.data["site_config"]:
                 try:
                     existing = await db.execute(
-                        select(ConfigurationSetting).where(ConfigurationSetting.key == config_data["key"])
+                        select(ConfigurationSetting).where(
+                            ConfigurationSetting.key == config_data["key"]
+                        )
                     )
                     setting = existing.scalar_one_or_none()
 
                     if setting:
                         setting.value = config_data["value"]
                         setting.updated_by = "import"
                         count += 1
                 except Exception as e:
-                    errors.append({"type": "config", "key": config_data.get("key", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "config",
+                            "key": config_data.get("key", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["site_config"] = count
 
         # Import training prompts
         if request.options.training_prompts and "training_prompts" in request.data:
@@ -496,10 +551,11 @@
                             PromptCategory,
                             PromptDifficulty,
                             PromptFormat,
                             PromptSource,
                         )
+
                         prompt = TrainingPrompt(
                             name=prompt_data["name"],
                             description=prompt_data.get("description"),
                             category=PromptCategory(prompt_data.get("category", "general")),
                             difficulty=PromptDifficulty(prompt_data.get("difficulty", "basic")),
@@ -520,11 +576,17 @@
                             enabled=prompt_data.get("enabled", True),
                         )
                         db.add(prompt)
                         count += 1
                 except Exception as e:
-                    errors.append({"type": "training_prompt", "name": prompt_data.get("name", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "training_prompt",
+                            "name": prompt_data.get("name", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["training_prompts"] = count
 
         # Import prompt templates
         if request.options.prompt_templates and "prompt_templates" in request.data:
@@ -534,10 +596,11 @@
                     existing = await db.execute(
                         select(PromptTemplate).where(PromptTemplate.name == template_data["name"])
                     )
                     if not existing.scalar_one_or_none():
                         from src.models.training_prompt import PromptCategory, PromptFormat
+
                         template = PromptTemplate(
                             name=template_data["name"],
                             description=template_data.get("description"),
                             system_template=template_data.get("system_template"),
                             user_template=template_data.get("user_template", ""),
@@ -549,11 +612,17 @@
                             times_used=template_data.get("times_used", 0),
                         )
                         db.add(template)
                         count += 1
                 except Exception as e:
-                    errors.append({"type": "prompt_template", "name": template_data.get("name", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "prompt_template",
+                            "name": template_data.get("name", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["prompt_templates"] = count
 
         # Import training workers
         if request.options.training_workers and "training_workers" in request.data:
@@ -573,11 +642,13 @@
                             existing_worker.api_key = worker_data.get("api_key")
                             existing_worker.enabled = worker_data.get("enabled", True)
                             existing_worker.ollama_service_id = worker_data.get("ollama_service_id")
                             count += 1
                         else:
-                            warnings.append(f"Training worker '{worker_data['name']}' already exists, skipped")
+                            warnings.append(
+                                f"Training worker '{worker_data['name']}' already exists, skipped"
+                            )
                     else:
                         worker = TrainingWorker(
                             name=worker_data["name"],
                             description=worker_data.get("description"),
                             url=worker_data.get("url", ""),
@@ -586,21 +657,24 @@
                             ollama_service_id=worker_data.get("ollama_service_id"),
                         )
                         db.add(worker)
                         count += 1
                 except Exception as e:
-                    errors.append({"type": "training_worker", "name": worker_data.get("name", "unknown"), "error": str(e)})
+                    errors.append(
+                        {
+                            "type": "training_worker",
+                            "name": worker_data.get("name", "unknown"),
+                            "error": str(e),
+                        }
+                    )
 
             imported["training_workers"] = count
 
         await db.commit()
 
         result = ImportResult(
-            success=len(errors) == 0,
-            imported=imported,
-            errors=errors,
-            warnings=warnings
+            success=len(errors) == 0, imported=imported, errors=errors, warnings=warnings
         )
 
         logger.info(f"Configuration import completed: {imported}, errors: {len(errors)}")
 
         return result
@@ -618,11 +692,11 @@
     groups: bool = True,
     site_config: bool = True,
     training_prompts: bool = True,
     prompt_templates: bool = True,
     training_workers: bool = True,
-    db: AsyncSession = Depends(get_db_session)
+    db: AsyncSession = Depends(get_db_session),
 ) -> Dict[str, int]:
     """Preview what would be exported with the given options."""
     stats = {}
 
     if services:
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/backup.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/groups.py	2025-12-31 13:30:51.506007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/groups.py	2025-12-31 13:41:35.335361+00:00
@@ -32,10 +32,11 @@
 router = APIRouter(prefix="/api/groups", tags=["groups"])
 
 
 # --- Non-parameterized routes (must come before /{group_id}) ---
 
+
 @router.get("/available-tools", response_model=dict)
 async def get_available_tools(db: AsyncSession = Depends(get_db)):
     """Get all available tools from registered services for permission assignment."""
     from ..routers.openapi_tools import get_tool_registry
 
@@ -44,52 +45,51 @@
 
     for tool_def in registry.list_tools():
         service_type = tool_def.requires_service or "system"
         if service_type not in tools_by_service:
             tools_by_service[service_type] = []
-        tools_by_service[service_type].append({
-            "name": tool_def.name,
-            "description": tool_def.description,
-            "category": tool_def.category
-        })
+        tools_by_service[service_type].append(
+            {
+                "name": tool_def.name,
+                "description": tool_def.description,
+                "category": tool_def.category,
+            }
+        )
 
     return {
         "tools_by_service": tools_by_service,
-        "total_tools": sum(len(tools) for tools in tools_by_service.values())
+        "total_tools": sum(len(tools) for tools in tools_by_service.values()),
     }
 
 
 @router.post("/check-permission", response_model=PermissionCheckResponse)
 async def check_user_permission(
-    check_request: PermissionCheckRequest,
-    db: AsyncSession = Depends(get_db)
+    check_request: PermissionCheckRequest, db: AsyncSession = Depends(get_db)
 ):
     """Check if a user has permission to access a specific tool."""
     from ..services.permission_service import PermissionService
 
     permission_service = PermissionService(db)
     result = await permission_service.check_permission(
         central_user_id=check_request.central_user_id,
         tool_name=check_request.tool_name,
-        service_type=check_request.service_type
+        service_type=check_request.service_type,
     )
 
     return PermissionCheckResponse(
         has_access=result.has_access,
         central_user_id=check_request.central_user_id,
         tool_name=check_request.tool_name,
         service_type=check_request.service_type,
         granted_by_group=result.granted_by_group,
-        granted_by_group_id=result.granted_by_group_id
+        granted_by_group_id=result.granted_by_group_id,
     )
 
 
 @router.get("/tool/{tool_name}/groups", response_model=dict)
 async def get_tool_groups_api(
-    tool_name: str,
-    service_type: Optional[str] = Query(None),
-    db: AsyncSession = Depends(get_db)
+    tool_name: str, service_type: Optional[str] = Query(None), db: AsyncSession = Depends(get_db)
 ):
     """Get all groups that have permission for a specific tool."""
     from ..services.permission_service import PermissionService
 
     permission_service = PermissionService(db)
@@ -97,113 +97,90 @@
 
     return {
         "tool_name": tool_name,
         "service_type": service_type,
         "groups": groups,
-        "total_groups": len(groups)
+        "total_groups": len(groups),
     }
 
 
 @router.get("/tools-with-groups", response_model=dict)
 async def get_all_tools_with_groups(db: AsyncSession = Depends(get_db)):
     """Get all tools with their associated groups (for displaying in the UI)."""
     # Get all tool permissions with their groups
     result = await db.execute(
         select(GroupToolPermission, Group)
         .join(Group, GroupToolPermission.group_id == Group.id)
-        .where(
-            and_(
-                GroupToolPermission.enabled is True,
-                Group.enabled is True
-            )
-        )
+        .where(and_(GroupToolPermission.enabled is True, Group.enabled is True))
     )
     rows = result.all()
 
     # Build a mapping of tool_name -> list of groups
     tool_groups: dict = {}
     for permission, group in rows:
         if permission.tool_name not in tool_groups:
             tool_groups[permission.tool_name] = []
-        tool_groups[permission.tool_name].append({
-            "id": str(group.id),
-            "name": group.name,
-            "color": group.color,
-            "icon": group.icon,
-            "priority": group.priority,
-            "is_wildcard": permission.tool_name == "*"
-        })
-
-    return {
-        "tool_groups": tool_groups,
-        "total_tools_with_groups": len(tool_groups)
-    }
+        tool_groups[permission.tool_name].append(
+            {
+                "id": str(group.id),
+                "name": group.name,
+                "color": group.color,
+                "icon": group.icon,
+                "priority": group.priority,
+                "is_wildcard": permission.tool_name == "*",
+            }
+        )
+
+    return {"tool_groups": tool_groups, "total_tools_with_groups": len(tool_groups)}
 
 
 @router.get("/user/{central_user_id}", response_model=UserGroupsResponse)
-async def get_user_groups(
-    central_user_id: str,
-    db: AsyncSession = Depends(get_db)
-):
+async def get_user_groups(central_user_id: str, db: AsyncSession = Depends(get_db)):
     """Get all groups a user belongs to."""
     # Get all memberships for this user
     memberships_result = await db.execute(
-        select(GroupMembership)
-        .where(
+        select(GroupMembership).where(
             and_(
-                GroupMembership.central_user_id == central_user_id,
-                GroupMembership.enabled is True
+                GroupMembership.central_user_id == central_user_id, GroupMembership.enabled is True
             )
         )
     )
     memberships = memberships_result.scalars().all()
 
     if not memberships:
-        return UserGroupsResponse(
-            central_user_id=central_user_id,
-            groups=[],
-            total_groups=0
-        )
+        return UserGroupsResponse(central_user_id=central_user_id, groups=[], total_groups=0)
 
     # Get the actual groups
     group_ids = [m.group_id for m in memberships]
     groups_result = await db.execute(
         select(Group)
-        .options(
-            selectinload(Group.memberships),
-            selectinload(Group.tool_permissions)
-        )
-        .where(
-            and_(
-                Group.id.in_(group_ids),
-                Group.enabled is True
-            )
-        )
+        .options(selectinload(Group.memberships), selectinload(Group.tool_permissions))
+        .where(and_(Group.id.in_(group_ids), Group.enabled is True))
         .order_by(Group.priority.desc())
     )
     groups = groups_result.scalars().all()
 
     return UserGroupsResponse(
         central_user_id=central_user_id,
         groups=[GroupResponse.model_validate(g) for g in groups],
-        total_groups=len(groups)
+        total_groups=len(groups),
     )
 
 
 # --- Group CRUD ---
+
 
 @router.get("/", response_model=GroupListResponse)
 async def list_groups(
     enabled: Optional[bool] = Query(None, description="Filter by enabled status"),
     skip: int = Query(0, ge=0, description="Number of records to skip"),
     limit: int = Query(100, ge=1, le=1000, description="Number of records to return"),
-    db: AsyncSession = Depends(get_db)
+    db: AsyncSession = Depends(get_db),
 ):
     """List all groups with optional filtering."""
     query = select(Group).options(
-        selectinload(Group.memberships),
-        selectinload(Group.tool_permissions)
+        selectinload(Group.memberships), selectinload(Group.tool_permissions)
     )
 
     if enabled is not None:
         query = query.where(Group.enabled == enabled)
 
@@ -221,32 +198,26 @@
 
     return GroupListResponse(
         groups=[GroupResponse.model_validate(g) for g in groups],
         total=total,
         skip=skip,
-        limit=limit
+        limit=limit,
     )
 
 
 @router.get("/{group_id}", response_model=GroupDetailResponse)
 async def get_group(group_id: str, db: AsyncSession = Depends(get_db)):
     """Get a specific group with all details."""
     result = await db.execute(
         select(Group)
-        .options(
-            selectinload(Group.memberships),
-            selectinload(Group.tool_permissions)
-        )
+        .options(selectinload(Group.memberships), selectinload(Group.tool_permissions))
         .where(Group.id == group_id)
     )
     group = result.scalar_one_or_none()
 
     if not group:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Group not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Group not found")
 
     # Get usernames for members
     usernames = {}
     if group.memberships:
         user_ids = [m.central_user_id for m in group.memberships]
@@ -260,23 +231,17 @@
 
     return GroupDetailResponse.model_validate(group, usernames)
 
 
 @router.post("/", response_model=GroupResponse, status_code=status.HTTP_201_CREATED)
-async def create_group(
-    group_data: GroupCreate,
-    db: AsyncSession = Depends(get_db)
-):
+async def create_group(group_data: GroupCreate, db: AsyncSession = Depends(get_db)):
     """Create a new group."""
     # Check if name already exists
-    existing = await db.execute(
-        select(Group).where(Group.name == group_data.name)
-    )
+    existing = await db.execute(select(Group).where(Group.name == group_data.name))
     if existing.scalar_one_or_none():
         raise HTTPException(
-            status_code=status.HTTP_409_CONFLICT,
-            detail="Group with this name already exists"
+            status_code=status.HTTP_409_CONFLICT, detail="Group with this name already exists"
         )
 
     group = Group(**group_data.model_dump())
     db.add(group)
     await db.commit()
@@ -285,41 +250,28 @@
     logger.info(f"Created group: {group.name} ({group.id})")
     return GroupResponse.model_validate(group)
 
 
 @router.put("/{group_id}", response_model=GroupResponse)
-async def update_group(
-    group_id: str,
-    group_data: GroupUpdate,
-    db: AsyncSession = Depends(get_db)
-):
+async def update_group(group_id: str, group_data: GroupUpdate, db: AsyncSession = Depends(get_db)):
     """Update an existing group."""
     result = await db.execute(
         select(Group)
-        .options(
-            selectinload(Group.memberships),
-            selectinload(Group.tool_permissions)
-        )
+        .options(selectinload(Group.memberships), selectinload(Group.tool_permissions))
         .where(Group.id == group_id)
     )
     group = result.scalar_one_or_none()
 
     if not group:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Group not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Group not found")
 
     # Check name uniqueness if being changed
     if group_data.name and group_data.name != group.name:
-        existing = await db.execute(
-            select(Group).where(Group.name == group_data.name)
-        )
+        existing = await db.execute(select(Group).where(Group.name == group_data.name))
         if existing.scalar_one_or_none():
             raise HTTPException(
-                status_code=status.HTTP_409_CONFLICT,
-                detail="Group with this name already exists"
+                status_code=status.HTTP_409_CONFLICT, detail="Group with this name already exists"
             )
 
     # Update fields
     update_data = group_data.model_dump(exclude_unset=True)
     for field, value in update_data.items():
@@ -337,33 +289,28 @@
     """Delete a group."""
     result = await db.execute(select(Group).where(Group.id == group_id))
     group = result.scalar_one_or_none()
 
     if not group:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Group not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Group not found")
 
     if group.is_system:
         raise HTTPException(
-            status_code=status.HTTP_403_FORBIDDEN,
-            detail="Cannot delete system groups"
+            status_code=status.HTTP_403_FORBIDDEN, detail="Cannot delete system groups"
         )
 
     await db.delete(group)
     await db.commit()
     logger.info(f"Deleted group: {group.name} ({group.id})")
 
 
 # --- Group Memberships ---
+
 
 @router.get("/{group_id}/members", response_model=List[GroupMembershipResponse])
 async def list_group_members(
-    group_id: str,
-    enabled: Optional[bool] = Query(None),
-    db: AsyncSession = Depends(get_db)
+    group_id: str, enabled: Optional[bool] = Query(None), db: AsyncSession = Depends(get_db)
 ):
     """List all members of a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -392,15 +339,17 @@
         GroupMembershipResponse.model_validate(m, usernames.get(m.central_user_id))
         for m in memberships
     ]
 
 
-@router.post("/{group_id}/members", response_model=GroupMembershipResponse, status_code=status.HTTP_201_CREATED)
+@router.post(
+    "/{group_id}/members",
+    response_model=GroupMembershipResponse,
+    status_code=status.HTTP_201_CREATED,
+)
 async def add_group_member(
-    group_id: str,
-    membership_data: GroupMembershipCreate,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, membership_data: GroupMembershipCreate, db: AsyncSession = Depends(get_db)
 ):
     """Add a user to a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -409,24 +358,20 @@
     # Check if membership already exists
     existing = await db.execute(
         select(GroupMembership).where(
             and_(
                 GroupMembership.group_id == group_id,
-                GroupMembership.central_user_id == membership_data.central_user_id
+                GroupMembership.central_user_id == membership_data.central_user_id,
             )
         )
     )
     if existing.scalar_one_or_none():
         raise HTTPException(
-            status_code=status.HTTP_409_CONFLICT,
-            detail="User is already a member of this group"
-        )
-
-    membership = GroupMembership(
-        group_id=group_id,
-        **membership_data.model_dump()
-    )
+            status_code=status.HTTP_409_CONFLICT, detail="User is already a member of this group"
+        )
+
+    membership = GroupMembership(group_id=group_id, **membership_data.model_dump())
     db.add(membership)
     await db.commit()
     await db.refresh(membership)
 
     # Get username
@@ -441,20 +386,18 @@
     return GroupMembershipResponse.model_validate(membership, username)
 
 
 @router.delete("/{group_id}/members/{central_user_id}", status_code=status.HTTP_204_NO_CONTENT)
 async def remove_group_member(
-    group_id: str,
-    central_user_id: str,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, central_user_id: str, db: AsyncSession = Depends(get_db)
 ):
     """Remove a user from a group."""
     result = await db.execute(
         select(GroupMembership).where(
             and_(
                 GroupMembership.group_id == group_id,
-                GroupMembership.central_user_id == central_user_id
+                GroupMembership.central_user_id == central_user_id,
             )
         )
     )
     membership = result.scalar_one_or_none()
 
@@ -466,13 +409,11 @@
     logger.info(f"Removed user {central_user_id} from group {group_id}")
 
 
 @router.post("/{group_id}/members/bulk", response_model=dict)
 async def bulk_update_members(
-    group_id: str,
-    bulk_data: BulkMembershipUpdate,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, bulk_data: BulkMembershipUpdate, db: AsyncSession = Depends(get_db)
 ):
     """Bulk add or remove members from a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -488,27 +429,24 @@
                 # Check if already exists
                 existing = await db.execute(
                     select(GroupMembership).where(
                         and_(
                             GroupMembership.group_id == group_id,
-                            GroupMembership.central_user_id == user_id
+                            GroupMembership.central_user_id == user_id,
                         )
                     )
                 )
                 if not existing.scalar_one_or_none():
-                    membership = GroupMembership(
-                        group_id=group_id,
-                        central_user_id=user_id
-                    )
+                    membership = GroupMembership(group_id=group_id, central_user_id=user_id)
                     db.add(membership)
                     added += 1
             elif bulk_data.action == "remove":
                 result = await db.execute(
                     select(GroupMembership).where(
                         and_(
                             GroupMembership.group_id == group_id,
-                            GroupMembership.central_user_id == user_id
+                            GroupMembership.central_user_id == user_id,
                         )
                     )
                 )
                 membership = result.scalar_one_or_none()
                 if membership:
@@ -517,26 +455,22 @@
         except Exception as e:
             errors.append({"user_id": user_id, "error": str(e)})
 
     await db.commit()
 
-    return {
-        "action": bulk_data.action,
-        "added": added,
-        "removed": removed,
-        "errors": errors
-    }
+    return {"action": bulk_data.action, "added": added, "removed": removed, "errors": errors}
 
 
 # --- Tool Permissions ---
+
 
 @router.get("/{group_id}/permissions", response_model=List[GroupToolPermissionResponse])
 async def list_group_permissions(
     group_id: str,
     service_type: Optional[str] = Query(None),
     enabled: Optional[bool] = Query(None),
-    db: AsyncSession = Depends(get_db)
+    db: AsyncSession = Depends(get_db),
 ):
     """List all tool permissions for a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -552,15 +486,17 @@
     permissions = result.scalars().all()
 
     return [GroupToolPermissionResponse.model_validate(p) for p in permissions]
 
 
-@router.post("/{group_id}/permissions", response_model=GroupToolPermissionResponse, status_code=status.HTTP_201_CREATED)
+@router.post(
+    "/{group_id}/permissions",
+    response_model=GroupToolPermissionResponse,
+    status_code=status.HTTP_201_CREATED,
+)
 async def add_tool_permission(
-    group_id: str,
-    permission_data: GroupToolPermissionCreate,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, permission_data: GroupToolPermissionCreate, db: AsyncSession = Depends(get_db)
 ):
     """Add a tool permission to a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -570,24 +506,20 @@
     existing = await db.execute(
         select(GroupToolPermission).where(
             and_(
                 GroupToolPermission.group_id == group_id,
                 GroupToolPermission.tool_name == permission_data.tool_name,
-                GroupToolPermission.service_type == permission_data.service_type
+                GroupToolPermission.service_type == permission_data.service_type,
             )
         )
     )
     if existing.scalar_one_or_none():
         raise HTTPException(
-            status_code=status.HTTP_409_CONFLICT,
-            detail="Permission already exists for this tool"
-        )
-
-    permission = GroupToolPermission(
-        group_id=group_id,
-        **permission_data.model_dump()
-    )
+            status_code=status.HTTP_409_CONFLICT, detail="Permission already exists for this tool"
+        )
+
+    permission = GroupToolPermission(group_id=group_id, **permission_data.model_dump())
     db.add(permission)
     await db.commit()
     await db.refresh(permission)
 
     logger.info(f"Added permission for tool {permission_data.tool_name} to group {group_id}")
@@ -597,19 +529,16 @@
 @router.put("/{group_id}/permissions/{permission_id}", response_model=GroupToolPermissionResponse)
 async def update_tool_permission(
     group_id: str,
     permission_id: str,
     permission_data: GroupToolPermissionUpdate,
-    db: AsyncSession = Depends(get_db)
+    db: AsyncSession = Depends(get_db),
 ):
     """Update a tool permission."""
     result = await db.execute(
         select(GroupToolPermission).where(
-            and_(
-                GroupToolPermission.id == permission_id,
-                GroupToolPermission.group_id == group_id
-            )
+            and_(GroupToolPermission.id == permission_id, GroupToolPermission.group_id == group_id)
         )
     )
     permission = result.scalar_one_or_none()
 
     if not permission:
@@ -625,21 +554,16 @@
     return GroupToolPermissionResponse.model_validate(permission)
 
 
 @router.delete("/{group_id}/permissions/{permission_id}", status_code=status.HTTP_204_NO_CONTENT)
 async def delete_tool_permission(
-    group_id: str,
-    permission_id: str,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, permission_id: str, db: AsyncSession = Depends(get_db)
 ):
     """Delete a tool permission."""
     result = await db.execute(
         select(GroupToolPermission).where(
-            and_(
-                GroupToolPermission.id == permission_id,
-                GroupToolPermission.group_id == group_id
-            )
+            and_(GroupToolPermission.id == permission_id, GroupToolPermission.group_id == group_id)
         )
     )
     permission = result.scalar_one_or_none()
 
     if not permission:
@@ -650,13 +574,11 @@
     logger.info(f"Deleted permission {permission_id} from group {group_id}")
 
 
 @router.post("/{group_id}/permissions/bulk", response_model=dict)
 async def bulk_update_permissions(
-    group_id: str,
-    bulk_data: BulkPermissionUpdate,
-    db: AsyncSession = Depends(get_db)
+    group_id: str, bulk_data: BulkPermissionUpdate, db: AsyncSession = Depends(get_db)
 ):
     """Bulk add or update tool permissions for a group."""
     # Verify group exists
     group_result = await db.execute(select(Group).where(Group.id == group_id))
     if not group_result.scalar_one_or_none():
@@ -672,11 +594,11 @@
             existing_result = await db.execute(
                 select(GroupToolPermission).where(
                     and_(
                         GroupToolPermission.group_id == group_id,
                         GroupToolPermission.tool_name == tool_name,
-                        GroupToolPermission.service_type == bulk_data.service_type
+                        GroupToolPermission.service_type == bulk_data.service_type,
                     )
                 )
             )
             existing = existing_result.scalar_one_or_none()
 
@@ -686,19 +608,15 @@
             else:
                 permission = GroupToolPermission(
                     group_id=group_id,
                     tool_name=tool_name,
                     service_type=bulk_data.service_type,
-                    enabled=bulk_data.enabled
+                    enabled=bulk_data.enabled,
                 )
                 db.add(permission)
                 added += 1
         except Exception as e:
             errors.append({"tool_name": tool_name, "error": str(e)})
 
     await db.commit()
 
-    return {
-        "added": added,
-        "updated": updated,
-        "errors": errors
-    }
+    return {"added": added, "updated": updated, "errors": errors}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/groups.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/mcp.py	2025-12-31 13:30:51.547007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/mcp.py	2025-12-31 13:41:35.382751+00:00
@@ -42,12 +42,11 @@
         return {}
 
     # Find Open WebUI service
     openwebui_result = await session.execute(
         select(ServiceConfig).where(
-            ServiceConfig.service_type == "openwebui",
-            ServiceConfig.enabled is True
+            ServiceConfig.service_type == "openwebui", ServiceConfig.enabled is True
         )
     )
     openwebui_service = openwebui_result.scalar_one_or_none()
 
     if not openwebui_service:
@@ -56,11 +55,11 @@
     # Look up Open WebUI mappings where service_email matches any of the user_ids (emails)
     mapping_result = await session.execute(
         select(UserMapping).where(
             UserMapping.service_config_id == str(openwebui_service.id),
             UserMapping.service_email.in_(valid_user_ids),
-            UserMapping.enabled is True
+            UserMapping.enabled is True,
         )
     )
     openwebui_mappings = mapping_result.scalars().all()
 
     if not openwebui_mappings:
@@ -70,12 +69,11 @@
     central_user_ids = [m.central_user_id for m in openwebui_mappings]
 
     # Get all mappings for these users to find the best display name
     all_mappings_result = await session.execute(
         select(UserMapping).where(
-            UserMapping.central_user_id.in_(central_user_ids),
-            UserMapping.enabled is True
+            UserMapping.central_user_id.in_(central_user_ids), UserMapping.enabled is True
         )
     )
     all_mappings = all_mappings_result.scalars().all()
 
     # Build lookup: central_user_id -> best display name
@@ -87,22 +85,21 @@
 
         if not current_name:
             best_names[mapping.central_user_id] = candidate
         elif current_name and candidate:
             # Prefer names that don't look like email prefixes (contain dots or match email pattern)
-            current_looks_like_email = '.' in current_name and '@' not in current_name
-            candidate_looks_like_email = '.' in candidate and '@' not in candidate
+            current_looks_like_email = "." in current_name and "@" not in current_name
+            candidate_looks_like_email = "." in candidate and "@" not in candidate
             if current_looks_like_email and not candidate_looks_like_email:
                 best_names[mapping.central_user_id] = candidate
 
     # Build final lookup: email -> display name
     display_names = {}
     for mapping in openwebui_mappings:
         if mapping.service_email:
             display_names[mapping.service_email] = best_names.get(
-                mapping.central_user_id,
-                mapping.central_username or mapping.service_username
+                mapping.central_user_id, mapping.central_username or mapping.service_username
             )
 
     return display_names
 
 
@@ -141,13 +138,11 @@
     from src.mcp.tools.wikijs_tools import WikiJSTools
     from src.mcp.tools.zammad_tools import ZammadTools
     from src.models import ServiceConfig
 
     # Get enabled services from database
-    result = await session.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    result = await session.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     enabled_services = result.scalars().all()
     enabled_service_types = [s.service_type.lower() for s in enabled_services]
 
     registry = ToolRegistry()
     registry.register(SystemTools)
@@ -299,11 +294,11 @@
         items=[
             McpRequestResponse(
                 id=str(req.id),
                 tool_name=req.tool_name,
                 tool_category=req.tool_category,
-                status=req.status.value if hasattr(req.status, 'value') else req.status,
+                status=req.status.value if hasattr(req.status, "value") else req.status,
                 input_params=req.input_params,
                 output_result=req.output_result,
                 error_message=req.error_message,
                 duration_ms=req.duration_ms,
                 user_id=req.user_id,
@@ -328,10 +323,11 @@
     """Get a specific MCP request by ID."""
     request = await mcp_audit_service.get_request_by_id(session, request_id)
 
     if not request:
         from fastapi import HTTPException
+
         raise HTTPException(status_code=404, detail="MCP request not found")
 
     # Get user display name if user_id exists
     user_display_name = None
     if request.user_id:
@@ -340,11 +336,11 @@
 
     return McpRequestResponse(
         id=str(request.id),
         tool_name=request.tool_name,
         tool_category=request.tool_category,
-        status=request.status.value if hasattr(request.status, 'value') else request.status,
+        status=request.status.value if hasattr(request.status, "value") else request.status,
         input_params=request.input_params,
         output_result=request.output_result,
         error_message=request.error_message,
         duration_ms=request.duration_ms,
         user_id=request.user_id,
@@ -397,12 +393,11 @@
     user_ids = [s["user_id"] for s in stats if s["user_id"]]
     display_names = await get_user_display_names(session, user_ids)
 
     return [
         McpUserStatsResponse(
-            **s,
-            user_display_name=display_names.get(s["user_id"]) if s["user_id"] else None
+            **s, user_display_name=display_names.get(s["user_id"]) if s["user_id"] else None
         )
         for s in stats
     ]
 
 
@@ -418,12 +413,11 @@
     user_ids = list({s["user_id"] for s in stats if s["user_id"]})
     display_names = await get_user_display_names(session, user_ids)
 
     return [
         McpUserServiceStatsResponse(
-            **s,
-            user_display_name=display_names.get(s["user_id"]) if s["user_id"] else None
+            **s, user_display_name=display_names.get(s["user_id"]) if s["user_id"] else None
         )
         for s in stats
     ]
 
 
@@ -439,12 +433,11 @@
     user_ids = list({u["user_id"] for u in usage if u["user_id"]})
     display_names = await get_user_display_names(session, user_ids)
 
     return [
         McpHourlyUserUsageResponse(
-            **u,
-            user_display_name=display_names.get(u["user_id"]) if u["user_id"] else None
+            **u, user_display_name=display_names.get(u["user_id"]) if u["user_id"] else None
         )
         for u in usage
     ]
 
 
@@ -483,13 +476,11 @@
     from src.mcp.tools.wikijs_tools import WikiJSTools
     from src.mcp.tools.zammad_tools import ZammadTools
     from src.models import ServiceConfig
 
     # Get enabled services from database
-    result = await session.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    result = await session.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     enabled_services = result.scalars().all()
     enabled_service_types = {s.service_type.lower() for s in enabled_services}
 
     registry = ToolRegistry()
 
@@ -520,28 +511,30 @@
         if service_type in service_tools_map:
             registry.register(service_tools_map[service_type])
 
     tools = []
     for name, tool_def in registry.tools.items():
-        tools.append({
-            "name": name,
-            "description": tool_def.description,
-            "category": tool_def.category,
-            "is_mutation": tool_def.is_mutation,
-            "requires_service": tool_def.requires_service,
-            "parameters": [
-                {
-                    "name": p.name,
-                    "description": p.description,
-                    "type": p.type,
-                    "required": p.required,
-                    "enum": p.enum,
-                    "default": p.default,
-                }
-                for p in tool_def.parameters
-            ],
-        })
+        tools.append(
+            {
+                "name": name,
+                "description": tool_def.description,
+                "category": tool_def.category,
+                "is_mutation": tool_def.is_mutation,
+                "requires_service": tool_def.requires_service,
+                "parameters": [
+                    {
+                        "name": p.name,
+                        "description": p.description,
+                        "type": p.type,
+                        "required": p.required,
+                        "enum": p.enum,
+                        "default": p.default,
+                    }
+                    for p in tool_def.parameters
+                ],
+            }
+        )
 
     # Group by category
     categories = {}
     for tool in tools:
         cat = tool["category"]
@@ -599,25 +592,23 @@
     from src.models import ServiceConfig
 
     start_time = time.time()
 
     # Get enabled services from database
-    result = await session.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    result = await session.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     enabled_services = result.scalars().all()
 
     # Build service configs dict
     service_configs = {}
     for svc in enabled_services:
         service_configs[svc.service_type.lower()] = {
             "url": svc.base_url,
             "port": svc.port,
             "api_key": svc.api_key,
-            "username": getattr(svc, 'username', None),
-            "password": getattr(svc, 'password', None),
-            "extra_config": getattr(svc, 'extra_config', None) or {},
+            "username": getattr(svc, "username", None),
+            "password": getattr(svc, "password", None),
+            "extra_config": getattr(svc, "extra_config", None) or {},
         }
 
     # Tool class mapping
     tool_classes = {
         "system": SystemTools,
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/mcp.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/system.py	2025-12-31 13:30:51.566007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/system.py	2025-12-31 13:41:35.440723+00:00
@@ -17,76 +17,78 @@
 router = APIRouter(prefix="/api/v1/system")
 
 
 class HealthCheck(BaseModel):
     """Health check details."""
+
     name: str
     status: str
     message: str
     response_time_ms: Optional[float] = None
 
 
 class HealthStatus(BaseModel):
     """System health status."""
+
     status: str
     checks: List[HealthCheck]
 
 
 class SystemMetrics(BaseModel):
     """System metrics response."""
+
     timestamps: List[str]
     cpu: List[float]
     memory: List[float]
     disk: List[float]
     network_sent: List[float]
     network_recv: List[float]
 
 
 class MetricsDuration(str, Enum):
     """Available metrics duration options."""
+
     ONE_MINUTE = "1m"
     FIVE_MINUTES = "5m"
     FIFTEEN_MINUTES = "15m"
     ONE_HOUR = "1h"
     TWENTY_FOUR_HOURS = "24h"
 
 
 @router.get("/health", response_model=HealthStatus)
-async def get_system_health(
-    db: AsyncSession = Depends(get_db_session)
-) -> HealthStatus:
+async def get_system_health(db: AsyncSession = Depends(get_db_session)) -> HealthStatus:
     """Get detailed system health status."""
 
     logger.info(
-        "System health check requested",
-        extra={
-            "component": "system",
-            "action": "health_check"
-        }
+        "System health check requested", extra={"component": "system", "action": "health_check"}
     )
 
     system_monitor = SystemMonitorService()
 
     checks = []
 
     # Database health check
     try:
         # Simple query to test database
         await db.execute("SELECT 1")
-        checks.append(HealthCheck(
-            name="database",
-            status="healthy",
-            message="Database connection successful",
-            response_time_ms=5.2
-        ))
-    except Exception as e:
-        checks.append(HealthCheck(
-            name="database",
-            status="unhealthy",
-            message=f"Database connection failed: {str(e)}",
-            response_time_ms=None
-        ))
+        checks.append(
+            HealthCheck(
+                name="database",
+                status="healthy",
+                message="Database connection successful",
+                response_time_ms=5.2,
+            )
+        )
+    except Exception as e:
+        checks.append(
+            HealthCheck(
+                name="database",
+                status="unhealthy",
+                message=f"Database connection failed: {str(e)}",
+                response_time_ms=None,
+            )
+        )
 
     # System resources check
     try:
         system_status = await system_monitor.get_current_system_status()
         cpu_percent = system_status.get("cpu_percent", 0)
@@ -98,46 +100,51 @@
             message = f"High resource usage: CPU {cpu_percent}%, Memory {memory_percent}%, Disk {disk_percent}%"
         else:
             status = "healthy"
             message = "System resources within normal range"
 
-        checks.append(HealthCheck(
-            name="system_resources",
-            status=status,
-            message=message,
-            response_time_ms=2.1
-        ))
-    except Exception as e:
-        checks.append(HealthCheck(
-            name="system_resources",
-            status="unhealthy",
-            message=f"Failed to get system resources: {str(e)}"
-        ))
+        checks.append(
+            HealthCheck(
+                name="system_resources", status=status, message=message, response_time_ms=2.1
+            )
+        )
+    except Exception as e:
+        checks.append(
+            HealthCheck(
+                name="system_resources",
+                status="unhealthy",
+                message=f"Failed to get system resources: {str(e)}",
+            )
+        )
 
     # Docker health check
     try:
         docker_status = await system_monitor.get_docker_status()
-        checks.append(HealthCheck(
-            name="docker",
-            status="healthy",
-            message=f"Docker running with {docker_status.get('containers_running', 0)} containers",
-            response_time_ms=15.3
-        ))
-    except Exception as e:
-        checks.append(HealthCheck(
-            name="docker",
+        checks.append(
+            HealthCheck(
+                name="docker",
+                status="healthy",
+                message=f"Docker running with {docker_status.get('containers_running', 0)} containers",
+                response_time_ms=15.3,
+            )
+        )
+    except Exception as e:
+        checks.append(
+            HealthCheck(
+                name="docker", status="degraded", message=f"Docker status unknown: {str(e)}"
+            )
+        )
+
+    # External services check (would be implemented when services are configured)
+    checks.append(
+        HealthCheck(
+            name="external_services",
             status="degraded",
-            message=f"Docker status unknown: {str(e)}"
-        ))
-
-    # External services check (would be implemented when services are configured)
-    checks.append(HealthCheck(
-        name="external_services",
-        status="degraded",
-        message="No services configured yet",
-        response_time_ms=None
-    ))
+            message="No services configured yet",
+            response_time_ms=None,
+        )
+    )
 
     # Determine overall status
     statuses = [check.status for check in checks]
     if "unhealthy" in statuses:
         overall_status = "unhealthy"
@@ -150,18 +157,15 @@
         "System health check completed",
         extra={
             "component": "system",
             "action": "health_check_completed",
             "overall_status": overall_status,
-            "checks_count": len(checks)
-        }
-    )
-
-    return HealthStatus(
-        status=overall_status,
-        checks=checks
-    )
+            "checks_count": len(checks),
+        },
+    )
+
+    return HealthStatus(status=overall_status, checks=checks)
 
 
 @router.get("/system-metrics")
 async def get_current_system_metrics():
     """Get current system metrics in frontend-compatible format."""
@@ -170,51 +174,47 @@
     import psutil
 
     try:
         cpu_usage = psutil.cpu_percent(interval=0.1)
         memory = psutil.virtual_memory()
-        disk = psutil.disk_usage('/')
+        disk = psutil.disk_usage("/")
         network = psutil.net_io_counters()
 
         # Get boot time for uptime calculation
         boot_time = psutil.boot_time()
         uptime = time.time() - boot_time
 
         return {
             "cpu_usage": cpu_usage,
-            "cpu_load_avg": psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0,
+            "cpu_load_avg": psutil.getloadavg()[0] if hasattr(psutil, "getloadavg") else 0,
             "memory_usage": memory.percent,
             "memory_used": memory.used,
             "memory_total": memory.total,
             "disk_usage": (disk.used / disk.total) * 100,
             "disk_used": disk.used,
             "disk_total": disk.total,
             "network_bytes_sent": network.bytes_sent,
             "network_bytes_recv": network.bytes_recv,
             "services_running": 5,  # Mock data
-            "services_total": 6,    # Mock data
-            "uptime": uptime
+            "services_total": 6,  # Mock data
+            "uptime": uptime,
         }
     except Exception as e:
         logger.error(f"Failed to get system metrics: {e}")
         raise HTTPException(status_code=500, detail="Failed to retrieve system metrics")
 
 
 @router.get("/metrics", response_model=SystemMetrics)
 async def get_system_metrics(
     duration: MetricsDuration = Query(default=MetricsDuration.FIVE_MINUTES),
-    db: AsyncSession = Depends(get_db_session)
+    db: AsyncSession = Depends(get_db_session),
 ) -> SystemMetrics:
     """Get system metrics for specified duration."""
 
     logger.info(
         f"System metrics requested for duration: {duration}",
-        extra={
-            "component": "system",
-            "action": "get_metrics",
-            "duration": duration
-        }
+        extra={"component": "system", "action": "get_metrics", "duration": duration},
     )
 
     system_monitor = SystemMonitorService()
 
     # Convert duration to timedelta
@@ -235,27 +235,26 @@
 
     # Generate timestamps
     intervals = 30  # Number of data points
     interval_seconds = time_delta.total_seconds() / intervals
     timestamps = [
-        (start_time + timedelta(seconds=i * interval_seconds)).isoformat()
-        for i in range(intervals)
+        (start_time + timedelta(seconds=i * interval_seconds)).isoformat() for i in range(intervals)
     ]
 
     logger.info(
         f"Generated {len(timestamps)} data points for metrics",
         extra={
             "component": "system",
             "action": "metrics_generated",
             "data_points": len(timestamps),
-            "duration": duration
-        }
+            "duration": duration,
+        },
     )
 
     return SystemMetrics(
         timestamps=timestamps,
         cpu=metrics_data.get("cpu", [0.0] * intervals),
         memory=metrics_data.get("memory", [0.0] * intervals),
         disk=metrics_data.get("disk", [0.0] * intervals),
         network_sent=metrics_data.get("network_sent", [0.0] * intervals),
-        network_recv=metrics_data.get("network_recv", [0.0] * intervals)
-    )
+        network_recv=metrics_data.get("network_recv", [0.0] * intervals),
+    )
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/system.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/services.py	2025-12-31 13:30:51.539007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/services.py	2025-12-31 13:41:35.465704+00:00
@@ -21,11 +21,11 @@
 
 @router.get("/", response_model=List[ServiceConfigResponse])
 async def list_services(
     service_type: Optional[ServiceType] = None,
     enabled_only: bool = False,
-    db: AsyncSession = Depends(get_db_session)
+    db: AsyncSession = Depends(get_db_session),
 ):
     """List all configured services."""
     query = select(ServiceConfig)
 
     if service_type:
@@ -45,33 +45,28 @@
     """Get a specific service configuration."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     return ServiceConfigResponse.model_validate(service)
 
 
 @router.post("/", response_model=ServiceConfigResponse, status_code=status.HTTP_201_CREATED)
 async def create_service(
-    service_data: ServiceConfigCreate,
-    db: AsyncSession = Depends(get_db_session)
+    service_data: ServiceConfigCreate, db: AsyncSession = Depends(get_db_session)
 ):
     """Create a new service configuration."""
     # Check if service name already exists
-    existing_service = (await db.execute(
-        select(ServiceConfig).where(ServiceConfig.name == service_data.name)
-    )).scalar_one_or_none()
+    existing_service = (
+        await db.execute(select(ServiceConfig).where(ServiceConfig.name == service_data.name))
+    ).scalar_one_or_none()
 
     if existing_service:
         raise HTTPException(
-            status_code=status.HTTP_409_CONFLICT,
-            detail="Service with this name already exists"
+            status_code=status.HTTP_409_CONFLICT, detail="Service with this name already exists"
         )
 
     # Create new service
     service = ServiceConfig(**service_data.model_dump())
     db.add(service)
@@ -81,23 +76,18 @@
     return ServiceConfigResponse.model_validate(service)
 
 
 @router.put("/{service_id}", response_model=ServiceConfigResponse)
 async def update_service(
-    service_id: str,
-    service_data: ServiceConfigUpdate,
-    db: AsyncSession = Depends(get_db_session)
+    service_id: str, service_data: ServiceConfigUpdate, db: AsyncSession = Depends(get_db_session)
 ):
     """Update an existing service configuration."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     # Update only provided fields
     update_data = service_data.model_dump(exclude_unset=True)
     for field, value in update_data.items():
         setattr(service, field, value)
@@ -113,14 +103,11 @@
     """Delete a service configuration."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     await db.delete(service)
     await db.commit()
 
 
@@ -129,14 +116,11 @@
     """Test connection to a service."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     # Import the service tester
     from ..services.service_tester import ServiceTester
 
     # Test the connection using the appropriate adapter
@@ -144,25 +128,22 @@
 
     return ServiceTestResult(
         service_id=service_id,
         success=test_result.success,
         error_message=test_result.message if not test_result.success else None,
-        response_time_ms=test_result.response_time_ms
+        response_time_ms=test_result.response_time_ms,
     )
 
 
 @router.patch("/{service_id}/enable")
 async def enable_service(service_id: str, db: AsyncSession = Depends(get_db_session)):
     """Enable a service configuration."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     service.enabled = True
     await db.commit()
 
     return {"message": "Service enabled successfully"}
@@ -173,14 +154,11 @@
     """Disable a service configuration."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     service.enabled = False
     await db.commit()
 
     return {"message": "Service disabled successfully"}
@@ -191,42 +169,36 @@
     """Get service health status."""
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     # Handle status - could be string or enum depending on how it was loaded
-    status_value = service.status.value if hasattr(service.status, 'value') else service.status
+    status_value = service.status.value if hasattr(service.status, "value") else service.status
 
     return {
         "id": service_id,
         "name": service.name,
         "status": status_value,
         "enabled": service.enabled,
         "healthy": service.is_healthy,
         "last_test_at": service.last_test_at.isoformat() if service.last_test_at else None,
         "last_test_success": service.last_test_success,
-        "last_error": service.last_error
+        "last_error": service.last_error,
     }
 
 
 @router.get("/health/history", response_model=List[dict])
 async def get_all_services_health_history(
-    hours: int = 24,
-    db: AsyncSession = Depends(get_db_session)
+    hours: int = 24, db: AsyncSession = Depends(get_db_session)
 ):
     """Get health history for all services for the specified time range."""
     since = datetime.utcnow() - timedelta(hours=hours)
 
     # Get all enabled services
-    services_result = await db.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    services_result = await db.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     services = services_result.scalars().all()
 
     result = []
     for service in services:
         # Get health history for this service
@@ -237,47 +209,48 @@
             .order_by(desc(ServiceHealthHistory.tested_at))
         )
         history = history_result.scalars().all()
 
         # Handle service_type - could be string or enum
-        service_type_value = service.service_type.value if hasattr(service.service_type, 'value') else service.service_type
-
-        result.append({
-            "service_id": service.id,
-            "service_name": service.name,
-            "service_type": service_type_value,
-            "enabled": service.enabled,
-            "history": [
-                {
-                    "tested_at": h.tested_at.isoformat(),
-                    "success": h.success,
-                    "response_time_ms": h.response_time_ms,
-                    "error_message": h.error_message
-                }
-                for h in history
-            ]
-        })
+        service_type_value = (
+            service.service_type.value
+            if hasattr(service.service_type, "value")
+            else service.service_type
+        )
+
+        result.append(
+            {
+                "service_id": service.id,
+                "service_name": service.name,
+                "service_type": service_type_value,
+                "enabled": service.enabled,
+                "history": [
+                    {
+                        "tested_at": h.tested_at.isoformat(),
+                        "success": h.success,
+                        "response_time_ms": h.response_time_ms,
+                        "error_message": h.error_message,
+                    }
+                    for h in history
+                ],
+            }
+        )
 
     return result
 
 
 @router.get("/{service_id}/health/history", response_model=dict)
 async def get_service_health_history(
-    service_id: str,
-    hours: int = 24,
-    db: AsyncSession = Depends(get_db_session)
+    service_id: str, hours: int = 24, db: AsyncSession = Depends(get_db_session)
 ):
     """Get health history for a specific service."""
     # Get the service
     result = await db.execute(select(ServiceConfig).where(ServiceConfig.id == service_id))
     service = result.scalar_one_or_none()
 
     if not service:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Service not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="Service not found")
 
     since = datetime.utcnow() - timedelta(hours=hours)
 
     # Get health history
     history_result = await db.execute(
@@ -287,11 +260,15 @@
         .order_by(desc(ServiceHealthHistory.tested_at))
     )
     history = history_result.scalars().all()
 
     # Handle service_type - could be string or enum
-    service_type_value = service.service_type.value if hasattr(service.service_type, 'value') else service.service_type
+    service_type_value = (
+        service.service_type.value
+        if hasattr(service.service_type, "value")
+        else service.service_type
+    )
 
     return {
         "service_id": service_id,
         "service_name": service.name,
         "service_type": service_type_value,
@@ -299,32 +276,39 @@
         "history": [
             {
                 "tested_at": h.tested_at.isoformat(),
                 "success": h.success,
                 "response_time_ms": h.response_time_ms,
-                "error_message": h.error_message
+                "error_message": h.error_message,
             }
             for h in history
         ],
         "summary": {
             "total_tests": len(history),
             "success_count": sum(1 for h in history if h.success),
             "failure_count": sum(1 for h in history if not h.success),
-            "uptime_percentage": (sum(1 for h in history if h.success) / len(history) * 100) if history else 0,
-            "avg_response_time_ms": (sum(h.response_time_ms or 0 for h in history if h.success) / max(1, sum(1 for h in history if h.success)))
-        }
+            "uptime_percentage": (sum(1 for h in history if h.success) / len(history) * 100)
+            if history
+            else 0,
+            "avg_response_time_ms": (
+                sum(h.response_time_ms or 0 for h in history if h.success)
+                / max(1, sum(1 for h in history if h.success))
+            ),
+        },
     }
 
 
 # =====================
 # Health Check Scheduler Endpoints
 # =====================
 
+
 @router.get("/health/scheduler/status", response_model=dict)
 async def get_scheduler_status():
     """Get the current status of the health check scheduler."""
     from ..services.health_scheduler import health_scheduler
+
     return health_scheduler.status
 
 
 @router.post("/health/scheduler/start", response_model=dict)
 async def start_scheduler(interval_minutes: int = 15):
@@ -332,47 +316,44 @@
     from ..services.health_scheduler import health_scheduler
 
     if interval_minutes < 1 or interval_minutes > 1440:
         raise HTTPException(
             status_code=status.HTTP_400_BAD_REQUEST,
-            detail="Interval must be between 1 and 1440 minutes"
+            detail="Interval must be between 1 and 1440 minutes",
         )
 
     await health_scheduler.start(interval_minutes)
     return {
         "message": f"Scheduler started with {interval_minutes} minute interval",
-        "status": health_scheduler.status
+        "status": health_scheduler.status,
     }
 
 
 @router.post("/health/scheduler/stop", response_model=dict)
 async def stop_scheduler():
     """Stop the automatic health check scheduler."""
     from ..services.health_scheduler import health_scheduler
 
     await health_scheduler.stop()
-    return {
-        "message": "Scheduler stopped",
-        "status": health_scheduler.status
-    }
+    return {"message": "Scheduler stopped", "status": health_scheduler.status}
 
 
 @router.put("/health/scheduler/interval", response_model=dict)
 async def update_scheduler_interval(interval_minutes: int):
     """Update the health check interval."""
     from ..services.health_scheduler import health_scheduler
 
     if interval_minutes < 1 or interval_minutes > 1440:
         raise HTTPException(
             status_code=status.HTTP_400_BAD_REQUEST,
-            detail="Interval must be between 1 and 1440 minutes"
+            detail="Interval must be between 1 and 1440 minutes",
         )
 
     await health_scheduler.update_interval(interval_minutes)
     return {
         "message": f"Interval updated to {interval_minutes} minutes",
-        "status": health_scheduler.status
+        "status": health_scheduler.status,
     }
 
 
 @router.post("/health/scheduler/run-now", response_model=dict)
 async def run_health_checks_now():
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/services.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/users.py	2025-12-31 13:30:51.531007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/users.py	2025-12-31 13:41:35.956873+00:00
@@ -31,11 +31,11 @@
     service_id: Optional[str] = Query(None, description="Filter by service ID"),
     status: Optional[MappingStatus] = Query(None, description="Filter by mapping status"),
     role: Optional[UserRole] = Query(None, description="Filter by user role"),
     skip: int = Query(0, ge=0, description="Number of records to skip"),
     limit: int = Query(100, ge=1, le=1000, description="Number of records to return"),
-    db: AsyncSession = Depends(get_db)
+    db: AsyncSession = Depends(get_db),
 ):
     """List user mappings with optional filtering."""
     query = select(UserMapping).options(selectinload(UserMapping.service_config))
 
     # Apply filters
@@ -67,11 +67,11 @@
 
     return UserMappingListResponse(
         mappings=[UserMappingResponse.model_validate(mapping) for mapping in mappings],
         total=total,
         skip=skip,
-        limit=limit
+        limit=limit,
     )
 
 
 @router.get("/statistics", response_model=dict)
 async def get_user_mapping_statistics(db: AsyncSession = Depends(get_db)):
@@ -95,19 +95,18 @@
         select(UserMapping).where(UserMapping.status == MappingStatus.INACTIVE)
     )
     inactive_mappings = len(inactive_result.scalars().all())
 
     # Get unique users count
-    unique_users_result = await db.execute(
-        select(UserMapping.central_user_id).distinct()
-    )
+    unique_users_result = await db.execute(select(UserMapping.central_user_id).distinct())
     unique_users = len(unique_users_result.scalars().all())
 
     # Get mappings by service
     services_result = await db.execute(
-        select(ServiceConfig.name, ServiceConfig.id)
-        .join(UserMapping, ServiceConfig.id == UserMapping.service_config_id)
+        select(ServiceConfig.name, ServiceConfig.id).join(
+            UserMapping, ServiceConfig.id == UserMapping.service_config_id
+        )
     )
     service_mappings = services_result.all()
 
     service_stats = {}
     for service_name, _service_id in service_mappings:
@@ -119,21 +118,20 @@
         "total_mappings": total_mappings,
         "unique_users": unique_users,
         "status_breakdown": {
             "active": active_mappings,
             "pending": pending_mappings,
-            "inactive": inactive_mappings
+            "inactive": inactive_mappings,
         },
         "service_breakdown": service_stats,
-        "average_mappings_per_user": total_mappings / unique_users if unique_users > 0 else 0
+        "average_mappings_per_user": total_mappings / unique_users if unique_users > 0 else 0,
     }
 
 
 @router.get("/central-user/{central_user_id}", response_model=List[UserMappingResponse])
 async def get_user_mappings_by_central_user(
-    central_user_id: str,
-    db: AsyncSession = Depends(get_db)
+    central_user_id: str, db: AsyncSession = Depends(get_db)
 ):
     """Get all mappings for a central user."""
     result = await db.execute(
         select(UserMapping)
         .options(selectinload(UserMapping.service_config))
@@ -143,14 +141,11 @@
 
     return [UserMappingResponse.model_validate(mapping) for mapping in mappings]
 
 
 @router.get("/service/{service_id}", response_model=List[UserMappingResponse])
-async def get_user_mappings_by_service(
-    service_id: str,
-    db: AsyncSession = Depends(get_db)
-):
+async def get_user_mappings_by_service(service_id: str, db: AsyncSession = Depends(get_db)):
     """Get all user mappings for a service."""
     result = await db.execute(
         select(UserMapping)
         .options(selectinload(UserMapping.service_config))
         .where(UserMapping.service_config_id == service_id)
@@ -167,56 +162,57 @@
 
     # Get unique central_user_id with their service counts
     result = await db.execute(
         select(
             UserMapping.central_user_id,
-            func.max(UserMapping.service_username).label('central_username'),
-            func.count(distinct(UserMapping.service_config_id)).label('service_count')
+            func.max(UserMapping.service_username).label("central_username"),
+            func.count(distinct(UserMapping.service_config_id)).label("service_count"),
         )
         .where(UserMapping.central_user_id.isnot(None))
         .group_by(UserMapping.central_user_id)
         .order_by(func.max(UserMapping.service_username))
     )
 
     users = [
         {
             "central_user_id": row.central_user_id,
             "central_username": row.central_username or row.central_user_id,
-            "service_count": row.service_count
+            "service_count": row.service_count,
         }
         for row in result.fetchall()
     ]
 
-    return {
-        "users": users,
-        "total": len(users)
-    }
+    return {"users": users, "total": len(users)}
 
 
 @router.get("/enumerate-users", response_model=dict)
 async def enumerate_all_users(db: AsyncSession = Depends(get_db)):
     """Enumerate users from all configured services for manual mapping."""
     from ..services.service_registry import service_registry
 
     # Services that don't have user management (skip them)
-    SERVICES_WITHOUT_USERS = {'ollama'}
+    SERVICES_WITHOUT_USERS = {"ollama"}
 
     # Get all enabled services
-    services_result = await db.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    services_result = await db.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     services = services_result.scalars().all()
 
     all_users = {}
     errors = []
     skipped_services = 0
 
     for service in services:
         # Skip services that don't have user management
-        service_type = service.service_type.value if hasattr(service.service_type, 'value') else service.service_type
+        service_type = (
+            service.service_type.value
+            if hasattr(service.service_type, "value")
+            else service.service_type
+        )
         if service_type.lower() in SERVICES_WITHOUT_USERS:
-            logger.debug(f"Skipping {service.name} - service type {service_type} does not support user management")
+            logger.debug(
+                f"Skipping {service.name} - service type {service_type} does not support user management"
+            )
             skipped_services += 1
             continue
 
         try:
             adapter = await service_registry.create_adapter(service)
@@ -231,55 +227,59 @@
                     errors.append(f"{service.name}: Connection failed - {test_result.message}")
                     continue
 
                 # Try to get users if adapter supports it
                 try:
-                    if hasattr(adapter, 'get_users'):
+                    if hasattr(adapter, "get_users"):
                         users_data = await adapter.get_users()
-                        if isinstance(users_data, dict) and 'users' in users_data:
-                            users = users_data['users']
+                        if isinstance(users_data, dict) and "users" in users_data:
+                            users = users_data["users"]
                         elif isinstance(users_data, list):
                             users = users_data
                         else:
                             users = []
 
                         all_users[service.id] = {
-                            'service_name': service.name,
-                            'service_type': service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
-                            'base_url': service.base_url,
-                            'users': users,
-                            'user_count': len(users)
+                            "service_name": service.name,
+                            "service_type": service.service_type.value
+                            if hasattr(service.service_type, "value")
+                            else service.service_type,
+                            "base_url": service.base_url,
+                            "users": users,
+                            "user_count": len(users),
                         }
                     else:
                         all_users[service.id] = {
-                            'service_name': service.name,
-                            'service_type': service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
-                            'base_url': service.base_url,
-                            'users': [],
-                            'user_count': 0,
-                            'note': 'Service does not support user enumeration'
+                            "service_name": service.name,
+                            "service_type": service.service_type.value
+                            if hasattr(service.service_type, "value")
+                            else service.service_type,
+                            "base_url": service.base_url,
+                            "users": [],
+                            "user_count": 0,
+                            "note": "Service does not support user enumeration",
                         }
                 except Exception as e:
                     errors.append(f"{service.name}: Failed to enumerate users - {str(e)}")
                     all_users[service.id] = {
-                        'service_name': service.name,
-                        'service_type': service.service_type.value,
-                        'base_url': service.base_url,
-                        'users': [],
-                        'user_count': 0,
-                        'error': str(e)
+                        "service_name": service.name,
+                        "service_type": service.service_type.value,
+                        "base_url": service.base_url,
+                        "users": [],
+                        "user_count": 0,
+                        "error": str(e),
                     }
 
         except Exception as e:
             errors.append(f"{service.name}: Adapter error - {str(e)}")
 
     return {
-        'services': all_users,
-        'total_services': len(services),
-        'successful_enumerations': len([s for s in all_users.values() if 'error' not in s]),
-        'errors': errors,
-        'enumerated_at': datetime.utcnow()
+        "services": all_users,
+        "total_services": len(services),
+        "successful_enumerations": len([s for s in all_users.values() if "error" not in s]),
+        "errors": errors,
+        "enumerated_at": datetime.utcnow(),
     }
 
 
 @router.get("/{mapping_id}", response_model=UserMappingResponse)
 async def get_user_mapping(mapping_id: str, db: AsyncSession = Depends(get_db)):
@@ -290,31 +290,26 @@
         .where(UserMapping.id == mapping_id)
     )
     mapping = result.scalar_one_or_none()
 
     if not mapping:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="User mapping not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User mapping not found")
 
     return UserMappingResponse.model_validate(mapping)
 
 
 @router.post("/", response_model=UserMappingResponse, status_code=status.HTTP_201_CREATED)
-async def create_user_mapping(
-    request: Request,
-    db: AsyncSession = Depends(get_db)
-):
+async def create_user_mapping(request: Request, db: AsyncSession = Depends(get_db)):
     """Create a new user mapping."""
     try:
         # Read raw request body first
         raw_body = await request.body()
         logger.info(f" Raw request body: {raw_body.decode()}")
 
         # Parse JSON manually to see what we get
         import json
+
         try:
             raw_data = json.loads(raw_body.decode())
             logger.info(f" Parsed JSON data: {raw_data}")
         except json.JSONDecodeError as e:
             logger.error(f" JSON decode error: {e}")
@@ -336,32 +331,33 @@
         service = service_result.scalar_one_or_none()
 
         if not service:
             logger.error(f" Service not found: {mapping_data.service_config_id}")
             raise HTTPException(
-                status_code=status.HTTP_404_NOT_FOUND,
-                detail="Service configuration not found"
+                status_code=status.HTTP_404_NOT_FOUND, detail="Service configuration not found"
             )
 
         logger.info(f" Service found: {service.name} ({service.id})")
 
         # Check if mapping already exists for this user and service
         existing_result = await db.execute(
             select(UserMapping).where(
                 and_(
                     UserMapping.central_user_id == mapping_data.central_user_id,
-                    UserMapping.service_config_id == mapping_data.service_config_id
+                    UserMapping.service_config_id == mapping_data.service_config_id,
                 )
             )
         )
         existing_mapping = existing_result.scalar_one_or_none()
 
         if existing_mapping:
-            logger.error(f" Mapping already exists: central_user={mapping_data.central_user_id}, service={mapping_data.service_config_id}")
+            logger.error(
+                f" Mapping already exists: central_user={mapping_data.central_user_id}, service={mapping_data.service_config_id}"
+            )
             raise HTTPException(
                 status_code=status.HTTP_409_CONFLICT,
-                detail="User mapping already exists for this user and service"
+                detail="User mapping already exists for this user and service",
             )
 
         # Create new mapping
         logger.info(f" Creating mapping object with data: {mapping_data.model_dump()}")
         mapping = UserMapping(**mapping_data.model_dump())
@@ -378,33 +374,28 @@
     except Exception as e:
         logger.error(f" Unexpected error creating user mapping: {str(e)}")
         logger.error(f" Mapping data causing error: {mapping_data.model_dump()}")
         raise HTTPException(
             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
-            detail=f"Failed to create user mapping: {str(e)}"
+            detail=f"Failed to create user mapping: {str(e)}",
         )
 
 
 @router.put("/{mapping_id}", response_model=UserMappingResponse)
 async def update_user_mapping(
-    mapping_id: str,
-    mapping_data: UserMappingUpdate,
-    db: AsyncSession = Depends(get_db)
+    mapping_id: str, mapping_data: UserMappingUpdate, db: AsyncSession = Depends(get_db)
 ):
     """Update an existing user mapping."""
     result = await db.execute(
         select(UserMapping)
         .options(selectinload(UserMapping.service_config))
         .where(UserMapping.id == mapping_id)
     )
     mapping = result.scalar_one_or_none()
 
     if not mapping:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="User mapping not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User mapping not found")
 
     # Update only provided fields
     update_data = mapping_data.model_dump(exclude_unset=True)
     for field, value in update_data.items():
         setattr(mapping, field, value)
@@ -420,23 +411,19 @@
     """Delete a user mapping."""
     result = await db.execute(select(UserMapping).where(UserMapping.id == mapping_id))
     mapping = result.scalar_one_or_none()
 
     if not mapping:
-        raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="User mapping not found"
-        )
+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail="User mapping not found")
 
     await db.delete(mapping)
     await db.commit()
 
 
 @router.get("/central-user/{central_user_id}", response_model=List[UserMappingResponse])
 async def get_user_mappings_by_central_user(
-    central_user_id: str,
-    db: AsyncSession = Depends(get_db)
+    central_user_id: str, db: AsyncSession = Depends(get_db)
 ):
     """Get all mappings for a central user."""
     result = await db.execute(
         select(UserMapping)
         .options(selectinload(UserMapping.service_config))
@@ -446,14 +433,11 @@
 
     return [UserMappingResponse.model_validate(mapping) for mapping in mappings]
 
 
 @router.get("/service/{service_id}", response_model=List[UserMappingResponse])
-async def get_user_mappings_by_service(
-    service_id: str,
-    db: AsyncSession = Depends(get_db)
-):
+async def get_user_mappings_by_service(service_id: str, db: AsyncSession = Depends(get_db)):
     """Get all user mappings for a service."""
     result = await db.execute(
         select(UserMapping)
         .options(selectinload(UserMapping.service_config))
         .where(UserMapping.service_config_id == service_id)
@@ -463,12 +447,11 @@
     return [UserMappingResponse.model_validate(mapping) for mapping in mappings]
 
 
 @router.post("/sync", response_model=UserSyncResult)
 async def sync_user_with_services(
-    sync_request: UserSyncRequest,
-    db: AsyncSession = Depends(get_db)
+    sync_request: UserSyncRequest, db: AsyncSession = Depends(get_db)
 ):
     """Synchronize a user across all mapped services."""
     # Get all mappings for the user
     result = await db.execute(
         select(UserMapping)
@@ -478,11 +461,11 @@
     mappings = result.scalars().all()
 
     if not mappings:
         raise HTTPException(
             status_code=status.HTTP_404_NOT_FOUND,
-            detail="No user mappings found for this central user"
+            detail="No user mappings found for this central user",
         )
 
     sync_results = []
     success_count = 0
 
@@ -491,93 +474,103 @@
             # Import service tester for adapter functionality
             from ..services.service_tester import ServiceTester
 
             adapter = ServiceTester.get_adapter_for_service(mapping.service_config)
             if not adapter:
-                sync_results.append({
-                    "service_id": mapping.service_config_id,
-                    "service_name": mapping.service_config.name,
-                    "success": False,
-                    "error": "No adapter available for service type"
-                })
+                sync_results.append(
+                    {
+                        "service_id": mapping.service_config_id,
+                        "service_name": mapping.service_config.name,
+                        "success": False,
+                        "error": "No adapter available for service type",
+                    }
+                )
                 continue
 
             # Check if adapter supports user management
             from ..adapters.base import ServiceCapability
+
             if ServiceCapability.USER_MANAGEMENT not in adapter.supported_capabilities:
-                sync_results.append({
-                    "service_id": mapping.service_config_id,
-                    "service_name": mapping.service_config.name,
-                    "success": False,
-                    "error": "Service does not support user management"
-                })
+                sync_results.append(
+                    {
+                        "service_id": mapping.service_config_id,
+                        "service_name": mapping.service_config.name,
+                        "success": False,
+                        "error": "Service does not support user management",
+                    }
+                )
                 continue
 
             # TODO: Implement actual user synchronization
             # For now, just mark as successful
             mapping.mark_sync_attempt(success=True)
             success_count += 1
 
-            sync_results.append({
-                "service_id": mapping.service_config_id,
-                "service_name": mapping.service_config.name,
-                "success": True,
-                "error": None
-            })
+            sync_results.append(
+                {
+                    "service_id": mapping.service_config_id,
+                    "service_name": mapping.service_config.name,
+                    "success": True,
+                    "error": None,
+                }
+            )
 
         except Exception as e:
             mapping.mark_sync_attempt(success=False, error=str(e))
-            sync_results.append({
-                "service_id": mapping.service_config_id,
-                "service_name": mapping.service_config.name,
-                "success": False,
-                "error": str(e)
-            })
+            sync_results.append(
+                {
+                    "service_id": mapping.service_config_id,
+                    "service_name": mapping.service_config.name,
+                    "success": False,
+                    "error": str(e),
+                }
+            )
 
     await db.commit()
 
     return UserSyncResult(
         central_user_id=sync_request.central_user_id,
         total_services=len(mappings),
         successful_syncs=success_count,
         failed_syncs=len(mappings) - success_count,
-        sync_results=sync_results
+        sync_results=sync_results,
     )
 
 
 @router.post("/bulk-sync", response_model=List[UserSyncResult])
-async def bulk_sync_users(
-    central_user_ids: List[str],
-    db: AsyncSession = Depends(get_db)
-):
+async def bulk_sync_users(central_user_ids: List[str], db: AsyncSession = Depends(get_db)):
     """Synchronize multiple users across their mapped services."""
     results = []
 
     for user_id in central_user_ids:
         try:
             sync_request = UserSyncRequest(central_user_id=user_id)
             result = await sync_user_with_services(sync_request, db)
             results.append(result)
         except HTTPException as e:
             # User not found or no mappings
-            results.append(UserSyncResult(
-                central_user_id=user_id,
-                total_services=0,
-                successful_syncs=0,
-                failed_syncs=0,
-                sync_results=[],
-                error=e.detail
-            ))
+            results.append(
+                UserSyncResult(
+                    central_user_id=user_id,
+                    total_services=0,
+                    successful_syncs=0,
+                    failed_syncs=0,
+                    sync_results=[],
+                    error=e.detail,
+                )
+            )
         except Exception as e:
-            results.append(UserSyncResult(
-                central_user_id=user_id,
-                total_services=0,
-                successful_syncs=0,
-                failed_syncs=0,
-                sync_results=[],
-                error=str(e)
-            ))
+            results.append(
+                UserSyncResult(
+                    central_user_id=user_id,
+                    total_services=0,
+                    successful_syncs=0,
+                    failed_syncs=0,
+                    sync_results=[],
+                    error=str(e),
+                )
+            )
 
     return results
 
 
 @router.get("/statistics", response_model=dict)
@@ -602,19 +595,18 @@
         select(UserMapping).where(UserMapping.status == MappingStatus.INACTIVE)
     )
     inactive_mappings = len(inactive_result.scalars().all())
 
     # Get unique users count
-    unique_users_result = await db.execute(
-        select(UserMapping.central_user_id).distinct()
-    )
+    unique_users_result = await db.execute(select(UserMapping.central_user_id).distinct())
     unique_users = len(unique_users_result.scalars().all())
 
     # Get mappings by service
     services_result = await db.execute(
-        select(ServiceConfig.name, ServiceConfig.id)
-        .join(UserMapping, ServiceConfig.id == UserMapping.service_config_id)
+        select(ServiceConfig.name, ServiceConfig.id).join(
+            UserMapping, ServiceConfig.id == UserMapping.service_config_id
+        )
     )
     service_mappings = services_result.all()
 
     service_stats = {}
     for service_name, _service_id in service_mappings:
@@ -626,22 +618,19 @@
         "total_mappings": total_mappings,
         "unique_users": unique_users,
         "status_breakdown": {
             "active": active_mappings,
             "pending": pending_mappings,
-            "inactive": inactive_mappings
+            "inactive": inactive_mappings,
         },
         "service_breakdown": service_stats,
-        "average_mappings_per_user": total_mappings / unique_users if unique_users > 0 else 0
+        "average_mappings_per_user": total_mappings / unique_users if unique_users > 0 else 0,
     }
 
 
 @router.post("/detect-mappings", response_model=dict)
-async def detect_user_mappings(
-    authentik_service_id: str,
-    db: AsyncSession = Depends(get_db)
-):
+async def detect_user_mappings(authentik_service_id: str, db: AsyncSession = Depends(get_db)):
     """Detect potential user mappings across services using Authentik as the source."""
     from ..services.user_mapper import get_user_mapper
 
     user_mapper = await get_user_mapper()
     results = await user_mapper.detect_all_mappings(db, authentik_service_id)
@@ -659,14 +648,11 @@
 
     return results
 
 
 @router.post("/create-from-suggestions", response_model=dict)
-async def create_mappings_from_suggestions(
-    request_data: dict,
-    db: AsyncSession = Depends(get_db)
-):
+async def create_mappings_from_suggestions(request_data: dict, db: AsyncSession = Depends(get_db)):
     """Create user mappings from approved suggestions."""
     from ..services.user_mapper import get_user_mapper
 
     suggestions = request_data.get("suggestions", [])
     auto_approve_high_confidence = request_data.get("auto_approve_high_confidence", False)
@@ -681,11 +667,11 @@
 
 @router.get("/centralized/{central_user_id}", response_model=dict)
 async def get_centralized_user_data(
     central_user_id: str,
     refresh: bool = Query(False, description="Refresh data from services"),
-    db: AsyncSession = Depends(get_db)
+    db: AsyncSession = Depends(get_db),
 ):
     """Get centralized user data across all services."""
     from ..services.user_centralization import get_user_centralization_service
 
     user_centralization = await get_user_centralization_service()
@@ -693,18 +679,15 @@
     if refresh:
         centralized_data = await user_centralization.update_centralized_data_from_services(
             db, central_user_id
         )
     else:
-        centralized_data = await user_centralization.get_centralized_user_data(
-            db, central_user_id
-        )
+        centralized_data = await user_centralization.get_centralized_user_data(db, central_user_id)
 
     if not centralized_data:
         raise HTTPException(
-            status_code=status.HTTP_404_NOT_FOUND,
-            detail="Centralized user data not found"
+            status_code=status.HTTP_404_NOT_FOUND, detail="Centralized user data not found"
         )
 
     return centralized_data.to_dict()
 
 
@@ -717,27 +700,21 @@
     centralized_users = await user_centralization.get_all_centralized_users(db)
 
     return {
         "users": [user.to_dict() for user in centralized_users],
         "total_users": len(centralized_users),
-        "enumerated_at": datetime.utcnow()
+        "enumerated_at": datetime.utcnow(),
     }
 
 
 @router.post("/centralized/{central_user_id}/sync", response_model=dict)
-async def sync_centralized_user_metadata(
-    central_user_id: str,
-    db: AsyncSession = Depends(get_db)
-):
+async def sync_centralized_user_metadata(central_user_id: str, db: AsyncSession = Depends(get_db)):
     """Sync centralized user metadata from all services."""
     from ..services.user_centralization import get_user_centralization_service
 
     user_centralization = await get_user_centralization_service()
     result = await user_centralization.sync_centralized_user_metadata(db, central_user_id)
 
-    if not result['success']:
-        raise HTTPException(
-            status_code=status.HTTP_400_BAD_REQUEST,
-            detail=result['error']
-        )
+    if not result["success"]:
+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=result["error"])
 
     return result
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/users.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/workers.py	2025-12-31 13:30:51.515500+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/workers.py	2025-12-31 13:41:35.971922+00:00
@@ -20,31 +20,37 @@
 router = APIRouter(prefix="/api/workers", tags=["workers"])
 
 
 # ============= Pydantic Schemas =============
 
+
 class WorkerCreate(BaseModel):
     """Create a new worker."""
+
     name: str = Field(..., min_length=1, max_length=100)
     description: Optional[str] = None
     url: str = Field(..., description="Worker URL (e.g., http://192.168.1.100:8080)")
     api_key: Optional[str] = Field(None, description="Optional API key for authentication")
-    ollama_service_id: Optional[str] = Field(None, description="Ollama service to use for model import")
+    ollama_service_id: Optional[str] = Field(
+        None, description="Ollama service to use for model import"
+    )
 
 
 class WorkerUpdate(BaseModel):
     """Update a worker."""
+
     name: Optional[str] = Field(None, min_length=1, max_length=100)
     description: Optional[str] = None
     url: Optional[str] = None
     api_key: Optional[str] = None
     enabled: Optional[bool] = None
     ollama_service_id: Optional[str] = None
 
 
 class WorkerResponse(BaseModel):
     """Worker response."""
+
     id: str
     name: str
     description: Optional[str]
     url: str
     status: str
@@ -66,10 +72,11 @@
     updated_at: str
 
 
 class WorkerMetricsResponse(BaseModel):
     """Worker metrics response."""
+
     worker_id: str
     recorded_at: str
     cpu_percent: Optional[float]
     memory_percent: Optional[float]
     memory_used_mb: Optional[float]
@@ -81,18 +88,20 @@
     training_loss: Optional[float]
 
 
 class WorkerTestResult(BaseModel):
     """Result of testing a worker connection."""
+
     success: bool
     message: str
     worker_info: Optional[dict] = None
     error: Optional[str] = None
 
 
 class TrainingStartRequest(BaseModel):
     """Request to start training on a worker."""
+
     session_id: str = Field(..., description="Training session ID from MCParr")
     base_model: str = Field(default="unsloth/llama-3.2-3b-instruct-bnb-4bit")
     output_model_name: str = Field(..., description="Output model name in Ollama")
     overwrite_existing: bool = Field(default=False, description="Overwrite if model exists")
 
@@ -107,15 +116,14 @@
     quantization_method: str = Field(default="q4_k_m")
 
 
 # ============= Helper Functions =============
 
+
 async def get_worker_or_404(worker_id: str, session: AsyncSession) -> TrainingWorker:
     """Get worker by ID or raise 404."""
-    result = await session.execute(
-        select(TrainingWorker).where(TrainingWorker.id == worker_id)
-    )
+    result = await session.execute(select(TrainingWorker).where(TrainingWorker.id == worker_id))
     worker = result.scalar_one_or_none()
     if not worker:
         raise HTTPException(status_code=404, detail="Worker not found")
     return worker
 
@@ -141,11 +149,11 @@
         current_job_id=worker.current_job_id,
         current_session_id=worker.current_session_id,
         total_jobs_completed=worker.total_jobs_completed,
         total_training_time_seconds=worker.total_training_time_seconds,
         created_at=worker.created_at.isoformat(),
-        updated_at=worker.updated_at.isoformat()
+        updated_at=worker.updated_at.isoformat(),
     )
 
 
 async def fetch_worker_info(url: str, api_key: Optional[str] = None) -> dict:
     """Fetch worker info from the worker API."""
@@ -217,14 +225,14 @@
     await session.commit()
 
 
 # ============= Endpoints =============
 
+
 @router.get("", response_model=List[WorkerResponse])
 async def list_workers(
-    enabled_only: bool = Query(default=False),
-    session: AsyncSession = Depends(get_db_session)
+    enabled_only: bool = Query(default=False), session: AsyncSession = Depends(get_db_session)
 ):
     """List all training workers."""
     query = select(TrainingWorker).order_by(desc(TrainingWorker.created_at))
 
     if enabled_only:
@@ -235,29 +243,24 @@
 
     return [worker_to_response(w) for w in workers]
 
 
 @router.post("", response_model=WorkerResponse, status_code=201)
-async def create_worker(
-    data: WorkerCreate,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def create_worker(data: WorkerCreate, session: AsyncSession = Depends(get_db_session)):
     """Create a new training worker."""
     # Check if URL already exists
-    result = await session.execute(
-        select(TrainingWorker).where(TrainingWorker.url == data.url)
-    )
+    result = await session.execute(select(TrainingWorker).where(TrainingWorker.url == data.url))
     if result.scalar_one_or_none():
         raise HTTPException(status_code=400, detail="Worker with this URL already exists")
 
     worker = TrainingWorker(
         name=data.name,
         description=data.description,
-        url=data.url.rstrip('/'),
+        url=data.url.rstrip("/"),
         api_key=data.api_key,
         ollama_service_id=data.ollama_service_id,
-        status=WorkerStatus.UNKNOWN
+        status=WorkerStatus.UNKNOWN,
     )
 
     session.add(worker)
     await session.commit()
     await session.refresh(worker)
@@ -267,34 +270,29 @@
 
     return worker_to_response(worker)
 
 
 @router.get("/{worker_id}", response_model=WorkerResponse)
-async def get_worker(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_worker(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get a specific worker."""
     worker = await get_worker_or_404(worker_id, session)
     return worker_to_response(worker)
 
 
 @router.patch("/{worker_id}", response_model=WorkerResponse)
 async def update_worker(
-    worker_id: str,
-    data: WorkerUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    worker_id: str, data: WorkerUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Update a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     if data.name is not None:
         worker.name = data.name
     if data.description is not None:
         worker.description = data.description
     if data.url is not None:
-        worker.url = data.url.rstrip('/')
+        worker.url = data.url.rstrip("/")
     if data.api_key is not None:
         worker.api_key = data.api_key
     if data.enabled is not None:
         worker.enabled = data.enabled
     if data.ollama_service_id is not None:
@@ -306,35 +304,26 @@
 
     return worker_to_response(worker)
 
 
 @router.delete("/{worker_id}")
-async def delete_worker(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def delete_worker(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Delete a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     # Check if worker has an active job
     if worker.current_job_id:
-        raise HTTPException(
-            status_code=400,
-            detail="Cannot delete worker with active training job"
-        )
+        raise HTTPException(status_code=400, detail="Cannot delete worker with active training job")
 
     await session.delete(worker)
     await session.commit()
 
     return {"message": "Worker deleted"}
 
 
 @router.post("/{worker_id}/test", response_model=WorkerTestResult)
-async def test_worker(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def test_worker(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Test connection to a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     try:
         info = await fetch_worker_info(worker.url, worker.api_key)
@@ -343,49 +332,33 @@
         await update_worker_status(worker, session)
 
         return WorkerTestResult(
             success=True,
             message=f"Connected to {info.get('worker_name', 'worker')}",
-            worker_info=info
+            worker_info=info,
         )
 
     except httpx.ConnectError as e:
-        return WorkerTestResult(
-            success=False,
-            message="Cannot connect to worker",
-            error=str(e)
-        )
+        return WorkerTestResult(success=False, message="Cannot connect to worker", error=str(e))
     except httpx.HTTPStatusError as e:
         return WorkerTestResult(
-            success=False,
-            message=f"HTTP error: {e.response.status_code}",
-            error=str(e)
+            success=False, message=f"HTTP error: {e.response.status_code}", error=str(e)
         )
     except Exception as e:
-        return WorkerTestResult(
-            success=False,
-            message="Connection failed",
-            error=str(e)
-        )
+        return WorkerTestResult(success=False, message="Connection failed", error=str(e))
 
 
 @router.post("/{worker_id}/refresh")
-async def refresh_worker_status(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def refresh_worker_status(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Refresh worker status."""
     worker = await get_worker_or_404(worker_id, session)
     await update_worker_status(worker, session)
     return worker_to_response(worker)
 
 
 @router.get("/{worker_id}/metrics", response_model=WorkerMetricsResponse)
-async def get_worker_metrics(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_worker_metrics(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get current metrics from a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     if worker.status == WorkerStatus.OFFLINE:
         raise HTTPException(status_code=503, detail="Worker is offline")
@@ -405,11 +378,11 @@
             gpu_utilization_percent=gpu_metrics.get("gpu_utilization_percent"),
             gpu_memory_percent=gpu_metrics.get("memory_percent"),
             gpu_temperature_c=gpu_metrics.get("temperature_c"),
             gpu_power_draw_w=gpu_metrics.get("power_draw_w"),
             training_progress_percent=None,  # Will be set if training
-            training_loss=None
+            training_loss=None,
         )
 
     except Exception as e:
         raise HTTPException(status_code=503, detail=f"Failed to get metrics: {e}")
 
@@ -417,11 +390,11 @@
 @router.get("/{worker_id}/metrics/history")
 async def get_worker_metrics_history(
     worker_id: str,
     limit: int = Query(default=100, le=1000),
     minutes: int = Query(default=60, le=1440),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get historical metrics for a worker."""
     await get_worker_or_404(worker_id, session)
 
     since = datetime.utcnow() - timedelta(minutes=minutes)
@@ -445,23 +418,23 @@
                 "memory_percent": s.memory_percent,
                 "gpu_utilization_percent": s.gpu_utilization_percent,
                 "gpu_memory_percent": s.gpu_memory_percent,
                 "gpu_temperature_c": s.gpu_temperature_c,
                 "training_progress_percent": s.training_progress_percent,
-                "training_loss": s.training_loss
+                "training_loss": s.training_loss,
             }
             for s in snapshots
-        ]
+        ],
     }
 
 
 @router.post("/{worker_id}/training/start")
 async def start_training_on_worker(
     worker_id: str,
     request: TrainingStartRequest,
     background_tasks: BackgroundTasks,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Start training on a worker."""
     from src.models import TrainingPrompt, TrainingSession, TrainingStatus
 
     worker = await get_worker_or_404(worker_id, session)
@@ -482,16 +455,17 @@
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     # Get prompts
     prompt_result = await session.execute(
-        select(TrainingPrompt)
-        .where(TrainingPrompt.id.in_(
-            select(TrainingPrompt.id)
-            .join(TrainingSession.prompts)
-            .where(TrainingSession.id == request.session_id)
-        ))
+        select(TrainingPrompt).where(
+            TrainingPrompt.id.in_(
+                select(TrainingPrompt.id)
+                .join(TrainingSession.prompts)
+                .where(TrainingSession.id == request.session_id)
+            )
+        )
     )
     prompts = prompt_result.scalars().all()
 
     if not prompts:
         raise HTTPException(status_code=400, detail="No prompts in training session")
@@ -510,11 +484,11 @@
     prompts_data = [
         {
             "id": str(p.id),
             "system_prompt": p.system_prompt,
             "user_input": p.user_input,
-            "expected_output": p.expected_output
+            "expected_output": p.expected_output,
         }
         for p in prompts
     ]
 
     # Build request body for new worker API v2.0
@@ -551,13 +525,11 @@
         if worker.api_key:
             headers["X-API-Key"] = worker.api_key
 
         async with httpx.AsyncClient(timeout=30.0) as client:
             response = await client.post(
-                f"{worker.url}/api/training/start",
-                headers=headers,
-                json=training_request
+                f"{worker.url}/api/training/start", headers=headers, json=training_request
             )
             response.raise_for_status()
             result_data = response.json()
 
         # Update worker status
@@ -575,26 +547,24 @@
 
         return {
             "message": "Training started on worker",
             "worker_id": worker_id,
             "job_id": result_data.get("job_id"),
-            "session_id": request.session_id
+            "session_id": request.session_id,
         }
 
     except httpx.HTTPStatusError as e:
         raise HTTPException(
-            status_code=e.response.status_code,
-            detail=f"Worker error: {e.response.text}"
+            status_code=e.response.status_code, detail=f"Worker error: {e.response.text}"
         )
     except Exception as e:
         raise HTTPException(status_code=500, detail=f"Failed to start training: {e}")
 
 
 @router.get("/{worker_id}/training/status")
 async def get_worker_training_status(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
+    worker_id: str, session: AsyncSession = Depends(get_db_session)
 ):
     """Get current training status from a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     if not worker.current_job_id:
@@ -604,26 +574,20 @@
         headers = {}
         if worker.api_key:
             headers["X-API-Key"] = worker.api_key
 
         async with httpx.AsyncClient(timeout=10.0) as client:
-            response = await client.get(
-                f"{worker.url}/training/status",
-                headers=headers
-            )
+            response = await client.get(f"{worker.url}/training/status", headers=headers)
             response.raise_for_status()
             return response.json()
 
     except Exception as e:
         raise HTTPException(status_code=503, detail=f"Failed to get training status: {e}")
 
 
 @router.post("/{worker_id}/training/cancel")
-async def cancel_worker_training(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def cancel_worker_training(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Cancel training on a worker."""
     worker = await get_worker_or_404(worker_id, session)
 
     if not worker.current_job_id:
         raise HTTPException(status_code=400, detail="No active training job")
@@ -632,14 +596,11 @@
         headers = {}
         if worker.api_key:
             headers["X-API-Key"] = worker.api_key
 
         async with httpx.AsyncClient(timeout=10.0) as client:
-            response = await client.post(
-                f"{worker.url}/training/cancel",
-                headers=headers
-            )
+            response = await client.post(f"{worker.url}/training/cancel", headers=headers)
             response.raise_for_status()
 
         # Update worker status
         worker.status = WorkerStatus.ONLINE
         worker.current_job_id = None
@@ -652,43 +613,34 @@
     except Exception as e:
         raise HTTPException(status_code=503, detail=f"Failed to cancel training: {e}")
 
 
 @router.get("/{worker_id}/models")
-async def get_available_models(
-    worker_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_available_models(worker_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get available base models for training."""
     worker = await get_worker_or_404(worker_id, session)
 
     try:
         headers = {}
         if worker.api_key:
             headers["X-API-Key"] = worker.api_key
 
         async with httpx.AsyncClient(timeout=10.0) as client:
-            response = await client.get(
-                f"{worker.url}/models",
-                headers=headers
-            )
+            response = await client.get(f"{worker.url}/models", headers=headers)
             response.raise_for_status()
             return response.json()
 
     except Exception as e:
         raise HTTPException(status_code=503, detail=f"Failed to get models: {e}")
 
 
 @router.post("/refresh-all")
 async def refresh_all_workers(
-    background_tasks: BackgroundTasks,
-    session: AsyncSession = Depends(get_db_session)
+    background_tasks: BackgroundTasks, session: AsyncSession = Depends(get_db_session)
 ):
     """Refresh status of all enabled workers."""
-    result = await session.execute(
-        select(TrainingWorker).where(TrainingWorker.enabled is True)
-    )
+    result = await session.execute(select(TrainingWorker).where(TrainingWorker.enabled is True))
     workers = result.scalars().all()
 
     async def refresh_worker(worker_id: str):
         async with async_session_maker() as db_session:
             result = await db_session.execute(
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/workers.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/services.py	2025-12-31 13:30:51.480007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/services.py	2025-12-31 13:41:36.029002+00:00
@@ -8,10 +8,11 @@
 from ..models.service_config import ServiceStatus, ServiceType
 
 
 class ServiceConfigBase(BaseModel):
     """Base service configuration schema."""
+
     name: str = Field(..., min_length=1, max_length=100)
     service_type: ServiceType
     description: Optional[str] = None
     base_url: str = Field(..., min_length=1, max_length=255)
     port: Optional[int] = Field(None, ge=1, le=65535)
@@ -23,17 +24,19 @@
     tags: Dict[str, Any] = Field(default_factory=dict)
 
 
 class ServiceConfigCreate(ServiceConfigBase):
     """Schema for creating a service configuration."""
+
     api_key: Optional[str] = Field(None, max_length=2000)  # JWT tokens can be long
     username: Optional[str] = Field(None, max_length=100)
     password: Optional[str] = Field(None, max_length=255)
 
 
 class ServiceConfigUpdate(BaseModel):
     """Schema for updating a service configuration."""
+
     name: Optional[str] = Field(None, min_length=1, max_length=100)
     description: Optional[str] = None
     base_url: Optional[str] = Field(None, min_length=1, max_length=255)
     port: Optional[int] = Field(None, ge=1, le=65535)
     api_key: Optional[str] = Field(None, max_length=2000)  # JWT tokens can be long
@@ -47,10 +50,11 @@
     tags: Optional[Dict[str, Any]] = None
 
 
 class ServiceConfigResponse(ServiceConfigBase):
     """Schema for service configuration responses."""
+
     model_config = ConfigDict(from_attributes=True)
 
     id: str
     api_key: Optional[str] = None
     username: Optional[str] = None
@@ -72,27 +76,27 @@
 
     @property
     def is_healthy(self) -> bool:
         """Check if service is healthy based on last test."""
         return (
-            self.status == ServiceStatus.ACTIVE and
-            self.last_test_success is True and
-            self.enabled
+            self.status == ServiceStatus.ACTIVE and self.last_test_success is True and self.enabled
         )
 
 
 class ServiceTestResult(BaseModel):
     """Schema for service connection test results."""
+
     service_id: str
     success: bool
     error_message: Optional[str] = None
     response_time_ms: Optional[int] = None
     tested_at: datetime = Field(default_factory=datetime.utcnow)
 
 
 class ServiceHealthStatus(BaseModel):
     """Schema for service health status."""
+
     service_id: str
     name: str
     status: ServiceStatus
     enabled: bool
     healthy: bool
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/services.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/groups.py	2025-12-31 13:30:51.479007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/groups.py	2025-12-31 13:41:36.068919+00:00
@@ -5,28 +5,32 @@
 
 from pydantic import BaseModel, Field
 
 # --- Tool Permission Schemas ---
 
+
 class GroupToolPermissionCreate(BaseModel):
     """Schema for creating a tool permission."""
+
     tool_name: str = Field(..., description="Tool name or '*' for all tools")
     service_type: Optional[str] = Field(None, description="Service type filter (optional)")
     enabled: bool = Field(True, description="Whether permission is enabled")
     description: Optional[str] = Field(None, description="Permission description")
 
 
 class GroupToolPermissionUpdate(BaseModel):
     """Schema for updating a tool permission."""
+
     tool_name: Optional[str] = Field(None, description="Tool name or '*' for all tools")
     service_type: Optional[str] = Field(None, description="Service type filter")
     enabled: Optional[bool] = Field(None, description="Whether permission is enabled")
     description: Optional[str] = Field(None, description="Permission description")
 
 
 class GroupToolPermissionResponse(BaseModel):
     """Schema for tool permission API responses."""
+
     id: str
     group_id: str
     tool_name: str
     service_type: Optional[str]
     enabled: bool
@@ -43,30 +47,34 @@
             tool_name=obj.tool_name,
             service_type=obj.service_type,
             enabled=obj.enabled,
             description=obj.description,
             created_at=obj.created_at,
-            updated_at=obj.updated_at
+            updated_at=obj.updated_at,
         )
 
 
 # --- Group Membership Schemas ---
+
 
 class GroupMembershipCreate(BaseModel):
     """Schema for adding a user to a group."""
+
     central_user_id: str = Field(..., description="Central user ID to add")
     enabled: bool = Field(True, description="Whether membership is active")
     granted_by: Optional[str] = Field(None, description="Who granted this membership")
 
 
 class GroupMembershipUpdate(BaseModel):
     """Schema for updating a membership."""
+
     enabled: Optional[bool] = Field(None, description="Whether membership is active")
 
 
 class GroupMembershipResponse(BaseModel):
     """Schema for membership API responses."""
+
     id: str
     group_id: str
     central_user_id: str
     enabled: bool
     granted_at: datetime
@@ -86,38 +94,42 @@
             enabled=obj.enabled,
             granted_at=obj.granted_at,
             granted_by=obj.granted_by,
             created_at=obj.created_at,
             updated_at=obj.updated_at,
-            central_username=username
+            central_username=username,
         )
 
 
 # --- Group Schemas ---
+
 
 class GroupCreate(BaseModel):
     """Schema for creating a new group."""
+
     name: str = Field(..., description="Group name (unique)")
     description: Optional[str] = Field(None, description="Group description")
     color: Optional[str] = Field("#6366f1", description="Display color (hex)")
     icon: Optional[str] = Field(None, description="Icon name")
     priority: int = Field(0, description="Priority for permission resolution")
     enabled: bool = Field(True, description="Whether group is active")
 
 
 class GroupUpdate(BaseModel):
     """Schema for updating an existing group."""
+
     name: Optional[str] = Field(None, description="Group name")
     description: Optional[str] = Field(None, description="Group description")
     color: Optional[str] = Field(None, description="Display color (hex)")
     icon: Optional[str] = Field(None, description="Icon name")
     priority: Optional[int] = Field(None, description="Priority for permission resolution")
     enabled: Optional[bool] = Field(None, description="Whether group is active")
 
 
 class GroupResponse(BaseModel):
     """Schema for group API responses."""
+
     id: str
     name: str
     description: Optional[str]
     color: Optional[str]
     icon: Optional[str]
@@ -143,16 +155,19 @@
             is_system=obj.is_system,
             enabled=obj.enabled,
             created_at=obj.created_at,
             updated_at=obj.updated_at,
             member_count=len([m for m in obj.memberships if m.enabled]) if obj.memberships else 0,
-            tool_count=len([p for p in obj.tool_permissions if p.enabled]) if obj.tool_permissions else 0
+            tool_count=len([p for p in obj.tool_permissions if p.enabled])
+            if obj.tool_permissions
+            else 0,
         )
 
 
 class GroupDetailResponse(GroupResponse):
     """Detailed group response with members and permissions."""
+
     memberships: List[GroupMembershipResponse] = []
     tool_permissions: List[GroupToolPermissionResponse] = []
 
     @classmethod
     def model_validate(cls, obj, usernames: Optional[dict] = None):
@@ -168,66 +183,80 @@
             is_system=obj.is_system,
             enabled=obj.enabled,
             created_at=obj.created_at,
             updated_at=obj.updated_at,
             member_count=len([m for m in obj.memberships if m.enabled]) if obj.memberships else 0,
-            tool_count=len([p for p in obj.tool_permissions if p.enabled]) if obj.tool_permissions else 0,
+            tool_count=len([p for p in obj.tool_permissions if p.enabled])
+            if obj.tool_permissions
+            else 0,
             memberships=[
                 GroupMembershipResponse.model_validate(m, usernames.get(m.central_user_id))
                 for m in obj.memberships
-            ] if obj.memberships else [],
+            ]
+            if obj.memberships
+            else [],
             tool_permissions=[
-                GroupToolPermissionResponse.model_validate(p)
-                for p in obj.tool_permissions
-            ] if obj.tool_permissions else []
+                GroupToolPermissionResponse.model_validate(p) for p in obj.tool_permissions
+            ]
+            if obj.tool_permissions
+            else [],
         )
 
 
 class GroupListResponse(BaseModel):
     """Schema for paginated group list responses."""
+
     groups: List[GroupResponse]
     total: int
     skip: int
     limit: int
 
 
 # --- Bulk Operations ---
 
+
 class BulkPermissionUpdate(BaseModel):
     """Schema for bulk updating tool permissions."""
+
     service_type: Optional[str] = Field(None, description="Service type to update")
     tool_names: List[str] = Field(..., description="List of tool names to add/enable")
     enabled: bool = Field(True, description="Enable or disable these permissions")
 
 
 class BulkMembershipUpdate(BaseModel):
     """Schema for bulk updating group memberships."""
+
     central_user_ids: List[str] = Field(..., description="List of user IDs to add/remove")
     action: str = Field(..., description="Action: 'add' or 'remove'")
 
 
 # --- Permission Check ---
 
+
 class PermissionCheckRequest(BaseModel):
     """Schema for checking if a user has access to a tool."""
+
     central_user_id: str = Field(..., description="User to check")
     tool_name: str = Field(..., description="Tool to check access for")
     service_type: Optional[str] = Field(None, description="Service type context")
 
 
 class PermissionCheckResponse(BaseModel):
     """Schema for permission check results."""
+
     has_access: bool
     central_user_id: str
     tool_name: str
     service_type: Optional[str]
     granted_by_group: Optional[str] = None
     granted_by_group_id: Optional[str] = None
 
 
 # --- User Groups ---
 
+
 class UserGroupsResponse(BaseModel):
     """Schema for listing groups a user belongs to."""
+
     central_user_id: str
     groups: List[GroupResponse]
     total_groups: int
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/groups.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/users.py	2025-12-31 13:30:51.485007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/users.py	2025-12-31 13:41:36.120922+00:00
@@ -8,10 +8,11 @@
 from ..models.user_mapping import MappingStatus, UserRole
 
 
 class UserMappingCreate(BaseModel):
     """Schema for creating a new user mapping."""
+
     central_user_id: str = Field(..., description="Central user identifier")
     central_username: str = Field(..., description="Central username")
     central_email: Optional[str] = Field(None, description="Central user email")
     service_config_id: str = Field(..., description="Service configuration ID")
     service_user_id: str = Field(..., description="User ID in the service")
@@ -23,29 +24,34 @@
     service_metadata: Optional[Dict[str, Any]] = Field(None, description="Additional metadata")
 
 
 class UserMappingUpdate(BaseModel):
     """Schema for updating an existing user mapping."""
+
     service_user_id: Optional[str] = Field(None, description="User ID in the service")
     service_username: Optional[str] = Field(None, description="Username in the service")
     service_email: Optional[str] = Field(None, description="Email in the service")
     role: Optional[UserRole] = Field(None, description="User role in the service")
     status: Optional[MappingStatus] = Field(None, description="Mapping status")
-    sync_enabled: Optional[bool] = Field(None, description="Whether sync is enabled for this mapping")
+    sync_enabled: Optional[bool] = Field(
+        None, description="Whether sync is enabled for this mapping"
+    )
     service_metadata: Optional[Dict[str, Any]] = Field(None, description="Additional metadata")
 
 
 class ServiceConfigInfo(BaseModel):
     """Basic service configuration info for user mapping responses."""
+
     id: str
     name: str
     service_type: str
     base_url: str
 
 
 class UserMappingResponse(BaseModel):
     """Schema for user mapping API responses."""
+
     id: str
     central_user_id: str
     central_username: str
     central_email: Optional[str]
     service_config_id: str
@@ -83,51 +89,57 @@
             "last_sync_success": obj.last_sync_success,
             "last_sync_error": obj.last_sync_error,
             "sync_attempts": obj.sync_attempts,
             "service_metadata": obj.service_metadata,
             "created_at": obj.created_at,
-            "updated_at": obj.updated_at
+            "updated_at": obj.updated_at,
         }
 
         # Add service config info if available
-        if hasattr(obj, 'service_config') and obj.service_config:
+        if hasattr(obj, "service_config") and obj.service_config:
             data["service_config"] = ServiceConfigInfo(
                 id=str(obj.service_config.id),
                 name=obj.service_config.name,
                 service_type=obj.service_config.service_type,
-                base_url=obj.service_config.base_url
+                base_url=obj.service_config.base_url,
             )
 
         return cls(**data)
 
 
 class UserMappingListResponse(BaseModel):
     """Schema for paginated user mapping list responses."""
+
     mappings: List[UserMappingResponse]
     total: int
     skip: int
     limit: int
 
 
 class UserSyncRequest(BaseModel):
     """Schema for user synchronization requests."""
+
     central_user_id: str = Field(..., description="Central user identifier to sync")
     force_sync: bool = Field(False, description="Force sync even if recently synced")
-    sync_services: Optional[List[str]] = Field(None, description="Specific service IDs to sync (all if None)")
+    sync_services: Optional[List[str]] = Field(
+        None, description="Specific service IDs to sync (all if None)"
+    )
 
 
 class UserSyncServiceResult(BaseModel):
     """Result for a single service sync operation."""
+
     service_id: str
     service_name: str
     success: bool
     error: Optional[str] = None
     sync_time: Optional[datetime] = None
 
 
 class UserSyncResult(BaseModel):
     """Schema for user synchronization results."""
+
     central_user_id: str
     total_services: int
     successful_syncs: int
     failed_syncs: int
     sync_results: List[Dict[str, Any]]
@@ -136,36 +148,40 @@
     error: Optional[str] = None
 
 
 class UserMappingStats(BaseModel):
     """User mapping statistics schema."""
+
     total_mappings: int
     unique_users: int
     status_breakdown: Dict[str, int]
     service_breakdown: Dict[str, int]
     average_mappings_per_user: float
 
 
 class BulkUserMappingCreate(BaseModel):
     """Schema for creating multiple user mappings at once."""
+
     mappings: List[UserMappingCreate] = Field(..., description="List of user mappings to create")
     skip_existing: bool = Field(True, description="Skip mappings that already exist")
     validate_services: bool = Field(True, description="Validate that all services exist")
 
 
 class BulkUserMappingResult(BaseModel):
     """Result of bulk user mapping creation."""
+
     total_requested: int
     created: int
     skipped: int
     failed: int
     errors: List[Dict[str, str]] = Field(default_factory=list)
     created_mappings: List[UserMappingResponse] = Field(default_factory=list)
 
 
 class UserServiceInfo(BaseModel):
     """Information about a user in a specific service."""
+
     service_id: str
     service_name: str
     service_type: str
     user_id: Optional[str]
     username: Optional[str]
@@ -176,10 +192,11 @@
     sync_status: Optional[str]
 
 
 class CentralUserProfile(BaseModel):
     """Complete profile of a central user across all services."""
+
     central_user_id: str
     display_name: Optional[str]
     email: Optional[str]
     total_services: int
     active_services: int
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/schemas/users.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/alert_service.py	2025-12-31 13:30:51.473007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/alert_service.py	2025-12-31 13:41:36.209809+00:00
@@ -89,14 +89,11 @@
         query = select(AlertConfiguration).where(AlertConfiguration.id == config_id)
         result = await session.execute(query)
         return result.scalar_one_or_none()
 
     async def update_alert_config(
-        self,
-        session: AsyncSession,
-        config_id: str,
-        **updates
+        self, session: AsyncSession, config_id: str, **updates
     ) -> Optional[AlertConfiguration]:
         """Update an alert configuration."""
         config = await self.get_alert_config_by_id(session, config_id)
         if not config:
             return None
@@ -107,13 +104,11 @@
 
         await session.commit()
         await session.refresh(config)
         return config
 
-    async def delete_alert_config(
-        self, session: AsyncSession, config_id: str
-    ) -> bool:
+    async def delete_alert_config(self, session: AsyncSession, config_id: str) -> bool:
         """Delete an alert configuration."""
         config = await self.get_alert_config_by_id(session, config_id)
         if not config:
             return False
 
@@ -240,25 +235,21 @@
         result = await session.execute(query)
         history = list(result.scalars().all())
 
         return history, total or 0
 
-    async def get_active_alerts(
-        self, session: AsyncSession
-    ) -> List[AlertHistory]:
+    async def get_active_alerts(self, session: AsyncSession) -> List[AlertHistory]:
         """Get all currently active (unresolved) alerts."""
         query = (
             select(AlertHistory)
             .where(AlertHistory.is_resolved is False)
             .order_by(AlertHistory.triggered_at.desc())
         )
         result = await session.execute(query)
         return list(result.scalars().all())
 
-    async def get_alert_stats(
-        self, session: AsyncSession, hours: int = 24
-    ) -> Dict[str, Any]:
+    async def get_alert_stats(self, session: AsyncSession, hours: int = 24) -> Dict[str, Any]:
         """Get alert statistics for the specified time period."""
         cutoff = datetime.utcnow() - timedelta(hours=hours)
 
         # Count by severity
         severity_query = (
@@ -268,29 +259,22 @@
         )
         severity_result = await session.execute(severity_query)
         severity_counts = dict(severity_result.all())
 
         # Count active alerts
-        active_query = select(func.count(AlertHistory.id)).where(
-            AlertHistory.is_resolved is False
-        )
+        active_query = select(func.count(AlertHistory.id)).where(AlertHistory.is_resolved is False)
         active_count = await session.scalar(active_query) or 0
 
         # Total triggered in period
-        total_query = select(func.count(AlertHistory.id)).where(
-            AlertHistory.triggered_at >= cutoff
-        )
+        total_query = select(func.count(AlertHistory.id)).where(AlertHistory.triggered_at >= cutoff)
         total = await session.scalar(total_query) or 0
 
         # Mean time to resolution
-        resolved_query = (
-            select(AlertHistory)
-            .where(
-                AlertHistory.triggered_at >= cutoff,
-                AlertHistory.is_resolved is True,
-                AlertHistory.resolved_at.isnot(None),
-            )
+        resolved_query = select(AlertHistory).where(
+            AlertHistory.triggered_at >= cutoff,
+            AlertHistory.is_resolved is True,
+            AlertHistory.resolved_at.isnot(None),
         )
         resolved_result = await session.execute(resolved_query)
         resolved_alerts = list(resolved_result.scalars().all())
 
         mttr_seconds = 0
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/alert_service.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/circuit_breaker.py	2025-12-31 13:30:51.470007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/circuit_breaker.py	2025-12-31 13:41:36.256728+00:00
@@ -15,27 +15,30 @@
 logger = logging.getLogger(__name__)
 
 
 class CircuitState(Enum):
     """Circuit breaker states."""
-    CLOSED = "closed"      # Normal operation
-    OPEN = "open"         # Circuit is open, calls are rejected
+
+    CLOSED = "closed"  # Normal operation
+    OPEN = "open"  # Circuit is open, calls are rejected
     HALF_OPEN = "half_open"  # Testing if service has recovered
 
 
 @dataclass
 class CircuitBreakerConfig:
     """Configuration for a circuit breaker."""
-    failure_threshold: int = 5           # Number of failures before opening
-    recovery_timeout: int = 60           # Seconds to wait before testing recovery
-    success_threshold: int = 2           # Successes needed to close from half-open
-    timeout: float = 30.0               # Request timeout in seconds
+
+    failure_threshold: int = 5  # Number of failures before opening
+    recovery_timeout: int = 60  # Seconds to wait before testing recovery
+    success_threshold: int = 2  # Successes needed to close from half-open
+    timeout: float = 30.0  # Request timeout in seconds
     expected_exception: tuple = (Exception,)  # Exceptions that count as failures
 
 
 class CircuitBreakerError(Exception):
     """Exception raised when circuit breaker is open."""
+
     pass
 
 
 class CircuitBreaker:
     """Circuit breaker implementation for protecting service calls."""
@@ -75,22 +78,18 @@
         async with self._lock:
             await self._update_state()
 
             if self.state == CircuitState.OPEN:
                 raise CircuitBreakerError(
-                    f"Circuit breaker '{self.name}' is OPEN. "
-                    f"Service calls are being rejected."
+                    f"Circuit breaker '{self.name}' is OPEN. " f"Service calls are being rejected."
                 )
 
             self.call_count += 1
 
         # Execute the function with timeout
         try:
-            result = await asyncio.wait_for(
-                func(*args, **kwargs),
-                timeout=self.config.timeout
-            )
+            result = await asyncio.wait_for(func(*args, **kwargs), timeout=self.config.timeout)
 
             # Record success
             async with self._lock:
                 await self._record_success()
 
@@ -99,34 +98,30 @@
         except self.config.expected_exception as e:
             # Record failure
             async with self._lock:
                 await self._record_failure()
 
-            logger.warning(
-                f"Circuit breaker '{self.name}' recorded failure: {str(e)}"
-            )
+            logger.warning(f"Circuit breaker '{self.name}' recorded failure: {str(e)}")
             raise
 
         except asyncio.TimeoutError:
             # Timeout is also considered a failure
             async with self._lock:
                 await self._record_failure()
 
-            logger.warning(
-                f"Circuit breaker '{self.name}' timeout after {self.config.timeout}s"
-            )
+            logger.warning(f"Circuit breaker '{self.name}' timeout after {self.config.timeout}s")
             raise
 
     async def _update_state(self) -> None:
         """Update circuit breaker state based on current conditions."""
         now = datetime.utcnow()
 
         if self.state == CircuitState.OPEN:
             # Check if we should transition to half-open
-            if (self.last_failure_time and
-                now - self.last_failure_time >= timedelta(seconds=self.config.recovery_timeout)):
-
+            if self.last_failure_time and now - self.last_failure_time >= timedelta(
+                seconds=self.config.recovery_timeout
+            ):
                 logger.info(f"Circuit breaker '{self.name}' transitioning to HALF_OPEN")
                 self.state = CircuitState.HALF_OPEN
                 self.success_count = 0
 
         elif self.state == CircuitState.HALF_OPEN:
@@ -183,18 +178,22 @@
             "name": self.name,
             "state": self.state.value,
             "failure_count": self.failure_count,
             "success_count": self.success_count,
             "call_count": self.call_count,
-            "last_failure_time": self.last_failure_time.isoformat() if self.last_failure_time else None,
-            "last_success_time": self.last_success_time.isoformat() if self.last_success_time else None,
+            "last_failure_time": self.last_failure_time.isoformat()
+            if self.last_failure_time
+            else None,
+            "last_success_time": self.last_success_time.isoformat()
+            if self.last_success_time
+            else None,
             "config": {
                 "failure_threshold": self.config.failure_threshold,
                 "recovery_timeout": self.config.recovery_timeout,
                 "success_threshold": self.config.success_threshold,
-                "timeout": self.config.timeout
-            }
+                "timeout": self.config.timeout,
+            },
         }
 
     async def reset(self) -> None:
         """Reset circuit breaker to closed state."""
         async with self._lock:
@@ -220,11 +219,13 @@
     def __init__(self):
         """Initialize circuit breaker manager."""
         self._breakers: Dict[str, CircuitBreaker] = {}
         self._default_config = CircuitBreakerConfig()
 
-    def get_breaker(self, name: str, config: Optional[CircuitBreakerConfig] = None) -> CircuitBreaker:
+    def get_breaker(
+        self, name: str, config: Optional[CircuitBreakerConfig] = None
+    ) -> CircuitBreaker:
         """Get or create a circuit breaker.
 
         Args:
             name: Circuit breaker name
             config: Optional configuration (uses default if not provided)
@@ -281,11 +282,11 @@
     name: str,
     failure_threshold: int = 5,
     recovery_timeout: int = 60,
     success_threshold: int = 2,
     timeout: float = 30.0,
-    expected_exception: tuple = (Exception,)
+    expected_exception: tuple = (Exception,),
 ):
     """Decorator to add circuit breaker protection to async functions.
 
     Args:
         name: Circuit breaker name
@@ -301,11 +302,11 @@
     config = CircuitBreakerConfig(
         failure_threshold=failure_threshold,
         recovery_timeout=recovery_timeout,
         success_threshold=success_threshold,
         timeout=timeout,
-        expected_exception=expected_exception
+        expected_exception=expected_exception,
     )
 
     def decorator(func: Callable[..., Awaitable[Any]]) -> Callable[..., Awaitable[Any]]:
         @wraps(func)
         async def wrapper(*args, **kwargs):
@@ -327,39 +328,24 @@
     Returns:
         Appropriate configuration for the service
     """
     service_configs = {
         "plex": CircuitBreakerConfig(
-            failure_threshold=3,
-            recovery_timeout=30,
-            success_threshold=2,
-            timeout=15.0
+            failure_threshold=3, recovery_timeout=30, success_threshold=2, timeout=15.0
         ),
         "tautulli": CircuitBreakerConfig(
-            failure_threshold=3,
-            recovery_timeout=30,
-            success_threshold=2,
-            timeout=10.0
+            failure_threshold=3, recovery_timeout=30, success_threshold=2, timeout=10.0
         ),
         "overseerr": CircuitBreakerConfig(
-            failure_threshold=5,
-            recovery_timeout=60,
-            success_threshold=2,
-            timeout=20.0
+            failure_threshold=5, recovery_timeout=60, success_threshold=2, timeout=20.0
         ),
         "zammad": CircuitBreakerConfig(
-            failure_threshold=5,
-            recovery_timeout=45,
-            success_threshold=2,
-            timeout=25.0
+            failure_threshold=5, recovery_timeout=45, success_threshold=2, timeout=25.0
         ),
         "authentik": CircuitBreakerConfig(
-            failure_threshold=3,
-            recovery_timeout=30,
-            success_threshold=1,
-            timeout=15.0
-        )
+            failure_threshold=3, recovery_timeout=30, success_threshold=1, timeout=15.0
+        ),
     }
 
     return service_configs.get(service_type.lower(), CircuitBreakerConfig())
 
 
@@ -368,15 +354,11 @@
     return circuit_manager
 
 
 # Helper functions for service adapters
 async def call_with_circuit_breaker(
-    service_name: str,
-    service_type: str,
-    func: Callable[[], Awaitable[Any]],
-    *args,
-    **kwargs
+    service_name: str, service_type: str, func: Callable[[], Awaitable[Any]], *args, **kwargs
 ) -> Any:
     """Call a function with circuit breaker protection for a specific service.
 
     Args:
         service_name: Name of the service
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/circuit_breaker.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/health_scheduler.py	2025-12-31 13:30:51.473007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/health_scheduler.py	2025-12-31 13:41:36.285623+00:00
@@ -147,11 +147,11 @@
             return {"status": "already_running", "message": "Health checks are already running"}
 
         await self._run_health_checks()
         return {
             "status": "completed",
-            "last_run": self._last_run.isoformat() if self._last_run else None
+            "last_run": self._last_run.isoformat() if self._last_run else None,
         }
 
 
 # Global instance
 health_scheduler = HealthCheckScheduler.get_instance()
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/health_scheduler.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_service.py	2025-12-31 13:30:51.461007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_service.py	2025-12-31 13:41:36.404542+00:00
@@ -14,14 +14,11 @@
 
 class LogService:
     """Service for managing log entries and retention policies."""
 
     def __init__(
-        self,
-        retention_days: int = 30,
-        max_entries: int = 100000,
-        cleanup_interval_hours: int = 6
+        self, retention_days: int = 30, max_entries: int = 100000, cleanup_interval_hours: int = 6
     ):
         self.retention_days = retention_days
         self.max_entries = max_entries
         self.cleanup_interval_hours = cleanup_interval_hours
         self._cleanup_task: Optional[asyncio.Task] = None
@@ -112,13 +109,11 @@
         result = await session.execute(query)
         logs = list(result.scalars().all())
 
         return logs, total or 0
 
-    async def get_log_by_id(
-        self, session: AsyncSession, log_id: str
-    ) -> Optional[LogEntry]:
+    async def get_log_by_id(self, session: AsyncSession, log_id: str) -> Optional[LogEntry]:
         """Get a single log entry by ID."""
         query = select(LogEntry).where(LogEntry.id == log_id)
         result = await session.execute(query)
         return result.scalar_one_or_none()
 
@@ -132,13 +127,11 @@
             .order_by(LogEntry.logged_at.asc())
         )
         result = await session.execute(query)
         return list(result.scalars().all())
 
-    async def get_log_stats(
-        self, session: AsyncSession, hours: int = 24
-    ) -> Dict[str, Any]:
+    async def get_log_stats(self, session: AsyncSession, hours: int = 24) -> Dict[str, Any]:
         """Get log statistics for the specified time period."""
         cutoff = datetime.utcnow() - timedelta(hours=hours)
 
         # Count by level
         level_query = (
@@ -157,14 +150,11 @@
         )
         source_result = await session.execute(source_query)
         source_counts = dict(source_result.all())
 
         # Total count
-        total_query = (
-            select(func.count(LogEntry.id))
-            .where(LogEntry.logged_at >= cutoff)
-        )
+        total_query = select(func.count(LogEntry.id)).where(LogEntry.logged_at >= cutoff)
         total = await session.scalar(total_query) or 0
 
         # Error rate
         error_count = level_counts.get(LogLevel.ERROR.value, 0) + level_counts.get(
             LogLevel.CRITICAL.value, 0
@@ -194,15 +184,11 @@
         total = await session.scalar(total_query) or 0
 
         if total > self.max_entries:
             # Get IDs of oldest entries to delete
             excess = total - self.max_entries
-            oldest_query = (
-                select(LogEntry.id)
-                .order_by(LogEntry.logged_at.asc())
-                .limit(excess)
-            )
+            oldest_query = select(LogEntry.id).order_by(LogEntry.logged_at.asc()).limit(excess)
             oldest_result = await session.execute(oldest_query)
             oldest_ids = [row[0] for row in oldest_result.all()]
 
             if oldest_ids:
                 delete_excess = delete(LogEntry).where(LogEntry.id.in_(oldest_ids))
@@ -214,12 +200,11 @@
 
     async def cleanup_old_alerts(self, session: AsyncSession, days: int = 90) -> int:
         """Remove resolved alert history older than specified days."""
         cutoff_date = datetime.utcnow() - timedelta(days=days)
         delete_query = delete(AlertHistory).where(
-            AlertHistory.is_resolved is True,
-            AlertHistory.resolved_at < cutoff_date
+            AlertHistory.is_resolved is True, AlertHistory.resolved_at < cutoff_date
         )
         result = await session.execute(delete_query)
         await session.commit()
         return result.rowcount
 
@@ -231,13 +216,11 @@
 
     async def get_distinct_components(
         self, session: AsyncSession, source: Optional[str] = None
     ) -> List[str]:
         """Get all distinct log components, optionally filtered by source."""
-        query = select(LogEntry.component).distinct().where(
-            LogEntry.component.isnot(None)
-        )
+        query = select(LogEntry.component).distinct().where(LogEntry.component.isnot(None))
         if source:
             query = query.where(LogEntry.source == source)
         result = await session.execute(query)
         return [row[0] for row in result.all() if row[0]]
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_service.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_exporter.py	2025-12-31 13:30:51.471007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_exporter.py	2025-12-31 13:41:36.510646+00:00
@@ -64,33 +64,44 @@
     def _export_json(self, logs: List[LogEntry]) -> str:
         """Export logs as JSON."""
         data = {
             "exported_at": datetime.utcnow().isoformat(),
             "total_logs": len(logs),
-            "logs": [log.to_dict() for log in logs]
+            "logs": [log.to_dict() for log in logs],
         }
         return json.dumps(data, indent=2, default=str)
 
     def _export_csv(self, logs: List[LogEntry]) -> str:
         """Export logs as CSV."""
         output = io.StringIO()
 
         fieldnames = [
-            "id", "logged_at", "level", "source", "component", "message",
-            "correlation_id", "request_id", "user_id", "service_id",
-            "service_type", "exception_type", "exception_message",
-            "duration_ms", "created_at"
+            "id",
+            "logged_at",
+            "level",
+            "source",
+            "component",
+            "message",
+            "correlation_id",
+            "request_id",
+            "user_id",
+            "service_id",
+            "service_type",
+            "exception_type",
+            "exception_message",
+            "duration_ms",
+            "created_at",
         ]
 
-        writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction='ignore')
+        writer = csv.DictWriter(output, fieldnames=fieldnames, extrasaction="ignore")
         writer.writeheader()
 
         for log in logs:
             row = log.to_dict()
             # Flatten extra_data and stack_trace for CSV
-            row.pop('extra_data', None)
-            row.pop('stack_trace', None)
+            row.pop("extra_data", None)
+            row.pop("stack_trace", None)
             writer.writerow(row)
 
         return output.getvalue()
 
     def _export_text(self, logs: List[LogEntry]) -> str:
@@ -120,23 +131,19 @@
 
             # Add exception info if present
             if log.exception_type:
                 lines.append(f"    Exception: {log.exception_type}: {log.exception_message}")
                 if log.stack_trace:
-                    for trace_line in log.stack_trace.split('\n'):
+                    for trace_line in log.stack_trace.split("\n"):
                         lines.append(f"    {trace_line}")
 
-        return '\n'.join(lines)
+        return "\n".join(lines)
 
     def get_filename(self, format: ExportFormat) -> str:
         """Generate a filename for the export."""
         timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
-        extensions = {
-            "json": "json",
-            "csv": "csv",
-            "text": "log"
-        }
+        extensions = {"json": "json", "csv": "csv", "text": "log"}
         return f"mcparr_logs_{timestamp}.{extensions[format]}"
 
 
 # Global instance
 log_exporter = LogExporter()
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/log_exporter.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/ollama_service.py	2025-12-31 13:30:51.511007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/ollama_service.py	2025-12-31 13:41:36.696461+00:00
@@ -15,20 +15,23 @@
 logger = logging.getLogger(__name__)
 
 
 class OllamaError(Exception):
     """Base exception for Ollama service errors."""
+
     pass
 
 
 class OllamaConnectionError(OllamaError):
     """Raised when unable to connect to Ollama."""
+
     pass
 
 
 class OllamaModelError(OllamaError):
     """Raised when there's a model-related error."""
+
     pass
 
 
 class OllamaModel:
     """Representation of an Ollama model."""
@@ -42,11 +45,11 @@
         self.details = data.get("details", {})
 
     @property
     def size_gb(self) -> float:
         """Get model size in GB."""
-        return round(self.size / (1024 ** 3), 2)
+        return round(self.size / (1024**3), 2)
 
     @property
     def family(self) -> str:
         """Get model family (e.g., llama, mistral)."""
         return self.details.get("family", "unknown")
@@ -70,11 +73,11 @@
             "size_gb": self.size_gb,
             "digest": self.digest,
             "family": self.family,
             "parameter_size": self.parameter_size,
             "quantization_level": self.quantization_level,
-            "details": self.details
+            "details": self.details,
         }
 
 
 class OllamaService:
     """Service for interacting with Ollama API."""
@@ -83,18 +86,15 @@
         self.base_url = base_url.rstrip("/")
         self.timeout = httpx.Timeout(30.0, read=300.0)  # Longer read timeout for generation
 
     @classmethod
     async def from_service_config(
-        cls,
-        session: AsyncSession,
-        service_id: Optional[str] = None
+        cls, session: AsyncSession, service_id: Optional[str] = None
     ) -> Optional["OllamaService"]:
         """Create OllamaService from database configuration."""
         query = select(ServiceConfig).where(
-            ServiceConfig.service_type == ServiceType.OLLAMA,
-            ServiceConfig.enabled is True
+            ServiceConfig.service_type == ServiceType.OLLAMA, ServiceConfig.enabled is True
         )
         if service_id:
             query = query.where(ServiceConfig.id == service_id)
 
         result = await session.execute(query)
@@ -103,16 +103,11 @@
         if not config:
             return None
 
         return cls(base_url=config.full_url)
 
-    async def _request(
-        self,
-        method: str,
-        endpoint: str,
-        **kwargs
-    ) -> Dict[str, Any]:
+    async def _request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
         """Make HTTP request to Ollama API."""
         url = f"{self.base_url}{endpoint}"
 
         async with httpx.AsyncClient(timeout=self.timeout) as client:
             try:
@@ -121,23 +116,18 @@
                 # Handle empty responses (e.g., DELETE returns 200 with no body)
                 if response.headers.get("content-length") == "0" or not response.content:
                     return {}
                 return response.json()
             except httpx.ConnectError as e:
-                raise OllamaConnectionError(
-                    f"Unable to connect to Ollama at {self.base_url}: {e}"
-                )
+                raise OllamaConnectionError(f"Unable to connect to Ollama at {self.base_url}: {e}")
             except httpx.HTTPStatusError as e:
                 raise OllamaError(f"Ollama API error: {e.response.status_code} - {e.response.text}")
             except Exception as e:
                 raise OllamaError(f"Ollama request failed: {e}")
 
     async def _stream_request(
-        self,
-        method: str,
-        endpoint: str,
-        **kwargs
+        self, method: str, endpoint: str, **kwargs
     ) -> AsyncGenerator[Dict[str, Any], None]:
         """Make streaming HTTP request to Ollama API."""
         url = f"{self.base_url}{endpoint}"
 
         async with httpx.AsyncClient(timeout=self.timeout) as client:
@@ -149,13 +139,11 @@
                             try:
                                 yield json.loads(line)
                             except json.JSONDecodeError:
                                 continue
             except httpx.ConnectError as e:
-                raise OllamaConnectionError(
-                    f"Unable to connect to Ollama at {self.base_url}: {e}"
-                )
+                raise OllamaConnectionError(f"Unable to connect to Ollama at {self.base_url}: {e}")
             except httpx.HTTPStatusError as e:
                 raise OllamaError(f"Ollama API error: {e.response.status_code}")
 
     async def health_check(self) -> Dict[str, Any]:
         """Check Ollama server health."""
@@ -164,18 +152,14 @@
                 response = await client.get(f"{self.base_url}/api/version")
                 if response.status_code == 200:
                     return {
                         "status": "healthy",
                         "version": response.json().get("version", "unknown"),
-                        "url": self.base_url
+                        "url": self.base_url,
                     }
         except Exception as e:
-            return {
-                "status": "unhealthy",
-                "error": str(e),
-                "url": self.base_url
-            }
+            return {"status": "unhealthy", "error": str(e), "url": self.base_url}
         return {"status": "unknown", "url": self.base_url}
 
     async def list_models(self) -> List[OllamaModel]:
         """List all available models."""
         data = await self._request("GET", "/api/tags")
@@ -186,19 +170,15 @@
         """Get detailed information about a model."""
         data = await self._request("POST", "/api/show", json={"name": model_name})
         return data
 
     async def pull_model(
-        self,
-        model_name: str,
-        progress_callback: Optional[callable] = None
+        self, model_name: str, progress_callback: Optional[callable] = None
     ) -> AsyncGenerator[Dict[str, Any], None]:
         """Pull a model from Ollama registry with progress updates."""
         async for update in self._stream_request(
-            "POST",
-            "/api/pull",
-            json={"name": model_name, "stream": True}
+            "POST", "/api/pull", json={"name": model_name, "stream": True}
         ):
             if progress_callback:
                 await progress_callback(update)
             yield update
 
@@ -208,14 +188,13 @@
         return True
 
     async def copy_model(self, source: str, destination: str) -> bool:
         """Copy a model to a new name."""
         try:
-            await self._request("POST", "/api/copy", json={
-                "source": source,
-                "destination": destination
-            })
+            await self._request(
+                "POST", "/api/copy", json={"source": source, "destination": destination}
+            )
             return True
         except OllamaError:
             return False
 
     async def generate(
@@ -224,15 +203,11 @@
         prompt: str,
         system: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
     ) -> Dict[str, Any]:
         """Generate completion from a model (non-streaming)."""
-        payload = {
-            "model": model,
-            "prompt": prompt,
-            "stream": False
-        }
+        payload = {"model": model, "prompt": prompt, "stream": False}
         if system:
             payload["system"] = system
         if options:
             payload["options"] = options
 
@@ -244,15 +219,11 @@
         prompt: str,
         system: Optional[str] = None,
         options: Optional[Dict[str, Any]] = None,
     ) -> AsyncGenerator[Dict[str, Any], None]:
         """Generate completion from a model (streaming)."""
-        payload = {
-            "model": model,
-            "prompt": prompt,
-            "stream": True
-        }
+        payload = {"model": model, "prompt": prompt, "stream": True}
         if system:
             payload["system"] = system
         if options:
             payload["options"] = options
 
@@ -264,15 +235,11 @@
         model: str,
         messages: List[Dict[str, str]],
         options: Optional[Dict[str, Any]] = None,
     ) -> Dict[str, Any]:
         """Chat completion from a model (non-streaming)."""
-        payload = {
-            "model": model,
-            "messages": messages,
-            "stream": False
-        }
+        payload = {"model": model, "messages": messages, "stream": False}
         if options:
             payload["options"] = options
 
         return await self._request("POST", "/api/chat", json=payload)
 
@@ -281,32 +248,23 @@
         model: str,
         messages: List[Dict[str, str]],
         options: Optional[Dict[str, Any]] = None,
     ) -> AsyncGenerator[Dict[str, Any], None]:
         """Chat completion from a model (streaming)."""
-        payload = {
-            "model": model,
-            "messages": messages,
-            "stream": True
-        }
+        payload = {"model": model, "messages": messages, "stream": True}
         if options:
             payload["options"] = options
 
         async for chunk in self._stream_request("POST", "/api/chat", json=payload):
             yield chunk
 
     async def create_model(
-        self,
-        name: str,
-        modelfile: str,
-        progress_callback: Optional[callable] = None
+        self, name: str, modelfile: str, progress_callback: Optional[callable] = None
     ) -> AsyncGenerator[Dict[str, Any], None]:
         """Create a new model from a Modelfile."""
         async for update in self._stream_request(
-            "POST",
-            "/api/create",
-            json={"name": name, "modelfile": modelfile, "stream": True}
+            "POST", "/api/create", json={"name": name, "modelfile": modelfile, "stream": True}
         ):
             if progress_callback:
                 await progress_callback(update)
             yield update
 
@@ -320,45 +278,48 @@
 
     async def load_model(self, model_name: str) -> bool:
         """Load a model into memory (warm it up)."""
         try:
             # Use generate with empty prompt to load the model
-            await self._request("POST", "/api/generate", json={
-                "model": model_name,
-                "prompt": "",
-                "stream": False,
-                "keep_alive": "10m"  # Keep in memory for 10 minutes
-            })
+            await self._request(
+                "POST",
+                "/api/generate",
+                json={
+                    "model": model_name,
+                    "prompt": "",
+                    "stream": False,
+                    "keep_alive": "10m",  # Keep in memory for 10 minutes
+                },
+            )
             return True
         except OllamaError as e:
             logger.error(f"Failed to load model {model_name}: {e}")
             return False
 
     async def unload_model(self, model_name: str) -> bool:
         """Unload a model from memory."""
         try:
-            await self._request("POST", "/api/generate", json={
-                "model": model_name,
-                "prompt": "",
-                "stream": False,
-                "keep_alive": 0  # Immediately unload
-            })
+            await self._request(
+                "POST",
+                "/api/generate",
+                json={
+                    "model": model_name,
+                    "prompt": "",
+                    "stream": False,
+                    "keep_alive": 0,  # Immediately unload
+                },
+            )
             return True
         except OllamaError as e:
             logger.error(f"Failed to unload model {model_name}: {e}")
             return False
 
-    async def get_embeddings(
-        self,
-        model: str,
-        prompt: str
-    ) -> List[float]:
+    async def get_embeddings(self, model: str, prompt: str) -> List[float]:
         """Get embeddings for text."""
-        data = await self._request("POST", "/api/embeddings", json={
-            "model": model,
-            "prompt": prompt
-        })
+        data = await self._request(
+            "POST", "/api/embeddings", json={"model": model, "prompt": prompt}
+        )
         return data.get("embedding", [])
 
 
 class OllamaMetricsCollector:
     """Collect real-time metrics from Ollama."""
@@ -375,11 +336,11 @@
         metrics = {
             "timestamp": datetime.utcnow().isoformat(),
             "status": health.get("status"),
             "version": health.get("version"),
             "models": [],
-            "running_models": []
+            "running_models": [],
         }
 
         if health.get("status") == "healthy":
             try:
                 models = await self.ollama.list_models()
@@ -420,13 +381,11 @@
 _ollama_service: Optional[OllamaService] = None
 _metrics_collector: Optional[OllamaMetricsCollector] = None
 
 
 async def get_ollama_service(
-    session: AsyncSession = None,
-    service_id: str = None,
-    allow_fallback: bool = False
+    session: AsyncSession = None, service_id: str = None, allow_fallback: bool = False
 ) -> Optional[OllamaService]:
     """Get or create Ollama service instance.
 
     Args:
         session: Database session to fetch service config
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/ollama_service.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/mcp_audit.py	2025-12-31 13:30:51.470007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/mcp_audit.py	2025-12-31 13:41:36.713829+00:00
@@ -62,13 +62,11 @@
         self,
         session: AsyncSession,
         request_id: str,
     ) -> Optional[McpRequest]:
         """Get a specific MCP request by ID."""
-        result = await session.execute(
-            select(McpRequest).where(McpRequest.id == request_id)
-        )
+        result = await session.execute(select(McpRequest).where(McpRequest.id == request_id))
         return result.scalar_one_or_none()
 
     async def get_stats(
         self,
         session: AsyncSession,
@@ -77,12 +75,11 @@
         """Get MCP request statistics for the specified time period."""
         since = datetime.utcnow() - timedelta(hours=hours)
 
         # Total requests
         total_result = await session.execute(
-            select(func.count(McpRequest.id))
-            .where(McpRequest.created_at >= since)
+            select(func.count(McpRequest.id)).where(McpRequest.created_at >= since)
         )
         total = total_result.scalar() or 0
 
         # By status
         status_result = await session.execute(
@@ -110,20 +107,20 @@
         )
         top_tools = {row[0]: row[1] for row in tool_result.fetchall()}
 
         # Average duration
         avg_duration_result = await session.execute(
-            select(func.avg(McpRequest.duration_ms))
-            .where(and_(
-                McpRequest.created_at >= since,
-                McpRequest.duration_ms.isnot(None)
-            ))
+            select(func.avg(McpRequest.duration_ms)).where(
+                and_(McpRequest.created_at >= since, McpRequest.duration_ms.isnot(None))
+            )
         )
         avg_duration = avg_duration_result.scalar() or 0
 
         # Success rate
-        completed = by_status.get(McpRequestStatus.COMPLETED.value, 0) + by_status.get("completed", 0)
+        completed = by_status.get(McpRequestStatus.COMPLETED.value, 0) + by_status.get(
+            "completed", 0
+        )
         failed = by_status.get(McpRequestStatus.FAILED.value, 0) + by_status.get("failed", 0)
         success_rate = (completed / (completed + failed) * 100) if (completed + failed) > 0 else 100
 
         return {
             "total": total,
@@ -147,16 +144,13 @@
             select(
                 McpRequest.tool_name,
                 McpRequest.tool_category,
                 func.count(McpRequest.id).label("count"),
                 func.avg(McpRequest.duration_ms).label("avg_duration"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.COMPLETED, 1),
-                        else_=0
-                    )
-                ).label("success_count"),
+                func.sum(case((McpRequest.status == McpRequestStatus.COMPLETED, 1), else_=0)).label(
+                    "success_count"
+                ),
             )
             .where(McpRequest.created_at >= since)
             .group_by(McpRequest.tool_name, McpRequest.tool_category)
             .order_by(func.count(McpRequest.id).desc())
         )
@@ -165,11 +159,13 @@
             {
                 "tool_name": row.tool_name,
                 "category": row.tool_category,
                 "usage_count": row.count,
                 "avg_duration_ms": round(row.avg_duration or 0, 2),
-                "success_rate": round((row.success_count / row.count) * 100, 2) if row.count > 0 else 0,
+                "success_rate": round((row.success_count / row.count) * 100, 2)
+                if row.count > 0
+                else 0,
             }
             for row in result.fetchall()
         ]
 
     async def get_hourly_usage(
@@ -181,28 +177,22 @@
         since = datetime.utcnow() - timedelta(hours=hours)
 
         # SQLite doesn't have date_trunc, use strftime instead
         result = await session.execute(
             select(
-                func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at).label("hour"),
-                func.count(McpRequest.id).label("count"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.COMPLETED, 1),
-                        else_=0
-                    )
-                ).label("success_count"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.FAILED, 1),
-                        else_=0
-                    )
-                ).label("failed_count"),
-            )
-            .where(McpRequest.created_at >= since)
-            .group_by(func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at))
-            .order_by(func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at))
+                func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at).label("hour"),
+                func.count(McpRequest.id).label("count"),
+                func.sum(case((McpRequest.status == McpRequestStatus.COMPLETED, 1), else_=0)).label(
+                    "success_count"
+                ),
+                func.sum(case((McpRequest.status == McpRequestStatus.FAILED, 1), else_=0)).label(
+                    "failed_count"
+                ),
+            )
+            .where(McpRequest.created_at >= since)
+            .group_by(func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at))
+            .order_by(func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at))
         )
 
         return [
             {
                 "hour": row.hour,
@@ -221,13 +211,11 @@
         """Delete MCP requests older than retention period."""
         from sqlalchemy import delete
 
         cutoff = datetime.utcnow() - timedelta(days=retention_days)
 
-        result = await session.execute(
-            delete(McpRequest).where(McpRequest.created_at < cutoff)
-        )
+        result = await session.execute(delete(McpRequest).where(McpRequest.created_at < cutoff))
         await session.commit()
 
         return result.rowcount
 
     async def get_user_stats(
@@ -241,27 +229,18 @@
         result = await session.execute(
             select(
                 McpRequest.user_id,
                 func.count(McpRequest.id).label("count"),
                 func.avg(McpRequest.duration_ms).label("avg_duration"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.COMPLETED, 1),
-                        else_=0
-                    )
-                ).label("success_count"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.FAILED, 1),
-                        else_=0
-                    )
-                ).label("failed_count"),
-            )
-            .where(and_(
-                McpRequest.created_at >= since,
-                McpRequest.user_id.isnot(None)
-            ))
+                func.sum(case((McpRequest.status == McpRequestStatus.COMPLETED, 1), else_=0)).label(
+                    "success_count"
+                ),
+                func.sum(case((McpRequest.status == McpRequestStatus.FAILED, 1), else_=0)).label(
+                    "failed_count"
+                ),
+            )
+            .where(and_(McpRequest.created_at >= since, McpRequest.user_id.isnot(None)))
             .group_by(McpRequest.user_id)
             .order_by(func.count(McpRequest.id).desc())
         )
 
         return [
@@ -269,11 +248,13 @@
                 "user_id": row.user_id,
                 "request_count": row.count,
                 "avg_duration_ms": round(row.avg_duration or 0, 2),
                 "success_count": row.success_count or 0,
                 "failed_count": row.failed_count or 0,
-                "success_rate": round((row.success_count / row.count) * 100, 2) if row.count > 0 else 0,
+                "success_rate": round((row.success_count / row.count) * 100, 2)
+                if row.count > 0
+                else 0,
             }
             for row in result.fetchall()
         ]
 
     async def get_user_service_stats(
@@ -285,43 +266,42 @@
         since = datetime.utcnow() - timedelta(hours=hours)
 
         # Extract service name from tool_name (prefix before first underscore)
         # e.g., "plex_search_media" -> "plex", "radarr_get_queue" -> "radarr"
         service_expr = func.substr(
-            McpRequest.tool_name,
-            1,
-            func.instr(McpRequest.tool_name, '_') - 1
+            McpRequest.tool_name, 1, func.instr(McpRequest.tool_name, "_") - 1
         ).label("service")
 
         result = await session.execute(
             select(
                 McpRequest.user_id,
                 service_expr,
                 func.count(McpRequest.id).label("count"),
-                func.sum(
-                    case(
-                        (McpRequest.status == McpRequestStatus.COMPLETED, 1),
-                        else_=0
-                    )
-                ).label("success_count"),
-            )
-            .where(and_(
-                McpRequest.created_at >= since,
-                McpRequest.user_id.isnot(None),
-                McpRequest.tool_name.contains('_')  # Only tools with underscore
-            ))
+                func.sum(case((McpRequest.status == McpRequestStatus.COMPLETED, 1), else_=0)).label(
+                    "success_count"
+                ),
+            )
+            .where(
+                and_(
+                    McpRequest.created_at >= since,
+                    McpRequest.user_id.isnot(None),
+                    McpRequest.tool_name.contains("_"),  # Only tools with underscore
+                )
+            )
             .group_by(McpRequest.user_id, service_expr)
             .order_by(func.count(McpRequest.id).desc())
         )
 
         return [
             {
                 "user_id": row.user_id,
                 "service": row.service,
                 "request_count": row.count,
                 "success_count": row.success_count or 0,
-                "success_rate": round((row.success_count / row.count) * 100, 2) if row.count > 0 else 0,
+                "success_rate": round((row.success_count / row.count) * 100, 2)
+                if row.count > 0
+                else 0,
             }
             for row in result.fetchall()
         ]
 
     async def get_hourly_usage_by_user(
@@ -332,23 +312,17 @@
         """Get hourly usage statistics broken down by user."""
         since = datetime.utcnow() - timedelta(hours=hours)
 
         result = await session.execute(
             select(
-                func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at).label("hour"),
+                func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at).label("hour"),
                 McpRequest.user_id,
                 func.count(McpRequest.id).label("count"),
             )
-            .where(and_(
-                McpRequest.created_at >= since,
-                McpRequest.user_id.isnot(None)
-            ))
-            .group_by(
-                func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at),
-                McpRequest.user_id
-            )
-            .order_by(func.strftime('%Y-%m-%d %H:00:00', McpRequest.created_at))
+            .where(and_(McpRequest.created_at >= since, McpRequest.user_id.isnot(None)))
+            .group_by(func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at), McpRequest.user_id)
+            .order_by(func.strftime("%Y-%m-%d %H:00:00", McpRequest.created_at))
         )
 
         return [
             {
                 "hour": row.hour,
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/mcp_audit.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/permission_service.py	2025-12-31 13:30:51.519007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/permission_service.py	2025-12-31 13:41:36.780981+00:00
@@ -12,10 +12,11 @@
 
 
 @dataclass
 class PermissionCheckResult:
     """Result of a permission check."""
+
     has_access: bool
     granted_by_group: Optional[str] = None
     granted_by_group_id: Optional[str] = None
     denial_reason: Optional[str] = None
 
@@ -24,41 +25,33 @@
     """Service for checking user permissions based on group memberships."""
 
     def __init__(self, db: AsyncSession):
         self.db = db
 
-    async def _is_tool_restricted(
-        self,
-        tool_name: str,
-        service_type: Optional[str] = None
-    ) -> bool:
+    async def _is_tool_restricted(self, tool_name: str, service_type: Optional[str] = None) -> bool:
         """
         Check if a tool is restricted (associated with any group).
         A tool is restricted if any group has a permission for it.
         """
         # Check for exact tool match or wildcard permissions
         result = await self.db.execute(
-            select(func.count(GroupToolPermission.id))
-            .where(
+            select(func.count(GroupToolPermission.id)).where(
                 and_(
                     GroupToolPermission.enabled is True,
                     # Match tool name or wildcard
                     (
-                        (GroupToolPermission.tool_name == tool_name) |
-                        (GroupToolPermission.tool_name == "*")
-                    )
+                        (GroupToolPermission.tool_name == tool_name)
+                        | (GroupToolPermission.tool_name == "*")
+                    ),
                 )
             )
         )
         count = result.scalar()
         return count > 0
 
     async def check_permission(
-        self,
-        central_user_id: str,
-        tool_name: str,
-        service_type: Optional[str] = None
+        self, central_user_id: str, tool_name: str, service_type: Optional[str] = None
     ) -> PermissionCheckResult:
         """
         Check if a user has permission to access a specific tool.
 
         Permission resolution:
@@ -73,55 +66,48 @@
         tool_is_restricted = await self._is_tool_restricted(tool_name, service_type)
 
         if not tool_is_restricted:
             logger.debug(f"Tool {tool_name} is not restricted by any group, access granted")
             return PermissionCheckResult(
-                has_access=True,
-                granted_by_group=None,
-                granted_by_group_id=None
+                has_access=True, granted_by_group=None, granted_by_group_id=None
             )
 
         # Get user's active group memberships
         memberships_result = await self.db.execute(
-            select(GroupMembership)
-            .where(
+            select(GroupMembership).where(
                 and_(
                     GroupMembership.central_user_id == central_user_id,
-                    GroupMembership.enabled is True
+                    GroupMembership.enabled is True,
                 )
             )
         )
         memberships = memberships_result.scalars().all()
 
         if not memberships:
             # User has no groups but tool is restricted - deny access
-            logger.debug(f"User {central_user_id} has no group memberships and tool {tool_name} is restricted")
+            logger.debug(
+                f"User {central_user_id} has no group memberships and tool {tool_name} is restricted"
+            )
             return PermissionCheckResult(
                 has_access=False,
-                denial_reason="User is not a member of any group with access to this tool"
+                denial_reason="User is not a member of any group with access to this tool",
             )
 
         # Get all groups with their permissions, ordered by priority
         group_ids = [m.group_id for m in memberships]
         groups_result = await self.db.execute(
             select(Group)
             .options(selectinload(Group.tool_permissions))
-            .where(
-                and_(
-                    Group.id.in_(group_ids),
-                    Group.enabled is True
-                )
-            )
+            .where(and_(Group.id.in_(group_ids), Group.enabled is True))
             .order_by(Group.priority.desc())
         )
         groups = groups_result.scalars().all()
 
         if not groups:
             logger.debug(f"No enabled groups found for user {central_user_id}")
             return PermissionCheckResult(
-                has_access=False,
-                denial_reason="User's groups are all disabled"
+                has_access=False, denial_reason="User's groups are all disabled"
             )
 
         # Check each group's permissions in priority order
         for group in groups:
             for permission in group.tool_permissions:
@@ -134,31 +120,26 @@
                         f"by group {group.name} (priority {group.priority})"
                     )
                     return PermissionCheckResult(
                         has_access=True,
                         granted_by_group=group.name,
-                        granted_by_group_id=str(group.id)
+                        granted_by_group_id=str(group.id),
                     )
 
         logger.debug(f"User {central_user_id} denied access to {tool_name}: no matching permission")
         return PermissionCheckResult(
-            has_access=False,
-            denial_reason=f"No group grants access to tool '{tool_name}'"
-        )
-
-    async def get_user_allowed_tools(
-        self,
-        central_user_id: str
-    ) -> List[str]:
+            has_access=False, denial_reason=f"No group grants access to tool '{tool_name}'"
+        )
+
+    async def get_user_allowed_tools(self, central_user_id: str) -> List[str]:
         """Get all tools a user has access to based on their groups."""
         # Get user's active group memberships
         memberships_result = await self.db.execute(
-            select(GroupMembership)
-            .where(
+            select(GroupMembership).where(
                 and_(
                     GroupMembership.central_user_id == central_user_id,
-                    GroupMembership.enabled is True
+                    GroupMembership.enabled is True,
                 )
             )
         )
         memberships = memberships_result.scalars().all()
 
@@ -168,16 +149,11 @@
         # Get all groups with their permissions
         group_ids = [m.group_id for m in memberships]
         groups_result = await self.db.execute(
             select(Group)
             .options(selectinload(Group.tool_permissions))
-            .where(
-                and_(
-                    Group.id.in_(group_ids),
-                    Group.enabled is True
-                )
-            )
+            .where(and_(Group.id.in_(group_ids), Group.enabled is True))
         )
         groups = groups_result.scalars().all()
 
         # Collect all allowed tools
         allowed_tools = set()
@@ -197,46 +173,41 @@
             return ["*"]
 
         return list(allowed_tools)
 
     async def get_tool_groups(
-        self,
-        tool_name: str,
-        service_type: Optional[str] = None
+        self, tool_name: str, service_type: Optional[str] = None
     ) -> List[dict]:
         """Get all groups that have access to a specific tool."""
         # Get all groups with permissions for this tool
         result = await self.db.execute(
-            select(Group)
-            .options(selectinload(Group.tool_permissions))
-            .where(Group.enabled is True)
+            select(Group).options(selectinload(Group.tool_permissions)).where(Group.enabled is True)
         )
         groups = result.scalars().all()
 
         matching_groups = []
         for group in groups:
             for permission in group.tool_permissions:
                 if not permission.enabled:
                     continue
                 if permission.matches_tool(tool_name, service_type):
-                    matching_groups.append({
-                        "id": group.id,
-                        "name": group.name,
-                        "color": group.color,
-                        "icon": group.icon,
-                        "priority": group.priority,
-                        "is_wildcard": permission.tool_name == "*"
-                    })
+                    matching_groups.append(
+                        {
+                            "id": group.id,
+                            "name": group.name,
+                            "color": group.color,
+                            "icon": group.icon,
+                            "priority": group.priority,
+                            "is_wildcard": permission.tool_name == "*",
+                        }
+                    )
                     break  # Only add group once even if multiple permissions match
 
         return matching_groups
 
 
 async def check_tool_permission(
-    db: AsyncSession,
-    central_user_id: str,
-    tool_name: str,
-    service_type: Optional[str] = None
+    db: AsyncSession, central_user_id: str, tool_name: str, service_type: Optional[str] = None
 ) -> PermissionCheckResult:
     """Convenience function to check tool permission."""
     service = PermissionService(db)
     return await service.check_permission(central_user_id, tool_name, service_type)
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/permission_service.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_registry.py	2025-12-31 13:30:51.457007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_registry.py	2025-12-31 13:41:36.816583+00:00
@@ -72,14 +72,11 @@
     def has_adapter(self, service_type: str) -> bool:
         """Check if an adapter is available for the given service type."""
         return service_type.lower() in self._adapters
 
     async def create_adapter(
-        self,
-        service_config: ServiceConfig,
-        timeout: int = 30,
-        verify_ssl: bool = True
+        self, service_config: ServiceConfig, timeout: int = 30, verify_ssl: bool = True
     ) -> Optional[BaseServiceAdapter]:
         """Create and return an adapter instance for the given service config.
 
         Args:
             service_config: Service configuration to create adapter for
@@ -87,19 +84,19 @@
             verify_ssl: Whether to verify SSL certificates
 
         Returns:
             Adapter instance if successful, None if service type not supported
         """
-        adapter_class = self.get_adapter_class(service_config.service_type.value if hasattr(service_config.service_type, 'value') else service_config.service_type)
+        adapter_class = self.get_adapter_class(
+            service_config.service_type.value
+            if hasattr(service_config.service_type, "value")
+            else service_config.service_type
+        )
         if not adapter_class:
             return None
 
-        return adapter_class(
-            service_config=service_config,
-            timeout=timeout,
-            verify_ssl=verify_ssl
-        )
+        return adapter_class(service_config=service_config, timeout=timeout, verify_ssl=verify_ssl)
 
     async def get_service_capabilities(self, service_type: str) -> List[str]:
         """Get the capabilities supported by a service adapter.
 
         Args:
@@ -115,11 +112,11 @@
         # Create a temporary instance to get capabilities
         # Note: This is a bit of a hack since we need a ServiceConfig
         # In practice, capabilities should be class-level properties
         try:
             # Try to get capabilities without instantiating if possible
-            if hasattr(adapter_class, 'supported_capabilities'):
+            if hasattr(adapter_class, "supported_capabilities"):
                 capabilities = adapter_class.supported_capabilities
                 if callable(capabilities):
                     # It's a property or method, we need an instance
                     return []
                 else:
@@ -128,13 +125,11 @@
             return []
         except Exception:
             return []
 
     async def discover_services(
-        self,
-        db: AsyncSession,
-        service_type: Optional[str] = None
+        self, db: AsyncSession, service_type: Optional[str] = None
     ) -> List[ServiceConfig]:
         """Discover all configured services, optionally filtered by type.
 
         Args:
             db: Database session
@@ -162,15 +157,19 @@
         """
         services = await self.discover_services(db)
         results = {}
 
         for service in services:
-            service_type_str = service.service_type.value if hasattr(service.service_type, 'value') else service.service_type
+            service_type_str = (
+                service.service_type.value
+                if hasattr(service.service_type, "value")
+                else service.service_type
+            )
             if not self.has_adapter(service_type_str):
                 results[service.id] = {
                     "success": False,
-                    "error": f"No adapter available for service type: {service_type_str}"
+                    "error": f"No adapter available for service type: {service_type_str}",
                 }
                 continue
 
             try:
                 adapter = await self.create_adapter(service)
@@ -179,21 +178,18 @@
                         test_result = await adapter.test_connection()
                         results[service.id] = {
                             "success": test_result.success,
                             "message": test_result.message,
                             "response_time_ms": test_result.response_time_ms,
-                            "details": test_result.details
+                            "details": test_result.details,
                         }
                 else:
-                    results[service.id] = {
-                        "success": False,
-                        "error": "Failed to create adapter"
-                    }
+                    results[service.id] = {"success": False, "error": "Failed to create adapter"}
             except Exception as e:
                 results[service.id] = {
                     "success": False,
-                    "error": f"Exception during test: {str(e)}"
+                    "error": f"Exception during test: {str(e)}",
                 }
 
         return results
 
     async def get_service_statistics(self, db: AsyncSession) -> Dict[str, Any]:
@@ -210,30 +206,42 @@
             "total_services": len(services),
             "services_by_type": {},
             "active_services": 0,
             "inactive_services": 0,
             "error_services": 0,
-            "supported_service_types": self.get_available_service_types()
+            "supported_service_types": self.get_available_service_types(),
         }
 
         for service in services:
-            service_type = service.service_type.value if hasattr(service.service_type, 'value') else service.service_type
-            stats["services_by_type"][service_type] = stats["services_by_type"].get(service_type, 0) + 1
-
-            if service.status.value if hasattr(service.status, 'value') else service.status == "active":
+            service_type = (
+                service.service_type.value
+                if hasattr(service.service_type, "value")
+                else service.service_type
+            )
+            stats["services_by_type"][service_type] = (
+                stats["services_by_type"].get(service_type, 0) + 1
+            )
+
+            if (
+                service.status.value
+                if hasattr(service.status, "value")
+                else service.status == "active"
+            ):
                 stats["active_services"] += 1
-            elif service.status.value if hasattr(service.status, 'value') else service.status == "inactive":
+            elif (
+                service.status.value
+                if hasattr(service.status, "value")
+                else service.status == "inactive"
+            ):
                 stats["inactive_services"] += 1
             else:
                 stats["error_services"] += 1
 
         return stats
 
     async def auto_discover_services(
-        self,
-        network_range: Optional[str] = None,
-        common_ports: Optional[List[int]] = None
+        self, network_range: Optional[str] = None, common_ports: Optional[List[int]] = None
     ) -> List[Dict[str, Any]]:
         """Automatically discover services on the network.
 
         This is a placeholder for future implementation of network discovery.
 
@@ -251,16 +259,16 @@
 
         # Placeholder implementation
         if common_ports is None:
             common_ports = [
                 32400,  # Plex
-                8096,   # Jellyfin
-                5055,   # Overseerr
-                8181,   # Tautulli
-                8080,   # Various services
-                443,    # HTTPS
-                80      # HTTP
+                8096,  # Jellyfin
+                5055,  # Overseerr
+                8181,  # Tautulli
+                8080,  # Various services
+                443,  # HTTPS
+                80,  # HTTP
             ]
 
         # In a real implementation, this would:
         # 1. Scan the network range for open ports
         # 2. Attempt to identify services by their responses
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_registry.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_tester.py	2025-12-31 13:30:51.479007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_tester.py	2025-12-31 13:41:36.886989+00:00
@@ -45,11 +45,11 @@
         "jackett": JackettAdapter,
         "deluge": DelugeAdapter,
         "komga": KomgaAdapter,
         "romm": RommAdapter,
         "audiobookshelf": AudiobookshelfAdapter,
-        "wikijs": WikiJSAdapter
+        "wikijs": WikiJSAdapter,
     }
 
     @classmethod
     def get_adapter_for_service(cls, service_config: ServiceConfig) -> Optional[BaseServiceAdapter]:
         """Get the appropriate adapter for a service configuration."""
@@ -64,24 +64,24 @@
             logger.error(f"Failed to create adapter for service {service_config.id}: {e}")
             return None
 
     @classmethod
     async def test_service_connection(
-        cls,
-        service_config: ServiceConfig,
-        db_session: Optional[AsyncSession] = None
+        cls, service_config: ServiceConfig, db_session: Optional[AsyncSession] = None
     ) -> ConnectionTestResult:
         """Test connection to a service using its adapter."""
-        logger.info(f"Testing connection to service: {service_config.name} ({service_config.service_type})")
+        logger.info(
+            f"Testing connection to service: {service_config.name} ({service_config.service_type})"
+        )
 
         # Get the appropriate adapter
         adapter = cls.get_adapter_for_service(service_config)
         if not adapter:
             return ConnectionTestResult(
                 success=False,
                 message=f"No adapter available for service type: {service_config.service_type}",
-                details={"error": "unsupported_service_type"}
+                details={"error": "unsupported_service_type"},
             )
 
         try:
             # Test the connection using the adapter
             async with adapter:
@@ -89,20 +89,19 @@
 
             # Update service with test results if database session is provided
             if db_session:
                 try:
                     service_config.update_test_result(
-                        success=result.success,
-                        error=result.message if not result.success else None
+                        success=result.success, error=result.message if not result.success else None
                     )
 
                     # Store health history record
                     health_record = ServiceHealthHistory(
                         service_id=service_config.id,
                         success=result.success,
                         response_time_ms=result.response_time_ms,
-                        error_message=result.message if not result.success else None
+                        error_message=result.message if not result.success else None,
                     )
                     db_session.add(health_record)
 
                     await db_session.commit()
                     logger.info(f"Updated test results for service {service_config.name}")
@@ -120,11 +119,11 @@
             logger.error(f"Error testing service {service_config.name}: {e}")
 
             error_result = ConnectionTestResult(
                 success=False,
                 message=f"Test failed with error: {str(e)}",
-                details={"error": "test_exception", "exception": str(e)}
+                details={"error": "test_exception", "exception": str(e)},
             )
 
             # Update service with error if database session is provided
             if db_session:
                 try:
@@ -133,11 +132,11 @@
                     # Store health history record for error
                     health_record = ServiceHealthHistory(
                         service_id=service_config.id,
                         success=False,
                         response_time_ms=None,
-                        error_message=str(e)
+                        error_message=str(e),
                     )
                     db_session.add(health_record)
 
                     await db_session.commit()
                 except Exception as db_error:
@@ -175,11 +174,11 @@
             return {"error": "No adapter available"}
 
         try:
             async with adapter:
                 # Check if adapter has statistics method
-                if hasattr(adapter, 'get_statistics'):
+                if hasattr(adapter, "get_statistics"):
                     stats = await adapter.get_statistics()
                     logger.info(f"Retrieved statistics for {service_config.name}")
                     return stats
                 else:
                     return {"error": "Statistics not supported for this service type"}
@@ -195,11 +194,11 @@
 
         adapter = cls.get_adapter_for_service(service_config)
         if not adapter:
             return {
                 "valid": False,
-                "errors": [f"No adapter available for service type: {service_config.service_type}"]
+                "errors": [f"No adapter available for service type: {service_config.service_type}"],
             }
 
         try:
             errors = adapter.validate_config()
             is_valid = len(errors) == 0
@@ -211,46 +210,47 @@
 
             return {
                 "valid": is_valid,
                 "errors": errors,
                 "service_type": adapter.service_type,
-                "supported_capabilities": [cap.value for cap in adapter.supported_capabilities]
+                "supported_capabilities": [cap.value for cap in adapter.supported_capabilities],
             }
 
         except Exception as e:
             logger.error(f"Error validating configuration for {service_config.name}: {e}")
-            return {
-                "valid": False,
-                "errors": [f"Validation failed: {str(e)}"]
-            }
+            return {"valid": False, "errors": [f"Validation failed: {str(e)}"]}
 
     @classmethod
     def get_supported_service_types(cls) -> Dict[str, Dict[str, Any]]:
         """Get information about all supported service types."""
         supported_types = {}
 
         for service_type, adapter_class in cls.ADAPTER_REGISTRY.items():
             try:
                 # Create a dummy service config to get adapter info
-                dummy_config = type('DummyConfig', (), {
-                    'service_type': service_type,
-                    'base_url': 'http://example.com',
-                    'get_config_value': lambda self, key, default=None: default
-                })()
+                dummy_config = type(
+                    "DummyConfig",
+                    (),
+                    {
+                        "service_type": service_type,
+                        "base_url": "http://example.com",
+                        "get_config_value": lambda self, key, default=None: default,
+                    },
+                )()
 
                 adapter = adapter_class(dummy_config)
 
                 supported_types[service_type] = {
                     "name": service_type.title(),
                     "capabilities": [cap.value for cap in adapter.supported_capabilities],
-                    "description": f"{service_type.title()} service adapter"
+                    "description": f"{service_type.title()} service adapter",
                 }
 
             except Exception as e:
                 logger.warning(f"Error getting info for service type {service_type}: {e}")
                 supported_types[service_type] = {
                     "name": service_type.title(),
                     "capabilities": [],
-                    "description": f"{service_type.title()} service adapter (error loading)"
+                    "description": f"{service_type.title()} service adapter (error loading)",
                 }
 
         return supported_types
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/service_tester.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/system_monitor.py	2025-12-31 13:30:51.513007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/system_monitor.py	2025-12-31 13:41:36.914161+00:00
@@ -9,10 +9,11 @@
 import psutil
 from loguru import logger
 
 try:
     import docker
+
     DOCKER_AVAILABLE = True
 except ImportError:
     DOCKER_AVAILABLE = False
     logger.warning("Docker library not available, Docker monitoring disabled")
 
@@ -39,11 +40,11 @@
             memory_used_mb = int(memory.used / 1024 / 1024)
             memory_total_mb = int(memory.total / 1024 / 1024)
             memory_percent = memory.percent
 
             # Disk usage
-            disk = psutil.disk_usage('/')
+            disk = psutil.disk_usage("/")
             disk_used_gb = round(disk.used / 1024 / 1024 / 1024, 2)
             disk_total_gb = round(disk.total / 1024 / 1024 / 1024, 2)
             disk_percent = round((disk.used / disk.total) * 100, 1)
 
             # System uptime
@@ -99,13 +100,13 @@
         try:
             containers = self.docker_client.containers.list(all=True)
             images = self.docker_client.images.list()
             volumes = self.docker_client.volumes.list()
 
-            running = sum(1 for c in containers if c.status == 'running')
-            stopped = sum(1 for c in containers if c.status in ['exited', 'stopped'])
-            paused = sum(1 for c in containers if c.status == 'paused')
+            running = sum(1 for c in containers if c.status == "running")
+            stopped = sum(1 for c in containers if c.status in ["exited", "stopped"])
+            paused = sum(1 for c in containers if c.status == "paused")
 
             return {
                 "containers_running": running,
                 "containers_stopped": stopped,
                 "containers_paused": paused,
@@ -125,34 +126,33 @@
 
     async def get_process_list(self, limit: int = 10) -> List[Dict[str, Any]]:
         """Get list of running processes."""
         try:
             processes = []
-            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
+            for proc in psutil.process_iter(["pid", "name", "cpu_percent", "memory_percent"]):
                 try:
-                    processes.append({
-                        "pid": proc.info['pid'],
-                        "name": proc.info['name'],
-                        "cpu_percent": proc.info['cpu_percent'] or 0,
-                        "memory_percent": proc.info['memory_percent'] or 0,
-                    })
+                    processes.append(
+                        {
+                            "pid": proc.info["pid"],
+                            "name": proc.info["name"],
+                            "cpu_percent": proc.info["cpu_percent"] or 0,
+                            "memory_percent": proc.info["memory_percent"] or 0,
+                        }
+                    )
                 except (psutil.NoSuchProcess, psutil.AccessDenied):
                     continue
 
             # Sort by CPU usage and return top N
-            processes.sort(key=lambda x: x['cpu_percent'], reverse=True)
+            processes.sort(key=lambda x: x["cpu_percent"], reverse=True)
             return processes[:limit]
 
         except Exception as e:
             logger.error(f"Failed to get process list: {e}")
             return []
 
     async def get_metrics_history(
-        self,
-        start_time: datetime,
-        end_time: datetime,
-        interval_seconds: int = 60
+        self, start_time: datetime, end_time: datetime, interval_seconds: int = 60
     ) -> Dict[str, List[float]]:
         """Get historical metrics data (mock implementation for now)."""
         # For now, generate realistic mock data
         # In a real implementation, this would query the database
 
@@ -199,13 +199,11 @@
             **docker_status,
             "collected_at": datetime.utcnow().isoformat(),
         }
 
     async def start_metrics_collection(
-        self,
-        interval_seconds: int = 60,
-        callback: Optional[callable] = None
+        self, interval_seconds: int = 60, callback: Optional[callable] = None
     ):
         """Start background metrics collection."""
         logger.info(f"Starting metrics collection with {interval_seconds}s interval")
 
         while True:
@@ -220,11 +218,11 @@
                     extra={
                         "component": "system_monitor",
                         "action": "metrics_collected",
                         "cpu_percent": metrics.get("cpu_percent"),
                         "memory_percent": metrics.get("memory_percent"),
-                    }
+                    },
                 )
 
             except Exception as e:
                 logger.error(f"Error collecting metrics: {e}")
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/system_monitor.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/training.py	2025-12-31 13:30:51.591007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/training.py	2025-12-31 13:41:37.011601+00:00
@@ -58,10 +58,11 @@
 router = APIRouter(prefix="/api/training", tags=["training"])
 
 
 # ============= Pydantic Schemas =============
 
+
 class OllamaModelResponse(BaseModel):
     name: str
     model: str
     size: int
     size_gb: float
@@ -86,17 +87,21 @@
 class TrainingSessionCreate(BaseModel):
     name: str = Field(..., min_length=1, max_length=200)
     description: Optional[str] = None
     base_model: str = Field(..., min_length=1, max_length=100)
     training_type: TrainingType = TrainingType.FINE_TUNE
-    training_backend: str = Field(default="ollama_modelfile", description="Training backend: ollama_modelfile or unsloth")
+    training_backend: str = Field(
+        default="ollama_modelfile", description="Training backend: ollama_modelfile or unsloth"
+    )
     worker_id: Optional[str] = Field(default=None, description="Training worker ID")
     total_epochs: int = Field(default=1, ge=1, le=100)
     hyperparameters: dict = Field(default_factory=dict)
     ollama_service_id: Optional[str] = None
     # For incremental training: path to existing LoRA adapter on the worker
-    base_adapter_path: Optional[str] = Field(default=None, description="Path to existing LoRA adapter for incremental training")
+    base_adapter_path: Optional[str] = Field(
+        default=None, description="Path to existing LoRA adapter for incremental training"
+    )
 
 
 class TrainingSessionUpdate(BaseModel):
     name: Optional[str] = Field(None, min_length=1, max_length=200)
     description: Optional[str] = None
@@ -142,15 +147,23 @@
     difficulty: PromptDifficulty = PromptDifficulty.BASIC
     format: PromptFormat = PromptFormat.CHAT
     system_prompt: Optional[str] = None
     user_input: str
     # Tool calling support
-    tool_call: Optional[dict] = Field(default=None, description="Expected tool call: {'name': 'tool_name', 'arguments': {...}}")
-    tool_response: Optional[dict] = Field(default=None, description="Example tool response (realistic mock data)")
-    assistant_response: Optional[str] = Field(default=None, description="Final assistant response after processing tool results")
+    tool_call: Optional[dict] = Field(
+        default=None, description="Expected tool call: {'name': 'tool_name', 'arguments': {...}}"
+    )
+    tool_response: Optional[dict] = Field(
+        default=None, description="Example tool response (realistic mock data)"
+    )
+    assistant_response: Optional[str] = Field(
+        default=None, description="Final assistant response after processing tool results"
+    )
     # DEPRECATED - use assistant_response instead
-    expected_output: str = Field(default="", description="DEPRECATED: use assistant_response instead")
+    expected_output: str = Field(
+        default="", description="DEPRECATED: use assistant_response instead"
+    )
     tags: List[str] = Field(default_factory=list)
     session_id: Optional[str] = None
 
 
 class TrainingPromptUpdate(BaseModel):
@@ -208,30 +221,30 @@
     recent_sessions: List[TrainingSessionResponse]
 
 
 # ============= Ollama Endpoints =============
 
+
 @router.get("/ollama/status", response_model=OllamaStatusResponse)
 async def get_ollama_status(
-    service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    service_id: Optional[str] = None, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Ollama server status and available models."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         return OllamaStatusResponse(
             status="not_configured",
             url="",
-            error="No Ollama service configured. Add an Ollama service in Settings."
+            error="No Ollama service configured. Add an Ollama service in Settings.",
         )
 
     health = await ollama.health_check()
     response = OllamaStatusResponse(
         status=health.get("status", "unknown"),
         version=health.get("version"),
         url=health.get("url", ""),
-        error=health.get("error")
+        error=health.get("error"),
     )
 
     if health.get("status") == "healthy":
         try:
             models = await ollama.list_models()
@@ -242,11 +255,11 @@
                     size=m.size,
                     size_gb=m.size_gb,
                     family=m.family,
                     parameter_size=m.parameter_size,
                     quantization_level=m.quantization_level,
-                    modified_at=m.modified_at
+                    modified_at=m.modified_at,
                 )
                 for m in models
             ]
             response.model_count = len(models)
             response.total_size_gb = sum(m.size_gb for m in models)
@@ -260,12 +273,11 @@
     return response
 
 
 @router.get("/ollama/models")
 async def list_ollama_models(
-    service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    service_id: Optional[str] = None, session: AsyncSession = Depends(get_db_session)
 ):
     """List all available Ollama models."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         raise HTTPException(status_code=404, detail="No Ollama service configured")
@@ -281,11 +293,11 @@
 
 @router.get("/ollama/models/{model_name}")
 async def get_ollama_model_info(
     model_name: str,
     service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get detailed information about a specific model."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         raise HTTPException(status_code=404, detail="No Ollama service configured")
@@ -299,11 +311,11 @@
 
 @router.delete("/ollama/models/{model_name}")
 async def delete_ollama_model(
     model_name: str,
     service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Delete an Ollama model."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         raise HTTPException(status_code=404, detail="No Ollama service configured")
@@ -319,11 +331,11 @@
 
 @router.post("/ollama/models/{model_name}/load")
 async def load_ollama_model(
     model_name: str,
     service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Load an Ollama model into memory (warm it up)."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         raise HTTPException(status_code=404, detail="No Ollama service configured")
@@ -339,11 +351,11 @@
 
 @router.post("/ollama/models/{model_name}/unload")
 async def unload_ollama_model(
     model_name: str,
     service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Unload an Ollama model from memory."""
     ollama = await get_ollama_service(session, service_id)
     if not ollama:
         raise HTTPException(status_code=404, detail="No Ollama service configured")
@@ -357,16 +369,17 @@
         raise HTTPException(status_code=500, detail=str(e))
 
 
 # ============= Training Session Endpoints =============
 
+
 @router.get("/sessions", response_model=List[TrainingSessionResponse])
 async def list_training_sessions(
     status: Optional[str] = None,
     skip: int = Query(0, ge=0),
     limit: int = Query(50, ge=1, le=100),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """List all training sessions."""
     query = select(TrainingSession)
 
     if status:
@@ -379,12 +392,11 @@
     return sessions
 
 
 @router.post("/sessions", response_model=TrainingSessionResponse)
 async def create_training_session(
-    data: TrainingSessionCreate,
-    session: AsyncSession = Depends(get_db_session)
+    data: TrainingSessionCreate, session: AsyncSession = Depends(get_db_session)
 ):
     """Create a new training session."""
     # Session starts with 0 prompts - user must add them
     # Store base_adapter_path in hyperparameters for incremental training
     hyperparams = data.hyperparameters.copy() if data.hyperparameters else {}
@@ -402,42 +414,34 @@
         total_epochs=data.total_epochs,
         hyperparameters=hyperparams,
         ollama_service_id=data.ollama_service_id,
         dataset_size=0,
         created_at=datetime.utcnow(),
-        updated_at=datetime.utcnow()
+        updated_at=datetime.utcnow(),
     )
 
     session.add(training_session)
     await session.commit()
     await session.refresh(training_session)
 
     return training_session
 
 
 @router.get("/sessions/{session_id}", response_model=TrainingSessionResponse)
-async def get_training_session(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_training_session(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get a specific training session."""
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     return training_session
 
 
 @router.get("/sessions/{session_id}/summary")
-async def get_session_summary(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_session_summary(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get comprehensive summary and metrics for a training session.
 
     Returns detailed information including:
     - Basic session info (name, status, models)
     - Timing (duration, start/end times)
@@ -465,11 +469,11 @@
     summary["prompts_count"] = len(training_session.prompts)
     summary["prompts"] = [
         {
             "id": p.id,
             "name": p.name,
-            "category": p.category.value if hasattr(p.category, 'value') else p.category,
+            "category": p.category.value if hasattr(p.category, "value") else p.category,
         }
         for p in training_session.prompts[:10]  # Limit to first 10
     ]
 
     # Add hyperparameters
@@ -487,106 +491,92 @@
 
     return summary
 
 
 @router.get("/sessions/{session_id}/logs")
-async def get_session_logs(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_session_logs(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get training logs for a session.
 
     For active sessions, fetches logs from the worker.
     For completed sessions, returns stored logs from the database.
     """
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     # If session is completed and has stored logs, return them
     if training_session.training_logs and training_session.status in [
-        TrainingStatus.COMPLETED, TrainingStatus.FAILED, TrainingStatus.CANCELLED
+        TrainingStatus.COMPLETED,
+        TrainingStatus.FAILED,
+        TrainingStatus.CANCELLED,
     ]:
         return {
             "session_id": session_id,
             "logs": training_session.training_logs,
-            "source": "stored"
+            "source": "stored",
         }
 
     # Try to fetch logs from worker for active sessions
     if training_session.worker_id:
         from src.models import TrainingWorker
+
         worker_result = await session.execute(
             select(TrainingWorker).where(TrainingWorker.id == training_session.worker_id)
         )
         worker = worker_result.scalar_one_or_none()
 
         if worker and worker.url:
             import httpx
+
             try:
                 # Get the job_id from hyperparameters if stored there
                 job_id = training_session.hyperparameters.get("job_id")
                 if job_id:
                     async with httpx.AsyncClient(timeout=30.0) as client:
                         response = await client.get(f"{worker.url}/api/logs/job/{job_id}")
                         if response.status_code == 200:
                             data = response.json()
                             logs = "\n".join(data.get("logs", []))
-                            return {
-                                "session_id": session_id,
-                                "logs": logs,
-                                "source": "worker"
-                            }
+                            return {"session_id": session_id, "logs": logs, "source": "worker"}
 
                 # Fallback to recent logs
                 async with httpx.AsyncClient(timeout=30.0) as client:
                     response = await client.get(f"{worker.url}/api/logs/recent?count=500")
                     if response.status_code == 200:
                         data = response.json()
-                        logs = "\n".join([
-                            f"[{log.get('timestamp', '')}] [{log.get('level', '')}] {log.get('message', '')}"
-                            for log in data
-                        ])
-                        return {
-                            "session_id": session_id,
-                            "logs": logs,
-                            "source": "worker_recent"
-                        }
+                        logs = "\n".join(
+                            [
+                                f"[{log.get('timestamp', '')}] [{log.get('level', '')}] {log.get('message', '')}"
+                                for log in data
+                            ]
+                        )
+                        return {"session_id": session_id, "logs": logs, "source": "worker_recent"}
             except Exception as e:
                 logger.warning(f"Failed to fetch logs from worker: {e}")
 
     return {
         "session_id": session_id,
         "logs": training_session.training_logs or "Aucun log disponible",
-        "source": "none"
+        "source": "none",
     }
 
 
 @router.patch("/sessions/{session_id}", response_model=TrainingSessionResponse)
 async def update_training_session(
-    session_id: str,
-    data: TrainingSessionUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    session_id: str, data: TrainingSessionUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Update a training session."""
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status in [TrainingStatus.RUNNING, TrainingStatus.PREPARING]:
-        raise HTTPException(
-            status_code=400,
-            detail="Cannot update a running training session"
-        )
+        raise HTTPException(status_code=400, detail="Cannot update a running training session")
 
     update_data = data.model_dump(exclude_unset=True)
     for key, value in update_data.items():
         setattr(training_session, key, value)
 
@@ -596,40 +586,31 @@
 
     return training_session
 
 
 @router.delete("/sessions/{session_id}")
-async def delete_training_session(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def delete_training_session(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Delete a training session."""
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status in [TrainingStatus.RUNNING, TrainingStatus.PREPARING]:
         raise HTTPException(
-            status_code=400,
-            detail="Cannot delete a running training session. Cancel it first."
+            status_code=400, detail="Cannot delete a running training session. Cancel it first."
         )
 
     await session.delete(training_session)
     await session.commit()
 
     return {"message": "Training session deleted"}
 
 
 async def run_ollama_training_background(
-    session_id: str,
-    prompts_data: List[dict],
-    config: OllamaModelfileConfig,
-    ollama_url: str
+    session_id: str, prompts_data: List[dict], config: OllamaModelfileConfig, ollama_url: str
 ):
     """Background task to create Ollama model via Modelfile."""
     global _training_service
     from loguru import logger
 
@@ -665,13 +646,11 @@
                 training_session.updated_at = datetime.utcnow()
                 await db_session.commit()
 
         # Create Ollama model
         result = await _training_service.create_ollama_model(
-            prompts=prompts_data,
-            config=config,
-            progress_callback=update_progress
+            prompts=prompts_data, config=config, progress_callback=update_progress
         )
 
         # Update final status
         async with async_session_maker() as db_session:
             result_db = await db_session.execute(
@@ -706,11 +685,13 @@
                 training_session.completed_at = datetime.utcnow()
                 training_session.updated_at = datetime.utcnow()
                 await db_session.commit()
 
 
-async def run_training_background(session_id: str, prompts_data: List[dict], config: TrainingConfig):
+async def run_training_background(
+    session_id: str, prompts_data: List[dict], config: TrainingConfig
+):
     """Background task to run the actual Unsloth fine-tuning (requires GPU)."""
     global _training_service
     from loguru import logger
 
     if not _training_service:
@@ -746,11 +727,11 @@
 
         # Run training
         result = await _training_service.start_training(
             prompts=prompts_data,
             config=config,
-            progress_callback=lambda p: asyncio.create_task(update_progress(p))
+            progress_callback=lambda p: asyncio.create_task(update_progress(p)),
         )
 
         # Update final status
         async with async_session_maker() as db_session:
             result_db = await db_session.execute(
@@ -822,11 +803,13 @@
                 training_session = result.scalar_one_or_none()
                 if training_session:
                     training_session.training_logs = logs_text
                     training_session.updated_at = datetime.utcnow()
                     await db_session.commit()
-                    logger.info(f"Saved {len(formatted_logs) if isinstance(logs_list, list) else 1} log entries to session {session_id}")
+                    logger.info(
+                        f"Saved {len(formatted_logs) if isinstance(logs_list, list) else 1} log entries to session {session_id}"
+                    )
         else:
             logger.warning(f"No logs found for job {job_id}")
     except Exception as e:
         logger.error(f"Failed to fetch and save logs for session {session_id}: {e}")
 
@@ -901,35 +884,53 @@
                 # Add to metrics history for summary analysis
                 if training_session.metrics_history is None:
                     training_session.metrics_history = []
 
                 # If worker has more loss_history data than our metrics_history, sync from worker
-                if job_status.loss_history and len(job_status.loss_history) > len(training_session.metrics_history):
-                    logger.info(f"Syncing metrics_history from worker loss_history ({len(job_status.loss_history)} points, was {len(training_session.metrics_history)})")
+                if job_status.loss_history and len(job_status.loss_history) > len(
+                    training_session.metrics_history
+                ):
+                    logger.info(
+                        f"Syncing metrics_history from worker loss_history ({len(job_status.loss_history)} points, was {len(training_session.metrics_history)})"
+                    )
                     training_session.metrics_history = []
                     for i, loss_val in enumerate(job_status.loss_history):
-                        training_session.metrics_history.append({
-                            "timestamp": datetime.utcnow().isoformat(),
-                            "step": i + 1,
-                            "epoch": (i * job_status.total_epochs) // len(job_status.loss_history) + 1 if job_status.loss_history else 0,
-                            "loss": loss_val,
-                            "learning_rate": job_status.learning_rate,
-                        })
+                        training_session.metrics_history.append(
+                            {
+                                "timestamp": datetime.utcnow().isoformat(),
+                                "step": i + 1,
+                                "epoch": (i * job_status.total_epochs)
+                                // len(job_status.loss_history)
+                                + 1
+                                if job_status.loss_history
+                                else 0,
+                                "loss": loss_val,
+                                "learning_rate": job_status.learning_rate,
+                            }
+                        )
                 elif job_status.loss is not None:
                     # Only add if we have a new step (avoid duplicates)
-                    last_step = training_session.metrics_history[-1].get("step") if training_session.metrics_history else -1
+                    last_step = (
+                        training_session.metrics_history[-1].get("step")
+                        if training_session.metrics_history
+                        else -1
+                    )
                     if job_status.current_step > last_step:
-                        training_session.metrics_history.append({
-                            "timestamp": datetime.utcnow().isoformat(),
-                            "step": job_status.current_step,
-                            "epoch": job_status.current_epoch,
-                            "loss": job_status.loss,
-                            "learning_rate": job_status.learning_rate,
-                        })
+                        training_session.metrics_history.append(
+                            {
+                                "timestamp": datetime.utcnow().isoformat(),
+                                "step": job_status.current_step,
+                                "epoch": job_status.current_epoch,
+                                "loss": job_status.loss,
+                                "learning_rate": job_status.learning_rate,
+                            }
+                        )
                         # Keep last 1000 entries
                         if len(training_session.metrics_history) > 1000:
-                            training_session.metrics_history = training_session.metrics_history[-1000:]
+                            training_session.metrics_history = training_session.metrics_history[
+                                -1000:
+                            ]
 
                 training_session.updated_at = datetime.utcnow()
                 await db_session.commit()
 
                 # Calculate metrics from history for WebSocket broadcast
@@ -939,11 +940,15 @@
                 best_loss_epoch = job_status.current_epoch
                 loss_trend = "stable"
                 loss_improvement_rate = 0.0
 
                 if training_session.metrics_history:
-                    loss_history = [m.get("loss") for m in training_session.metrics_history if m.get("loss") is not None]
+                    loss_history = [
+                        m.get("loss")
+                        for m in training_session.metrics_history
+                        if m.get("loss") is not None
+                    ]
 
                     if loss_history:
                         # Find best (minimum) loss
                         best_loss = min(loss_history)
                         for m in training_session.metrics_history:
@@ -954,12 +959,12 @@
 
                         # Calculate loss trend (use more values and lower threshold for fine-tuning)
                         if len(loss_history) >= 3:
                             # Use up to last 10 values for better trend detection
                             recent = loss_history[-10:] if len(loss_history) >= 10 else loss_history
-                            first_half = recent[:len(recent)//2]
-                            second_half = recent[len(recent)//2:]
+                            first_half = recent[: len(recent) // 2]
+                            second_half = recent[len(recent) // 2 :]
 
                             if first_half and second_half:
                                 avg_first = sum(first_half) / len(first_half)
                                 avg_second = sum(second_half) / len(second_half)
 
@@ -971,11 +976,13 @@
                                 else:
                                     loss_trend = "stable"
 
                         # Calculate improvement rate
                         if len(loss_history) >= 2 and loss_history[0] > 0:
-                            loss_improvement_rate = (loss_history[0] - loss_history[-1]) / loss_history[0] * 100
+                            loss_improvement_rate = (
+                                (loss_history[0] - loss_history[-1]) / loss_history[0] * 100
+                            )
 
                 # Determine training health based on trend
                 training_health = "good"
                 health_message = f"Phase: {worker_status}"
                 if loss_trend == "decreasing":
@@ -1023,15 +1030,22 @@
                         "accuracy": None,
                         "entropy": None,
                     },
                     "gpu": gpu_data,
                     "time": {
-                        "elapsed_seconds": (datetime.utcnow() - training_session.started_at).total_seconds() if training_session.started_at else 0,
+                        "elapsed_seconds": (
+                            datetime.utcnow() - training_session.started_at
+                        ).total_seconds()
+                        if training_session.started_at
+                        else 0,
                         "eta_seconds": job_status.eta_seconds,
                         "samples_per_second": job_status.samples_per_second,
-                        "tokens_per_second": job_status.samples_per_second * 512,  # Estimate: ~512 tokens per sample average
-                        "step_duration_ms": (1000 / job_status.samples_per_second) if job_status.samples_per_second > 0 else 0,
+                        "tokens_per_second": job_status.samples_per_second
+                        * 512,  # Estimate: ~512 tokens per sample average
+                        "step_duration_ms": (1000 / job_status.samples_per_second)
+                        if job_status.samples_per_second > 0
+                        else 0,
                     },
                     "quality": {
                         "loss_trend": loss_trend,
                         "loss_improvement_rate": loss_improvement_rate,
                         "training_health": training_health,
@@ -1048,17 +1062,19 @@
                     },
                     # Add current phase for UI display
                     "phase": worker_status,
                 }
 
-                await connection_manager.broadcast_to_frontend({
-                    "type": "session_update",
-                    "session_id": session_id,
-                    "update_type": update_type,
-                    "data": ws_data,
-                    "timestamp": datetime.utcnow().isoformat(),
-                })
+                await connection_manager.broadcast_to_frontend(
+                    {
+                        "type": "session_update",
+                        "session_id": session_id,
+                        "update_type": update_type,
+                        "data": ws_data,
+                        "timestamp": datetime.utcnow().isoformat(),
+                    }
+                )
 
                 logger.debug(
                     f"Session {session_id}: {worker_status} - "
                     f"Step {job_status.current_step}/{job_status.total_steps} - "
                     f"{job_status.progress_percent:.1f}%"
@@ -1089,11 +1105,14 @@
         async with async_session_maker() as db_session:
             result = await db_session.execute(
                 select(TrainingSession).where(TrainingSession.id == session_id)
             )
             training_session = result.scalar_one_or_none()
-            if training_session and training_session.status in [TrainingStatus.RUNNING, TrainingStatus.PREPARING]:
+            if training_session and training_session.status in [
+                TrainingStatus.RUNNING,
+                TrainingStatus.PREPARING,
+            ]:
                 training_session.status = TrainingStatus.FAILED
                 training_session.error_message = f"Lost connection to training worker: {e}"
                 training_session.completed_at = datetime.utcnow()
                 training_session.updated_at = datetime.utcnow()
                 await db_session.commit()
@@ -1108,11 +1127,11 @@
     prompts_data: List[dict],
     base_model: str,
     output_model_name: str,
     ollama_url: str,
     hyperparams: dict,
-    total_epochs: int
+    total_epochs: int,
 ):
     """Start training on remote GPU worker and begin polling."""
     from loguru import logger
 
     worker_client = get_worker_client()
@@ -1142,11 +1161,11 @@
         max_seq_length=hyperparams.get("max_seq_length", 2048),
         lora_r=hyperparams.get("lora_r", 16),
         lora_alpha=hyperparams.get("lora_alpha", 16),
         quantization_method=hyperparams.get("quantization_method", "q4_k_m"),
         overwrite_existing=hyperparams.get("overwrite_existing", False),
-        base_adapter_path=hyperparams.get("base_adapter_path")  # For incremental training
+        base_adapter_path=hyperparams.get("base_adapter_path"),  # For incremental training
     )
 
     if not result.get("success"):
         # Mark as failed
         async with async_session_maker() as db_session:
@@ -1154,11 +1173,13 @@
                 select(TrainingSession).where(TrainingSession.id == session_id)
             )
             training_session = result_db.scalar_one_or_none()
             if training_session:
                 training_session.status = TrainingStatus.FAILED
-                training_session.error_message = result.get("error", "Failed to start training on worker")
+                training_session.error_message = result.get(
+                    "error", "Failed to start training on worker"
+                )
                 training_session.completed_at = datetime.utcnow()
                 training_session.updated_at = datetime.utcnow()
                 await db_session.commit()
         logger.error(f"Failed to start training on worker: {result.get('error')}")
         return
@@ -1185,35 +1206,31 @@
 
 @router.post("/sessions/{session_id}/start")
 async def start_training_session(
     session_id: str,
     background_tasks: BackgroundTasks = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Start a training session.
 
     The backend is determined by the session's training_backend field:
     - ollama_modelfile: Creates an Ollama model with embedded examples (no GPU needed)
     - unsloth / gpu_worker: Real fine-tuning with Unsloth (GPU required on worker)
     """
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status != TrainingStatus.PENDING:
         raise HTTPException(
-            status_code=400,
-            detail=f"Cannot start session with status {training_session.status}"
+            status_code=400, detail=f"Cannot start session with status {training_session.status}"
         )
 
     # Get prompts for this session (many-to-many via association table)
     from sqlalchemy.orm import selectinload
-
 
     # Reload session with prompts
     result_with_prompts = await session.execute(
         select(TrainingSession)
         .options(selectinload(TrainingSession.prompts))
@@ -1221,21 +1238,18 @@
     )
     training_session = result_with_prompts.scalar_one_or_none()
     prompts = training_session.prompts if training_session else []
 
     if not prompts:
-        raise HTTPException(
-            status_code=400,
-            detail="No prompts associated with this session"
-        )
+        raise HTTPException(status_code=400, detail="No prompts associated with this session")
 
     # Prepare prompts data
     prompts_data = [
         {
             "system_prompt": p.system_prompt,
             "user_input": p.user_input,
-            "expected_output": p.expected_output
+            "expected_output": p.expected_output,
         }
         for p in prompts
     ]
 
     # Mark prompts as used (increment usage counter)
@@ -1253,14 +1267,13 @@
         if service and service.full_url:
             ollama_url = service.full_url.rstrip("/")
     else:
         # Try to find any Ollama service
         service_result = await session.execute(
-            select(ServiceConfig).where(
-                ServiceConfig.service_type == ServiceType.OLLAMA,
-                ServiceConfig.enabled is True
-            ).limit(1)
+            select(ServiceConfig)
+            .where(ServiceConfig.service_type == ServiceType.OLLAMA, ServiceConfig.enabled is True)
+            .limit(1)
         )
         service = service_result.scalar_one_or_none()
         if service and service.full_url:
             ollama_url = service.full_url.rstrip("/")
 
@@ -1295,27 +1308,23 @@
 
         await session.commit()
 
         # Start Ollama training in background
         background_tasks.add_task(
-            run_ollama_training_background,
-            session_id,
-            prompts_data,
-            config,
-            ollama_url
+            run_ollama_training_background, session_id, prompts_data, config, ollama_url
         )
 
         return {
             "message": "Creating Ollama model with embedded examples",
             "session_id": session_id,
             "backend": "ollama_modelfile",
             "prompts_count": len(prompts),
             "config": {
                 "base_model": config.base_model,
                 "output_model": config.output_model_name,
-                "ollama_url": ollama_url
-            }
+                "ollama_url": ollama_url,
+            },
         }
 
     elif backend in ("unsloth", "gpu_worker"):
         # Unsloth fine-tuning on remote GPU worker
         settings = get_settings()
@@ -1326,11 +1335,11 @@
 
         if not worker_status.online:
             raise HTTPException(
                 status_code=503,
                 detail=f"Training worker not available: {worker_status.error or 'Connection failed'}. "
-                       f"Check that the worker is running at {settings.training_worker_url}"
+                f"Check that the worker is running at {settings.training_worker_url}",
             )
 
         # Prepare model name for Unsloth (convert ollama format to unsloth)
         # e.g., "llama3.2:3b" -> "unsloth/llama-3.2-3b-instruct-bnb-4bit"
         base_model_raw = training_session.base_model.lower()
@@ -1348,11 +1357,13 @@
                 "qwen2.5:3b": "unsloth/Qwen2.5-3B-Instruct-bnb-4bit",
                 "qwen2.5:7b": "unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
             }
             base_model = unsloth_model_map.get(
                 base_model_raw,
-                hyperparams.get("unsloth_model", f"unsloth/{base_model_raw.replace(':', '-')}-bnb-4bit")
+                hyperparams.get(
+                    "unsloth_model", f"unsloth/{base_model_raw.replace(':', '-')}-bnb-4bit"
+                ),
             )
         output_model_name = f"mcparr-{training_session.name.lower().replace(' ', '-')}"
 
         # Update session to preparing
         training_session.status = TrainingStatus.PREPARING
@@ -1369,11 +1380,11 @@
             prompts_data,
             base_model,
             output_model_name,
             ollama_url,
             hyperparams,
-            training_session.total_epochs
+            training_session.total_epochs,
         )
 
         return {
             "message": "Starting Unsloth fine-tuning on GPU worker",
             "session_id": session_id,
@@ -1382,39 +1393,37 @@
             "prompts_count": len(prompts),
             "config": {
                 "base_model": base_model,
                 "epochs": training_session.total_epochs,
                 "output_model": output_model_name,
-                "ollama_url": ollama_url
-            }
+                "ollama_url": ollama_url,
+            },
         }
 
     else:
         raise HTTPException(
             status_code=400,
-            detail=f"Unknown backend: {backend}. Use 'ollama_modelfile', 'unsloth' or 'gpu_worker'"
+            detail=f"Unknown backend: {backend}. Use 'ollama_modelfile', 'unsloth' or 'gpu_worker'",
         )
 
 
 @router.post("/sessions/{session_id}/cancel")
-async def cancel_training_session(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def cancel_training_session(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Cancel a running training session."""
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
-    if training_session.status not in [TrainingStatus.RUNNING, TrainingStatus.PREPARING, TrainingStatus.PENDING]:
+    if training_session.status not in [
+        TrainingStatus.RUNNING,
+        TrainingStatus.PREPARING,
+        TrainingStatus.PENDING,
+    ]:
         raise HTTPException(
-            status_code=400,
-            detail=f"Cannot cancel session with status {training_session.status}"
+            status_code=400, detail=f"Cannot cancel session with status {training_session.status}"
         )
 
     training_session.cancel_training()
     training_session.updated_at = datetime.utcnow()
 
@@ -1440,12 +1449,11 @@
     return {"message": "Training session cancelled", "session_id": session_id}
 
 
 @router.post("/sessions/{session_id}/duplicate")
 async def duplicate_training_session(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
+    session_id: str, session: AsyncSession = Depends(get_db_session)
 ):
     """Duplicate a training session with all its prompts."""
     from sqlalchemy.orm import selectinload
 
     # Get original session with prompts
@@ -1461,19 +1469,18 @@
 
     # Find the next version number for naming
     base_name = original_session.name
     # Remove version suffix if present (e.g., "Test v1" -> "Test")
     import re
+
     match = re.match(r"(.+?)\s*v(\d+)$", base_name)
     if match:
         base_name = match.group(1).strip()
 
     # Find existing sessions with similar names to get next version
     similar_result = await session.execute(
-        select(TrainingSession).where(
-            TrainingSession.name.like(f"{base_name}%")
-        )
+        select(TrainingSession).where(TrainingSession.name.like(f"{base_name}%"))
     )
     similar_sessions = similar_result.scalars().all()
 
     max_version = 0
     for s in similar_sessions:
@@ -1488,11 +1495,13 @@
         name=new_name,
         description=original_session.description,
         base_model=original_session.base_model,
         training_type=original_session.training_type,
         total_epochs=original_session.total_epochs,
-        hyperparameters=original_session.hyperparameters.copy() if original_session.hyperparameters else {},
+        hyperparameters=original_session.hyperparameters.copy()
+        if original_session.hyperparameters
+        else {},
         ollama_service_id=original_session.ollama_service_id,
         status=TrainingStatus.PENDING,
     )
 
     session.add(new_session)
@@ -1500,24 +1509,22 @@
 
     # Copy prompt associations
     for prompt in original_session.prompts:
         await session.execute(
             session_prompt_association.insert().values(
-                session_id=new_session.id,
-                prompt_id=prompt.id,
-                added_at=datetime.utcnow()
+                session_id=new_session.id, prompt_id=prompt.id, added_at=datetime.utcnow()
             )
         )
 
     await session.commit()
 
     return {
         "message": "Session duplicated successfully",
         "original_session_id": session_id,
         "new_session_id": new_session.id,
         "new_name": new_name,
-        "prompts_copied": len(original_session.prompts)
+        "prompts_copied": len(original_session.prompts),
     }
 
 
 @router.get("/requirements")
 async def check_training_requirements():
@@ -1542,11 +1549,11 @@
     if not health.online:
         return {
             "online": False,
             "worker_url": settings.training_worker_url,
             "error": health.error,
-            "gpu_available": False
+            "gpu_available": False,
         }
 
     # Get detailed info
     info = await worker_client.get_worker_info()
     gpu_metrics = await worker_client.get_gpu_metrics()
@@ -1559,11 +1566,11 @@
         "status": info.status,
         "gpu_available": info.gpu_available,
         "gpu_count": info.gpu_count,
         "gpu_names": info.gpu_names,
         "current_job_id": info.current_job_id,
-        "gpu_metrics": gpu_metrics
+        "gpu_metrics": gpu_metrics,
     }
 
 
 @router.get("/worker/models")
 async def get_worker_models():
@@ -1572,54 +1579,54 @@
 
     # Check worker is online first
     health = await worker_client.health_check()
     if not health.online:
         raise HTTPException(
-            status_code=503,
-            detail=f"Training worker not available: {health.error}"
+            status_code=503, detail=f"Training worker not available: {health.error}"
         )
 
     models = await worker_client.get_available_models()
     return models
 
 
 # ============= Worker Logs Endpoints =============
+
 
 @router.get("/worker/logs/system")
 async def get_worker_system_logs(
     tail: int = Query(default=100, le=1000, description="Number of lines to return"),
-    level: Optional[str] = Query(default=None, description="Filter by log level (debug, info, warning, error)")
+    level: Optional[str] = Query(
+        default=None, description="Filter by log level (debug, info, warning, error)"
+    ),
 ):
     """Get system logs from training worker."""
     worker_client = get_worker_client()
 
     # Check worker is online first
     health = await worker_client.health_check()
     if not health.online:
         raise HTTPException(
-            status_code=503,
-            detail=f"Training worker not available: {health.error}"
+            status_code=503, detail=f"Training worker not available: {health.error}"
         )
 
     return await worker_client.get_system_logs(tail=tail, level=level)
 
 
 @router.get("/worker/logs/job/{job_id}")
 async def get_worker_job_logs(
     job_id: str,
     tail: int = Query(default=100, le=5000, description="Number of lines to return"),
-    level: Optional[str] = Query(default=None, description="Filter by log level")
+    level: Optional[str] = Query(default=None, description="Filter by log level"),
 ):
     """Get logs for a specific training job from worker."""
     worker_client = get_worker_client()
 
     # Check worker is online first
     health = await worker_client.health_check()
     if not health.online:
         raise HTTPException(
-            status_code=503,
-            detail=f"Training worker not available: {health.error}"
+            status_code=503, detail=f"Training worker not available: {health.error}"
         )
 
     return await worker_client.get_job_logs(job_id=job_id, tail=tail, level=level)
 
 
@@ -1630,12 +1637,11 @@
 
     # Check worker is online first
     health = await worker_client.health_check()
     if not health.online:
         raise HTTPException(
-            status_code=503,
-            detail=f"Training worker not available: {health.error}"
+            status_code=503, detail=f"Training worker not available: {health.error}"
         )
 
     return await worker_client.get_available_job_logs()
 
 
@@ -1646,12 +1652,11 @@
 
     # Check worker is online first
     health = await worker_client.health_check()
     if not health.online:
         raise HTTPException(
-            status_code=503,
-            detail=f"Training worker not available: {health.error}"
+            status_code=503, detail=f"Training worker not available: {health.error}"
         )
 
     return await worker_client.delete_job_logs(job_id)
 
 
@@ -1662,11 +1667,11 @@
     settings = get_settings()
 
     return {
         "stream_url": worker_client.get_job_logs_stream_url(job_id),
         "worker_url": settings.training_worker_url,
-        "job_id": job_id
+        "job_id": job_id,
     }
 
 
 @router.get("/worker/logs/system/stream-url")
 async def get_system_logs_stream_url():
@@ -1674,39 +1679,36 @@
     worker_client = get_worker_client()
     settings = get_settings()
 
     return {
         "stream_url": worker_client.get_system_logs_stream_url(),
-        "worker_url": settings.training_worker_url
+        "worker_url": settings.training_worker_url,
     }
 
 
 @router.post("/sessions/{session_id}/import-ollama")
-async def import_model_to_ollama(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def import_model_to_ollama(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Import a completed training session's model into Ollama."""
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     training_session = result.scalar_one_or_none()
 
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status != TrainingStatus.COMPLETED:
         raise HTTPException(
             status_code=400,
-            detail=f"Cannot import model from session with status {training_session.status}"
+            detail=f"Cannot import model from session with status {training_session.status}",
         )
 
     global _training_service
     if not _training_service:
         _training_service = TrainingService()
 
-    model_name = training_session.output_model or f"mcparr-{training_session.name.lower().replace(' ', '-')}"
+    model_name = (
+        training_session.output_model or f"mcparr-{training_session.name.lower().replace(' ', '-')}"
+    )
     result = await _training_service.import_to_ollama(model_name)
 
     if result.get("success"):
         training_session.output_model = model_name
         training_session.updated_at = datetime.utcnow()
@@ -1715,25 +1717,22 @@
     return result
 
 
 # ============= Session Prompts Management =============
 
+
 class SessionPromptsUpdate(BaseModel):
     """Update prompts for a session."""
+
     prompt_ids: List[str] = Field(..., description="List of prompt IDs to associate with session")
 
 
 @router.get("/sessions/{session_id}/prompts", response_model=List[TrainingPromptResponse])
-async def get_session_prompts(
-    session_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_session_prompts(session_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get all prompts associated with a session."""
     # Verify session exists
-    result = await session.execute(
-        select(TrainingSession).where(TrainingSession.id == session_id)
-    )
+    result = await session.execute(select(TrainingSession).where(TrainingSession.id == session_id))
     if not result.scalar_one_or_none():
         raise HTTPException(status_code=404, detail="Training session not found")
 
     # Get prompts for this session
     prompts_result = await session.execute(
@@ -1744,13 +1743,11 @@
     return list(prompts_result.scalars().all())
 
 
 @router.put("/sessions/{session_id}/prompts")
 async def update_session_prompts(
-    session_id: str,
-    data: SessionPromptsUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    session_id: str, data: SessionPromptsUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Set prompts for a session (replaces existing associations). Many-to-many: prompts can be in multiple sessions."""
     from sqlalchemy.orm import selectinload
 
     # Get session with prompts loaded
@@ -1764,12 +1761,11 @@
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status != TrainingStatus.PENDING:
         raise HTTPException(
-            status_code=400,
-            detail="Cannot modify prompts for a session that is not pending"
+            status_code=400, detail="Cannot modify prompts for a session that is not pending"
         )
 
     # Clear existing associations (many-to-many)
     training_session.prompts.clear()
 
@@ -1792,19 +1788,17 @@
     await session.commit()
 
     return {
         "message": f"Updated session with {training_session.dataset_size} prompts",
         "session_id": session_id,
-        "prompt_count": training_session.dataset_size
+        "prompt_count": training_session.dataset_size,
     }
 
 
 @router.post("/sessions/{session_id}/prompts/add")
 async def add_prompts_to_session(
-    session_id: str,
-    data: SessionPromptsUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    session_id: str, data: SessionPromptsUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Add prompts to a session (keeps existing associations). Many-to-many: prompts can be in multiple sessions."""
     from sqlalchemy.orm import selectinload
 
     result = await session.execute(
@@ -1817,12 +1811,11 @@
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status != TrainingStatus.PENDING:
         raise HTTPException(
-            status_code=400,
-            detail="Cannot modify prompts for a session that is not pending"
+            status_code=400, detail="Cannot modify prompts for a session that is not pending"
         )
 
     # Add new associations (many-to-many, no restriction on already assigned)
     added = 0
     if data.prompt_ids:
@@ -1845,19 +1838,17 @@
 
     return {
         "message": f"Added {added} prompts to session",
         "session_id": session_id,
         "added": added,
-        "total": training_session.dataset_size
+        "total": training_session.dataset_size,
     }
 
 
 @router.post("/sessions/{session_id}/prompts/remove")
 async def remove_prompts_from_session(
-    session_id: str,
-    data: SessionPromptsUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    session_id: str, data: SessionPromptsUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Remove prompts from a session (many-to-many: only removes from this session, prompt still exists)."""
     from sqlalchemy.orm import selectinload
 
     result = await session.execute(
@@ -1870,12 +1861,11 @@
     if not training_session:
         raise HTTPException(status_code=404, detail="Training session not found")
 
     if training_session.status != TrainingStatus.PENDING:
         raise HTTPException(
-            status_code=400,
-            detail="Cannot modify prompts for a session that is not pending"
+            status_code=400, detail="Cannot modify prompts for a session that is not pending"
         )
 
     # Remove associations from many-to-many
     removed = 0
     if data.prompt_ids:
@@ -1893,15 +1883,16 @@
 
     return {
         "message": f"Removed {removed} prompts from session",
         "session_id": session_id,
         "removed": removed,
-        "total": training_session.dataset_size
+        "total": training_session.dataset_size,
     }
 
 
 # ============= Training Prompts Endpoints =============
+
 
 @router.get("/prompts", response_model=List[TrainingPromptResponse])
 async def list_training_prompts(
     category: Optional[str] = None,
     difficulty: Optional[str] = None,
@@ -1909,11 +1900,11 @@
     enabled: Optional[bool] = None,
     session_id: Optional[str] = None,
     search: Optional[str] = None,
     skip: int = Query(0, ge=0),
     limit: Optional[int] = Query(None, ge=1),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """List training prompts with filtering. No limit by default (returns all)."""
     query = select(TrainingPrompt)
     conditions = []
 
@@ -1927,12 +1918,12 @@
         conditions.append(TrainingPrompt.enabled == enabled)
     if session_id:
         conditions.append(TrainingPrompt.session_id == session_id)
     if search:
         conditions.append(
-            TrainingPrompt.name.ilike(f"%{search}%") |
-            TrainingPrompt.user_input.ilike(f"%{search}%")
+            TrainingPrompt.name.ilike(f"%{search}%")
+            | TrainingPrompt.user_input.ilike(f"%{search}%")
         )
 
     if conditions:
         query = query.where(and_(*conditions))
 
@@ -1945,12 +1936,11 @@
     return prompts
 
 
 @router.post("/prompts", response_model=TrainingPromptResponse)
 async def create_training_prompt(
-    data: TrainingPromptCreate,
-    session: AsyncSession = Depends(get_db_session)
+    data: TrainingPromptCreate, session: AsyncSession = Depends(get_db_session)
 ):
     """Create a new training prompt.
 
     For tool calling prompts:
     - tool_call: {"name": "tool_name", "arguments": {...}}
@@ -1965,11 +1955,11 @@
         "system_prompt": data.system_prompt,
         "user_input": data.user_input,
         "tool_call": data.tool_call,
         "tool_response": data.tool_response,
         "assistant_response": data.assistant_response,
-        "expected_output": data.expected_output
+        "expected_output": data.expected_output,
     }
 
     # Use assistant_response if provided, otherwise fall back to expected_output
     final_expected_output = data.expected_output or ""
 
@@ -1989,84 +1979,77 @@
         assistant_response=data.assistant_response,
         expected_output=final_expected_output,
         tags=data.tags,
         session_id=data.session_id,
         created_at=datetime.utcnow(),
-        updated_at=datetime.utcnow()
+        updated_at=datetime.utcnow(),
     )
 
     session.add(prompt)
     await session.commit()
     await session.refresh(prompt)
 
     return prompt
 
 
 @router.get("/prompts/{prompt_id}", response_model=TrainingPromptResponse)
-async def get_training_prompt(
-    prompt_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_training_prompt(prompt_id: str, session: AsyncSession = Depends(get_db_session)):
     """Get a specific training prompt."""
-    result = await session.execute(
-        select(TrainingPrompt).where(TrainingPrompt.id == prompt_id)
-    )
+    result = await session.execute(select(TrainingPrompt).where(TrainingPrompt.id == prompt_id))
     prompt = result.scalar_one_or_none()
 
     if not prompt:
         raise HTTPException(status_code=404, detail="Training prompt not found")
 
     return prompt
 
 
 @router.patch("/prompts/{prompt_id}", response_model=TrainingPromptResponse)
 async def update_training_prompt(
-    prompt_id: str,
-    data: TrainingPromptUpdate,
-    session: AsyncSession = Depends(get_db_session)
+    prompt_id: str, data: TrainingPromptUpdate, session: AsyncSession = Depends(get_db_session)
 ):
     """Update a training prompt."""
-    result = await session.execute(
-        select(TrainingPrompt).where(TrainingPrompt.id == prompt_id)
-    )
+    result = await session.execute(select(TrainingPrompt).where(TrainingPrompt.id == prompt_id))
     prompt = result.scalar_one_or_none()
 
     if not prompt:
         raise HTTPException(status_code=404, detail="Training prompt not found")
 
     update_data = data.model_dump(exclude_unset=True)
     for key, value in update_data.items():
         setattr(prompt, key, value)
 
     # Update content if any relevant field changed
-    content_fields = ["user_input", "expected_output", "system_prompt", "tool_call", "tool_response", "assistant_response"]
+    content_fields = [
+        "user_input",
+        "expected_output",
+        "system_prompt",
+        "tool_call",
+        "tool_response",
+        "assistant_response",
+    ]
     if any(field in update_data for field in content_fields):
         prompt.content = {
             "system_prompt": prompt.system_prompt,
             "user_input": prompt.user_input,
             "tool_call": prompt.tool_call,
             "tool_response": prompt.tool_response,
             "assistant_response": prompt.assistant_response,
-            "expected_output": prompt.expected_output
+            "expected_output": prompt.expected_output,
         }
 
     prompt.updated_at = datetime.utcnow()
     await session.commit()
     await session.refresh(prompt)
 
     return prompt
 
 
 @router.delete("/prompts/{prompt_id}")
-async def delete_training_prompt(
-    prompt_id: str,
-    session: AsyncSession = Depends(get_db_session)
-):
+async def delete_training_prompt(prompt_id: str, session: AsyncSession = Depends(get_db_session)):
     """Delete a training prompt."""
-    result = await session.execute(
-        select(TrainingPrompt).where(TrainingPrompt.id == prompt_id)
-    )
+    result = await session.execute(select(TrainingPrompt).where(TrainingPrompt.id == prompt_id))
     prompt = result.scalar_one_or_none()
 
     if not prompt:
         raise HTTPException(status_code=404, detail="Training prompt not found")
 
@@ -2079,16 +2062,14 @@
 @router.post("/prompts/{prompt_id}/validate")
 async def validate_training_prompt(
     prompt_id: str,
     score: Optional[float] = Query(None, ge=0, le=1),
     validated_by: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Mark a prompt as validated."""
-    result = await session.execute(
-        select(TrainingPrompt).where(TrainingPrompt.id == prompt_id)
-    )
+    result = await session.execute(select(TrainingPrompt).where(TrainingPrompt.id == prompt_id))
     prompt = result.scalar_one_or_none()
 
     if not prompt:
         raise HTTPException(status_code=404, detail="Training prompt not found")
 
@@ -2100,14 +2081,13 @@
     return {"message": "Prompt validated", "prompt_id": prompt_id}
 
 
 # ============= Stats Endpoint =============
 
+
 @router.get("/stats", response_model=TrainingStatsResponse)
-async def get_training_stats(
-    session: AsyncSession = Depends(get_db_session)
-):
+async def get_training_stats(session: AsyncSession = Depends(get_db_session)):
     """Get training statistics."""
     # Session counts
     total_sessions = await session.execute(select(func.count(TrainingSession.id)))
     total_sessions = total_sessions.scalar() or 0
 
@@ -2141,20 +2121,19 @@
     )
     validated_prompts = validated_prompts.scalar() or 0
 
     # Prompts by category
     category_result = await session.execute(
-        select(TrainingPrompt.category, func.count(TrainingPrompt.id))
-        .group_by(TrainingPrompt.category)
+        select(TrainingPrompt.category, func.count(TrainingPrompt.id)).group_by(
+            TrainingPrompt.category
+        )
     )
     prompts_by_category = {row[0]: row[1] for row in category_result.fetchall()}
 
     # Recent sessions
     recent_result = await session.execute(
-        select(TrainingSession)
-        .order_by(TrainingSession.created_at.desc())
-        .limit(5)
+        select(TrainingSession).order_by(TrainingSession.created_at.desc()).limit(5)
     )
     recent_sessions = list(recent_result.scalars().all())
 
     return TrainingStatsResponse(
         total_sessions=total_sessions,
@@ -2162,28 +2141,28 @@
         completed_sessions=completed_sessions,
         failed_sessions=failed_sessions,
         total_prompts=total_prompts,
         validated_prompts=validated_prompts,
         prompts_by_category=prompts_by_category,
-        recent_sessions=recent_sessions
+        recent_sessions=recent_sessions,
     )
 
 
 # ============= Import/Export Endpoints =============
+
 
 @router.post("/prompts/import")
 async def import_training_prompts(
-    prompts: List[TrainingPromptCreate],
-    session: AsyncSession = Depends(get_db_session)
+    prompts: List[TrainingPromptCreate], session: AsyncSession = Depends(get_db_session)
 ):
     """Import multiple training prompts."""
     created = []
     for data in prompts:
         content = {
             "system_prompt": data.system_prompt,
             "user_input": data.user_input,
-            "expected_output": data.expected_output
+            "expected_output": data.expected_output,
         }
 
         prompt = TrainingPrompt(
             id=str(uuid4()),
             name=data.name,
@@ -2197,11 +2176,11 @@
             user_input=data.user_input,
             expected_output=data.expected_output,
             tags=data.tags,
             session_id=data.session_id,
             created_at=datetime.utcnow(),
-            updated_at=datetime.utcnow()
+            updated_at=datetime.utcnow(),
         )
         session.add(prompt)
         created.append(prompt)
 
     await session.commit()
@@ -2212,11 +2191,11 @@
 @router.get("/prompts/export")
 async def export_training_prompts(
     category: Optional[str] = None,
     session_id: Optional[str] = None,
     format: str = Query("json", regex="^(json|jsonl)$"),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Export training prompts for download."""
     query = select(TrainingPrompt).where(TrainingPrompt.enabled is True)
 
     if category:
@@ -2229,19 +2208,16 @@
 
     export_data = []
     for prompt in prompts:
         export_data.append(prompt.to_training_format())
 
-    return {
-        "format": format,
-        "count": len(export_data),
-        "data": export_data
-    }
+    return {"format": format, "count": len(export_data), "data": export_data}
 
 
 class OllamaMetricsResponse(BaseModel):
     """Ollama and system metrics response."""
+
     # Ollama metrics
     ollama_status: str
     ollama_version: Optional[str] = None
     ollama_url: str = ""
     models_count: int = 0
@@ -2271,20 +2247,16 @@
     error: Optional[str] = None
 
 
 @router.get("/ollama/metrics", response_model=OllamaMetricsResponse)
 async def get_ollama_metrics(
-    service_id: Optional[str] = None,
-    session: AsyncSession = Depends(get_db_session)
+    service_id: Optional[str] = None, session: AsyncSession = Depends(get_db_session)
 ):
     """Get comprehensive Ollama and system metrics for training stats."""
     import psutil
 
-    response = OllamaMetricsResponse(
-        ollama_status="not_configured",
-        ollama_url=""
-    )
+    response = OllamaMetricsResponse(ollama_status="not_configured", ollama_url="")
 
     # Get Ollama service and status
     ollama = await get_ollama_service(session, service_id)
     if ollama:
         health = await ollama.health_check()
@@ -2303,11 +2275,11 @@
                     {
                         "name": m.name,
                         "size_gb": m.size_gb,
                         "family": m.family,
                         "parameter_size": m.parameter_size,
-                        "quantization_level": m.quantization_level
+                        "quantization_level": m.quantization_level,
                     }
                     for m in models
                 ]
 
                 # Get running models
@@ -2329,17 +2301,23 @@
         response.system_memory_percent = memory.percent
 
         # GPU (try nvidia-smi via subprocess)
         try:
             import subprocess
+
             result = subprocess.run(
-                ['nvidia-smi', '--query-gpu=name,memory.used,memory.total,utilization.gpu',
-                 '--format=csv,noheader,nounits'],
-                capture_output=True, text=True, timeout=5
+                [
+                    "nvidia-smi",
+                    "--query-gpu=name,memory.used,memory.total,utilization.gpu",
+                    "--format=csv,noheader,nounits",
+                ],
+                capture_output=True,
+                text=True,
+                timeout=5,
             )
             if result.returncode == 0 and result.stdout.strip():
-                parts = result.stdout.strip().split(',')
+                parts = result.stdout.strip().split(",")
                 if len(parts) >= 4:
                     response.system_gpu_name = parts[0].strip()
                     response.system_gpu_used_gb = round(float(parts[1].strip()) / 1024, 2)
                     response.system_gpu_total_gb = round(float(parts[2].strip()) / 1024, 2)
                     response.system_gpu_percent = float(parts[3].strip())
@@ -2372,41 +2350,38 @@
         total_prompts = await session.execute(select(func.count(TrainingPrompt.id)))
         response.training_total_prompts = total_prompts.scalar() or 0
 
         # Prompts by category
         category_result = await session.execute(
-            select(TrainingPrompt.category, func.count(TrainingPrompt.id))
-            .group_by(TrainingPrompt.category)
-        )
-        response.training_prompts_by_category = {row[0]: row[1] for row in category_result.fetchall()}
+            select(TrainingPrompt.category, func.count(TrainingPrompt.id)).group_by(
+                TrainingPrompt.category
+            )
+        )
+        response.training_prompts_by_category = {
+            row[0]: row[1] for row in category_result.fetchall()
+        }
     except Exception:
         pass
 
     return response
 
 
 @router.delete("/prompts/all")
-async def delete_all_prompts(
-    session: AsyncSession = Depends(get_db_session)
-):
+async def delete_all_prompts(session: AsyncSession = Depends(get_db_session)):
     """Delete all training prompts."""
     result = await session.execute(select(func.count(TrainingPrompt.id)))
     count = result.scalar() or 0
 
     await session.execute(delete(TrainingPrompt))
     await session.commit()
 
-    return {
-        "message": f"Deleted {count} prompts",
-        "deleted_count": count
-    }
+    return {"message": f"Deleted {count} prompts", "deleted_count": count}
 
 
 @router.post("/prompts/seed")
 async def seed_training_prompts(
-    reset: bool = False,
-    session: AsyncSession = Depends(get_db_session)
+    reset: bool = False, session: AsyncSession = Depends(get_db_session)
 ):
     """Load pre-defined homelab training prompts from seed files.
 
     Args:
         reset: If True, delete all existing prompts before seeding
@@ -2454,29 +2429,32 @@
             expected_output=prompt_data["expected_output"],
             tags=prompt_data.get("tags", []),
             content={
                 "system_prompt": prompt_data.get("system_prompt"),
                 "user_input": prompt_data["user_input"],
-                "expected_output": prompt_data["expected_output"]
+                "expected_output": prompt_data["expected_output"],
             },
             created_at=datetime.utcnow(),
-            updated_at=datetime.utcnow()
+            updated_at=datetime.utcnow(),
         )
         session.add(prompt)
         created.append(prompt_data["name"])
 
     await session.commit()
 
     return {
-        "message": f"Seeded {len(created)} prompts" + (f", skipped {len(skipped)} existing" if skipped else "") + (" (reset mode)" if reset else ""),
+        "message": f"Seeded {len(created)} prompts"
+        + (f", skipped {len(skipped)} existing" if skipped else "")
+        + (" (reset mode)" if reset else ""),
         "created": created,
         "skipped": skipped,
-        "reset": reset
+        "reset": reset,
     }
 
 
 # ============= WebSocket Endpoints =============
+
 
 @router.websocket("/ws")
 async def websocket_frontend(websocket: WebSocket):
     """
     WebSocket endpoint for frontend clients to receive real-time training updates.
@@ -2507,11 +2485,13 @@
 
                 elif msg_type == "unsubscribe":
                     session_id = data.get("session_id")
                     if session_id:
                         connection_manager.unsubscribe_from_session(websocket, session_id)
-                        await websocket.send_json({"type": "unsubscribed", "session_id": session_id})
+                        await websocket.send_json(
+                            {"type": "unsubscribed", "session_id": session_id}
+                        )
 
                 elif msg_type == "ping":
                     await websocket.send_json({"type": "pong"})
 
             except json.JSONDecodeError:
@@ -2568,10 +2548,11 @@
     """Get WebSocket connection statistics."""
     return connection_manager.get_stats()
 
 
 # ============= Session Update Callback =============
+
 
 async def _handle_session_update(session_id: str, update_type: str, data: dict):
     """
     Callback to update session in database when receiving worker updates.
     This is called by the connection_manager when it receives updates from workers.
@@ -2596,29 +2577,33 @@
 
                 session.current_epoch = progress.get("current_epoch", session.current_epoch)
                 session.total_epochs = progress.get("total_epochs", session.total_epochs)
                 session.current_step = progress.get("current_step", session.current_step)
                 session.total_steps = progress.get("total_steps", session.total_steps)
-                session.progress_percent = progress.get("progress_percent", session.progress_percent)
+                session.progress_percent = progress.get(
+                    "progress_percent", session.progress_percent
+                )
 
                 if performance.get("loss") is not None:
                     session.loss = performance.get("loss")
                 if performance.get("learning_rate") is not None:
                     session.learning_rate = performance.get("learning_rate")
 
                 # Store metrics history
                 if session.metrics_history is None:
                     session.metrics_history = []
 
-                session.metrics_history.append({
-                    "timestamp": datetime.utcnow().isoformat(),
-                    "step": progress.get("current_step"),
-                    "epoch": progress.get("current_epoch"),
-                    "loss": performance.get("loss"),
-                    "learning_rate": performance.get("learning_rate"),
-                    "quality": quality,
-                })
+                session.metrics_history.append(
+                    {
+                        "timestamp": datetime.utcnow().isoformat(),
+                        "step": progress.get("current_step"),
+                        "epoch": progress.get("current_epoch"),
+                        "loss": performance.get("loss"),
+                        "learning_rate": performance.get("learning_rate"),
+                        "quality": quality,
+                    }
+                )
 
                 # Keep last 1000 metrics
                 if len(session.metrics_history) > 1000:
                     session.metrics_history = session.metrics_history[-1000:]
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/training.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_ws.py	2025-12-31 13:30:51.498007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_ws.py	2025-12-31 13:41:37.051090+00:00
@@ -8,10 +8,11 @@
 from loguru import logger
 
 
 class WSMessageType(str, Enum):
     """WebSocket message types."""
+
     # Worker  Backend
     CONNECTED = "connected"
     PROGRESS_UPDATE = "progress_update"
     METRICS_UPDATE = "metrics_update"
     LOG_LINE = "log_line"
@@ -66,15 +67,18 @@
                 logger.error(f"Failed to send to worker {job_id}: {e}")
                 self.disconnect_worker(job_id)
 
     async def cancel_worker_job(self, job_id: str):
         """Send cancel request to worker."""
-        await self.send_to_worker(job_id, {
-            "type": WSMessageType.CANCEL_JOB.value,
-            "job_id": job_id,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.send_to_worker(
+            job_id,
+            {
+                "type": WSMessageType.CANCEL_JOB.value,
+                "job_id": job_id,
+                "timestamp": datetime.utcnow().isoformat(),
+            },
+        )
 
     # ============= Frontend Connections =============
 
     async def connect_frontend(self, websocket: WebSocket):
         """Register a frontend client connection."""
@@ -169,26 +173,31 @@
     async def _handle_progress_update(self, session_id: str, message: Dict[str, Any]):
         """Handle progress update from worker."""
         metrics = message.get("data", {}).get("metrics", {})
 
         # Forward to frontend subscribers
-        await self.send_to_session_subscribers(session_id, {
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "progress",
-            "data": metrics,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.send_to_session_subscribers(
+            session_id,
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "progress",
+                "data": metrics,
+                "timestamp": datetime.utcnow().isoformat(),
+            },
+        )
 
         # Also broadcast to all frontend clients
-        await self.broadcast_to_frontend({
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "progress",
-            "data": metrics,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.broadcast_to_frontend(
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "progress",
+                "data": metrics,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
+        )
 
         # Trigger callbacks for database update
         for callback in self._session_update_callbacks:
             try:
                 await callback(session_id, "progress", metrics)
@@ -197,40 +206,48 @@
 
     async def _handle_metrics_update(self, session_id: str, message: Dict[str, Any]):
         """Handle metrics update from worker."""
         metrics = message.get("data", {}).get("metrics", {})
 
-        await self.send_to_session_subscribers(session_id, {
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "metrics",
-            "data": metrics,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.send_to_session_subscribers(
+            session_id,
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "metrics",
+                "data": metrics,
+                "timestamp": datetime.utcnow().isoformat(),
+            },
+        )
 
     async def _handle_log_line(self, session_id: str, message: Dict[str, Any]):
         """Handle log line from worker."""
         log = message.get("data", {}).get("log", {})
 
-        await self.send_to_session_subscribers(session_id, {
-            "type": WSMessageType.LOG_LINE.value,
-            "session_id": session_id,
-            "data": log,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.send_to_session_subscribers(
+            session_id,
+            {
+                "type": WSMessageType.LOG_LINE.value,
+                "session_id": session_id,
+                "data": log,
+                "timestamp": datetime.utcnow().isoformat(),
+            },
+        )
 
     async def _handle_job_started(self, session_id: str, message: Dict[str, Any]):
         """Handle job started notification."""
         data = message.get("data", {})
 
-        await self.broadcast_to_frontend({
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "started",
-            "data": data,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.broadcast_to_frontend(
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "started",
+                "data": data,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
+        )
 
         for callback in self._session_update_callbacks:
             try:
                 await callback(session_id, "started", data)
             except Exception as e:
@@ -238,17 +255,19 @@
 
     async def _handle_job_completed(self, session_id: str, message: Dict[str, Any]):
         """Handle job completed notification."""
         data = message.get("data", {})
 
-        await self.broadcast_to_frontend({
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "completed",
-            "data": data,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.broadcast_to_frontend(
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "completed",
+                "data": data,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
+        )
 
         for callback in self._session_update_callbacks:
             try:
                 await callback(session_id, "completed", data)
             except Exception as e:
@@ -256,17 +275,19 @@
 
     async def _handle_job_failed(self, session_id: str, message: Dict[str, Any]):
         """Handle job failed notification."""
         data = message.get("data", {})
 
-        await self.broadcast_to_frontend({
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "failed",
-            "data": data,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.broadcast_to_frontend(
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "failed",
+                "data": data,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
+        )
 
         for callback in self._session_update_callbacks:
             try:
                 await callback(session_id, "failed", data)
             except Exception as e:
@@ -274,17 +295,19 @@
 
     async def _handle_job_cancelled(self, session_id: str, message: Dict[str, Any]):
         """Handle job cancelled notification."""
         data = message.get("data", {})
 
-        await self.broadcast_to_frontend({
-            "type": WSMessageType.SESSION_UPDATE.value,
-            "session_id": session_id,
-            "update_type": "cancelled",
-            "data": data,
-            "timestamp": datetime.utcnow().isoformat(),
-        })
+        await self.broadcast_to_frontend(
+            {
+                "type": WSMessageType.SESSION_UPDATE.value,
+                "session_id": session_id,
+                "update_type": "cancelled",
+                "data": data,
+                "timestamp": datetime.utcnow().isoformat(),
+            }
+        )
 
         for callback in self._session_update_callbacks:
             try:
                 await callback(session_id, "cancelled", data)
             except Exception as e:
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_ws.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/openapi_tools.py	2025-12-31 13:30:51.589007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/openapi_tools.py	2025-12-31 13:41:37.035338+00:00
@@ -47,10 +47,11 @@
 
 # ============================================================================
 # Open WebUI User Resolution (Session Auth)
 # ============================================================================
 
+
 def decode_jwt_user_id(token: str) -> Optional[str]:
     """
     Decode a JWT token without verifying the signature to extract user ID.
     This is safe in a trusted network environment where the token comes from Open WebUI.
     """
@@ -93,45 +94,49 @@
 
     # Call Open WebUI API to get full user info (email, name, role)
     try:
         async with httpx.AsyncClient(timeout=5.0) as client:
             response = await client.get(
-                f"{OPEN_WEBUI_BASE_URL}/api/v1/auths/",
-                headers={"Authorization": f"Bearer {token}"}
+                f"{OPEN_WEBUI_BASE_URL}/api/v1/auths/", headers={"Authorization": f"Bearer {token}"}
             )
 
             if response.status_code == 200:
                 data = response.json()
                 user_info = {
                     "id": data.get("id"),
                     "email": data.get("email"),
                     "name": data.get("name"),
                     "role": data.get("role"),
                 }
-                logger.info(f"[OpenWebUI] Resolved user: {user_info.get('email')} (id: {user_info.get('id')})")
+                logger.info(
+                    f"[OpenWebUI] Resolved user: {user_info.get('email')} (id: {user_info.get('id')})"
+                )
                 return user_info
             else:
                 # API call failed, return just the ID from JWT
-                logger.warning(f"[OpenWebUI] API call failed ({response.status_code}), using JWT id only")
+                logger.warning(
+                    f"[OpenWebUI] API call failed ({response.status_code}), using JWT id only"
+                )
                 return {"id": user_id, "email": None, "name": None, "role": None}
     except Exception as e:
         logger.warning(f"[OpenWebUI] Error calling API: {e}, using JWT id only")
         return {"id": user_id, "email": None, "name": None, "role": None}
 
 
 # ============================================================================
 # Open WebUI compatible OpenAPI spec endpoint
 # ============================================================================
+
 
 def generate_openwebui_openapi_spec() -> dict:
     """Generate a simplified OpenAPI 3.0.3 spec compatible with Open WebUI."""
     return {
         "openapi": "3.0.3",
         "info": {
             "title": "MCParr AI Tools",
             "description": "AI tools for homelab services management",
-            "version": "1.0.0"
+            "version": "1.0.0",
         },
         "paths": {
             "/tools/system_get_health": {
                 "post": {
                     "operationId": "system_get_health",
@@ -142,13 +147,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/system_get_metrics": {
                 "post": {
                     "operationId": "system_get_metrics",
@@ -159,13 +164,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_get_libraries": {
                 "post": {
                     "operationId": "plex_get_libraries",
@@ -176,13 +181,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_search_media": {
                 "post": {
                     "operationId": "plex_search_media",
@@ -196,36 +201,36 @@
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {
                                             "type": "string",
-                                            "description": "Search query (title, actor, director, etc.)"
+                                            "description": "Search query (title, actor, director, etc.)",
                                         },
                                         "media_type": {
                                             "type": "string",
-                                            "description": "Type of media: movie, show, episode, artist, album, track"
+                                            "description": "Type of media: movie, show, episode, artist, album, track",
                                         },
                                         "limit": {
                                             "type": "integer",
                                             "default": 10,
-                                            "description": "Maximum number of results to return"
-                                        }
-                                    }
+                                            "description": "Maximum number of results to return",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_get_recently_added": {
                 "post": {
                     "operationId": "plex_get_recently_added",
@@ -237,18 +242,18 @@
                                 "schema": {
                                     "type": "object",
                                     "properties": {
                                         "library_name": {
                                             "type": "string",
-                                            "description": "Name of the library (e.g., 'Movies', 'TV Shows')"
+                                            "description": "Name of the library (e.g., 'Movies', 'TV Shows')",
                                         },
                                         "limit": {
                                             "type": "integer",
                                             "default": 10,
-                                            "description": "Maximum number of items to return"
-                                        }
-                                    }
+                                            "description": "Maximum number of items to return",
+                                        },
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -256,13 +261,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_get_on_deck": {
                 "post": {
                     "operationId": "plex_get_on_deck",
@@ -275,13 +280,13 @@
                                     "type": "object",
                                     "properties": {
                                         "limit": {
                                             "type": "integer",
                                             "default": 10,
-                                            "description": "Maximum number of items to return"
+                                            "description": "Maximum number of items to return",
                                         }
-                                    }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -289,13 +294,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_get_media_details": {
                 "post": {
                     "operationId": "plex_get_media_details",
@@ -309,31 +314,31 @@
                                     "type": "object",
                                     "required": ["title"],
                                     "properties": {
                                         "title": {
                                             "type": "string",
-                                            "description": "Title of the movie or TV show"
+                                            "description": "Title of the movie or TV show",
                                         },
                                         "year": {
                                             "type": "integer",
-                                            "description": "Release year (helps with disambiguation)"
-                                        }
-                                    }
+                                            "description": "Release year (helps with disambiguation)",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/plex_get_active_sessions": {
                 "post": {
                     "operationId": "plex_get_active_sessions",
@@ -344,13 +349,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/overseerr_search": {
                 "post": {
                     "operationId": "overseerr_search",
@@ -364,31 +369,31 @@
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {
                                             "type": "string",
-                                            "description": "Search query for movies or TV shows"
+                                            "description": "Search query for movies or TV shows",
                                         },
                                         "media_type": {
                                             "type": "string",
-                                            "description": "Filter by type: movie or tv"
-                                        }
-                                    }
+                                            "description": "Filter by type: movie or tv",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/overseerr_get_requests": {
                 "post": {
                     "operationId": "overseerr_get_requests",
@@ -399,13 +404,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/overseerr_request_media": {
                 "post": {
                     "operationId": "overseerr_request_media",
@@ -419,35 +424,35 @@
                                     "type": "object",
                                     "required": ["title", "media_type"],
                                     "properties": {
                                         "title": {
                                             "type": "string",
-                                            "description": "Title of the media to request"
+                                            "description": "Title of the media to request",
                                         },
                                         "media_type": {
                                             "type": "string",
-                                            "description": "Type of media: movie or tv"
+                                            "description": "Type of media: movie or tv",
                                         },
                                         "year": {
                                             "type": "integer",
-                                            "description": "Release year for disambiguation"
-                                        }
-                                    }
+                                            "description": "Release year for disambiguation",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/overseerr_get_trending": {
                 "post": {
                     "operationId": "overseerr_get_trending",
@@ -458,13 +463,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_activity": {
                 "post": {
                     "operationId": "tautulli_get_activity",
@@ -475,13 +480,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_history": {
                 "post": {
                     "operationId": "tautulli_get_history",
@@ -494,17 +499,17 @@
                                     "type": "object",
                                     "properties": {
                                         "length": {
                                             "type": "integer",
                                             "default": 25,
-                                            "description": "Number of history items to return"
+                                            "description": "Number of history items to return",
                                         },
                                         "user": {
                                             "type": "string",
-                                            "description": "Filter history by username"
-                                        }
-                                    }
+                                            "description": "Filter history by username",
+                                        },
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -512,13 +517,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_users": {
                 "post": {
                     "operationId": "tautulli_get_users",
@@ -529,13 +534,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_libraries": {
                 "post": {
                     "operationId": "tautulli_get_libraries",
@@ -546,13 +551,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_statistics": {
                 "post": {
                     "operationId": "tautulli_get_statistics",
@@ -563,13 +568,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_recently_added": {
                 "post": {
                     "operationId": "tautulli_get_recently_added",
@@ -582,13 +587,13 @@
                                     "type": "object",
                                     "properties": {
                                         "count": {
                                             "type": "integer",
                                             "default": 25,
-                                            "description": "Number of recently added items to return"
+                                            "description": "Number of recently added items to return",
                                         }
-                                    }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -596,13 +601,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_server_info": {
                 "post": {
                     "operationId": "tautulli_get_server_info",
@@ -613,13 +618,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_my_stats": {
                 "post": {
                     "operationId": "tautulli_get_my_stats",
@@ -633,27 +638,27 @@
                                     "type": "object",
                                     "properties": {
                                         "length": {
                                             "type": "integer",
                                             "description": "Number of history items to return",
-                                            "default": 25
+                                            "default": 25,
                                         }
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_top_users": {
                 "post": {
                     "operationId": "tautulli_get_top_users",
@@ -664,28 +669,41 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of users to return", "default": 10}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of users to return",
+                                            "default": 10,
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_top_movies": {
                 "post": {
                     "operationId": "tautulli_get_top_movies",
@@ -696,29 +714,45 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of movies to return", "default": 10},
-                                        "username": {"type": "string", "description": "Filter by username (optional)"}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of movies to return",
+                                            "default": 10,
+                                        },
+                                        "username": {
+                                            "type": "string",
+                                            "description": "Filter by username (optional)",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_top_tv_shows": {
                 "post": {
                     "operationId": "tautulli_get_top_tv_shows",
@@ -729,29 +763,45 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of TV shows to return", "default": 10},
-                                        "username": {"type": "string", "description": "Filter by username (optional)"}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of TV shows to return",
+                                            "default": 10,
+                                        },
+                                        "username": {
+                                            "type": "string",
+                                            "description": "Filter by username (optional)",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_top_music": {
                 "post": {
                     "operationId": "tautulli_get_top_music",
@@ -762,29 +812,45 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of music items to return", "default": 10},
-                                        "username": {"type": "string", "description": "Filter by username (optional)"}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of music items to return",
+                                            "default": 10,
+                                        },
+                                        "username": {
+                                            "type": "string",
+                                            "description": "Filter by username (optional)",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_top_platforms": {
                 "post": {
                     "operationId": "tautulli_get_top_platforms",
@@ -795,28 +861,41 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of platforms to return", "default": 10}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of platforms to return",
+                                            "default": 10,
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_user_stats": {
                 "post": {
                     "operationId": "tautulli_get_user_stats",
@@ -828,27 +907,34 @@
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "required": ["username"],
                                     "properties": {
-                                        "username": {"type": "string", "description": "Username or friendly name of the user"},
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30}
-                                    }
+                                        "username": {
+                                            "type": "string",
+                                            "description": "Username or friendly name of the user",
+                                        },
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/tautulli_get_watch_stats_summary": {
                 "post": {
                     "operationId": "tautulli_get_watch_stats_summary",
@@ -859,28 +945,41 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "description": "Number of days to analyze", "default": 30},
-                                        "stats_type": {"type": "string", "enum": ["plays", "duration"], "description": "Type of stats", "default": "plays"},
-                                        "limit": {"type": "integer", "description": "Number of items per category", "default": 5}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "description": "Number of days to analyze",
+                                            "default": 30,
+                                        },
+                                        "stats_type": {
+                                            "type": "string",
+                                            "enum": ["plays", "duration"],
+                                            "description": "Type of stats",
+                                            "default": "plays",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "description": "Number of items per category",
+                                            "default": 5,
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_get_tickets": {
                 "post": {
                     "operationId": "zammad_get_tickets",
@@ -891,13 +990,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_search_tickets": {
                 "post": {
                     "operationId": "zammad_search_tickets",
@@ -911,32 +1010,32 @@
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {
                                             "type": "string",
-                                            "description": "Search query for tickets"
+                                            "description": "Search query for tickets",
                                         },
                                         "limit": {
                                             "type": "integer",
                                             "default": 10,
-                                            "description": "Maximum number of results"
-                                        }
-                                    }
+                                            "description": "Maximum number of results",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_create_ticket": {
                 "post": {
                     "operationId": "zammad_create_ticket",
@@ -950,40 +1049,40 @@
                                     "type": "object",
                                     "required": ["title", "body"],
                                     "properties": {
                                         "title": {
                                             "type": "string",
-                                            "description": "Ticket title/subject"
+                                            "description": "Ticket title/subject",
                                         },
                                         "body": {
                                             "type": "string",
-                                            "description": "Ticket body/description"
+                                            "description": "Ticket body/description",
                                         },
                                         "customer_email": {
                                             "type": "string",
-                                            "description": "Customer email address"
+                                            "description": "Customer email address",
                                         },
                                         "priority": {
                                             "type": "string",
                                             "default": "normal",
-                                            "description": "Priority: low, normal, high"
-                                        }
-                                    }
+                                            "description": "Priority: low, normal, high",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_get_organizations": {
                 "post": {
                     "operationId": "zammad_get_organizations",
@@ -994,13 +1093,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_get_users": {
                 "post": {
                     "operationId": "zammad_get_users",
@@ -1011,13 +1110,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_get_ticket_details": {
                 "post": {
                     "operationId": "zammad_get_ticket_details",
@@ -1031,27 +1130,27 @@
                                     "type": "object",
                                     "required": ["ticket_id"],
                                     "properties": {
                                         "ticket_id": {
                                             "type": "integer",
-                                            "description": "ID or number of the ticket to retrieve (e.g., 1 or 20001)"
+                                            "description": "ID or number of the ticket to retrieve (e.g., 1 or 20001)",
                                         }
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_add_comment": {
                 "post": {
                     "operationId": "zammad_add_comment",
@@ -1065,36 +1164,36 @@
                                     "type": "object",
                                     "required": ["ticket_id", "comment"],
                                     "properties": {
                                         "ticket_id": {
                                             "type": "integer",
-                                            "description": "ID of the ticket"
+                                            "description": "ID of the ticket",
                                         },
                                         "comment": {
                                             "type": "string",
-                                            "description": "Comment content"
+                                            "description": "Comment content",
                                         },
                                         "internal": {
                                             "type": "boolean",
                                             "default": False,
-                                            "description": "Whether the comment is internal (not visible to customer)"
-                                        }
-                                    }
+                                            "description": "Whether the comment is internal (not visible to customer)",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_update_ticket_status": {
                 "post": {
                     "operationId": "zammad_update_ticket_status",
@@ -1108,32 +1207,32 @@
                                     "type": "object",
                                     "required": ["ticket_id", "status"],
                                     "properties": {
                                         "ticket_id": {
                                             "type": "integer",
-                                            "description": "ID of the ticket"
+                                            "description": "ID of the ticket",
                                         },
                                         "status": {
                                             "type": "string",
                                             "enum": ["open", "pending", "closed"],
-                                            "description": "New status for the ticket"
-                                        }
-                                    }
+                                            "description": "New status for the ticket",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/zammad_get_ticket_stats": {
                 "post": {
                     "operationId": "zammad_get_ticket_stats",
@@ -1144,13 +1243,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_get_status": {
                 "post": {
                     "operationId": "openwebui_get_status",
@@ -1161,13 +1260,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_get_users": {
                 "post": {
                     "operationId": "openwebui_get_users",
@@ -1180,13 +1279,13 @@
                                     "type": "object",
                                     "properties": {
                                         "limit": {
                                             "type": "integer",
                                             "default": 50,
-                                            "description": "Maximum number of users to return"
+                                            "description": "Maximum number of users to return",
                                         }
-                                    }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1194,13 +1293,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_get_models": {
                 "post": {
                     "operationId": "openwebui_get_models",
@@ -1211,13 +1310,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_get_chats": {
                 "post": {
                     "operationId": "openwebui_get_chats",
@@ -1230,13 +1329,13 @@
                                     "type": "object",
                                     "properties": {
                                         "limit": {
                                             "type": "integer",
                                             "default": 20,
-                                            "description": "Maximum number of chats to return"
+                                            "description": "Maximum number of chats to return",
                                         }
-                                    }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1244,13 +1343,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_get_statistics": {
                 "post": {
                     "operationId": "openwebui_get_statistics",
@@ -1261,13 +1360,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/openwebui_search_users": {
                 "post": {
                     "operationId": "openwebui_search_users",
@@ -1281,27 +1380,27 @@
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {
                                             "type": "string",
-                                            "description": "Search query (email or name)"
+                                            "description": "Search query (email or name)",
                                         }
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             # ============== ROMM ==============
             "/tools/romm_get_platforms": {
                 "post": {
@@ -1313,13 +1412,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/romm_get_roms": {
                 "post": {
                     "operationId": "romm_get_roms",
@@ -1329,13 +1428,20 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "platform_id": {"type": "integer", "description": "Platform ID to filter"},
-                                        "limit": {"type": "integer", "default": 50, "description": "Max results"}
-                                    }
+                                        "platform_id": {
+                                            "type": "integer",
+                                            "description": "Platform ID to filter",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "default": 50,
+                                            "description": "Max results",
+                                        },
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1343,13 +1449,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/romm_search": {
                 "post": {
                     "operationId": "romm_search",
@@ -1362,25 +1468,25 @@
                                 "schema": {
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {"type": "string", "description": "Search query"}
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/romm_get_statistics": {
                 "post": {
                     "operationId": "romm_get_statistics",
@@ -1391,13 +1497,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             # ============== KOMGA ==============
             "/tools/komga_get_libraries": {
                 "post": {
@@ -1409,13 +1515,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/komga_get_series": {
                 "post": {
                     "operationId": "komga_get_series",
@@ -1425,13 +1531,20 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "library_id": {"type": "string", "description": "Library ID to filter"},
-                                        "limit": {"type": "integer", "default": 50, "description": "Max results"}
-                                    }
+                                        "library_id": {
+                                            "type": "string",
+                                            "description": "Library ID to filter",
+                                        },
+                                        "limit": {
+                                            "type": "integer",
+                                            "default": 50,
+                                            "description": "Max results",
+                                        },
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1439,13 +1552,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/komga_search": {
                 "post": {
                     "operationId": "komga_search",
@@ -1458,25 +1571,25 @@
                                 "schema": {
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {"type": "string", "description": "Search query"}
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/komga_get_statistics": {
                 "post": {
                     "operationId": "komga_get_statistics",
@@ -1487,13 +1600,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             # ============== SONARR ==============
             "/tools/sonarr_get_series": {
                 "post": {
@@ -1504,12 +1617,16 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "limit": {"type": "integer", "default": 50, "description": "Max results"}
-                                    }
+                                        "limit": {
+                                            "type": "integer",
+                                            "default": 50,
+                                            "description": "Max results",
+                                        }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1517,13 +1634,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/sonarr_search_series": {
                 "post": {
                     "operationId": "sonarr_search_series",
@@ -1535,26 +1652,29 @@
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
-                                        "query": {"type": "string", "description": "TV series title"}
-                                    }
+                                        "query": {
+                                            "type": "string",
+                                            "description": "TV series title",
+                                        }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/sonarr_get_queue": {
                 "post": {
                     "operationId": "sonarr_get_queue",
@@ -1565,13 +1685,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/sonarr_get_calendar": {
                 "post": {
                     "operationId": "sonarr_get_calendar",
@@ -1581,12 +1701,16 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "default": 7, "description": "Days ahead"}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "default": 7,
+                                            "description": "Days ahead",
+                                        }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1594,13 +1718,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/sonarr_get_statistics": {
                 "post": {
                     "operationId": "sonarr_get_statistics",
@@ -1611,13 +1735,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             # ============== RADARR ==============
             "/tools/radarr_get_movies": {
                 "post": {
@@ -1628,12 +1752,16 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "limit": {"type": "integer", "default": 50, "description": "Max results"}
-                                    }
+                                        "limit": {
+                                            "type": "integer",
+                                            "default": 50,
+                                            "description": "Max results",
+                                        }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1641,13 +1769,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/radarr_search_movie": {
                 "post": {
                     "operationId": "radarr_search_movie",
@@ -1660,25 +1788,25 @@
                                 "schema": {
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {"type": "string", "description": "Movie title"}
-                                    }
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/radarr_get_queue": {
                 "post": {
                     "operationId": "radarr_get_queue",
@@ -1689,13 +1817,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/radarr_get_calendar": {
                 "post": {
                     "operationId": "radarr_get_calendar",
@@ -1705,12 +1833,16 @@
                         "content": {
                             "application/json": {
                                 "schema": {
                                     "type": "object",
                                     "properties": {
-                                        "days": {"type": "integer", "default": 7, "description": "Days ahead"}
-                                    }
+                                        "days": {
+                                            "type": "integer",
+                                            "default": 7,
+                                            "description": "Days ahead",
+                                        }
+                                    },
                                 }
                             }
                         }
                     },
                     "responses": {
@@ -1718,13 +1850,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/radarr_get_statistics": {
                 "post": {
                     "operationId": "radarr_get_statistics",
@@ -1735,13 +1867,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             # ============== PROWLARR ==============
             "/tools/prowlarr_get_indexers": {
                 "post": {
@@ -1753,13 +1885,13 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/prowlarr_search": {
                 "post": {
                     "operationId": "prowlarr_search",
@@ -1772,26 +1904,30 @@
                                 "schema": {
                                     "type": "object",
                                     "required": ["query"],
                                     "properties": {
                                         "query": {"type": "string", "description": "Search query"},
-                                        "limit": {"type": "integer", "default": 50, "description": "Max results"}
-                                    }
+                                        "limit": {
+                                            "type": "integer",
+                                            "default": 50,
+                                            "description": "Max results",
+                                        },
+                                    },
                                 }
                             }
-                        }
-                    },
-                    "responses": {
-                        "200": {
-                            "description": "Successful response",
-                            "content": {
-                                "application/json": {
-                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
-                                }
-                            }
-                        }
-                    }
+                        },
+                    },
+                    "responses": {
+                        "200": {
+                            "description": "Successful response",
+                            "content": {
+                                "application/json": {
+                                    "schema": {"$ref": "#/components/schemas/ToolResponse"}
+                                }
+                            },
+                        }
+                    },
                 }
             },
             "/tools/prowlarr_get_statistics": {
                 "post": {
                     "operationId": "prowlarr_get_statistics",
@@ -1802,38 +1938,38 @@
                             "description": "Successful response",
                             "content": {
                                 "application/json": {
                                     "schema": {"$ref": "#/components/schemas/ToolResponse"}
                                 }
-                            }
-                        }
-                    }
-                }
-            }
+                            },
+                        }
+                    },
+                }
+            },
         },
         "components": {
             "schemas": {
                 "ToolResponse": {
                     "type": "object",
                     "properties": {
                         "success": {
                             "type": "boolean",
-                            "description": "Whether the tool executed successfully"
+                            "description": "Whether the tool executed successfully",
                         },
                         "result": {
                             "type": "object",
-                            "description": "The result data from the tool"
+                            "description": "The result data from the tool",
                         },
                         "error": {
                             "type": "string",
-                            "description": "Error message if the tool failed"
-                        }
-                    },
-                    "required": ["success"]
+                            "description": "Error message if the tool failed",
+                        },
+                    },
+                    "required": ["success"],
                 }
             }
-        }
+        },
     }
 
 
 def filter_spec_by_services(spec: dict, services: list[str], title: str, description: str) -> dict:
     """Filter OpenAPI spec to include only paths for specified services."""
@@ -1844,153 +1980,159 @@
         if path_service in services:
             filtered_paths[path] = path_def
 
     return {
         "openapi": spec["openapi"],
-        "info": {
-            "title": title,
-            "description": description,
-            "version": spec["info"]["version"]
-        },
+        "info": {"title": title, "description": description, "version": spec["info"]["version"]},
         "paths": filtered_paths,
-        "components": spec.get("components", {})
+        "components": spec.get("components", {}),
     }
 
 
-@router.get(
-    "/openapi.json",
-    include_in_schema=False,
-    response_class=JSONResponse
-)
+@router.get("/openapi.json", include_in_schema=False, response_class=JSONResponse)
 async def get_openwebui_openapi():
     """Get OpenAPI spec optimized for Open WebUI compatibility."""
     return JSONResponse(content=generate_openwebui_openapi_spec())
 
 
-@router.get(
-    "/media/openapi.json",
-    include_in_schema=False,
-    response_class=JSONResponse
-)
+@router.get("/media/openapi.json", include_in_schema=False, response_class=JSONResponse)
 async def get_media_openapi():
     """Get OpenAPI spec for media tools (Plex, Tautulli, Overseerr, Komga, RomM)."""
     full_spec = generate_openwebui_openapi_spec()
-    return JSONResponse(content=filter_spec_by_services(
-        full_spec,
-        ["plex", "tautulli", "overseerr", "komga", "romm"],
-        "MCParr Media Tools",
-        "AI tools for media playback and libraries (Plex, Tautulli, Overseerr, Komga, RomM)"
-    ))
-
-
-@router.get(
-    "/processing/openapi.json",
-    include_in_schema=False,
-    response_class=JSONResponse
-)
+    return JSONResponse(
+        content=filter_spec_by_services(
+            full_spec,
+            ["plex", "tautulli", "overseerr", "komga", "romm"],
+            "MCParr Media Tools",
+            "AI tools for media playback and libraries (Plex, Tautulli, Overseerr, Komga, RomM)",
+        )
+    )
+
+
+@router.get("/processing/openapi.json", include_in_schema=False, response_class=JSONResponse)
 async def get_processing_openapi():
     """Get OpenAPI spec for media processing tools (Radarr, Sonarr, Prowlarr, Jackett, Deluge)."""
     full_spec = generate_openwebui_openapi_spec()
-    return JSONResponse(content=filter_spec_by_services(
-        full_spec,
-        ["radarr", "sonarr", "prowlarr", "jackett", "deluge"],
-        "MCParr Processing Tools",
-        "AI tools for media acquisition and processing (Radarr, Sonarr, Prowlarr, Jackett, Deluge)"
-    ))
-
-
-@router.get(
-    "/system/openapi.json",
-    include_in_schema=False,
-    response_class=JSONResponse
-)
+    return JSONResponse(
+        content=filter_spec_by_services(
+            full_spec,
+            ["radarr", "sonarr", "prowlarr", "jackett", "deluge"],
+            "MCParr Processing Tools",
+            "AI tools for media acquisition and processing (Radarr, Sonarr, Prowlarr, Jackett, Deluge)",
+        )
+    )
+
+
+@router.get("/system/openapi.json", include_in_schema=False, response_class=JSONResponse)
 async def get_system_openapi():
     """Get OpenAPI spec for system tools (System, OpenWebUI, Zammad)."""
     full_spec = generate_openwebui_openapi_spec()
-    return JSONResponse(content=filter_spec_by_services(
-        full_spec,
-        ["system", "openwebui", "zammad"],
-        "MCParr System Tools",
-        "AI tools for system management (health, support)"
-    ))
+    return JSONResponse(
+        content=filter_spec_by_services(
+            full_spec,
+            ["system", "openwebui", "zammad"],
+            "MCParr System Tools",
+            "AI tools for system management (health, support)",
+        )
+    )
 
 
 # ============================================================================
 # Pydantic models for tool requests/responses
 # ============================================================================
 
+
 class ToolResponse(BaseModel):
     """Standard response for all tools."""
+
     success: bool
     result: Optional[Dict[str, Any]] = None
     error: Optional[str] = None
 
 
 # --- Plex Tools ---
 
+
 class PlexSearchRequest(BaseModel):
     """Search for media in Plex library."""
+
     query: str = Field(..., description="Search query (title, actor, director, etc.)")
-    media_type: Optional[str] = Field(None, description="Type of media: movie, show, episode, artist, album, track")
+    media_type: Optional[str] = Field(
+        None, description="Type of media: movie, show, episode, artist, album, track"
+    )
     limit: int = Field(10, description="Maximum number of results to return")
 
 
 class PlexRecentlyAddedRequest(BaseModel):
     """Get recently added media."""
-    library_name: Optional[str] = Field(None, description="Name of the library (e.g., 'Movies', 'TV Shows')")
+
+    library_name: Optional[str] = Field(
+        None, description="Name of the library (e.g., 'Movies', 'TV Shows')"
+    )
     limit: int = Field(10, description="Maximum number of items to return")
 
 
 class PlexOnDeckRequest(BaseModel):
     """Get on deck items."""
+
     limit: int = Field(10, description="Maximum number of items to return")
 
 
 class PlexMediaDetailsRequest(BaseModel):
     """Get details for a specific media item."""
+
     title: str = Field(..., description="Title of the movie or TV show")
     year: Optional[int] = Field(None, description="Release year (helps with disambiguation)")
 
 
 # --- Overseerr Tools ---
 
+
 class OverseerrSearchRequest(BaseModel):
     """Search for media in Overseerr."""
+
     query: str = Field(..., description="Search query for movies or TV shows")
     media_type: Optional[str] = Field(None, description="Filter by type: movie or tv")
 
 
 class OverseerrRequestMediaRequest(BaseModel):
     """Request media through Overseerr."""
+
     title: str = Field(..., description="Title of the media to request")
     media_type: str = Field(..., description="Type of media: movie or tv")
     year: Optional[int] = Field(None, description="Release year for disambiguation")
 
 
 # --- Tautulli Tools ---
 
+
 class TautulliHistoryRequest(BaseModel):
     """Get play history from Tautulli."""
+
     length: int = Field(25, description="Number of history items to return")
     user: Optional[str] = Field(None, description="Filter history by username")
 
 
 class TautulliRecentlyAddedRequest(BaseModel):
     """Get recently added items."""
+
     count: int = Field(25, description="Number of recently added items to return")
 
 
 # --- Zammad Tools ---
+
 
 class ZammadSearchTicketsRequest(BaseModel):
     """Search Zammad tickets."""
+
     query: str = Field(..., description="Search query for tickets")
     limit: int = Field(10, description="Maximum number of results")
 
 
 class ZammadCreateTicketRequest(BaseModel):
     """Create a new Zammad ticket."""
+
     title: str = Field(..., description="Ticket title/subject")
     body: str = Field(..., description="Ticket body/description")
     customer_email: Optional[str] = Field(None, description="Customer email address")
     priority: Optional[str] = Field("normal", description="Priority: low, normal, high")
 
@@ -2051,25 +2193,24 @@
 
 # ============================================================================
 # Helper to get tool registry with enabled services
 # ============================================================================
 
+
 async def get_tool_registry(session: AsyncSession) -> ToolRegistry:
     """Get tool registry with enabled services."""
-    result = await session.execute(
-        select(ServiceConfig).where(ServiceConfig.enabled is True)
-    )
+    result = await session.execute(select(ServiceConfig).where(ServiceConfig.enabled is True))
     enabled_services = result.scalars().all()
 
     configs_by_type = {}
     for svc in enabled_services:
         svc_type = svc.service_type.lower()
         # Construct full URL with port if specified
         base_url = svc.base_url
         if svc.port:
             # Remove trailing slash if present
-            base_url = base_url.rstrip('/')
+            base_url = base_url.rstrip("/")
             base_url = f"{base_url}:{svc.port}"
         configs_by_type[svc_type] = {
             "base_url": base_url,
             "api_key": svc.api_key,
             "username": svc.username,
@@ -2196,19 +2337,18 @@
                         f"[MCP] Access denied for user {central_user_id} to tool {tool_name}: "
                         f"{permission_result.denial_reason}"
                     )
                     # Log the denied request
                     mcp_request.mark_failed(
-                        f"Access denied: {permission_result.denial_reason}",
-                        "PermissionDenied"
+                        f"Access denied: {permission_result.denial_reason}", "PermissionDenied"
                     )
                     session.add(mcp_request)
                     await session.commit()
                     return {
                         "success": False,
                         "error": f"Access denied: You don't have permission to use this tool. {permission_result.denial_reason}",
-                        "error_type": "PermissionDenied"
+                        "error_type": "PermissionDenied",
                     }
                 else:
                     logger.info(
                         f"[MCP] Access granted for user {central_user_id} to tool {tool_name} "
                         f"by group: {permission_result.granted_by_group}"
@@ -2233,12 +2373,11 @@
         # Mark as completed
         if result.get("success"):
             mcp_request.mark_completed(result)
         else:
             mcp_request.mark_failed(
-                result.get("error", "Unknown error"),
-                result.get("error_type", "ToolError")
+                result.get("error", "Unknown error"), result.get("error_type", "ToolError")
             )
 
         await session.commit()
         return result
 
@@ -2250,69 +2389,60 @@
 
 # ============================================================================
 # System Tools
 # ============================================================================
 
+
 @router.post(
     "/system_get_health",
     response_model=ToolResponse,
     summary="Get system health status",
-    description="Get overall system health status including CPU, memory, disk usage and any issues detected."
-)
-async def system_get_health(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get overall system health status including CPU, memory, disk usage and any issues detected.",
+)
+async def system_get_health(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get system health status."""
     result = await execute_tool_with_logging(session, "system_get_health", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/system_get_metrics",
     response_model=ToolResponse,
     summary="Get system metrics",
-    description="Get current system resource metrics including CPU, memory, disk, network usage and uptime."
-)
-async def system_get_metrics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get current system resource metrics including CPU, memory, disk, network usage and uptime.",
+)
+async def system_get_metrics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get system metrics."""
     result = await execute_tool_with_logging(session, "system_get_metrics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Plex Tools
 # ============================================================================
 
+
 @router.post(
     "/plex_get_libraries",
     response_model=ToolResponse,
     summary="Get Plex libraries",
-    description="Get list of all Plex media libraries (Movies, TV Shows, Music, etc.)"
-)
-async def plex_get_libraries(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of all Plex media libraries (Movies, TV Shows, Music, etc.)",
+)
+async def plex_get_libraries(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get all Plex libraries."""
     result = await execute_tool_with_logging(session, "plex_get_libraries", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/plex_search_media",
     response_model=ToolResponse,
     summary="Search Plex media",
-    description="Search for movies, TV shows, or other media in Plex library by title, actor, director, etc."
+    description="Search for movies, TV shows, or other media in Plex library by title, actor, director, etc.",
 )
 async def plex_search_media(
-    request: Request,
-    body: PlexSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: PlexSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search for media in Plex."""
     result = await execute_tool_with_logging(
         session, "plex_search_media", body.model_dump(exclude_none=True), request
     )
@@ -2321,16 +2451,16 @@
 
 @router.post(
     "/plex_get_recently_added",
     response_model=ToolResponse,
     summary="Get recently added media",
-    description="Get recently added media to Plex library. Can filter by library name."
+    description="Get recently added media to Plex library. Can filter by library name.",
 )
 async def plex_get_recently_added(
     request: Request,
     body: PlexRecentlyAddedRequest = PlexRecentlyAddedRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get recently added media."""
     result = await execute_tool_with_logging(
         session, "plex_get_recently_added", body.model_dump(exclude_none=True), request
     )
@@ -2339,16 +2469,16 @@
 
 @router.post(
     "/plex_get_on_deck",
     response_model=ToolResponse,
     summary="Get On Deck items",
-    description="Get 'On Deck' items (continue watching) for the Plex server."
+    description="Get 'On Deck' items (continue watching) for the Plex server.",
 )
 async def plex_get_on_deck(
     request: Request,
     body: PlexOnDeckRequest = PlexOnDeckRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get on deck items."""
     result = await execute_tool_with_logging(
         session, "plex_get_on_deck", body.model_dump(), request
     )
@@ -2357,16 +2487,14 @@
 
 @router.post(
     "/plex_get_media_details",
     response_model=ToolResponse,
     summary="Get media details",
-    description="Get detailed information about a specific movie or TV show including cast, genres, rating."
+    description="Get detailed information about a specific movie or TV show including cast, genres, rating.",
 )
 async def plex_get_media_details(
-    request: Request,
-    body: PlexMediaDetailsRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: PlexMediaDetailsRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Get media details."""
     result = await execute_tool_with_logging(
         session, "plex_get_media_details", body.model_dump(exclude_none=True), request
     )
@@ -2375,35 +2503,33 @@
 
 @router.post(
     "/plex_get_active_sessions",
     response_model=ToolResponse,
     summary="Get active streaming sessions",
-    description="Get list of currently active streaming sessions on Plex (who is watching what)."
+    description="Get list of currently active streaming sessions on Plex (who is watching what).",
 )
 async def plex_get_active_sessions(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get active streaming sessions."""
     result = await execute_tool_with_logging(session, "plex_get_active_sessions", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Overseerr Tools
 # ============================================================================
 
+
 @router.post(
     "/overseerr_search",
     response_model=ToolResponse,
     summary="Search Overseerr",
-    description="Search for movies or TV shows in Overseerr to check availability or request."
+    description="Search for movies or TV shows in Overseerr to check availability or request.",
 )
 async def overseerr_search(
-    request: Request,
-    body: OverseerrSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: OverseerrSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search Overseerr."""
     result = await execute_tool_with_logging(
         session, "overseerr_search", body.model_dump(exclude_none=True), request
     )
@@ -2412,31 +2538,28 @@
 
 @router.post(
     "/overseerr_get_requests",
     response_model=ToolResponse,
     summary="Get Overseerr requests",
-    description="Get list of pending and recent media requests from Overseerr."
-)
-async def overseerr_get_requests(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of pending and recent media requests from Overseerr.",
+)
+async def overseerr_get_requests(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Overseerr requests."""
     result = await execute_tool_with_logging(session, "overseerr_get_requests", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/overseerr_request_media",
     response_model=ToolResponse,
     summary="Request media on Overseerr",
-    description="Request a movie or TV show to be added to the library via Overseerr."
+    description="Request a movie or TV show to be added to the library via Overseerr.",
 )
 async def overseerr_request_media(
     request: Request,
     body: OverseerrRequestMediaRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Request media on Overseerr."""
     result = await execute_tool_with_logging(
         session, "overseerr_request_media", body.model_dump(exclude_none=True), request
     )
@@ -2445,50 +2568,45 @@
 
 @router.post(
     "/overseerr_get_trending",
     response_model=ToolResponse,
     summary="Get trending media",
-    description="Get trending movies and TV shows from Overseerr."
-)
-async def overseerr_get_trending(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get trending movies and TV shows from Overseerr.",
+)
+async def overseerr_get_trending(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get trending media."""
     result = await execute_tool_with_logging(session, "overseerr_get_trending", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Tautulli Tools
 # ============================================================================
 
+
 @router.post(
     "/tautulli_get_activity",
     response_model=ToolResponse,
     summary="Get Plex activity",
-    description="Get current Plex streaming activity including active sessions, bandwidth usage, and stream counts."
-)
-async def tautulli_get_activity(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get current Plex streaming activity including active sessions, bandwidth usage, and stream counts.",
+)
+async def tautulli_get_activity(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get current Plex activity."""
     result = await execute_tool_with_logging(session, "tautulli_get_activity", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/tautulli_get_history",
     response_model=ToolResponse,
     summary="Get play history",
-    description="Get play history from Tautulli with optional user filtering."
+    description="Get play history from Tautulli with optional user filtering.",
 )
 async def tautulli_get_history(
     request: Request,
     body: TautulliHistoryRequest = TautulliHistoryRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get play history."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_history", body.model_dump(exclude_none=True), request
     )
@@ -2497,61 +2615,54 @@
 
 @router.post(
     "/tautulli_get_users",
     response_model=ToolResponse,
     summary="Get Plex users",
-    description="Get list of all Plex users known to Tautulli with their details and permissions."
-)
-async def tautulli_get_users(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of all Plex users known to Tautulli with their details and permissions.",
+)
+async def tautulli_get_users(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Plex users."""
     result = await execute_tool_with_logging(session, "tautulli_get_users", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/tautulli_get_libraries",
     response_model=ToolResponse,
     summary="Get library statistics",
-    description="Get library statistics from Tautulli including item counts and types."
-)
-async def tautulli_get_libraries(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get library statistics from Tautulli including item counts and types.",
+)
+async def tautulli_get_libraries(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get library statistics."""
     result = await execute_tool_with_logging(session, "tautulli_get_libraries", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/tautulli_get_statistics",
     response_model=ToolResponse,
     summary="Get comprehensive statistics",
-    description="Get comprehensive statistics including activity, history, users, and libraries overview."
+    description="Get comprehensive statistics including activity, history, users, and libraries overview.",
 )
 async def tautulli_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get comprehensive statistics."""
     result = await execute_tool_with_logging(session, "tautulli_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/tautulli_get_recently_added",
     response_model=ToolResponse,
     summary="Get recently added via Tautulli",
-    description="Get recently added items to Plex libraries via Tautulli."
+    description="Get recently added items to Plex libraries via Tautulli.",
 )
 async def tautulli_get_recently_added(
     request: Request,
     body: TautulliRecentlyAddedRequest = TautulliRecentlyAddedRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get recently added items."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_recently_added", body.model_dump(), request
     )
@@ -2560,30 +2671,27 @@
 
 @router.post(
     "/tautulli_get_server_info",
     response_model=ToolResponse,
     summary="Get server info",
-    description="Get Tautulli and Plex server information including versions and status."
+    description="Get Tautulli and Plex server information including versions and status.",
 )
 async def tautulli_get_server_info(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get server information."""
     result = await execute_tool_with_logging(session, "tautulli_get_server_info", {}, request)
     return ToolResponse(**result)
 
 
 class TautulliMyStatsRequest(BaseModel):
     """Request body for tautulli_get_my_stats."""
+
     length: int = Field(default=25, description="Number of history items to return")
 
 
-async def get_user_tautulli_mapping(
-    session: AsyncSession,
-    openwebui_user: dict
-) -> Optional[str]:
+async def get_user_tautulli_mapping(session: AsyncSession, openwebui_user: dict) -> Optional[str]:
     """
     Get the Tautulli username for an Open WebUI user.
 
     Args:
         session: Database session
@@ -2622,12 +2730,11 @@
         return None
 
     # Now find the Tautulli service config
     tautulli_service = await session.execute(
         select(ServiceConfig).where(
-            ServiceConfig.service_type == "tautulli",
-            ServiceConfig.enabled is True
+            ServiceConfig.service_type == "tautulli", ServiceConfig.enabled is True
         )
     )
     tautulli_config = tautulli_service.scalar_one_or_none()
 
     if not tautulli_config:
@@ -2636,11 +2743,11 @@
     # Find the user's Tautulli mapping
     tautulli_mapping = await session.execute(
         select(UserMapping).where(
             UserMapping.central_user_id == central_user_id,
             UserMapping.service_config_id == str(tautulli_config.id),
-            UserMapping.enabled is True
+            UserMapping.enabled is True,
         )
     )
     mapping = tautulli_mapping.scalar_one_or_none()
 
     if mapping:
@@ -2651,38 +2758,38 @@
 
 @router.post(
     "/tautulli_get_my_stats",
     response_model=ToolResponse,
     summary="Get my personal viewing statistics",
-    description="Get your personal viewing history and statistics from Tautulli. Requires a user mapping between Open WebUI and Tautulli."
+    description="Get your personal viewing history and statistics from Tautulli. Requires a user mapping between Open WebUI and Tautulli.",
 )
 async def tautulli_get_my_stats(
     request: Request,
     body: TautulliMyStatsRequest = TautulliMyStatsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get personal viewing statistics for the current user."""
     from datetime import datetime
 
     # Resolve Open WebUI user
     openwebui_user = await resolve_openwebui_user(request)
     if not openwebui_user:
         return ToolResponse(
             success=False,
-            error="Impossible d'identifier l'utilisateur. Veuillez vous connecter  Open WebUI."
+            error="Impossible d'identifier l'utilisateur. Veuillez vous connecter  Open WebUI.",
         )
 
     # Get Tautulli username mapping
     tautulli_username = await get_user_tautulli_mapping(session, openwebui_user)
 
     if not tautulli_username:
         user_display = openwebui_user.get("name") or openwebui_user.get("email") or "Utilisateur"
         return ToolResponse(
             success=False,
             error=f"Aucun mapping Tautulli trouv pour {user_display}. "
-                  f"Veuillez configurer le mapping utilisateur dans les paramtres "
-                  f"(Open WebUI  Tautulli) pour accder  vos statistiques personnelles."
+            f"Veuillez configurer le mapping utilisateur dans les paramtres "
+            f"(Open WebUI  Tautulli) pour accder  vos statistiques personnelles.",
         )
 
     # Log the request with user context
     mcp_request = McpRequest(
         tool_name="tautulli_get_my_stats",
@@ -2700,31 +2807,29 @@
 
     try:
         # Get Tautulli service config
         tautulli_service = await session.execute(
             select(ServiceConfig).where(
-                ServiceConfig.service_type == "tautulli",
-                ServiceConfig.enabled is True
+                ServiceConfig.service_type == "tautulli", ServiceConfig.enabled is True
             )
         )
         tautulli_config = tautulli_service.scalar_one_or_none()
 
         if not tautulli_config:
             mcp_request.mark_failed("Tautulli service not configured", "ConfigError")
             await session.commit()
-            return ToolResponse(
-                success=False,
-                error="Le service Tautulli n'est pas configur."
-            )
+            return ToolResponse(success=False, error="Le service Tautulli n'est pas configur.")
 
         # Create adapter and get history for the user
         from src.adapters.tautulli import TautulliAdapter
 
         class ServiceConfigProxy:
             def __init__(self, config):
                 self.api_key = config.api_key
-                self.base_url = f"{config.base_url}:{config.port}" if config.port else config.base_url
+                self.base_url = (
+                    f"{config.base_url}:{config.port}" if config.port else config.base_url
+                )
                 self.port = None
                 self.config = config.config or {}
 
             def get_config_value(self, key: str, default=None):
                 return self.config.get(key, default)
@@ -2762,11 +2867,11 @@
                     "percent_complete": item.get("percent_complete"),
                     "watched_status": item.get("watched_status"),
                     "player": item.get("player"),
                 }
                 for item in history_items
-            ]
+            ],
         }
 
         end_time = datetime.utcnow()
         duration_ms = int((end_time - start_time).total_seconds() * 1000)
 
@@ -2802,46 +2907,50 @@
 
 
 # New Tautulli statistics models
 class TautulliTopRequest(BaseModel):
     """Request body for top statistics endpoints."""
+
     days: int = Field(default=30, description="Number of days to analyze")
     stats_type: str = Field(default="plays", description="Type of stats: 'plays' or 'duration'")
     limit: int = Field(default=10, description="Number of items to return")
 
 
 class TautulliTopWithUserRequest(BaseModel):
     """Request body for top statistics with optional user filter."""
+
     days: int = Field(default=30, description="Number of days to analyze")
     stats_type: str = Field(default="plays", description="Type of stats: 'plays' or 'duration'")
     limit: int = Field(default=10, description="Number of items to return")
     username: Optional[str] = Field(default=None, description="Filter by username (optional)")
 
 
 class TautulliUserStatsRequest(BaseModel):
     """Request body for user statistics."""
+
     username: str = Field(..., description="Username or friendly name of the user")
     days: int = Field(default=30, description="Number of days to analyze")
 
 
 class TautulliWatchSummaryRequest(BaseModel):
     """Request body for watch statistics summary."""
+
     days: int = Field(default=30, description="Number of days to analyze")
     stats_type: str = Field(default="plays", description="Type of stats: 'plays' or 'duration'")
     limit: int = Field(default=5, description="Number of items per category")
 
 
 @router.post(
     "/tautulli_get_top_users",
     response_model=ToolResponse,
     summary="Get top Plex users",
-    description="Get top Plex users by play count or watch duration over a specified period."
+    description="Get top Plex users by play count or watch duration over a specified period.",
 )
 async def tautulli_get_top_users(
     request: Request,
     body: TautulliTopRequest = TautulliTopRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get top users by plays or duration."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_top_users", body.model_dump(), request
     )
@@ -2850,16 +2959,16 @@
 
 @router.post(
     "/tautulli_get_top_movies",
     response_model=ToolResponse,
     summary="Get top watched movies",
-    description="Get top watched movies over a specified period, optionally filtered by user."
+    description="Get top watched movies over a specified period, optionally filtered by user.",
 )
 async def tautulli_get_top_movies(
     request: Request,
     body: TautulliTopWithUserRequest = TautulliTopWithUserRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get top watched movies."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_top_movies", body.model_dump(exclude_none=True), request
     )
@@ -2868,16 +2977,16 @@
 
 @router.post(
     "/tautulli_get_top_tv_shows",
     response_model=ToolResponse,
     summary="Get top watched TV shows",
-    description="Get top watched TV shows over a specified period, optionally filtered by user."
+    description="Get top watched TV shows over a specified period, optionally filtered by user.",
 )
 async def tautulli_get_top_tv_shows(
     request: Request,
     body: TautulliTopWithUserRequest = TautulliTopWithUserRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get top watched TV shows."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_top_tv_shows", body.model_dump(exclude_none=True), request
     )
@@ -2886,16 +2995,16 @@
 
 @router.post(
     "/tautulli_get_top_music",
     response_model=ToolResponse,
     summary="Get top listened music",
-    description="Get top listened music over a specified period, optionally filtered by user."
+    description="Get top listened music over a specified period, optionally filtered by user.",
 )
 async def tautulli_get_top_music(
     request: Request,
     body: TautulliTopWithUserRequest = TautulliTopWithUserRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get top listened music."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_top_music", body.model_dump(exclude_none=True), request
     )
@@ -2904,16 +3013,16 @@
 
 @router.post(
     "/tautulli_get_top_platforms",
     response_model=ToolResponse,
     summary="Get top streaming platforms",
-    description="Get most used platforms/devices for streaming over a specified period."
+    description="Get most used platforms/devices for streaming over a specified period.",
 )
 async def tautulli_get_top_platforms(
     request: Request,
     body: TautulliTopRequest = TautulliTopRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get top platforms."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_top_platforms", body.model_dump(), request
     )
@@ -2922,16 +3031,16 @@
 
 @router.post(
     "/tautulli_get_user_stats",
     response_model=ToolResponse,
     summary="Get user statistics",
-    description="Get detailed watch statistics for a specific user including watch time, top content, and devices."
+    description="Get detailed watch statistics for a specific user including watch time, top content, and devices.",
 )
 async def tautulli_get_user_stats(
     request: Request,
     body: TautulliUserStatsRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get detailed statistics for a specific user."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_user_stats", body.model_dump(), request
     )
@@ -2940,16 +3049,16 @@
 
 @router.post(
     "/tautulli_get_watch_stats_summary",
     response_model=ToolResponse,
     summary="Get watch statistics summary",
-    description="Get a comprehensive summary of watch statistics including top users, movies, TV shows, and platforms."
+    description="Get a comprehensive summary of watch statistics including top users, movies, TV shows, and platforms.",
 )
 async def tautulli_get_watch_stats_summary(
     request: Request,
     body: TautulliWatchSummaryRequest = TautulliWatchSummaryRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get comprehensive watch statistics summary."""
     result = await execute_tool_with_logging(
         session, "tautulli_get_watch_stats_summary", body.model_dump(), request
     )
@@ -2958,35 +3067,33 @@
 
 # ============================================================================
 # Zammad Tools
 # ============================================================================
 
+
 @router.post(
     "/zammad_get_tickets",
     response_model=ToolResponse,
     summary="Get support tickets",
-    description="Get list of support tickets from Zammad with their status."
-)
-async def zammad_get_tickets(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of support tickets from Zammad with their status.",
+)
+async def zammad_get_tickets(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get support tickets."""
     result = await execute_tool_with_logging(session, "zammad_get_tickets", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/zammad_search_tickets",
     response_model=ToolResponse,
     summary="Search tickets",
-    description="Search Zammad tickets by keyword."
+    description="Search Zammad tickets by keyword.",
 )
 async def zammad_search_tickets(
     request: Request,
     body: ZammadSearchTicketsRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Search tickets."""
     result = await execute_tool_with_logging(
         session, "zammad_search_tickets", body.model_dump(), request
     )
@@ -2995,16 +3102,16 @@
 
 @router.post(
     "/zammad_create_ticket",
     response_model=ToolResponse,
     summary="Create support ticket",
-    description="Create a new support ticket in Zammad."
+    description="Create a new support ticket in Zammad.",
 )
 async def zammad_create_ticket(
     request: Request,
     body: ZammadCreateTicketRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Create a support ticket."""
     result = await execute_tool_with_logging(
         session, "zammad_create_ticket", body.model_dump(exclude_none=True), request
     )
@@ -3013,64 +3120,67 @@
 
 @router.post(
     "/zammad_get_organizations",
     response_model=ToolResponse,
     summary="Get organizations",
-    description="Get list of organizations from Zammad."
+    description="Get list of organizations from Zammad.",
 )
 async def zammad_get_organizations(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get organizations."""
     result = await execute_tool_with_logging(session, "zammad_get_organizations", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/zammad_get_users",
     response_model=ToolResponse,
     summary="Get Zammad users",
-    description="Get list of users from Zammad."
-)
-async def zammad_get_users(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of users from Zammad.",
+)
+async def zammad_get_users(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Zammad users."""
     result = await execute_tool_with_logging(session, "zammad_get_users", {}, request)
     return ToolResponse(**result)
 
 
 class ZammadGetTicketDetailsRequest(BaseModel):
     """Get ticket details request."""
-    ticket_id: int = Field(..., description="ID or number of the ticket to retrieve (e.g., 1 or 20001)")
+
+    ticket_id: int = Field(
+        ..., description="ID or number of the ticket to retrieve (e.g., 1 or 20001)"
+    )
 
 
 class ZammadAddCommentRequest(BaseModel):
     """Add comment to ticket request."""
+
     ticket_id: int = Field(..., description="ID of the ticket")
     comment: str = Field(..., description="Comment content")
-    internal: bool = Field(False, description="Whether the comment is internal (not visible to customer)")
+    internal: bool = Field(
+        False, description="Whether the comment is internal (not visible to customer)"
+    )
 
 
 class ZammadUpdateTicketStatusRequest(BaseModel):
     """Update ticket status request."""
+
     ticket_id: int = Field(..., description="ID of the ticket")
     status: str = Field(..., description="New status for the ticket (open, pending, closed)")
 
 
 @router.post(
     "/zammad_get_ticket_details",
     response_model=ToolResponse,
     summary="Get ticket details",
-    description="Get detailed information about a specific ticket including all articles/messages."
+    description="Get detailed information about a specific ticket including all articles/messages.",
 )
 async def zammad_get_ticket_details(
     request: Request,
     body: ZammadGetTicketDetailsRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get ticket details."""
     result = await execute_tool_with_logging(
         session, "zammad_get_ticket_details", body.model_dump(), request
     )
@@ -3079,16 +3189,14 @@
 
 @router.post(
     "/zammad_add_comment",
     response_model=ToolResponse,
     summary="Add comment to ticket",
-    description="Add a comment/reply to an existing ticket."
+    description="Add a comment/reply to an existing ticket.",
 )
 async def zammad_add_comment(
-    request: Request,
-    body: ZammadAddCommentRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: ZammadAddCommentRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Add comment to ticket."""
     result = await execute_tool_with_logging(
         session, "zammad_add_comment", body.model_dump(), request
     )
@@ -3097,16 +3205,16 @@
 
 @router.post(
     "/zammad_update_ticket_status",
     response_model=ToolResponse,
     summary="Update ticket status",
-    description="Update the status of a ticket (open, pending, closed)."
+    description="Update the status of a ticket (open, pending, closed).",
 )
 async def zammad_update_ticket_status(
     request: Request,
     body: ZammadUpdateTicketStatusRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Update ticket status."""
     result = await execute_tool_with_logging(
         session, "zammad_update_ticket_status", body.model_dump(), request
     )
@@ -3115,65 +3223,65 @@
 
 @router.post(
     "/zammad_get_ticket_stats",
     response_model=ToolResponse,
     summary="Get ticket statistics",
-    description="Get statistics about tickets (open count, pending, closed, etc.)."
+    description="Get statistics about tickets (open count, pending, closed, etc.).",
 )
 async def zammad_get_ticket_stats(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get ticket statistics."""
     result = await execute_tool_with_logging(session, "zammad_get_ticket_stats", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Open WebUI Tools
 # ============================================================================
 
+
 class OpenWebUIUsersRequest(BaseModel):
     """Get Open WebUI users request."""
+
     limit: int = Field(50, description="Maximum number of users to return")
 
 
 class OpenWebUIChatsRequest(BaseModel):
     """Get Open WebUI chats request."""
+
     limit: int = Field(20, description="Maximum number of chats to return")
 
 
 class OpenWebUISearchUsersRequest(BaseModel):
     """Search Open WebUI users request."""
+
     query: str = Field(..., description="Search query (email or name)")
 
 
 @router.post(
     "/openwebui_get_status",
     response_model=ToolResponse,
     summary="Get Open WebUI status",
-    description="Get Open WebUI service status including version and current user info."
-)
-async def openwebui_get_status(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get Open WebUI service status including version and current user info.",
+)
+async def openwebui_get_status(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Open WebUI status."""
     result = await execute_tool_with_logging(session, "openwebui_get_status", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/openwebui_get_users",
     response_model=ToolResponse,
     summary="Get Open WebUI users",
-    description="Get list of all users registered in Open WebUI (requires admin privileges)."
+    description="Get list of all users registered in Open WebUI (requires admin privileges).",
 )
 async def openwebui_get_users(
     request: Request,
     body: OpenWebUIUsersRequest = OpenWebUIUsersRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Open WebUI users."""
     result = await execute_tool_with_logging(
         session, "openwebui_get_users", body.model_dump(), request
     )
@@ -3182,31 +3290,28 @@
 
 @router.post(
     "/openwebui_get_models",
     response_model=ToolResponse,
     summary="Get available AI models",
-    description="Get list of available AI models in Open WebUI."
-)
-async def openwebui_get_models(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of available AI models in Open WebUI.",
+)
+async def openwebui_get_models(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get available AI models."""
     result = await execute_tool_with_logging(session, "openwebui_get_models", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/openwebui_get_chats",
     response_model=ToolResponse,
     summary="Get chat history",
-    description="Get chat history for the authenticated user."
+    description="Get chat history for the authenticated user.",
 )
 async def openwebui_get_chats(
     request: Request,
     body: OpenWebUIChatsRequest = OpenWebUIChatsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get chat history."""
     result = await execute_tool_with_logging(
         session, "openwebui_get_chats", body.model_dump(), request
     )
@@ -3215,31 +3320,30 @@
 
 @router.post(
     "/openwebui_get_statistics",
     response_model=ToolResponse,
     summary="Get Open WebUI statistics",
-    description="Get Open WebUI statistics including user count, models, and chat activity."
+    description="Get Open WebUI statistics including user count, models, and chat activity.",
 )
 async def openwebui_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Open WebUI statistics."""
     result = await execute_tool_with_logging(session, "openwebui_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/openwebui_search_users",
     response_model=ToolResponse,
     summary="Search Open WebUI users",
-    description="Search for users by email or name in Open WebUI (requires admin privileges)."
+    description="Search for users by email or name in Open WebUI (requires admin privileges).",
 )
 async def openwebui_search_users(
     request: Request,
     body: OpenWebUISearchUsersRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Search Open WebUI users."""
     result = await execute_tool_with_logging(
         session, "openwebui_search_users", body.model_dump(), request
     )
@@ -3248,46 +3352,46 @@
 
 # ============================================================================
 # RomM Tools
 # ============================================================================
 
+
 class RommRomsRequest(BaseModel):
     """Get ROMs request."""
+
     platform_id: Optional[int] = Field(None, description="Filter by platform ID")
     limit: int = Field(50, description="Maximum number of ROMs to return")
 
 
 class RommSearchRequest(BaseModel):
     """Search ROMs request."""
+
     query: str = Field(..., description="Search query (game title)")
 
 
 @router.post(
     "/romm_get_platforms",
     response_model=ToolResponse,
     summary="Get ROM platforms",
-    description="Get list of gaming platforms in RomM."
-)
-async def romm_get_platforms(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of gaming platforms in RomM.",
+)
+async def romm_get_platforms(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get RomM platforms."""
     result = await execute_tool_with_logging(session, "romm_get_platforms", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/romm_get_roms",
     response_model=ToolResponse,
     summary="Get ROMs",
-    description="Get list of ROMs, optionally filtered by platform."
+    description="Get list of ROMs, optionally filtered by platform.",
 )
 async def romm_get_roms(
     request: Request,
     body: RommRomsRequest = RommRomsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get ROMs from RomM."""
     result = await execute_tool_with_logging(
         session, "romm_get_roms", body.model_dump(exclude_none=True), request
     )
@@ -3296,16 +3400,14 @@
 
 @router.post(
     "/romm_search",
     response_model=ToolResponse,
     summary="Search ROMs",
-    description="Search for ROMs by name."
+    description="Search for ROMs by name.",
 )
 async def romm_search(
-    request: Request,
-    body: RommSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: RommSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search ROMs in RomM."""
     result = await execute_tool_with_logging(
         session, "romm_search_roms", body.model_dump(), request
     )
@@ -3314,61 +3416,58 @@
 
 @router.post(
     "/romm_get_statistics",
     response_model=ToolResponse,
     summary="Get RomM statistics",
-    description="Get RomM library statistics."
-)
-async def romm_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get RomM library statistics.",
+)
+async def romm_get_statistics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get RomM statistics."""
     result = await execute_tool_with_logging(session, "romm_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Komga Tools
 # ============================================================================
 
+
 class KomgaSeriesRequest(BaseModel):
     """Get series request."""
+
     library_id: Optional[str] = Field(None, description="Filter by library ID")
     limit: int = Field(50, description="Maximum number of series to return")
 
 
 class KomgaSearchRequest(BaseModel):
     """Search Komga request."""
+
     query: str = Field(..., description="Search query")
 
 
 @router.post(
     "/komga_get_libraries",
     response_model=ToolResponse,
     summary="Get Komga libraries",
-    description="Get list of comic/manga libraries in Komga."
-)
-async def komga_get_libraries(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of comic/manga libraries in Komga.",
+)
+async def komga_get_libraries(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Komga libraries."""
     result = await execute_tool_with_logging(session, "komga_get_libraries", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/komga_get_series",
     response_model=ToolResponse,
     summary="Get Komga series",
-    description="Get list of comic/manga series."
+    description="Get list of comic/manga series.",
 )
 async def komga_get_series(
     request: Request,
     body: KomgaSeriesRequest = KomgaSeriesRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Komga series."""
     result = await execute_tool_with_logging(
         session, "komga_get_series", body.model_dump(exclude_none=True), request
     )
@@ -3377,68 +3476,65 @@
 
 @router.post(
     "/komga_search",
     response_model=ToolResponse,
     summary="Search Komga",
-    description="Search for series and books in Komga."
+    description="Search for series and books in Komga.",
 )
 async def komga_search(
-    request: Request,
-    body: KomgaSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: KomgaSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search Komga."""
-    result = await execute_tool_with_logging(
-        session, "komga_search", body.model_dump(), request
-    )
+    result = await execute_tool_with_logging(session, "komga_search", body.model_dump(), request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/komga_get_statistics",
     response_model=ToolResponse,
     summary="Get Komga statistics",
-    description="Get Komga library statistics."
-)
-async def komga_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get Komga library statistics.",
+)
+async def komga_get_statistics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Komga statistics."""
     result = await execute_tool_with_logging(session, "komga_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Radarr Tools
 # ============================================================================
 
+
 class RadarrMoviesRequest(BaseModel):
     """Get movies request."""
+
     limit: int = Field(50, description="Maximum number of movies to return")
 
 
 class RadarrSearchRequest(BaseModel):
     """Search movie request."""
+
     query: str = Field(..., description="Movie title to search for")
 
 
 class RadarrCalendarRequest(BaseModel):
     """Get calendar request."""
+
     days: int = Field(7, description="Number of days ahead to look")
 
 
 @router.post(
     "/radarr_get_movies",
     response_model=ToolResponse,
     summary="Get movies from Radarr",
-    description="Get list of movies in Radarr library."
+    description="Get list of movies in Radarr library.",
 )
 async def radarr_get_movies(
     request: Request,
     body: RadarrMoviesRequest = RadarrMoviesRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get movies from Radarr."""
     result = await execute_tool_with_logging(
         session, "radarr_get_movies", body.model_dump(), request
     )
@@ -3447,16 +3543,14 @@
 
 @router.post(
     "/radarr_search_movie",
     response_model=ToolResponse,
     summary="Search for movie",
-    description="Search for a movie to add to Radarr."
+    description="Search for a movie to add to Radarr.",
 )
 async def radarr_search_movie(
-    request: Request,
-    body: RadarrSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: RadarrSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search for movie in Radarr."""
     result = await execute_tool_with_logging(
         session, "radarr_search_movie", body.model_dump(), request
     )
@@ -3465,31 +3559,28 @@
 
 @router.post(
     "/radarr_get_queue",
     response_model=ToolResponse,
     summary="Get Radarr download queue",
-    description="Get current download queue in Radarr."
-)
-async def radarr_get_queue(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get current download queue in Radarr.",
+)
+async def radarr_get_queue(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Radarr download queue."""
     result = await execute_tool_with_logging(session, "radarr_get_queue", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/radarr_get_calendar",
     response_model=ToolResponse,
     summary="Get Radarr calendar",
-    description="Get upcoming movie releases."
+    description="Get upcoming movie releases.",
 )
 async def radarr_get_calendar(
     request: Request,
     body: RadarrCalendarRequest = RadarrCalendarRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Radarr calendar."""
     result = await execute_tool_with_logging(
         session, "radarr_get_calendar", body.model_dump(), request
     )
@@ -3498,50 +3589,51 @@
 
 @router.post(
     "/radarr_get_statistics",
     response_model=ToolResponse,
     summary="Get Radarr statistics",
-    description="Get Radarr library statistics."
-)
-async def radarr_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get Radarr library statistics.",
+)
+async def radarr_get_statistics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Radarr statistics."""
     result = await execute_tool_with_logging(session, "radarr_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Sonarr Tools
 # ============================================================================
 
+
 class SonarrSeriesRequest(BaseModel):
     """Get series request."""
+
     limit: int = Field(50, description="Maximum number of series to return")
 
 
 class SonarrSearchRequest(BaseModel):
     """Search series request."""
+
     query: str = Field(..., description="TV series title to search for")
 
 
 class SonarrCalendarRequest(BaseModel):
     """Get calendar request."""
+
     days: int = Field(7, description="Number of days ahead to look")
 
 
 @router.post(
     "/sonarr_get_series",
     response_model=ToolResponse,
     summary="Get TV series from Sonarr",
-    description="Get list of TV series in Sonarr library."
+    description="Get list of TV series in Sonarr library.",
 )
 async def sonarr_get_series(
     request: Request,
     body: SonarrSeriesRequest = SonarrSeriesRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get series from Sonarr."""
     result = await execute_tool_with_logging(
         session, "sonarr_get_series", body.model_dump(), request
     )
@@ -3550,16 +3642,14 @@
 
 @router.post(
     "/sonarr_search_series",
     response_model=ToolResponse,
     summary="Search for TV series",
-    description="Search for a TV series to add to Sonarr."
+    description="Search for a TV series to add to Sonarr.",
 )
 async def sonarr_search_series(
-    request: Request,
-    body: SonarrSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: SonarrSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search for series in Sonarr."""
     result = await execute_tool_with_logging(
         session, "sonarr_search_series", body.model_dump(), request
     )
@@ -3568,31 +3658,28 @@
 
 @router.post(
     "/sonarr_get_queue",
     response_model=ToolResponse,
     summary="Get Sonarr download queue",
-    description="Get current download queue in Sonarr."
-)
-async def sonarr_get_queue(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get current download queue in Sonarr.",
+)
+async def sonarr_get_queue(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Sonarr download queue."""
     result = await execute_tool_with_logging(session, "sonarr_get_queue", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/sonarr_get_calendar",
     response_model=ToolResponse,
     summary="Get Sonarr calendar",
-    description="Get upcoming TV episode releases."
+    description="Get upcoming TV episode releases.",
 )
 async def sonarr_get_calendar(
     request: Request,
     body: SonarrCalendarRequest = SonarrCalendarRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Sonarr calendar."""
     result = await execute_tool_with_logging(
         session, "sonarr_get_calendar", body.model_dump(), request
     )
@@ -3601,163 +3688,157 @@
 
 @router.post(
     "/sonarr_get_statistics",
     response_model=ToolResponse,
     summary="Get Sonarr statistics",
-    description="Get Sonarr library statistics."
-)
-async def sonarr_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get Sonarr library statistics.",
+)
+async def sonarr_get_statistics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Sonarr statistics."""
     result = await execute_tool_with_logging(session, "sonarr_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Prowlarr Tools
 # ============================================================================
 
+
 class ProwlarrSearchRequest(BaseModel):
     """Search request."""
+
     query: str = Field(..., description="Search query")
     limit: int = Field(50, description="Maximum number of results")
 
 
 @router.post(
     "/prowlarr_get_indexers",
     response_model=ToolResponse,
     summary="Get Prowlarr indexers",
-    description="Get list of configured indexers."
-)
-async def prowlarr_get_indexers(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of configured indexers.",
+)
+async def prowlarr_get_indexers(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get Prowlarr indexers."""
     result = await execute_tool_with_logging(session, "prowlarr_get_indexers", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/prowlarr_search",
     response_model=ToolResponse,
     summary="Search in Prowlarr",
-    description="Search across all indexers."
+    description="Search across all indexers.",
 )
 async def prowlarr_search(
-    request: Request,
-    body: ProwlarrSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: ProwlarrSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search in Prowlarr."""
-    result = await execute_tool_with_logging(
-        session, "prowlarr_search", body.model_dump(), request
-    )
+    result = await execute_tool_with_logging(session, "prowlarr_search", body.model_dump(), request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/prowlarr_get_statistics",
     response_model=ToolResponse,
     summary="Get Prowlarr statistics",
-    description="Get Prowlarr overall statistics."
+    description="Get Prowlarr overall statistics.",
 )
 async def prowlarr_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Prowlarr statistics."""
     result = await execute_tool_with_logging(session, "prowlarr_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # Audiobookshelf Tools
 # ============================================================================
 
+
 @router.post(
     "/audiobookshelf_get_libraries",
     response_model=ToolResponse,
     summary="Get Audiobookshelf libraries",
-    description="Get list of libraries in Audiobookshelf (audiobooks and podcasts)."
+    description="Get list of libraries in Audiobookshelf (audiobooks and podcasts).",
 )
 async def audiobookshelf_get_libraries(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Audiobookshelf libraries."""
     result = await execute_tool_with_logging(session, "audiobookshelf_get_libraries", {}, request)
     return ToolResponse(**result)
 
 
 class AudiobookshelfLibraryItemsRequest(BaseModel):
     """Request for library items."""
+
     library_id: str = Field(..., description="Library ID to get items from")
     limit: int = Field(50, description="Maximum number of items to return")
     page: int = Field(0, description="Page number (0-indexed)")
 
 
 @router.post(
     "/audiobookshelf_get_library_items",
     response_model=ToolResponse,
     summary="Get Audiobookshelf library items",
-    description="Get items (audiobooks/podcasts) from a library."
+    description="Get items (audiobooks/podcasts) from a library.",
 )
 async def audiobookshelf_get_library_items(
     request: Request,
     body: AudiobookshelfLibraryItemsRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Audiobookshelf library items."""
     result = await execute_tool_with_logging(
         session, "audiobookshelf_get_library_items", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AudiobookshelfItemRequest(BaseModel):
     """Request for a specific item."""
+
     item_id: str = Field(..., description="ID of the audiobook/podcast to get")
 
 
 @router.post(
     "/audiobookshelf_get_item",
     response_model=ToolResponse,
     summary="Get Audiobookshelf item",
-    description="Get detailed information about a specific audiobook or podcast."
+    description="Get detailed information about a specific audiobook or podcast.",
 )
 async def audiobookshelf_get_item(
     request: Request,
     body: AudiobookshelfItemRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Audiobookshelf item."""
     result = await execute_tool_with_logging(
         session, "audiobookshelf_get_item", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AudiobookshelfSearchRequest(BaseModel):
     """Search request for Audiobookshelf."""
+
     library_id: str = Field(..., description="Library ID to search in")
     query: str = Field(..., description="Search query")
     limit: int = Field(25, description="Maximum number of results per category")
 
 
 @router.post(
     "/audiobookshelf_search",
     response_model=ToolResponse,
     summary="Search Audiobookshelf",
-    description="Search for audiobooks, podcasts, authors, or series in a library."
+    description="Search for audiobooks, podcasts, authors, or series in a library.",
 )
 async def audiobookshelf_search(
     request: Request,
     body: AudiobookshelfSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Search in Audiobookshelf."""
     result = await execute_tool_with_logging(
         session, "audiobookshelf_search", body.model_dump(), request
     )
@@ -3766,60 +3847,63 @@
 
 @router.post(
     "/audiobookshelf_get_users",
     response_model=ToolResponse,
     summary="Get Audiobookshelf users",
-    description="Get list of users in Audiobookshelf (admin only)."
+    description="Get list of users in Audiobookshelf (admin only).",
 )
 async def audiobookshelf_get_users(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Audiobookshelf users."""
     result = await execute_tool_with_logging(session, "audiobookshelf_get_users", {}, request)
     return ToolResponse(**result)
 
 
 class AudiobookshelfListeningStatsRequest(BaseModel):
     """Request for listening statistics."""
-    user_id: Optional[str] = Field(None, description="User ID to get stats for (optional, defaults to current user)")
+
+    user_id: Optional[str] = Field(
+        None, description="User ID to get stats for (optional, defaults to current user)"
+    )
 
 
 @router.post(
     "/audiobookshelf_get_listening_stats",
     response_model=ToolResponse,
     summary="Get Audiobookshelf listening stats",
-    description="Get listening statistics for current user or specified user."
+    description="Get listening statistics for current user or specified user.",
 )
 async def audiobookshelf_get_listening_stats(
     request: Request,
     body: AudiobookshelfListeningStatsRequest = AudiobookshelfListeningStatsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Audiobookshelf listening stats."""
     result = await execute_tool_with_logging(
         session, "audiobookshelf_get_listening_stats", body.model_dump(exclude_none=True), request
     )
     return ToolResponse(**result)
 
 
 class AudiobookshelfMediaProgressRequest(BaseModel):
     """Request for media progress."""
+
     library_item_id: str = Field(..., description="ID of the library item")
     episode_id: Optional[str] = Field(None, description="Episode ID for podcasts (optional)")
 
 
 @router.post(
     "/audiobookshelf_get_media_progress",
     response_model=ToolResponse,
     summary="Get Audiobookshelf media progress",
-    description="Get progress for a specific audiobook/podcast."
+    description="Get progress for a specific audiobook/podcast.",
 )
 async def audiobookshelf_get_media_progress(
     request: Request,
     body: AudiobookshelfMediaProgressRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Audiobookshelf media progress."""
     result = await execute_tool_with_logging(
         session, "audiobookshelf_get_media_progress", body.model_dump(exclude_none=True), request
     )
@@ -3828,112 +3912,108 @@
 
 @router.post(
     "/audiobookshelf_get_statistics",
     response_model=ToolResponse,
     summary="Get Audiobookshelf statistics",
-    description="Get Audiobookshelf library statistics."
+    description="Get Audiobookshelf library statistics.",
 )
 async def audiobookshelf_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Audiobookshelf statistics."""
     result = await execute_tool_with_logging(session, "audiobookshelf_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 # ============================================================================
 # WikiJS Tools
 # ============================================================================
 
+
 class WikiJSGetPagesRequest(BaseModel):
     """Request for getting pages."""
+
     limit: int = Field(50, description="Maximum number of pages to return")
     locale: str = Field("en", description="Locale/language filter")
 
 
 @router.post(
     "/wikijs_get_pages",
     response_model=ToolResponse,
     summary="Get WikiJS pages",
-    description="Get list of wiki pages from WikiJS, ordered by most recently updated."
+    description="Get list of wiki pages from WikiJS, ordered by most recently updated.",
 )
 async def wikijs_get_pages(
     request: Request,
     body: WikiJSGetPagesRequest = WikiJSGetPagesRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get WikiJS pages."""
     result = await execute_tool_with_logging(
         session, "wikijs_get_pages", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class WikiJSGetPageRequest(BaseModel):
     """Request for getting a specific page."""
+
     page_id: int = Field(..., description="ID of the page to retrieve")
 
 
 @router.post(
     "/wikijs_get_page",
     response_model=ToolResponse,
     summary="Get WikiJS page",
-    description="Get detailed content of a specific wiki page by its ID."
+    description="Get detailed content of a specific wiki page by its ID.",
 )
 async def wikijs_get_page(
-    request: Request,
-    body: WikiJSGetPageRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: WikiJSGetPageRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Get WikiJS page."""
-    result = await execute_tool_with_logging(
-        session, "wikijs_get_page", body.model_dump(), request
-    )
+    result = await execute_tool_with_logging(session, "wikijs_get_page", body.model_dump(), request)
     return ToolResponse(**result)
 
 
 class WikiJSSearchRequest(BaseModel):
     """Search request for WikiJS."""
+
     query: str = Field(..., description="Search query")
     locale: str = Field("en", description="Locale/language to search in")
 
 
 @router.post(
     "/wikijs_search",
     response_model=ToolResponse,
     summary="Search WikiJS",
-    description="Search for wiki pages by keyword or phrase."
+    description="Search for wiki pages by keyword or phrase.",
 )
 async def wikijs_search(
-    request: Request,
-    body: WikiJSSearchRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: WikiJSSearchRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Search in WikiJS."""
-    result = await execute_tool_with_logging(
-        session, "wikijs_search", body.model_dump(), request
-    )
+    result = await execute_tool_with_logging(session, "wikijs_search", body.model_dump(), request)
     return ToolResponse(**result)
 
 
 class WikiJSGetPageTreeRequest(BaseModel):
     """Request for getting page tree."""
+
     parent_path: str = Field("", description="Parent path to start from (empty for root)")
     locale: str = Field("en", description="Locale/language filter")
 
 
 @router.post(
     "/wikijs_get_page_tree",
     response_model=ToolResponse,
     summary="Get WikiJS page tree",
-    description="Get the hierarchical tree structure of wiki pages."
+    description="Get the hierarchical tree structure of wiki pages.",
 )
 async def wikijs_get_page_tree(
     request: Request,
     body: WikiJSGetPageTreeRequest = WikiJSGetPageTreeRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get WikiJS page tree."""
     result = await execute_tool_with_logging(
         session, "wikijs_get_page_tree", body.model_dump(), request
     )
@@ -3942,53 +4022,45 @@
 
 @router.post(
     "/wikijs_get_tags",
     response_model=ToolResponse,
     summary="Get WikiJS tags",
-    description="Get all tags used in the wiki."
-)
-async def wikijs_get_tags(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get all tags used in the wiki.",
+)
+async def wikijs_get_tags(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get WikiJS tags."""
     result = await execute_tool_with_logging(session, "wikijs_get_tags", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/wikijs_get_users",
     response_model=ToolResponse,
     summary="Get WikiJS users",
-    description="Get list of users in WikiJS."
-)
-async def wikijs_get_users(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get list of users in WikiJS.",
+)
+async def wikijs_get_users(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get WikiJS users."""
     result = await execute_tool_with_logging(session, "wikijs_get_users", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/wikijs_get_statistics",
     response_model=ToolResponse,
     summary="Get WikiJS statistics",
-    description="Get WikiJS statistics (page count, user count, etc.)."
-)
-async def wikijs_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
-):
+    description="Get WikiJS statistics (page count, user count, etc.).",
+)
+async def wikijs_get_statistics(request: Request, session: AsyncSession = Depends(get_db_session)):
     """Get WikiJS statistics."""
     result = await execute_tool_with_logging(session, "wikijs_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 class WikiJSCreatePageRequest(BaseModel):
     """Request for creating a page."""
+
     path: str = Field(..., description="Path for the page (e.g., 'docs/getting-started')")
     title: str = Field(..., description="Title of the page")
     content: str = Field(..., description="Markdown content of the page")
     description: str = Field("", description="Short description of the page")
     locale: str = Field("en", description="Locale/language for the page")
@@ -3997,16 +4069,14 @@
 
 @router.post(
     "/wikijs_create_page",
     response_model=ToolResponse,
     summary="Create WikiJS page",
-    description="Create a new wiki page in WikiJS."
+    description="Create a new wiki page in WikiJS.",
 )
 async def wikijs_create_page(
-    request: Request,
-    body: WikiJSCreatePageRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: WikiJSCreatePageRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Create WikiJS page."""
     result = await execute_tool_with_logging(
         session, "wikijs_create_page", body.model_dump(), request
     )
@@ -4015,144 +4085,149 @@
 
 # ============================================================================
 # Authentik Tools
 # ============================================================================
 
+
 class AuthentikGetUsersRequest(BaseModel):
     """Request for getting users."""
+
     search: Optional[str] = Field(None, description="Search query to filter users")
     is_active: Optional[bool] = Field(None, description="Filter by user active status")
     limit: int = Field(20, description="Maximum number of users to return")
 
 
 @router.post(
     "/authentik_get_users",
     response_model=ToolResponse,
     summary="Get Authentik users",
-    description="Get list of users from Authentik with optional search and filtering."
+    description="Get list of users from Authentik with optional search and filtering.",
 )
 async def authentik_get_users(
     request: Request,
     body: AuthentikGetUsersRequest = AuthentikGetUsersRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Authentik users."""
     result = await execute_tool_with_logging(
         session, "authentik_get_users", body.model_dump(exclude_none=True), request
     )
     return ToolResponse(**result)
 
 
 class AuthentikGetUserRequest(BaseModel):
     """Request for getting a specific user."""
+
     user_pk: int = Field(..., description="User primary key (ID)")
 
 
 @router.post(
     "/authentik_get_user",
     response_model=ToolResponse,
     summary="Get Authentik user",
-    description="Get details of a specific user by their ID."
+    description="Get details of a specific user by their ID.",
 )
 async def authentik_get_user(
-    request: Request,
-    body: AuthentikGetUserRequest,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, body: AuthentikGetUserRequest, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Authentik user."""
     result = await execute_tool_with_logging(
         session, "authentik_get_user", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AuthentikSearchUsersRequest(BaseModel):
     """Search request for users."""
+
     query: str = Field(..., description="Search query")
 
 
 @router.post(
     "/authentik_search_users",
     response_model=ToolResponse,
     summary="Search Authentik users",
-    description="Search for users by username, name, or email."
+    description="Search for users by username, name, or email.",
 )
 async def authentik_search_users(
     request: Request,
     body: AuthentikSearchUsersRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Search Authentik users."""
     result = await execute_tool_with_logging(
         session, "authentik_search_users", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AuthentikGetGroupsRequest(BaseModel):
     """Request for getting groups."""
+
     limit: int = Field(20, description="Maximum number of groups to return")
 
 
 @router.post(
     "/authentik_get_groups",
     response_model=ToolResponse,
     summary="Get Authentik groups",
-    description="Get list of groups from Authentik."
+    description="Get list of groups from Authentik.",
 )
 async def authentik_get_groups(
     request: Request,
     body: AuthentikGetGroupsRequest = AuthentikGetGroupsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Authentik groups."""
     result = await execute_tool_with_logging(
         session, "authentik_get_groups", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AuthentikGetApplicationsRequest(BaseModel):
     """Request for getting applications."""
+
     limit: int = Field(20, description="Maximum number of applications to return")
 
 
 @router.post(
     "/authentik_get_applications",
     response_model=ToolResponse,
     summary="Get Authentik applications",
-    description="Get list of applications configured in Authentik."
+    description="Get list of applications configured in Authentik.",
 )
 async def authentik_get_applications(
     request: Request,
     body: AuthentikGetApplicationsRequest = AuthentikGetApplicationsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Authentik applications."""
     result = await execute_tool_with_logging(
         session, "authentik_get_applications", body.model_dump(), request
     )
     return ToolResponse(**result)
 
 
 class AuthentikGetEventsRequest(BaseModel):
     """Request for getting events."""
+
     action: Optional[str] = Field(None, description="Filter by action type")
     username: Optional[str] = Field(None, description="Filter by username")
     limit: int = Field(20, description="Maximum number of events to return")
 
 
 @router.post(
     "/authentik_get_events",
     response_model=ToolResponse,
     summary="Get Authentik events",
-    description="Get audit events from Authentik."
+    description="Get audit events from Authentik.",
 )
 async def authentik_get_events(
     request: Request,
     body: AuthentikGetEventsRequest = AuthentikGetEventsRequest(),
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Get Authentik events."""
     result = await execute_tool_with_logging(
         session, "authentik_get_events", body.model_dump(exclude_none=True), request
     )
@@ -4161,51 +4236,50 @@
 
 @router.post(
     "/authentik_get_statistics",
     response_model=ToolResponse,
     summary="Get Authentik statistics",
-    description="Get Authentik statistics including user counts, groups, applications, and recent activity."
+    description="Get Authentik statistics including user counts, groups, applications, and recent activity.",
 )
 async def authentik_get_statistics(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Authentik statistics."""
     result = await execute_tool_with_logging(session, "authentik_get_statistics", {}, request)
     return ToolResponse(**result)
 
 
 @router.post(
     "/authentik_get_server_info",
     response_model=ToolResponse,
     summary="Get Authentik server info",
-    description="Get Authentik server information including version and current user."
+    description="Get Authentik server information including version and current user.",
 )
 async def authentik_get_server_info(
-    request: Request,
-    session: AsyncSession = Depends(get_db_session)
+    request: Request, session: AsyncSession = Depends(get_db_session)
 ):
     """Get Authentik server info."""
     result = await execute_tool_with_logging(session, "authentik_get_server_info", {}, request)
     return ToolResponse(**result)
 
 
 class AuthentikDeactivateUserRequest(BaseModel):
     """Request for deactivating a user."""
+
     user_pk: int = Field(..., description="User primary key (ID) to deactivate")
 
 
 @router.post(
     "/authentik_deactivate_user",
     response_model=ToolResponse,
     summary="Deactivate Authentik user",
-    description="Deactivate a user account (set is_active to false)."
+    description="Deactivate a user account (set is_active to false).",
 )
 async def authentik_deactivate_user(
     request: Request,
     body: AuthentikDeactivateUserRequest,
-    session: AsyncSession = Depends(get_db_session)
+    session: AsyncSession = Depends(get_db_session),
 ):
     """Deactivate Authentik user."""
     result = await execute_tool_with_logging(
         session, "authentik_deactivate_user", body.model_dump(), request
     )
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/routers/openapi_tools.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_service.py	2025-12-31 13:30:51.494007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_service.py	2025-12-31 13:41:37.150198+00:00
@@ -13,19 +13,21 @@
 from loguru import logger
 
 
 class TrainingBackend(str, Enum):
     """Available training backends."""
+
     OLLAMA_MODELFILE = "ollama_modelfile"  # Modelfile with embedded examples (no GPU needed)
     UNSLOTH = "unsloth"  # Fast, memory efficient fine-tuning (GPU required)
     TRANSFORMERS = "transformers"  # Standard HuggingFace
     MLXLM = "mlx-lm"  # For Apple Silicon
 
 
 @dataclass
 class OllamaModelfileConfig:
     """Configuration for Ollama Modelfile-based training."""
+
     base_model: str = "llama3.2:3b"  # Base Ollama model
     output_model_name: str = "mcparr-trained"
     temperature: float = 0.7
     top_p: float = 0.9
     top_k: int = 40
@@ -40,10 +42,11 @@
 
 
 @dataclass
 class TrainingConfig:
     """Configuration for fine-tuning (Unsloth/Transformers)."""
+
     # Model
     base_model: str = "unsloth/llama-3.2-3b-instruct-bnb-4bit"
     max_seq_length: int = 2048
     load_in_4bit: bool = True
 
@@ -69,13 +72,11 @@
 
 class TrainingService:
     """Service for training LLMs via Ollama Modelfile or local fine-tuning."""
 
     def __init__(
-        self,
-        ollama_url: str = "http://localhost:11434",
-        training_dir: Optional[str] = None
+        self, ollama_url: str = "http://localhost:11434", training_dir: Optional[str] = None
     ):
         self.ollama_url = ollama_url
         self.training_dir = Path(training_dir or "/tmp/mcparr_training")
         self.training_dir.mkdir(parents=True, exist_ok=True)
         self._current_process: Optional[subprocess.Popen] = None
@@ -83,13 +84,11 @@
         self._cancel_requested: bool = False
 
     # ============= Ollama Modelfile-based Training =============
 
     def generate_enriched_system_prompt(
-        self,
-        prompts: List[Dict[str, Any]],
-        config: OllamaModelfileConfig
+        self, prompts: List[Dict[str, Any]], config: OllamaModelfileConfig
     ) -> str:
         """Generate a system prompt enriched with training examples."""
         examples_text = []
 
         for i, prompt in enumerate(prompts, 1):
@@ -119,13 +118,11 @@
 3. Fournir les informations demandes de faon claire"""
 
         return enriched_prompt
 
     def generate_modelfile(
-        self,
-        prompts: List[Dict[str, Any]],
-        config: OllamaModelfileConfig
+        self, prompts: List[Dict[str, Any]], config: OllamaModelfileConfig
     ) -> str:
         """Generate Ollama Modelfile content with embedded training examples."""
         enriched_system = self.generate_enriched_system_prompt(prompts, config)
 
         # Escape quotes for Modelfile
@@ -149,52 +146,60 @@
 
     async def create_ollama_model(
         self,
         prompts: List[Dict[str, Any]],
         config: Optional[OllamaModelfileConfig] = None,
-        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None
+        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
     ) -> Dict[str, Any]:
         """Create a new Ollama model via the /api/create endpoint."""
         config = config or OllamaModelfileConfig()
         self._cancel_requested = False
 
-        logger.info(f"Creating Ollama model '{config.output_model_name}' with {len(prompts)} training examples")
+        logger.info(
+            f"Creating Ollama model '{config.output_model_name}' with {len(prompts)} training examples"
+        )
 
         # Generate enriched system prompt with examples
         enriched_system = self.generate_enriched_system_prompt(prompts, config)
 
         # Also generate Modelfile content for reference
         modelfile_content = self.generate_modelfile(prompts, config)
 
         # Save Modelfile locally for reference
         modelfile_path = self.training_dir / f"Modelfile_{config.output_model_name}"
-        with open(modelfile_path, 'w', encoding='utf-8') as f:
+        with open(modelfile_path, "w", encoding="utf-8") as f:
             f.write(modelfile_content)
 
         logger.debug(f"Modelfile saved to {modelfile_path}")
 
         if progress_callback:
-            await self._call_progress(progress_callback, {
-                "step": 1,
-                "total_steps": 3,
-                "progress_percent": 10,
-                "status": "preparing",
-                "message": "Generating system prompt..."
-            })
+            await self._call_progress(
+                progress_callback,
+                {
+                    "step": 1,
+                    "total_steps": 3,
+                    "progress_percent": 10,
+                    "status": "preparing",
+                    "message": "Generating system prompt...",
+                },
+            )
 
         try:
             # Call Ollama API to create the model
             # Note: Uses 'from' and 'system' fields for compatibility with older Ollama versions
             async with httpx.AsyncClient(timeout=600.0) as client:
                 if progress_callback:
-                    await self._call_progress(progress_callback, {
-                        "step": 2,
-                        "total_steps": 3,
-                        "progress_percent": 30,
-                        "status": "creating",
-                        "message": "Creating model on Ollama server..."
-                    })
+                    await self._call_progress(
+                        progress_callback,
+                        {
+                            "step": 2,
+                            "total_steps": 3,
+                            "progress_percent": 30,
+                            "status": "creating",
+                            "message": "Creating model on Ollama server...",
+                        },
+                    )
 
                 # Build request with 'from' and 'system' fields for compatibility
                 # This works with older Ollama versions (0.13+) and newer ones
                 create_request = {
                     "name": config.output_model_name,
@@ -204,27 +209,27 @@
                     "parameters": {
                         "temperature": config.temperature,
                         "top_p": config.top_p,
                         "top_k": config.top_k,
                         "num_ctx": config.num_ctx,
-                        "num_predict": config.num_predict
-                    }
+                        "num_predict": config.num_predict,
+                    },
                 }
 
-                logger.debug(f"Ollama create request: name={config.output_model_name}, from={config.base_model}")
+                logger.debug(
+                    f"Ollama create request: name={config.output_model_name}, from={config.base_model}"
+                )
 
                 # Stream the response
                 async with client.stream(
-                    "POST",
-                    f"{self.ollama_url}/api/create",
-                    json=create_request
+                    "POST", f"{self.ollama_url}/api/create", json=create_request
                 ) as response:
                     if response.status_code != 200:
                         error_text = await response.aread()
                         return {
                             "success": False,
-                            "error": f"Ollama API error: {response.status_code} - {error_text.decode()}"
+                            "error": f"Ollama API error: {response.status_code} - {error_text.decode()}",
                         }
 
                     last_status = ""
                     async for line in response.aiter_lines():
                         if self._cancel_requested:
@@ -249,66 +254,61 @@
                                         elif "writing" in status.lower():
                                             progress = 85
                                         elif "success" in status.lower():
                                             progress = 100
 
-                                        await self._call_progress(progress_callback, {
-                                            "step": 2,
-                                            "total_steps": 3,
-                                            "progress_percent": progress,
-                                            "status": "creating",
-                                            "message": status
-                                        })
+                                        await self._call_progress(
+                                            progress_callback,
+                                            {
+                                                "step": 2,
+                                                "total_steps": 3,
+                                                "progress_percent": progress,
+                                                "status": "creating",
+                                                "message": status,
+                                            },
+                                        )
 
                                 if data.get("error"):
-                                    return {
-                                        "success": False,
-                                        "error": data["error"]
-                                    }
+                                    return {"success": False, "error": data["error"]}
 
                             except json.JSONDecodeError:
                                 continue
 
             if progress_callback:
-                await self._call_progress(progress_callback, {
-                    "step": 3,
-                    "total_steps": 3,
-                    "progress_percent": 100,
-                    "status": "completed",
-                    "message": f"Model '{config.output_model_name}' created successfully!"
-                })
+                await self._call_progress(
+                    progress_callback,
+                    {
+                        "step": 3,
+                        "total_steps": 3,
+                        "progress_percent": 100,
+                        "status": "completed",
+                        "message": f"Model '{config.output_model_name}' created successfully!",
+                    },
+                )
 
             return {
                 "success": True,
                 "model_name": config.output_model_name,
                 "base_model": config.base_model,
                 "prompts_count": len(prompts),
                 "modelfile_path": str(modelfile_path),
-                "message": f"Model '{config.output_model_name}' created successfully with {len(prompts)} embedded examples"
+                "message": f"Model '{config.output_model_name}' created successfully with {len(prompts)} embedded examples",
             }
 
         except httpx.ConnectError as e:
             return {
                 "success": False,
-                "error": f"Cannot connect to Ollama at {self.ollama_url}: {e}"
+                "error": f"Cannot connect to Ollama at {self.ollama_url}: {e}",
             }
         except httpx.TimeoutException:
-            return {
-                "success": False,
-                "error": "Timeout while creating model"
-            }
+            return {"success": False, "error": "Timeout while creating model"}
         except Exception as e:
             logger.error(f"Failed to create Ollama model: {e}")
-            return {
-                "success": False,
-                "error": str(e)
-            }
+            return {"success": False, "error": str(e)}
 
     async def _call_progress(
-        self,
-        callback: Callable[[Dict[str, Any]], None],
-        progress: Dict[str, Any]
+        self, callback: Callable[[Dict[str, Any]], None], progress: Dict[str, Any]
     ):
         """Call progress callback safely."""
         try:
             if asyncio.iscoroutinefunction(callback):
                 await callback(progress)
@@ -333,12 +333,11 @@
     async def delete_ollama_model(self, model_name: str) -> Dict[str, Any]:
         """Delete a model from Ollama."""
         try:
             async with httpx.AsyncClient(timeout=30.0) as client:
                 response = await client.delete(
-                    f"{self.ollama_url}/api/delete",
-                    json={"name": model_name}
+                    f"{self.ollama_url}/api/delete", json={"name": model_name}
                 )
                 if response.status_code == 200:
                     return {"success": True, "message": f"Model '{model_name}' deleted"}
                 else:
                     return {"success": False, "error": f"Failed to delete: {response.status_code}"}
@@ -356,60 +355,69 @@
             "cuda_available": False,
             "unsloth_available": False,
             "transformers_available": False,
             "ollama_available": False,
             "recommended_backend": None,
-            "errors": []
+            "errors": [],
         }
 
         # Check GPU
         try:
             result = subprocess.run(
-                ['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'],
-                capture_output=True, text=True, timeout=5
+                ["nvidia-smi", "--query-gpu=name,memory.total", "--format=csv,noheader,nounits"],
+                capture_output=True,
+                text=True,
+                timeout=5,
             )
             if result.returncode == 0 and result.stdout.strip():
-                parts = result.stdout.strip().split(',')
+                parts = result.stdout.strip().split(",")
                 results["gpu_available"] = True
                 results["gpu_name"] = parts[0].strip()
                 results["gpu_memory_gb"] = round(float(parts[1].strip()) / 1024, 2)
         except Exception as e:
             results["errors"].append(f"GPU check failed: {e}")
 
         # Check CUDA
         try:
             result = subprocess.run(
-                ['python3', '-c', 'import torch; print(torch.cuda.is_available())'],
-                capture_output=True, text=True, timeout=10
+                ["python3", "-c", "import torch; print(torch.cuda.is_available())"],
+                capture_output=True,
+                text=True,
+                timeout=10,
             )
             results["cuda_available"] = result.stdout.strip() == "True"
         except Exception as e:
             results["errors"].append(f"CUDA check failed: {e}")
 
         # Check Unsloth
         try:
             result = subprocess.run(
-                ['python3', '-c', 'import unsloth; print("ok")'],
-                capture_output=True, text=True, timeout=10
+                ["python3", "-c", 'import unsloth; print("ok")'],
+                capture_output=True,
+                text=True,
+                timeout=10,
             )
             results["unsloth_available"] = result.stdout.strip() == "ok"
         except Exception:
             pass
 
         # Check transformers
         try:
             result = subprocess.run(
-                ['python3', '-c', 'import transformers; print("ok")'],
-                capture_output=True, text=True, timeout=10
+                ["python3", "-c", 'import transformers; print("ok")'],
+                capture_output=True,
+                text=True,
+                timeout=10,
             )
             results["transformers_available"] = result.stdout.strip() == "ok"
         except Exception:
             pass
 
         # Check Ollama
         try:
             import httpx
+
             async with httpx.AsyncClient() as client:
                 response = await client.get(f"{self.ollama_url}/api/version", timeout=5)
                 results["ollama_available"] = response.status_code == 200
         except Exception:
             pass
@@ -421,58 +429,45 @@
             results["recommended_backend"] = "transformers"
 
         return results
 
     def prepare_training_data(
-        self,
-        prompts: List[Dict[str, Any]],
-        output_path: Optional[Path] = None
+        self, prompts: List[Dict[str, Any]], output_path: Optional[Path] = None
     ) -> Path:
         """Convert prompts to training format (ShareGPT/Chat format)."""
         output_path = output_path or self.training_dir / "training_data.jsonl"
 
         training_data = []
         for prompt in prompts:
             # Convert to chat format
-            conversation = {
-                "conversations": []
-            }
+            conversation = {"conversations": []}
 
             # Add system prompt if present
             if prompt.get("system_prompt"):
-                conversation["conversations"].append({
-                    "from": "system",
-                    "value": prompt["system_prompt"]
-                })
+                conversation["conversations"].append(
+                    {"from": "system", "value": prompt["system_prompt"]}
+                )
 
             # Add user input
-            conversation["conversations"].append({
-                "from": "human",
-                "value": prompt["user_input"]
-            })
+            conversation["conversations"].append({"from": "human", "value": prompt["user_input"]})
 
             # Add expected output
-            conversation["conversations"].append({
-                "from": "gpt",
-                "value": prompt["expected_output"]
-            })
+            conversation["conversations"].append(
+                {"from": "gpt", "value": prompt["expected_output"]}
+            )
 
             training_data.append(conversation)
 
         # Write JSONL
-        with open(output_path, 'w', encoding='utf-8') as f:
+        with open(output_path, "w", encoding="utf-8") as f:
             for item in training_data:
-                f.write(json.dumps(item, ensure_ascii=False) + '\n')
+                f.write(json.dumps(item, ensure_ascii=False) + "\n")
 
         logger.info(f"Prepared {len(training_data)} training examples at {output_path}")
         return output_path
 
-    def generate_training_script(
-        self,
-        config: TrainingConfig,
-        data_path: Path
-    ) -> Path:
+    def generate_training_script(self, config: TrainingConfig, data_path: Path) -> Path:
         """Generate Python training script for Unsloth."""
         script_path = self.training_dir / "train.py"
 
         script = f'''#!/usr/bin/env python3
 """Auto-generated training script for MCParr fine-tuning."""
@@ -657,22 +652,22 @@
 
 if __name__ == "__main__":
     main()
 '''
 
-        with open(script_path, 'w') as f:
+        with open(script_path, "w") as f:
             f.write(script)
 
         os.chmod(script_path, 0o755)
         logger.info(f"Generated training script at {script_path}")
         return script_path
 
     async def start_training(
         self,
         prompts: List[Dict[str, Any]],
         config: Optional[TrainingConfig] = None,
-        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None
+        progress_callback: Optional[Callable[[Dict[str, Any]], None]] = None,
     ) -> Dict[str, Any]:
         """Start the training process."""
         config = config or TrainingConfig()
         self._progress_callback = progress_callback
 
@@ -685,21 +680,23 @@
         # Run training in subprocess
         logger.info("Starting training process...")
 
         try:
             self._current_process = subprocess.Popen(
-                ['python3', str(script_path)],
+                ["python3", str(script_path)],
                 stdout=subprocess.PIPE,
                 stderr=subprocess.STDOUT,
                 text=True,
                 bufsize=1,
-                cwd=str(self.training_dir)
+                cwd=str(self.training_dir),
             )
 
             output_lines = []
             current_step = 0
-            total_steps = config.max_steps if config.max_steps > 0 else len(prompts) * config.num_epochs
+            total_steps = (
+                config.max_steps if config.max_steps > 0 else len(prompts) * config.num_epochs
+            )
 
             while True:
                 line = self._current_process.stdout.readline()
                 if not line and self._current_process.poll() is not None:
                     break
@@ -712,17 +709,20 @@
                     if "loss" in line.lower() and progress_callback:
                         current_step += 1
                         progress = {
                             "step": current_step,
                             "total_steps": total_steps,
-                            "progress_percent": min(100, (current_step / max(1, total_steps)) * 100),
-                            "output": line.strip()
+                            "progress_percent": min(
+                                100, (current_step / max(1, total_steps)) * 100
+                            ),
+                            "output": line.strip(),
                         }
                         # Extract loss if possible
                         try:
                             if "'loss':" in line:
                                 import re
+
                                 loss_match = re.search(r"'loss':\s*([\d.]+)", line)
                                 if loss_match:
                                     progress["loss"] = float(loss_match.group(1))
                         except Exception:
                             pass
@@ -744,54 +744,45 @@
             else:
                 return {
                     "success": return_code == 0,
                     "return_code": return_code,
                     "output": output_lines[-50:],
-                    "error": "Training did not complete successfully" if return_code != 0 else None
+                    "error": "Training did not complete successfully" if return_code != 0 else None,
                 }
 
         except Exception as e:
             logger.error(f"Training failed: {e}")
-            return {
-                "success": False,
-                "error": str(e)
-            }
+            return {"success": False, "error": str(e)}
         finally:
             self._current_process = None
 
     async def import_to_ollama(
-        self,
-        model_name: str,
-        modelfile_path: Optional[str] = None
+        self, model_name: str, modelfile_path: Optional[str] = None
     ) -> Dict[str, Any]:
         """Import the fine-tuned model into Ollama."""
         modelfile_path = modelfile_path or str(self.training_dir / "Modelfile")
 
         if not Path(modelfile_path).exists():
             return {"success": False, "error": f"Modelfile not found: {modelfile_path}"}
 
         try:
             # Create model in Ollama
             result = subprocess.run(
-                ['ollama', 'create', model_name, '-f', modelfile_path],
+                ["ollama", "create", model_name, "-f", modelfile_path],
                 capture_output=True,
                 text=True,
-                timeout=300  # 5 minutes timeout
+                timeout=300,  # 5 minutes timeout
             )
 
             if result.returncode == 0:
                 logger.info(f"Successfully imported model '{model_name}' to Ollama")
-                return {
-                    "success": True,
-                    "model_name": model_name,
-                    "output": result.stdout
-                }
+                return {"success": True, "model_name": model_name, "output": result.stdout}
             else:
                 return {
                     "success": False,
                     "error": result.stderr or "Failed to create model",
-                    "output": result.stdout
+                    "output": result.stdout,
                 }
 
         except subprocess.TimeoutExpired:
             return {"success": False, "error": "Timeout while importing model"}
         except Exception as e:
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/training_service.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_centralization.py	2025-12-31 13:30:51.501007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_centralization.py	2025-12-31 13:41:37.185985+00:00
@@ -29,37 +29,43 @@
         self.service_data: Dict[str, Dict[str, Any]] = {}
         self.active_services: List[str] = []
         self.roles: Dict[str, str] = {}
         self.last_updated = datetime.utcnow()
 
-    def add_service_data(self, service_id: str, service_name: str, service_type: str, user_data: Dict[str, Any]):
+    def add_service_data(
+        self, service_id: str, service_name: str, service_type: str, user_data: Dict[str, Any]
+    ):
         """Add user data from a specific service."""
         # Extract and normalize common fields
-        if user_data.get('email'):
-            self.emails.add(user_data['email'])
-
-        if user_data.get('username'):
-            self.usernames.add(user_data['username'])
-
-        if user_data.get('display_name') or user_data.get('name') or user_data.get('friendly_name'):
-            display_name = user_data.get('display_name') or user_data.get('name') or user_data.get('friendly_name')
+        if user_data.get("email"):
+            self.emails.add(user_data["email"])
+
+        if user_data.get("username"):
+            self.usernames.add(user_data["username"])
+
+        if user_data.get("display_name") or user_data.get("name") or user_data.get("friendly_name"):
+            display_name = (
+                user_data.get("display_name")
+                or user_data.get("name")
+                or user_data.get("friendly_name")
+            )
             self.display_names.add(display_name)
 
         # Store complete service data
         self.service_data[service_id] = {
-            'service_name': service_name,
-            'service_type': service_type,
-            'user_data': user_data,
-            'updated_at': datetime.utcnow().isoformat()
+            "service_name": service_name,
+            "service_type": service_type,
+            "user_data": user_data,
+            "updated_at": datetime.utcnow().isoformat(),
         }
 
         # Track active services
         if service_id not in self.active_services:
             self.active_services.append(service_id)
 
         # Store role information
-        role = 'admin' if user_data.get('is_admin') or user_data.get('is_superuser') else 'user'
+        role = "admin" if user_data.get("is_admin") or user_data.get("is_superuser") else "user"
         self.roles[service_id] = role
 
     def get_primary_email(self) -> Optional[str]:
         """Get the primary email (first available)."""
         return list(self.emails)[0] if self.emails else None
@@ -72,28 +78,28 @@
         """Get the primary display name (first available)."""
         return list(self.display_names)[0] if self.display_names else None
 
     def is_admin_anywhere(self) -> bool:
         """Check if user has admin role in any service."""
-        return 'admin' in self.roles.values()
+        return "admin" in self.roles.values()
 
     def to_dict(self) -> Dict[str, Any]:
         """Convert to dictionary representation."""
         return {
-            'central_user_id': self.central_user_id,
-            'emails': list(self.emails),
-            'usernames': list(self.usernames),
-            'display_names': list(self.display_names),
-            'primary_email': self.get_primary_email(),
-            'primary_username': self.get_primary_username(),
-            'primary_display_name': self.get_primary_display_name(),
-            'service_data': self.service_data,
-            'active_services': self.active_services,
-            'service_count': len(self.active_services),
-            'roles': self.roles,
-            'is_admin_anywhere': self.is_admin_anywhere(),
-            'last_updated': self.last_updated.isoformat()
+            "central_user_id": self.central_user_id,
+            "emails": list(self.emails),
+            "usernames": list(self.usernames),
+            "display_names": list(self.display_names),
+            "primary_email": self.get_primary_email(),
+            "primary_username": self.get_primary_username(),
+            "primary_display_name": self.get_primary_display_name(),
+            "service_data": self.service_data,
+            "active_services": self.active_services,
+            "service_count": len(self.active_services),
+            "roles": self.roles,
+            "is_admin_anywhere": self.is_admin_anywhere(),
+            "last_updated": self.last_updated.isoformat(),
         }
 
 
 class UserCentralizationService:
     """Service for centralizing user information across all services."""
@@ -101,13 +107,11 @@
     def __init__(self):
         """Initialize the user centralization service."""
         pass
 
     async def get_centralized_user_data(
-        self,
-        db: AsyncSession,
-        central_user_id: str
+        self, db: AsyncSession, central_user_id: str
     ) -> Optional[CentralizedUserData]:
         """Get centralized user data for a specific central user ID.
 
         Args:
             db: Database session
@@ -145,41 +149,45 @@
                     logger.warning(f"Service config not found for mapping {mapping.id}")
                     continue
 
                 # Build user data from mapping and metadata
                 user_data = {
-                    'user_id': mapping.service_user_id,
-                    'username': mapping.service_username,
-                    'email': mapping.service_email,
-                    'role': mapping.role.value if hasattr(mapping.role, 'value') else mapping.role,
-                    'mapping_status': mapping.status.value if hasattr(mapping.status, 'value') else mapping.status,
-                    'last_sync_at': mapping.last_sync_at.isoformat() if mapping.last_sync_at else None,
-                    'sync_enabled': mapping.sync_enabled,
+                    "user_id": mapping.service_user_id,
+                    "username": mapping.service_username,
+                    "email": mapping.service_email,
+                    "role": mapping.role.value if hasattr(mapping.role, "value") else mapping.role,
+                    "mapping_status": mapping.status.value
+                    if hasattr(mapping.status, "value")
+                    else mapping.status,
+                    "last_sync_at": mapping.last_sync_at.isoformat()
+                    if mapping.last_sync_at
+                    else None,
+                    "sync_enabled": mapping.sync_enabled,
                 }
 
                 # Add metadata if available
                 if mapping.service_metadata:
                     user_data.update(mapping.service_metadata)
 
                 # Add to centralized data
                 centralized_data.add_service_data(
                     service_id=str(service.id),
                     service_name=service.name,
-                    service_type=service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
-                    user_data=user_data
+                    service_type=service.service_type.value
+                    if hasattr(service.service_type, "value")
+                    else service.service_type,
+                    user_data=user_data,
                 )
 
             except Exception as e:
                 logger.error(f"Error processing mapping {mapping.id}: {e}")
                 continue
 
         return centralized_data
 
     async def update_centralized_data_from_services(
-        self,
-        db: AsyncSession,
-        central_user_id: str
+        self, db: AsyncSession, central_user_id: str
     ) -> Optional[CentralizedUserData]:
         """Update centralized data by fetching fresh data from all services.
 
         Args:
             db: Database session
@@ -228,52 +236,61 @@
                         logger.warning(f"Service {service.name} connection failed")
                         continue
 
                     # Try to get fresh user data
                     fresh_user_data = None
-                    if hasattr(adapter, 'get_user_by_id') and mapping.service_user_id:
+                    if hasattr(adapter, "get_user_by_id") and mapping.service_user_id:
                         fresh_user_data = await adapter.get_user_by_id(mapping.service_user_id)
-                    elif hasattr(adapter, 'search_users') and mapping.service_username:
+                    elif hasattr(adapter, "search_users") and mapping.service_username:
                         users = await adapter.search_users(mapping.service_username)
                         if users:
                             fresh_user_data = users[0]
 
                     if fresh_user_data:
                         # Update mapping metadata with fresh data
                         mapping.service_metadata = {
                             **mapping.service_metadata,
-                            'fresh_data': fresh_user_data,
-                            'last_fetched': datetime.utcnow().isoformat()
+                            "fresh_data": fresh_user_data,
+                            "last_fetched": datetime.utcnow().isoformat(),
                         }
 
                         # Update basic fields if they've changed
-                        if fresh_user_data.get('email') and fresh_user_data['email'] != mapping.service_email:
-                            mapping.service_email = fresh_user_data['email']
+                        if (
+                            fresh_user_data.get("email")
+                            and fresh_user_data["email"] != mapping.service_email
+                        ):
+                            mapping.service_email = fresh_user_data["email"]
 
                         updated_mappings.append(mapping)
 
                         # Add to centralized data
                         centralized_data.add_service_data(
                             service_id=str(service.id),
                             service_name=service.name,
-                            service_type=service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
-                            user_data=fresh_user_data
+                            service_type=service.service_type.value
+                            if hasattr(service.service_type, "value")
+                            else service.service_type,
+                            user_data=fresh_user_data,
                         )
                     else:
                         # Use existing mapping data
                         user_data = {
-                            'user_id': mapping.service_user_id,
-                            'username': mapping.service_username,
-                            'email': mapping.service_email,
-                            'role': mapping.role.value if hasattr(mapping.role, 'value') else mapping.role,
+                            "user_id": mapping.service_user_id,
+                            "username": mapping.service_username,
+                            "email": mapping.service_email,
+                            "role": mapping.role.value
+                            if hasattr(mapping.role, "value")
+                            else mapping.role,
                         }
 
                         centralized_data.add_service_data(
                             service_id=str(service.id),
                             service_name=service.name,
-                            service_type=service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
-                            user_data=user_data
+                            service_type=service.service_type.value
+                            if hasattr(service.service_type, "value")
+                            else service.service_type,
+                            user_data=user_data,
                         )
 
             except Exception as e:
                 logger.error(f"Error updating mapping {mapping.id}: {e}")
                 continue
@@ -283,14 +300,11 @@
             await db.commit()
             logger.info(f"Updated {len(updated_mappings)} mappings with fresh data")
 
         return centralized_data
 
-    async def get_all_centralized_users(
-        self,
-        db: AsyncSession
-    ) -> List[CentralizedUserData]:
+    async def get_all_centralized_users(self, db: AsyncSession) -> List[CentralizedUserData]:
         """Get centralized data for all users.
 
         Args:
             db: Database session
 
@@ -318,13 +332,11 @@
                 continue
 
         return centralized_users
 
     async def sync_centralized_user_metadata(
-        self,
-        db: AsyncSession,
-        central_user_id: str
+        self, db: AsyncSession, central_user_id: str
     ) -> Dict[str, Any]:
         """Sync and update metadata for a centralized user.
 
         Args:
             db: Database session
@@ -338,14 +350,11 @@
         try:
             # Update centralized data from services
             centralized_data = await self.update_centralized_data_from_services(db, central_user_id)
 
             if not centralized_data:
-                return {
-                    'success': False,
-                    'error': 'No active mappings found for user'
-                }
+                return {"success": False, "error": "No active mappings found for user"}
 
             # Store centralized metadata in each mapping
             result = await db.execute(
                 select(UserMapping)
                 .where(UserMapping.central_user_id == central_user_id)
@@ -357,31 +366,28 @@
 
             for mapping in mappings:
                 # Add centralized data to metadata
                 mapping.service_metadata = {
                     **mapping.service_metadata,
-                    'centralized_data': centralized_dict,
-                    'centralized_updated_at': datetime.utcnow().isoformat()
+                    "centralized_data": centralized_dict,
+                    "centralized_updated_at": datetime.utcnow().isoformat(),
                 }
 
             await db.commit()
 
             return {
-                'success': True,
-                'central_user_id': central_user_id,
-                'services_count': len(centralized_data.active_services),
-                'emails_count': len(centralized_data.emails),
-                'usernames_count': len(centralized_data.usernames),
-                'centralized_data': centralized_dict
+                "success": True,
+                "central_user_id": central_user_id,
+                "services_count": len(centralized_data.active_services),
+                "emails_count": len(centralized_data.emails),
+                "usernames_count": len(centralized_data.usernames),
+                "centralized_data": centralized_dict,
             }
 
         except Exception as e:
             logger.error(f"Error syncing centralized metadata for user {central_user_id}: {e}")
-            return {
-                'success': False,
-                'error': str(e)
-            }
+            return {"success": False, "error": str(e)}
 
 
 # Global user centralization service instance
 user_centralization_service = UserCentralizationService()
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_centralization.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/utils/logging.py	2025-12-31 13:30:51.460869+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/utils/logging.py	2025-12-31 13:41:37.250748+00:00
@@ -85,11 +85,11 @@
             "status_code": status_code,
             "duration_ms": duration_ms,
             "correlation_id": correlation_id,
             "user_agent": user_agent,
             "ip_address": ip_address,
-        }
+        },
     )
 
 
 def log_error(
     error: Exception,
@@ -104,11 +104,11 @@
             "action": "error",
             "error_type": type(error).__name__,
             "error_message": str(error),
             "correlation_id": correlation_id,
             "context": context or {},
-        }
+        },
     )
 
 
 def log_service_call(
     service: str,
@@ -132,7 +132,7 @@
             "service_action": action,
             "success": success,
             "duration_ms": duration_ms,
             "correlation_id": correlation_id,
             "details": details or {},
-        }
+        },
     )
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/utils/logging.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/logs.py	2025-12-31 13:30:51.456007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/logs.py	2025-12-31 13:41:37.335364+00:00
@@ -26,11 +26,13 @@
 
     def disconnect(self, websocket: WebSocket):
         """Remove a WebSocket connection."""
         self.active_connections.discard(websocket)
         self.connection_filters.pop(websocket, None)
-        logger.info(f"Log WebSocket disconnected. Total connections: {len(self.active_connections)}")
+        logger.info(
+            f"Log WebSocket disconnected. Total connections: {len(self.active_connections)}"
+        )
 
     def update_filters(self, websocket: WebSocket, filters: Dict[str, Any]):
         """Update filters for a connection."""
         if websocket in self.active_connections:
             self.connection_filters[websocket] = filters
@@ -39,29 +41,29 @@
         """Check if a log entry matches the connection's filters."""
         if not filters:
             return True
 
         # Filter by level
-        if 'level' in filters and filters['level']:
-            if log_data.get('level') != filters['level']:
+        if "level" in filters and filters["level"]:
+            if log_data.get("level") != filters["level"]:
                 return False
 
         # Filter by source
-        if 'source' in filters and filters['source']:
-            if log_data.get('source') != filters['source']:
+        if "source" in filters and filters["source"]:
+            if log_data.get("source") != filters["source"]:
                 return False
 
         # Filter by service_id
-        if 'service_id' in filters and filters['service_id']:
-            if log_data.get('service_id') != filters['service_id']:
+        if "service_id" in filters and filters["service_id"]:
+            if log_data.get("service_id") != filters["service_id"]:
                 return False
 
         # Filter by minimum level severity
-        if 'min_level' in filters and filters['min_level']:
-            level_order = ['debug', 'info', 'warning', 'error', 'critical']
-            log_level = log_data.get('level', 'info').lower()
-            min_level = filters['min_level'].lower()
+        if "min_level" in filters and filters["min_level"]:
+            level_order = ["debug", "info", "warning", "error", "critical"]
+            log_level = log_data.get("level", "info").lower()
+            min_level = filters["min_level"].lower()
             if log_level in level_order and min_level in level_order:
                 if level_order.index(log_level) < level_order.index(min_level):
                     return False
 
         return True
@@ -70,15 +72,11 @@
         """Broadcast a new log entry to all connected clients."""
         if not self.active_connections:
             return
 
         log_data = log_entry.to_dict()
-        message = {
-            "type": "log",
-            "data": log_data,
-            "timestamp": datetime.utcnow().isoformat()
-        }
+        message = {"type": "log", "data": log_data, "timestamp": datetime.utcnow().isoformat()}
 
         disconnected = set()
 
         for websocket in self.active_connections:
             # Check if log matches this connection's filters
@@ -99,15 +97,11 @@
     async def broadcast_log_dict(self, log_data: Dict[str, Any]):
         """Broadcast a log entry from a dictionary."""
         if not self.active_connections:
             return
 
-        message = {
-            "type": "log",
-            "data": log_data,
-            "timestamp": datetime.utcnow().isoformat()
-        }
+        message = {"type": "log", "data": log_data, "timestamp": datetime.utcnow().isoformat()}
 
         disconnected = set()
 
         for websocket in self.active_connections:
             filters = self.connection_filters.get(websocket, {})
@@ -131,49 +125,45 @@
 async def websocket_logs_endpoint(websocket: WebSocket):
     """WebSocket endpoint for real-time log streaming."""
     # Parse query params for initial filters
     params = dict(websocket.query_params)
     filters = {
-        'level': params.get('level'),
-        'source': params.get('source'),
-        'service_id': params.get('service_id'),
-        'min_level': params.get('min_level'),
+        "level": params.get("level"),
+        "source": params.get("source"),
+        "service_id": params.get("service_id"),
+        "min_level": params.get("min_level"),
     }
 
     await log_stream_manager.connect(websocket, filters)
 
     try:
         # Send initial connection success message
-        await websocket.send_json({
-            "type": "connected",
-            "message": "Connected to log stream",
-            "filters": {k: v for k, v in filters.items() if v is not None}
-        })
+        await websocket.send_json(
+            {
+                "type": "connected",
+                "message": "Connected to log stream",
+                "filters": {k: v for k, v in filters.items() if v is not None},
+            }
+        )
 
         # Listen for filter updates from client
         while True:
             try:
                 data = await websocket.receive_json()
 
-                if data.get('type') == 'update_filters':
-                    new_filters = data.get('filters', {})
+                if data.get("type") == "update_filters":
+                    new_filters = data.get("filters", {})
                     log_stream_manager.update_filters(websocket, new_filters)
-                    await websocket.send_json({
-                        "type": "filters_updated",
-                        "filters": new_filters
-                    })
+                    await websocket.send_json({"type": "filters_updated", "filters": new_filters})
 
-                elif data.get('type') == 'ping':
+                elif data.get("type") == "ping":
                     await websocket.send_json({"type": "pong"})
 
             except WebSocketDisconnect:
                 break
             except json.JSONDecodeError:
-                await websocket.send_json({
-                    "type": "error",
-                    "message": "Invalid JSON"
-                })
+                await websocket.send_json({"type": "error", "message": "Invalid JSON"})
 
     except WebSocketDisconnect:
         pass
     finally:
         log_stream_manager.disconnect(websocket)
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/logs.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/manager.py	2025-12-31 13:30:51.466007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/manager.py	2025-12-31 13:41:37.409163+00:00
@@ -31,11 +31,11 @@
             f"WebSocket connection established: {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "connect",
                 "connection_id": connection_id,
-            }
+            },
         )
 
         return connection_id
 
     async def disconnect(self, connection_id: str):
@@ -48,18 +48,14 @@
                 f"WebSocket connection closed: {connection_id}",
                 extra={
                     "component": "websocket",
                     "action": "disconnect",
                     "connection_id": connection_id,
-                }
+                },
             )
 
-    async def send_message(
-        self,
-        connection_id: str,
-        message: Dict[str, Any]
-    ) -> bool:
+    async def send_message(self, connection_id: str, message: Dict[str, Any]) -> bool:
         """Send message to specific connection."""
         if connection_id not in self.active_connections:
             return False
 
         websocket = self.active_connections[connection_id]
@@ -76,11 +72,11 @@
                 extra={
                     "component": "websocket",
                     "action": "send_message",
                     "connection_id": connection_id,
                     "error": str(e),
-                }
+                },
             )
             # Remove broken connection
             await self.disconnect(connection_id)
             return False
 
@@ -104,24 +100,19 @@
                         "component": "websocket",
                         "action": "broadcast",
                         "connection_id": connection_id,
                         "channel": channel,
                         "error": str(e),
-                    }
+                    },
                 )
                 connections_to_remove.append(connection_id)
 
         # Clean up broken connections
         for connection_id in connections_to_remove:
             await self.disconnect(connection_id)
 
-    def subscribe(
-        self,
-        connection_id: str,
-        channel: str,
-        filters: Dict[str, Any] = None
-    ):
+    def subscribe(self, connection_id: str, channel: str, filters: Dict[str, Any] = None):
         """Subscribe connection to a channel with optional filters."""
         if connection_id not in self.subscriptions:
             self.subscriptions[connection_id] = {}
 
         self.subscriptions[connection_id][channel] = {
@@ -135,33 +126,31 @@
                 "component": "websocket",
                 "action": "subscribe",
                 "connection_id": connection_id,
                 "channel": channel,
                 "filters": filters,
-            }
+            },
         )
 
     def unsubscribe(self, connection_id: str, channel: str):
         """Unsubscribe connection from channel."""
-        if (connection_id in self.subscriptions and
-                channel in self.subscriptions[connection_id]):
+        if connection_id in self.subscriptions and channel in self.subscriptions[connection_id]:
             del self.subscriptions[connection_id][channel]
 
             logger.info(
                 f"Connection {connection_id} unsubscribed from {channel}",
                 extra={
                     "component": "websocket",
                     "action": "unsubscribe",
                     "connection_id": connection_id,
                     "channel": channel,
-                }
+                },
             )
 
     def _is_subscribed(self, connection_id: str, channel: str) -> bool:
         """Check if connection is subscribed to channel."""
-        return (connection_id in self.subscriptions and
-                channel in self.subscriptions[connection_id])
+        return connection_id in self.subscriptions and channel in self.subscriptions[connection_id]
 
     def get_connection_count(self) -> int:
         """Get number of active connections."""
         return len(self.active_connections)
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/manager.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_sync.py	2025-12-31 13:30:51.478007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_sync.py	2025-12-31 13:41:37.465731+00:00
@@ -26,14 +26,11 @@
         """Initialize the user sync service."""
         self.max_sync_attempts = 3
         self.sync_timeout = 300  # 5 minutes per sync operation
 
     async def sync_all_users(
-        self,
-        db: AsyncSession,
-        force: bool = False,
-        service_type: Optional[str] = None
+        self, db: AsyncSession, force: bool = False, service_type: Optional[str] = None
     ) -> Dict[str, Any]:
         """Sync all user mappings across services.
 
         Args:
             db: Database session
@@ -65,11 +62,11 @@
             "successful_syncs": 0,
             "failed_syncs": 0,
             "skipped_syncs": 0,
             "sync_details": [],
             "started_at": datetime.utcnow(),
-            "completed_at": None
+            "completed_at": None,
         }
 
         # Group mappings by service to sync efficiently
         mappings_by_service = {}
         for mapping in mappings:
@@ -78,13 +75,11 @@
                 mappings_by_service[service_id] = []
             mappings_by_service[service_id].append(mapping)
 
         # Sync each service
         for service_id, service_mappings in mappings_by_service.items():
-            service_result = await self._sync_service_users(
-                db, service_id, service_mappings, force
-            )
+            service_result = await self._sync_service_users(db, service_id, service_mappings, force)
             sync_results["sync_details"].append(service_result)
             sync_results["successful_syncs"] += service_result["successful_syncs"]
             sync_results["failed_syncs"] += service_result["failed_syncs"]
             sync_results["skipped_syncs"] += service_result["skipped_syncs"]
 
@@ -97,15 +92,11 @@
         )
 
         return sync_results
 
     async def _sync_service_users(
-        self,
-        db: AsyncSession,
-        service_id: str,
-        mappings: List[UserMapping],
-        force: bool = False
+        self, db: AsyncSession, service_id: str, mappings: List[UserMapping], force: bool = False
     ) -> Dict[str, Any]:
         """Sync users for a specific service.
 
         Args:
             db: Database session
@@ -130,21 +121,23 @@
                 "service_id": service_id,
                 "service_name": service.name if service else "Unknown",
                 "successful_syncs": 0,
                 "failed_syncs": 0,
                 "skipped_syncs": len(mappings),
-                "error": "Service not found or disabled"
+                "error": "Service not found or disabled",
             }
 
         result = {
             "service_id": service_id,
             "service_name": service.name,
-            "service_type": service.service_type.value if hasattr(service.service_type, 'value') else service.service_type,
+            "service_type": service.service_type.value
+            if hasattr(service.service_type, "value")
+            else service.service_type,
             "successful_syncs": 0,
             "failed_syncs": 0,
             "skipped_syncs": 0,
-            "errors": []
+            "errors": [],
         }
 
         # Get the appropriate adapter
         adapter = await service_registry.create_adapter(service)
         if not adapter:
@@ -170,13 +163,11 @@
                     try:
                         if not force and not mapping.needs_sync():
                             result["skipped_syncs"] += 1
                             continue
 
-                        sync_success = await self._sync_user_mapping(
-                            db, mapping, adapter
-                        )
+                        sync_success = await self._sync_user_mapping(db, mapping, adapter)
 
                         if sync_success:
                             result["successful_syncs"] += 1
                             mapping.update_sync_result(True)
                         else:
@@ -198,14 +189,11 @@
         await db.commit()
 
         return result
 
     async def _sync_user_mapping(
-        self,
-        db: AsyncSession,
-        mapping: UserMapping,
-        adapter: Any
+        self, db: AsyncSession, mapping: UserMapping, adapter: Any
     ) -> bool:
         """Sync a specific user mapping.
 
         Args:
             db: Database session
@@ -217,24 +205,21 @@
         """
         logger.debug(f"Syncing user mapping {mapping.id} for user {mapping.central_user_id}")
 
         try:
             # For Authentik, we sync user data from Authentik to other services
-            if hasattr(adapter, 'service_type') and adapter.service_type == 'authentik':
+            if hasattr(adapter, "service_type") and adapter.service_type == "authentik":
                 return await self._sync_from_authentik(db, mapping, adapter)
             else:
                 return await self._sync_to_service(db, mapping, adapter)
 
         except Exception as e:
             logger.error(f"Error during user mapping sync: {e}")
             return False
 
     async def _sync_from_authentik(
-        self,
-        db: AsyncSession,
-        mapping: UserMapping,
-        authentik_adapter: AuthentikAdapter
+        self, db: AsyncSession, mapping: UserMapping, authentik_adapter: AuthentikAdapter
     ) -> bool:
         """Sync user data from Authentik to update mapping.
 
         Args:
             db: Database session
@@ -253,42 +238,39 @@
                 return False
 
             user_data = users[0]  # Take the first match
 
             # Update mapping with latest Authentik data
-            mapping.service_user_id = str(user_data.get('pk'))
-            mapping.service_username = user_data.get('username')
-            mapping.service_email = user_data.get('email')
+            mapping.service_user_id = str(user_data.get("pk"))
+            mapping.service_username = user_data.get("username")
+            mapping.service_email = user_data.get("email")
 
             # Update metadata with additional user info
             if not mapping.metadata:
                 mapping.metadata = {}
 
-            mapping.metadata.update({
-                'authentik_user_id': user_data.get('pk'),
-                'name': user_data.get('name'),
-                'is_active': user_data.get('is_active'),
-                'is_superuser': user_data.get('is_superuser'),
-                'groups': user_data.get('groups', []),
-                'last_sync_from_authentik': datetime.utcnow().isoformat()
-            })
+            mapping.metadata.update(
+                {
+                    "authentik_user_id": user_data.get("pk"),
+                    "name": user_data.get("name"),
+                    "is_active": user_data.get("is_active"),
+                    "is_superuser": user_data.get("is_superuser"),
+                    "groups": user_data.get("groups", []),
+                    "last_sync_from_authentik": datetime.utcnow().isoformat(),
+                }
+            )
 
             if mapping.status == MappingStatus.PENDING:
                 mapping.status = MappingStatus.ACTIVE
 
             return True
 
         except Exception as e:
             logger.error(f"Error syncing from Authentik: {e}")
             return False
 
-    async def _sync_to_service(
-        self,
-        db: AsyncSession,
-        mapping: UserMapping,
-        adapter: Any
-    ) -> bool:
+    async def _sync_to_service(self, db: AsyncSession, mapping: UserMapping, adapter: Any) -> bool:
         """Sync user data to a service.
 
         Args:
             db: Database session
             mapping: User mapping to sync
@@ -299,16 +281,16 @@
         """
         try:
             # This is service-specific logic
             # For now, we just verify the user exists in the target service
 
-            if hasattr(adapter, 'get_users'):
+            if hasattr(adapter, "get_users"):
                 users = await adapter.get_users()
                 # Try to find the user by username or email
                 user_found = any(
-                    user.get('username') == mapping.service_username or
-                    user.get('email') == mapping.service_email
+                    user.get("username") == mapping.service_username
+                    or user.get("email") == mapping.service_email
                     for user in users
                 )
 
                 if user_found:
                     if mapping.status == MappingStatus.PENDING:
@@ -327,14 +309,11 @@
         except Exception as e:
             logger.error(f"Error syncing to service: {e}")
             return False
 
     async def sync_user(
-        self,
-        db: AsyncSession,
-        central_user_id: str,
-        force: bool = False
+        self, db: AsyncSession, central_user_id: str, force: bool = False
     ) -> Dict[str, Any]:
         """Sync a specific user across all their mapped services.
 
         Args:
             db: Database session
@@ -356,11 +335,11 @@
 
         if not mappings:
             return {
                 "central_user_id": central_user_id,
                 "success": False,
-                "error": "No mappings found for user"
+                "error": "No mappings found for user",
             }
 
         # Filter mappings that need syncing
         if not force:
             mappings = [mapping for mapping in mappings if mapping.needs_sync()]
@@ -368,11 +347,11 @@
         sync_result = {
             "central_user_id": central_user_id,
             "total_mappings": len(mappings),
             "successful_syncs": 0,
             "failed_syncs": 0,
-            "sync_details": []
+            "sync_details": [],
         }
 
         for mapping in mappings:
             try:
                 # Get service config
@@ -381,15 +360,17 @@
                 )
                 service = service_result.scalar_one_or_none()
 
                 if not service or not service.enabled:
                     sync_result["failed_syncs"] += 1
-                    sync_result["sync_details"].append({
-                        "service_id": mapping.service_config_id,
-                        "success": False,
-                        "error": "Service not found or disabled"
-                    })
+                    sync_result["sync_details"].append(
+                        {
+                            "service_id": mapping.service_config_id,
+                            "success": False,
+                            "error": "Service not found or disabled",
+                        }
+                    )
                     continue
 
                 # Create adapter and sync
                 adapter = await service_registry.create_adapter(service)
                 if adapter:
@@ -400,43 +381,43 @@
                             mapping.update_sync_result(True)
                         else:
                             sync_result["failed_syncs"] += 1
                             mapping.update_sync_result(False, "Sync failed")
 
-                        sync_result["sync_details"].append({
-                            "service_id": mapping.service_config_id,
-                            "service_name": service.name,
-                            "success": success
-                        })
+                        sync_result["sync_details"].append(
+                            {
+                                "service_id": mapping.service_config_id,
+                                "service_name": service.name,
+                                "success": success,
+                            }
+                        )
                 else:
                     sync_result["failed_syncs"] += 1
-                    sync_result["sync_details"].append({
-                        "service_id": mapping.service_config_id,
-                        "success": False,
-                        "error": "No adapter available"
-                    })
+                    sync_result["sync_details"].append(
+                        {
+                            "service_id": mapping.service_config_id,
+                            "success": False,
+                            "error": "No adapter available",
+                        }
+                    )
 
             except Exception as e:
                 logger.error(f"Error syncing mapping {mapping.id}: {e}")
                 sync_result["failed_syncs"] += 1
-                sync_result["sync_details"].append({
-                    "service_id": mapping.service_config_id,
-                    "success": False,
-                    "error": str(e)
-                })
+                sync_result["sync_details"].append(
+                    {"service_id": mapping.service_config_id, "success": False, "error": str(e)}
+                )
                 mapping.update_sync_result(False, str(e))
 
         # Commit all updates
         await db.commit()
 
         sync_result["success"] = sync_result["failed_syncs"] == 0
         return sync_result
 
     async def discover_users_from_authentik(
-        self,
-        db: AsyncSession,
-        authentik_service_id: str
+        self, db: AsyncSession, authentik_service_id: str
     ) -> Dict[str, Any]:
         """Discover users from Authentik and create mapping suggestions.
 
         Args:
             db: Database session
@@ -452,75 +433,66 @@
             select(ServiceConfig).where(ServiceConfig.id == authentik_service_id)
         )
         service = service_result.scalar_one_or_none()
 
         if not service or service.service_type != ServiceType.AUTHENTIK:
-            return {
-                "success": False,
-                "error": "Invalid Authentik service configuration"
-            }
+            return {"success": False, "error": "Invalid Authentik service configuration"}
 
         try:
             adapter = await service_registry.create_adapter(service)
             if not adapter:
-                return {
-                    "success": False,
-                    "error": "Could not create Authentik adapter"
-                }
+                return {"success": False, "error": "Could not create Authentik adapter"}
 
             async with adapter:
                 # Test connection
                 test_result = await adapter.test_connection()
                 if not test_result.success:
                     return {
                         "success": False,
-                        "error": f"Authentik connection failed: {test_result.message}"
+                        "error": f"Authentik connection failed: {test_result.message}",
                     }
 
                 # Get all users from Authentik
                 users_data = await adapter.get_users(page_size=100)
-                users = users_data.get('users', [])
+                users = users_data.get("users", [])
 
                 # Find existing mappings
                 existing_mappings = await db.execute(
-                    select(UserMapping)
-                    .where(UserMapping.service_config_id == authentik_service_id)
+                    select(UserMapping).where(UserMapping.service_config_id == authentik_service_id)
                 )
                 existing_users = {
-                    mapping.service_user_id
-                    for mapping in existing_mappings.scalars().all()
+                    mapping.service_user_id for mapping in existing_mappings.scalars().all()
                 }
 
                 # Create suggestions for unmapped users
                 suggestions = []
                 for user in users:
-                    user_id = str(user.get('pk'))
+                    user_id = str(user.get("pk"))
                     if user_id not in existing_users:
-                        suggestions.append({
-                            'authentik_user_id': user_id,
-                            'username': user.get('username'),
-                            'email': user.get('email'),
-                            'name': user.get('name'),
-                            'is_active': user.get('is_active'),
-                            'is_superuser': user.get('is_superuser'),
-                            'groups': user.get('groups', [])
-                        })
+                        suggestions.append(
+                            {
+                                "authentik_user_id": user_id,
+                                "username": user.get("username"),
+                                "email": user.get("email"),
+                                "name": user.get("name"),
+                                "is_active": user.get("is_active"),
+                                "is_superuser": user.get("is_superuser"),
+                                "groups": user.get("groups", []),
+                            }
+                        )
 
                 return {
                     "success": True,
                     "total_users": len(users),
                     "existing_mappings": len(existing_users),
                     "new_suggestions": len(suggestions),
-                    "user_suggestions": suggestions
+                    "user_suggestions": suggestions,
                 }
 
         except Exception as e:
             logger.error(f"Error discovering users from Authentik: {e}")
-            return {
-                "success": False,
-                "error": str(e)
-            }
+            return {"success": False, "error": str(e)}
 
 
 # Global user sync service instance
 user_sync_service = UserSyncService()
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_sync.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/system.py	2025-12-31 13:30:51.463098+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/system.py	2025-12-31 13:41:37.490012+00:00
@@ -60,43 +60,44 @@
             interval_seconds = 5
 
         subscription = {
             "metrics_types": metrics_types,
             "interval_seconds": interval_seconds,
-            "task": None
+            "task": None,
         }
 
         # Cancel existing subscription if any
         if connection_id in self.active_subscriptions:
             existing_task = self.active_subscriptions[connection_id].get("task")
             if existing_task:
                 existing_task.cancel()
 
         # Start metrics streaming task
-        task = asyncio.create_task(
-            self.stream_metrics(connection_id, subscription)
-        )
+        task = asyncio.create_task(self.stream_metrics(connection_id, subscription))
         subscription["task"] = task
 
         self.active_subscriptions[connection_id] = subscription
 
         # Send confirmation
-        await connection_manager.send_message(connection_id, {
-            "type": "metrics_subscribed",
-            "metrics_types": metrics_types,
-            "interval_seconds": interval_seconds
-        })
+        await connection_manager.send_message(
+            connection_id,
+            {
+                "type": "metrics_subscribed",
+                "metrics_types": metrics_types,
+                "interval_seconds": interval_seconds,
+            },
+        )
 
         logger.info(
             f"Metrics subscription started for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "metrics_subscribe",
                 "connection_id": connection_id,
                 "metrics_types": metrics_types,
-                "interval": interval_seconds
-            }
+                "interval": interval_seconds,
+            },
         )
 
     async def handle_metrics_unsubscribe(self, connection_id: str):
         """Handle metrics unsubscription request."""
         if connection_id in self.active_subscriptions:
@@ -105,21 +106,19 @@
             if task:
                 task.cancel()
 
             del self.active_subscriptions[connection_id]
 
-            await connection_manager.send_message(connection_id, {
-                "type": "metrics_unsubscribed"
-            })
+            await connection_manager.send_message(connection_id, {"type": "metrics_unsubscribed"})
 
             logger.info(
                 f"Metrics subscription stopped for {connection_id}",
                 extra={
                     "component": "websocket",
                     "action": "metrics_unsubscribe",
-                    "connection_id": connection_id
-                }
+                    "connection_id": connection_id,
+                },
             )
 
     async def stream_metrics(self, connection_id: str, subscription: Dict[str, Any]):
         """Stream metrics to WebSocket connection."""
         interval_seconds = subscription["interval_seconds"]
@@ -140,40 +139,37 @@
                         "disk_used_gb": system_status.get("disk_used_gb", 0),
                         "disk_total_gb": system_status.get("disk_total_gb", 0),
                         "disk_percent": system_status.get("disk_percent", 0),
                         "network_sent_mb": system_status.get("network_sent_mb", 0),
                         "network_recv_mb": system_status.get("network_recv_mb", 0),
-                        "load_average": [0.1, 0.2, 0.15]  # Mock data
+                        "load_average": [0.1, 0.2, 0.15],  # Mock data
                     }
 
                 if "docker" in metrics_types:
                     docker_status = await self.system_monitor.get_docker_status()
                     metrics_data["docker"] = {
                         "containers_running": docker_status.get("containers_running", 0),
                         "containers_stopped": docker_status.get("containers_stopped", 0),
                         "containers_paused": docker_status.get("containers_paused", 0),
                         "images_count": docker_status.get("images_count", 0),
-                        "volumes_count": docker_status.get("volumes_count", 0)
+                        "volumes_count": docker_status.get("volumes_count", 0),
                     }
 
                 if "services" in metrics_types:
                     # Mock services data (would be real when services are implemented)
                     metrics_data["services"] = [
                         {
                             "service_id": "mock-service-1",
                             "name": "Mock Service",
                             "status": "online",
                             "response_time_ms": 45.2,
-                            "last_check": system_status.get("timestamp")
+                            "last_check": system_status.get("timestamp"),
                         }
                     ]
 
                 # Send metrics update
-                message = {
-                    "type": "metrics_update",
-                    **metrics_data
-                }
+                message = {"type": "metrics_update", **metrics_data}
 
                 success = await connection_manager.send_message(connection_id, message)
                 if not success:
                     break
 
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/system.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/worker_client.py	2025-12-31 13:30:51.477007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/worker_client.py	2025-12-31 13:41:37.592056+00:00
@@ -10,10 +10,11 @@
 
 
 @dataclass
 class WorkerStatus:
     """Training worker status."""
+
     online: bool
     worker_id: str = ""
     worker_name: str = ""
     status: str = "unknown"
     gpu_available: bool = False
@@ -28,10 +29,11 @@
 
 
 @dataclass
 class TrainingJobStatus:
     """Training job status from worker."""
+
     job_id: str
     session_id: str
     status: str
     progress_percent: float
     current_step: int
@@ -50,10 +52,11 @@
     loss_history: Optional[List[float]] = None  # Full loss history from worker
 
 
 class WorkerClientError(Exception):
     """Worker client error."""
+
     pass
 
 
 class WorkerClient:
     """Client for communicating with the training worker."""
@@ -73,21 +76,18 @@
 
     async def health_check(self) -> WorkerStatus:
         """Check if worker is online and get its status."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
-                response = await client.get(
-                    f"{self.base_url}/health",
-                    headers=self._get_headers()
-                )
+                response = await client.get(f"{self.base_url}/health", headers=self._get_headers())
                 if response.status_code == 200:
                     data = response.json()
                     return WorkerStatus(
                         online=True,
                         worker_id=data.get("worker_id", ""),
                         status="healthy",
-                        gpu_available=data.get("gpu_available", False)
+                        gpu_available=data.get("gpu_available", False),
                     )
                 return WorkerStatus(online=False, error=f"HTTP {response.status_code}")
         except httpx.ConnectError:
             return WorkerStatus(online=False, error="Connection refused")
         except httpx.TimeoutException:
@@ -97,25 +97,22 @@
 
     async def get_worker_info(self) -> WorkerStatus:
         """Get detailed worker information."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
-                response = await client.get(
-                    f"{self.base_url}/",
-                    headers=self._get_headers()
-                )
+                response = await client.get(f"{self.base_url}/", headers=self._get_headers())
                 if response.status_code == 200:
                     data = response.json()
                     return WorkerStatus(
                         online=True,
                         worker_id=data.get("worker_id", ""),
                         worker_name=data.get("worker_name", ""),
                         status=data.get("status", "unknown"),
                         gpu_available=data.get("gpu_available", False),
                         gpu_count=data.get("gpu_count", 0),
                         gpu_names=data.get("gpu_names", []),
-                        current_job_id=data.get("current_job_id")
+                        current_job_id=data.get("current_job_id"),
                     )
                 return WorkerStatus(online=False, error=f"HTTP {response.status_code}")
         except Exception as e:
             logger.warning(f"Failed to get worker info: {e}")
             return WorkerStatus(online=False, error=str(e))
@@ -123,12 +120,11 @@
     async def get_gpu_metrics(self) -> Dict[str, Any]:
         """Get GPU metrics from worker."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/api/metrics/gpu",
-                    headers=self._get_headers()
+                    f"{self.base_url}/api/metrics/gpu", headers=self._get_headers()
                 )
                 if response.status_code == 200:
                     return response.json()
                 return {"available": False, "error": f"HTTP {response.status_code}"}
         except Exception as e:
@@ -147,11 +143,11 @@
         max_seq_length: int = 2048,
         lora_r: int = 16,
         lora_alpha: int = 16,
         quantization_method: str = "q4_k_m",
         overwrite_existing: bool = False,
-        base_adapter_path: Optional[str] = None
+        base_adapter_path: Optional[str] = None,
     ) -> Dict[str, Any]:
         """Start a training job on the worker.
 
         Args:
             session_id: MCParr session ID
@@ -179,11 +175,11 @@
             "output_model_name": output_model_name,
             "prompts": [
                 {
                     "system_prompt": p.get("system_prompt"),
                     "user_input": p["user_input"],
-                    "expected_output": p["expected_output"]
+                    "expected_output": p["expected_output"],
                 }
                 for p in prompts
             ],
             "hyperparameters": {
                 "num_epochs": num_epochs,
@@ -192,17 +188,17 @@
                 "max_seq_length": max_seq_length,
                 "warmup_steps": 5,
                 "weight_decay": 0.01,
                 "lora_r": lora_r,
                 "lora_alpha": lora_alpha,
-                "quantization_method": quantization_method
+                "quantization_method": quantization_method,
             },
             "ollama_target": {
                 "url": ollama_url,
                 "model_name": output_model_name,
-                "overwrite": overwrite_existing
-            }
+                "overwrite": overwrite_existing,
+            },
         }
 
         # Add base_adapter_path for incremental training
         if base_adapter_path:
             request_data["base_adapter_path"] = base_adapter_path
@@ -210,37 +206,31 @@
         try:
             async with httpx.AsyncClient(timeout=httpx.Timeout(60.0, connect=10.0)) as client:
                 response = await client.post(
                     f"{self.base_url}/api/training/start",
                     json=request_data,
-                    headers=self._get_headers()
+                    headers=self._get_headers(),
                 )
 
                 if response.status_code == 200:
                     data = response.json()
                     logger.info(f"Training job started: {data.get('job_id')}")
                     return {
                         "success": True,
                         "job_id": data.get("job_id"),
                         "message": data.get("message"),
-                        "status": data.get("status")
+                        "status": data.get("status"),
                     }
                 elif response.status_code == 409:
-                    return {
-                        "success": False,
-                        "error": "Worker is already training another job"
-                    }
+                    return {"success": False, "error": "Worker is already training another job"}
                 elif response.status_code == 503:
-                    return {
-                        "success": False,
-                        "error": "No GPU available on worker"
-                    }
+                    return {"success": False, "error": "No GPU available on worker"}
                 else:
                     error_detail = response.json().get("detail", response.text)
                     return {
                         "success": False,
-                        "error": f"HTTP {response.status_code}: {error_detail}"
+                        "error": f"HTTP {response.status_code}: {error_detail}",
                     }
 
         except httpx.ConnectError:
             return {"success": False, "error": "Cannot connect to training worker"}
         except httpx.TimeoutException:
@@ -252,12 +242,11 @@
     async def get_training_status(self) -> Optional[TrainingJobStatus]:
         """Get current training job status."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/training/status",
-                    headers=self._get_headers()
+                    f"{self.base_url}/training/status", headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     data = response.json()
                     if data is None:
@@ -265,11 +254,13 @@
                     progress = data.get("progress", {})
                     return TrainingJobStatus(
                         job_id=data.get("job_id", ""),
                         session_id=data.get("session_id", ""),
                         status=data.get("status", "unknown"),
-                        progress_percent=progress.get("progress_percent", data.get("progress_percent", 0)),
+                        progress_percent=progress.get(
+                            "progress_percent", data.get("progress_percent", 0)
+                        ),
                         current_step=progress.get("current_step", data.get("current_step", 0)),
                         total_steps=progress.get("total_steps", data.get("total_steps", 0)),
                         current_epoch=progress.get("current_epoch", data.get("current_epoch", 0)),
                         total_epochs=progress.get("total_epochs", data.get("total_epochs", 0)),
                         loss=progress.get("loss", data.get("loss")),
@@ -291,12 +282,11 @@
     async def get_job_status(self, job_id: str) -> Optional[TrainingJobStatus]:
         """Get status for a specific job."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/api/training/job/{job_id}",
-                    headers=self._get_headers()
+                    f"{self.base_url}/api/training/job/{job_id}", headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     data = response.json()
                     # Progress fields can be nested under 'progress' or at top level
@@ -312,11 +302,13 @@
 
                     return TrainingJobStatus(
                         job_id=data.get("job_id", ""),
                         session_id=data.get("session_id", ""),
                         status=data.get("status", "unknown"),
-                        progress_percent=progress.get("progress_percent", data.get("progress_percent", 0)),
+                        progress_percent=progress.get(
+                            "progress_percent", data.get("progress_percent", 0)
+                        ),
                         current_step=progress.get("current_step", data.get("current_step", 0)),
                         total_steps=progress.get("total_steps", data.get("total_steps", 0)),
                         current_epoch=progress.get("current_epoch", data.get("current_epoch", 0)),
                         total_epochs=progress.get("total_epochs", data.get("total_epochs", 0)),
                         loss=loss,
@@ -339,12 +331,11 @@
     async def cancel_training(self) -> Dict[str, Any]:
         """Cancel the current training job."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.post(
-                    f"{self.base_url}/training/cancel",
-                    headers=self._get_headers()
+                    f"{self.base_url}/training/cancel", headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     return {"success": True, **response.json()}
                 elif response.status_code == 404:
@@ -357,14 +348,11 @@
 
     async def get_available_models(self) -> Dict[str, Any]:
         """Get available base models for training."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
-                response = await client.get(
-                    f"{self.base_url}/models",
-                    headers=self._get_headers()
-                )
+                response = await client.get(f"{self.base_url}/models", headers=self._get_headers())
 
                 if response.status_code == 200:
                     return response.json()
                 return {"recommended": [], "quantization_methods": []}
 
@@ -381,13 +369,11 @@
             if level:
                 params["level"] = level
 
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/logs/system",
-                    params=params,
-                    headers=self._get_headers()
+                    f"{self.base_url}/logs/system", params=params, headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     return response.json()
                 return {"logs": [], "count": 0, "error": f"HTTP {response.status_code}"}
@@ -395,43 +381,42 @@
         except Exception as e:
             logger.warning(f"Failed to get system logs: {e}")
             return {"logs": [], "count": 0, "error": str(e)}
 
     async def get_job_logs(
-        self,
-        job_id: str,
-        tail: int = 100,
-        level: Optional[str] = None
+        self, job_id: str, tail: int = 100, level: Optional[str] = None
     ) -> Dict[str, Any]:
         """Get logs for a specific training job."""
         try:
             params = {"tail": tail}
             if level:
                 params["level"] = level
 
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/logs/job/{job_id}",
-                    params=params,
-                    headers=self._get_headers()
+                    f"{self.base_url}/logs/job/{job_id}", params=params, headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     return response.json()
-                return {"job_id": job_id, "logs": [], "count": 0, "error": f"HTTP {response.status_code}"}
+                return {
+                    "job_id": job_id,
+                    "logs": [],
+                    "count": 0,
+                    "error": f"HTTP {response.status_code}",
+                }
 
         except Exception as e:
             logger.warning(f"Failed to get job logs: {e}")
             return {"job_id": job_id, "logs": [], "count": 0, "error": str(e)}
 
     async def get_available_job_logs(self) -> Dict[str, Any]:
         """Get list of job IDs that have available logs."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.get(
-                    f"{self.base_url}/logs/jobs",
-                    headers=self._get_headers()
+                    f"{self.base_url}/logs/jobs", headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     return response.json()
                 return {"job_ids": [], "count": 0, "error": f"HTTP {response.status_code}"}
@@ -443,12 +428,11 @@
     async def delete_job_logs(self, job_id: str) -> Dict[str, Any]:
         """Delete logs for a specific job."""
         try:
             async with httpx.AsyncClient(timeout=self.timeout) as client:
                 response = await client.delete(
-                    f"{self.base_url}/logs/job/{job_id}",
-                    headers=self._get_headers()
+                    f"{self.base_url}/logs/job/{job_id}", headers=self._get_headers()
                 )
 
                 if response.status_code == 200:
                     return {"success": True, **response.json()}
                 return {"success": False, "error": f"HTTP {response.status_code}"}
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/worker_client.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/training.py	2025-12-31 13:30:51.461007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/training.py	2025-12-31 13:41:37.631092+00:00
@@ -29,14 +29,13 @@
         """Handle WebSocket connection for training progress."""
         connection_id = await connection_manager.connect(websocket)
 
         try:
             # Send initial connection confirmation
-            await connection_manager.send_message(connection_id, {
-                "type": "connected",
-                "message": "Connected to training WebSocket"
-            })
+            await connection_manager.send_message(
+                connection_id, {"type": "connected", "message": "Connected to training WebSocket"}
+            )
 
             while True:
                 # Receive message from client
                 data = await websocket.receive_text()
                 message = json.loads(data)
@@ -77,21 +76,19 @@
         handler = handlers.get(message_type)
         if handler:
             await handler(connection_id, message)
         else:
             logger.warning(f"Unknown training message type: {message_type}")
-            await connection_manager.send_message(connection_id, {
-                "type": "error",
-                "message": f"Unknown message type: {message_type}"
-            })
+            await connection_manager.send_message(
+                connection_id, {"type": "error", "message": f"Unknown message type: {message_type}"}
+            )
 
     async def handle_ping(self, connection_id: str, message: Dict[str, Any]):
         """Handle ping message."""
-        await connection_manager.send_message(connection_id, {
-            "type": "pong",
-            "timestamp": datetime.utcnow().isoformat()
-        })
+        await connection_manager.send_message(
+            connection_id, {"type": "pong", "timestamp": datetime.utcnow().isoformat()}
+        )
 
     async def handle_training_subscribe(self, connection_id: str, message: Dict[str, Any]):
         """Subscribe to general training updates."""
         interval_seconds = message.get("interval_seconds", 5)
 
@@ -100,65 +97,55 @@
             interval_seconds = 5
 
         # Cancel existing subscription if any
         await self._cancel_subscription(connection_id, "training")
 
-        subscription = {
-            "type": "training",
-            "interval_seconds": interval_seconds,
-            "task": None
-        }
+        subscription = {"type": "training", "interval_seconds": interval_seconds, "task": None}
 
         # Start training updates streaming task
-        task = asyncio.create_task(
-            self.stream_training_updates(connection_id, subscription)
-        )
+        task = asyncio.create_task(self.stream_training_updates(connection_id, subscription))
         subscription["task"] = task
 
         self.active_subscriptions[connection_id] = subscription
 
         # Send confirmation
-        await connection_manager.send_message(connection_id, {
-            "type": "training_subscribed",
-            "interval_seconds": interval_seconds
-        })
+        await connection_manager.send_message(
+            connection_id, {"type": "training_subscribed", "interval_seconds": interval_seconds}
+        )
 
         logger.info(
             f"Training subscription started for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "training_subscribe",
                 "connection_id": connection_id,
-                "interval": interval_seconds
-            }
+                "interval": interval_seconds,
+            },
         )
 
     async def handle_training_unsubscribe(self, connection_id: str, message: Dict[str, Any]):
         """Unsubscribe from training updates."""
         await self._cancel_subscription(connection_id, "training")
 
-        await connection_manager.send_message(connection_id, {
-            "type": "training_unsubscribed"
-        })
+        await connection_manager.send_message(connection_id, {"type": "training_unsubscribed"})
 
         logger.info(
             f"Training subscription stopped for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "training_unsubscribe",
-                "connection_id": connection_id
-            }
+                "connection_id": connection_id,
+            },
         )
 
     async def handle_session_subscribe(self, connection_id: str, message: Dict[str, Any]):
         """Subscribe to specific training session updates."""
         session_id = message.get("session_id")
         if not session_id:
-            await connection_manager.send_message(connection_id, {
-                "type": "error",
-                "message": "session_id is required"
-            })
+            await connection_manager.send_message(
+                connection_id, {"type": "error", "message": "session_id is required"}
+            )
             return
 
         interval_seconds = message.get("interval_seconds", 2)
 
         # Validate interval
@@ -170,54 +157,53 @@
 
         subscription = {
             "type": "session",
             "session_id": session_id,
             "interval_seconds": interval_seconds,
-            "task": None
+            "task": None,
         }
 
         # Start session progress streaming task
-        task = asyncio.create_task(
-            self.stream_session_progress(connection_id, subscription)
-        )
+        task = asyncio.create_task(self.stream_session_progress(connection_id, subscription))
         subscription["task"] = task
 
         self.active_subscriptions[connection_id] = subscription
 
         # Send confirmation
-        await connection_manager.send_message(connection_id, {
-            "type": "session_subscribed",
-            "session_id": session_id,
-            "interval_seconds": interval_seconds
-        })
+        await connection_manager.send_message(
+            connection_id,
+            {
+                "type": "session_subscribed",
+                "session_id": session_id,
+                "interval_seconds": interval_seconds,
+            },
+        )
 
         logger.info(
             f"Session subscription started for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "session_subscribe",
                 "connection_id": connection_id,
                 "session_id": session_id,
-                "interval": interval_seconds
-            }
+                "interval": interval_seconds,
+            },
         )
 
     async def handle_session_unsubscribe(self, connection_id: str, message: Dict[str, Any]):
         """Unsubscribe from session updates."""
         await self._cancel_subscription(connection_id, "session")
 
-        await connection_manager.send_message(connection_id, {
-            "type": "session_unsubscribed"
-        })
+        await connection_manager.send_message(connection_id, {"type": "session_unsubscribed"})
 
         logger.info(
             f"Session subscription stopped for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "session_unsubscribe",
-                "connection_id": connection_id
-            }
+                "connection_id": connection_id,
+            },
         )
 
     async def handle_ollama_metrics_subscribe(self, connection_id: str, message: Dict[str, Any]):
         """Subscribe to Ollama metrics updates."""
         interval_seconds = message.get("interval_seconds", 10)
@@ -240,52 +226,50 @@
 
         subscription = {
             "type": "ollama_metrics",
             "interval_seconds": interval_seconds,
             "ollama_service": ollama_service,
-            "task": None
+            "task": None,
         }
 
         # Start Ollama metrics streaming task
-        task = asyncio.create_task(
-            self.stream_ollama_metrics(connection_id, subscription)
-        )
+        task = asyncio.create_task(self.stream_ollama_metrics(connection_id, subscription))
         subscription["task"] = task
 
         self.active_subscriptions[connection_id] = subscription
 
         # Send confirmation
-        await connection_manager.send_message(connection_id, {
-            "type": "ollama_metrics_subscribed",
-            "interval_seconds": interval_seconds
-        })
+        await connection_manager.send_message(
+            connection_id,
+            {"type": "ollama_metrics_subscribed", "interval_seconds": interval_seconds},
+        )
 
         logger.info(
             f"Ollama metrics subscription started for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "ollama_metrics_subscribe",
                 "connection_id": connection_id,
-                "interval": interval_seconds
-            }
+                "interval": interval_seconds,
+            },
         )
 
     async def handle_ollama_metrics_unsubscribe(self, connection_id: str, message: Dict[str, Any]):
         """Unsubscribe from Ollama metrics updates."""
         await self._cancel_subscription(connection_id, "ollama_metrics")
 
-        await connection_manager.send_message(connection_id, {
-            "type": "ollama_metrics_unsubscribed"
-        })
+        await connection_manager.send_message(
+            connection_id, {"type": "ollama_metrics_unsubscribed"}
+        )
 
         logger.info(
             f"Ollama metrics subscription stopped for {connection_id}",
             extra={
                 "component": "websocket",
                 "action": "ollama_metrics_unsubscribe",
-                "connection_id": connection_id
-            }
+                "connection_id": connection_id,
+            },
         )
 
     async def _cancel_subscription(self, connection_id: str, subscription_type: str):
         """Cancel existing subscription."""
         if connection_id in self.active_subscriptions:
@@ -311,11 +295,11 @@
                         "queued_sessions": 0,
                         "completed_today": 0,
                         "total_prompts": 0,
                         "validated_prompts": 0,
                     },
-                    "recent_activity": []
+                    "recent_activity": [],
                 }
 
                 success = await connection_manager.send_message(connection_id, training_data)
                 if not success:
                     break
@@ -352,11 +336,11 @@
                         "loss": None,
                         "accuracy": None,
                         "learning_rate": None,
                         "elapsed_seconds": 0,
                         "estimated_remaining_seconds": None,
-                    }
+                    },
                 }
 
                 success = await connection_manager.send_message(connection_id, session_data)
                 if not success:
                     break
@@ -412,32 +396,23 @@
         except Exception as e:
             logger.error(f"Error streaming Ollama metrics for {connection_id}: {e}")
 
     async def broadcast_training_event(self, event_type: str, data: Dict[str, Any]):
         """Broadcast training event to all subscribed connections."""
-        message = {
-            "type": event_type,
-            **data,
-            "timestamp": datetime.utcnow().isoformat()
-        }
+        message = {"type": event_type, **data, "timestamp": datetime.utcnow().isoformat()}
 
         for connection_id, subscription in self.active_subscriptions.items():
             if subscription.get("type") in ["training", "session"]:
                 await connection_manager.send_message(connection_id, message)
 
-    async def broadcast_session_event(
-        self,
-        session_id: str,
-        event_type: str,
-        data: Dict[str, Any]
-    ):
+    async def broadcast_session_event(self, session_id: str, event_type: str, data: Dict[str, Any]):
         """Broadcast session-specific event to subscribed connections."""
         message = {
             "type": event_type,
             "session_id": session_id,
             **data,
-            "timestamp": datetime.utcnow().isoformat()
+            "timestamp": datetime.utcnow().isoformat(),
         }
 
         for connection_id, subscription in self.active_subscriptions.items():
             if subscription.get("type") == "session":
                 if subscription.get("session_id") == session_id:
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/websocket/training.py
--- /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_mapper.py	2025-12-31 13:30:51.531007+00:00
+++ /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_mapper.py	2025-12-31 13:41:37.717751+00:00
@@ -22,10 +22,11 @@
 
 
 @dataclass
 class UserSuggestion:
     """A suggested user mapping between services."""
+
     central_user_id: str
     service_config_id: str
     service_user_id: Optional[str] = None
     service_username: Optional[str] = None
     service_email: Optional[str] = None
@@ -48,13 +49,11 @@
         """Initialize the user mapping detector."""
         self.min_confidence_score = 0.5  # Minimum confidence for auto-suggestions
         self.fuzzy_match_threshold = 0.8  # Threshold for fuzzy string matching
 
     async def detect_all_mappings(
-        self,
-        db: AsyncSession,
-        authentik_service_id: str
+        self, db: AsyncSession, authentik_service_id: str
     ) -> Dict[str, Any]:
         """Detect user mappings across all services using Authentik as the source.
 
         Args:
             db: Database session
@@ -88,11 +87,11 @@
             "high_confidence_suggestions": [],
             "medium_confidence_suggestions": [],
             "low_confidence_suggestions": [],
             "errors": [],
             "started_at": datetime.utcnow(),
-            "completed_at": None
+            "completed_at": None,
         }
 
         # Process each service
         for service in other_services:
             try:
@@ -140,24 +139,30 @@
             Dict containing detection results and suggestions
         """
         logger.info("Starting automatic user mapping detection across all services")
 
         # Services that don't have user management (skip them)
-        SERVICES_WITHOUT_USERS = {'ollama'}
+        SERVICES_WITHOUT_USERS = {"ollama"}
 
         # Get all enabled services
         services_result = await db.execute(
             select(ServiceConfig).where(ServiceConfig.enabled is True)
         )
         all_services_raw = services_result.scalars().all()
 
         # Filter out services without user management
         all_services = [
-            s for s in all_services_raw
-            if (s.service_type.value if hasattr(s.service_type, 'value') else s.service_type).lower() not in SERVICES_WITHOUT_USERS
+            s
+            for s in all_services_raw
+            if (
+                s.service_type.value if hasattr(s.service_type, "value") else s.service_type
+            ).lower()
+            not in SERVICES_WITHOUT_USERS
         ]
-        logger.debug(f"Filtered out {len(all_services_raw) - len(all_services)} services without user management")
+        logger.debug(
+            f"Filtered out {len(all_services_raw) - len(all_services)} services without user management"
+        )
 
         if len(all_services) < 2:
             return {
                 "total_services": len(all_services),
                 "services_scanned": 0,
@@ -166,11 +171,11 @@
                 "high_confidence_suggestions": [],
                 "medium_confidence_suggestions": [],
                 "low_confidence_suggestions": [],
                 "errors": ["Need at least 2 enabled services to detect mappings"],
                 "started_at": datetime.utcnow(),
-                "completed_at": datetime.utcnow()
+                "completed_at": datetime.utcnow(),
             }
 
         detection_results = {
             "total_services": len(all_services),
             "services_scanned": 0,
@@ -179,24 +184,21 @@
             "medium_confidence_suggestions": [],
             "low_confidence_suggestions": [],
             "errors": [],
             "service_combinations": [],
             "started_at": datetime.utcnow(),
-            "completed_at": None
+            "completed_at": None,
         }
 
         # Get all users from all services
         services_with_users = {}
 
         for service in all_services:
             try:
                 service_users = await self._get_all_service_users(service)
                 if service_users:
-                    services_with_users[service.id] = {
-                        'service': service,
-                        'users': service_users
-                    }
+                    services_with_users[service.id] = {"service": service, "users": service_users}
                     detection_results["services_scanned"] += 1
                     logger.info(f"Found {len(service_users)} users in service {service.name}")
                 else:
                     logger.warning(f"No users found in service {service.name}")
 
@@ -209,22 +211,22 @@
         # Key format: "service_id:user_id"
         # Use primary ID from various field names (id, user_id, username as fallback)
         all_users_map: Dict[str, Dict[str, Any]] = {}
         for service_id, service_data in services_with_users.items():
             seen_ids = set()
-            for user in service_data['users']:
+            for user in service_data["users"]:
                 # Get user ID from various possible fields (Plex uses 'id', Tautulli uses 'user_id')
-                user_id = str(user.get('id') or user.get('user_id') or user.get('username') or '')
+                user_id = str(user.get("id") or user.get("user_id") or user.get("username") or "")
                 if not user_id or user_id in seen_ids:
                     continue
                 seen_ids.add(user_id)
                 key = f"{service_id}:{user_id}"
                 all_users_map[key] = {
-                    'service': service_data['service'],
-                    'user': user,
-                    'service_id': service_id,
-                    'user_id': user_id
+                    "service": service_data["service"],
+                    "user": user,
+                    "service_id": service_id,
+                    "user_id": user_id,
                 }
 
         # Union-Find data structure for clustering
         parent: Dict[str, str] = {key: key for key in all_users_map.keys()}
 
@@ -246,36 +248,46 @@
 
         # Compare users across all service pairs and build clusters
         service_ids = list(services_with_users.keys())
 
         for i, service_id_1 in enumerate(service_ids):
-            for service_id_2 in service_ids[i+1:]:
+            for service_id_2 in service_ids[i + 1 :]:
                 try:
                     service_1_data = services_with_users[service_id_1]
                     service_2_data = services_with_users[service_id_2]
 
                     combination = {
-                        'service_1': service_1_data['service'].name,
-                        'service_2': service_2_data['service'].name,
-                        'suggestions_found': 0
+                        "service_1": service_1_data["service"].name,
+                        "service_2": service_2_data["service"].name,
+                        "suggestions_found": 0,
                     }
 
                     match_count = 0
 
                     # Compare all users between the two services
-                    for user_1 in service_1_data['users']:
+                    for user_1 in service_1_data["users"]:
                         # Use same ID extraction logic as all_users_map
-                        user_1_id = str(user_1.get('id') or user_1.get('user_id') or user_1.get('username') or '')
+                        user_1_id = str(
+                            user_1.get("id")
+                            or user_1.get("user_id")
+                            or user_1.get("username")
+                            or ""
+                        )
                         key_1 = f"{service_id_1}:{user_1_id}"
 
                         # Skip if this user wasn't added to the map (filtered as duplicate)
                         if key_1 not in all_users_map:
                             continue
 
-                        for user_2 in service_2_data['users']:
+                        for user_2 in service_2_data["users"]:
                             # Use same ID extraction logic as all_users_map
-                            user_2_id = str(user_2.get('id') or user_2.get('user_id') or user_2.get('username') or '')
+                            user_2_id = str(
+                                user_2.get("id")
+                                or user_2.get("user_id")
+                                or user_2.get("username")
+                                or ""
+                            )
                             key_2 = f"{service_id_2}:{user_2_id}"
 
                             # Skip if this user wasn't added to the map (filtered as duplicate)
                             if key_2 not in all_users_map:
                                 continue
@@ -283,34 +295,39 @@
                             score, matching_attrs = self._calculate_user_match_score(user_1, user_2)
 
                             if score >= self.min_confidence_score:
                                 # For services that share the same ID system (Plex/Tautulli),
                                 # only union if IDs match to prevent false positives from name-only matches
-                                user_1_primary_id = user_1.get('id') or user_1.get('user_id')
-                                user_2_primary_id = user_2.get('id') or user_2.get('user_id')
+                                user_1_primary_id = user_1.get("id") or user_1.get("user_id")
+                                user_2_primary_id = user_2.get("id") or user_2.get("user_id")
 
                                 # Check if both services use Plex-style IDs (large integers > 1000000)
                                 # Plex/Tautulli use the same large numeric IDs
                                 # Overseerr uses small sequential IDs (1, 2, 3...)
                                 both_use_plex_ids = (
-                                    user_1_primary_id and user_2_primary_id and
-                                    isinstance(user_1_primary_id, int) and isinstance(user_2_primary_id, int) and
-                                    user_1_primary_id > 1000000 and user_2_primary_id > 1000000
+                                    user_1_primary_id
+                                    and user_2_primary_id
+                                    and isinstance(user_1_primary_id, int)
+                                    and isinstance(user_2_primary_id, int)
+                                    and user_1_primary_id > 1000000
+                                    and user_2_primary_id > 1000000
                                 )
 
                                 if both_use_plex_ids and user_1_primary_id != user_2_primary_id:
                                     # Both have Plex-style IDs but they don't match - skip this union
                                     continue
 
                                 # Union these two users into the same cluster
                                 union(key_1, key_2)
                                 match_count += 1
 
-                    combination['suggestions_found'] = match_count
+                    combination["suggestions_found"] = match_count
                     detection_results["service_combinations"].append(combination)
 
-                    logger.info(f"Found {match_count} matches between {service_1_data['service'].name} and {service_2_data['service'].name}")
+                    logger.info(
+                        f"Found {match_count} matches between {service_1_data['service'].name} and {service_2_data['service'].name}"
+                    )
 
                 except Exception as e:
                     error_msg = f"Error comparing {service_1_data['service'].name} and {service_2_data['service'].name}: {str(e)}"
                     logger.error(error_msg)
                     detection_results["errors"].append(error_msg)
@@ -334,11 +351,11 @@
                 continue
 
             # Check if cluster spans multiple services
             services_in_cluster = set()
             for key in cluster_members:
-                service_id = key.split(':')[0]
+                service_id = key.split(":")[0]
                 services_in_cluster.add(service_id)
 
             if len(services_in_cluster) < 2:
                 continue
 
@@ -347,19 +364,19 @@
             central_user_id = None
             best_email = None
             best_username = None
 
             for key in cluster_members:
-                user_data = all_users_map[key]['user']
-                email = user_data.get('email')
+                user_data = all_users_map[key]["user"]
+                email = user_data.get("email")
                 # Get username from various fields
                 username = (
-                    user_data.get('username') or
-                    user_data.get('login') or
-                    user_data.get('friendly_name') or
-                    user_data.get('name') or
-                    user_data.get('display_name')
+                    user_data.get("username")
+                    or user_data.get("login")
+                    or user_data.get("friendly_name")
+                    or user_data.get("name")
+                    or user_data.get("display_name")
                 )
 
                 if email and not best_email:
                     best_email = email.lower().strip()
                 if username and not best_username:
@@ -371,15 +388,15 @@
             # Use email first, then username, fallback to a generated ID
             central_user_id = best_email or best_username
             if not central_user_id:
                 # Generate a readable ID from the first available username
                 for key in cluster_members:
-                    user_data = all_users_map[key]['user']
+                    user_data = all_users_map[key]["user"]
                     fallback_name = (
-                        user_data.get('friendly_name') or
-                        user_data.get('name') or
-                        user_data.get('username')
+                        user_data.get("friendly_name")
+                        or user_data.get("name")
+                        or user_data.get("username")
                     )
                     if fallback_name:
                         central_user_id = str(fallback_name).lower().strip()
                         break
             if not central_user_id:
@@ -389,33 +406,36 @@
             # This prevents duplicates when multiple users from same service match by name
             best_user_per_service: Dict[str, Tuple[str, float]] = {}  # service_id -> (key, score)
 
             for key in cluster_members:
                 user_info = all_users_map[key]
-                service_id = user_info['service_id']
-                user = user_info['user']
+                service_id = user_info["service_id"]
+                user = user_info["user"]
 
                 # Calculate score for this user
                 max_score = 0.0
                 for other_key in cluster_members:
                     if other_key == key:
                         continue
-                    other_user = all_users_map[other_key]['user']
+                    other_user = all_users_map[other_key]["user"]
                     score, _ = self._calculate_user_match_score(user, other_user)
                     if score > max_score:
                         max_score = score
 
                 # Keep only the best user per service
-                if service_id not in best_user_per_service or max_score > best_user_per_service[service_id][1]:
+                if (
+                    service_id not in best_user_per_service
+                    or max_score > best_user_per_service[service_id][1]
+                ):
                     best_user_per_service[service_id] = (key, max_score)
 
             # Create suggestions only for the best user per service
             for key in [k for k, _ in best_user_per_service.values()]:
                 user_info = all_users_map[key]
-                service = user_info['service']
-                user = user_info['user']
-                user_id = user_info['user_id']
+                service = user_info["service"]
+                user = user_info["user"]
+                user_id = user_info["user_id"]
 
                 # Skip if already has a mapping
                 if user_id in existing_mappings.get(service.id, {}):
                     continue
 
@@ -424,33 +444,35 @@
                 all_matching_attrs = set()
 
                 for other_key in cluster_members:
                     if other_key == key:
                         continue
-                    other_user = all_users_map[other_key]['user']
+                    other_user = all_users_map[other_key]["user"]
                     score, attrs = self._calculate_user_match_score(user, other_user)
                     if score > max_score:
                         max_score = score
                     all_matching_attrs.update(attrs)
 
                 suggestion = UserSuggestion(
                     central_user_id=central_user_id,
                     service_config_id=service.id,
                     service_user_id=user_id,
-                    service_username=user.get('username', user.get('login', user.get('friendly_name'))),
-                    service_email=user.get('email'),
+                    service_username=user.get(
+                        "username", user.get("login", user.get("friendly_name"))
+                    ),
+                    service_email=user.get("email"),
                     confidence_score=max_score,
                     matching_attributes=list(all_matching_attrs),
                     role=self._determine_user_role_from_service_user(user),
                     metadata={
-                        'detection_method': 'cluster_analysis',
-                        'cluster_size': len(cluster_members),
-                        'services_in_cluster': list(services_in_cluster),
-                        'target_service': service.name,
-                        'target_user': user,
-                        'detected_at': datetime.utcnow().isoformat()
-                    }
+                        "detection_method": "cluster_analysis",
+                        "cluster_size": len(cluster_members),
+                        "services_in_cluster": list(services_in_cluster),
+                        "target_service": service.name,
+                        "target_user": user,
+                        "detected_at": datetime.utcnow().isoformat(),
+                    },
                 )
 
                 detection_results["suggestions"].append(suggestion)
 
                 # Categorize by confidence
@@ -471,13 +493,11 @@
         )
 
         return detection_results
 
     async def _get_authentik_users(
-        self,
-        db: AsyncSession,
-        authentik_service_id: str
+        self, db: AsyncSession, authentik_service_id: str
     ) -> Dict[str, Any]:
         """Get users from Authentik service.
 
         Args:
             db: Database session
@@ -491,53 +511,38 @@
             select(ServiceConfig).where(ServiceConfig.id == authentik_service_id)
         )
         service = service_result.scalar_one_or_none()
 
         if not service or service.service_type != ServiceType.AUTHENTIK:
-            return {
-                "success": False,
-                "error": "Invalid or missing Authentik service configuration"
-            }
+            return {"success": False, "error": "Invalid or missing Authentik service configuration"}
 
         try:
             adapter = await service_registry.create_adapter(service)
             if not adapter:
-                return {
-                    "success": False,
-                    "error": "Could not create Authentik adapter"
-                }
+                return {"success": False, "error": "Could not create Authentik adapter"}
 
             async with adapter:
                 # Test connection first
                 test_result = await adapter.test_connection()
                 if not test_result.success:
                     return {
                         "success": False,
-                        "error": f"Authentik connection failed: {test_result.message}"
+                        "error": f"Authentik connection failed: {test_result.message}",
                     }
 
                 # Get all users
                 users_data = await adapter.get_users(page_size=200)
-                users = users_data.get('users', [])
-
-                return {
-                    "success": True,
-                    "users": users
-                }
+                users = users_data.get("users", [])
+
+                return {"success": True, "users": users}
 
         except Exception as e:
             logger.error(f"Error getting Authentik users: {e}")
-            return {
-                "success": False,
-                "error": str(e)
-            }
+            return {"success": False, "error": str(e)}
 
     async def _detect_mappings_for_service(
-        self,
-        db: AsyncSession,
-        service: ServiceConfig,
-        authentik_users: List[Dict[str, Any]]
+        self, db: AsyncSession, service: ServiceConfig, authentik_users: List[Dict[str, Any]]
     ) -> List[UserSuggestion]:
         """Detect user mappings for a specific service.
 
         Args:
             db: Database session
@@ -550,12 +555,18 @@
         logger.debug(f"Detecting mappings for service: {service.name}")
 
         suggestions = []
 
         # Skip if we don't have an adapter for this service type
-        if not service_registry.has_adapter(service.service_type.value if hasattr(service.service_type, 'value') else service.service_type):
-            logger.warning(f"No adapter available for service type: {service.service_type.value if hasattr(service.service_type, 'value') else service.service_type}")
+        if not service_registry.has_adapter(
+            service.service_type.value
+            if hasattr(service.service_type, "value")
+            else service.service_type
+        ):
+            logger.warning(
+                f"No adapter available for service type: {service.service_type.value if hasattr(service.service_type, 'value') else service.service_type}"
+            )
             return suggestions
 
         try:
             adapter = await service_registry.create_adapter(service)
             if not adapter:
@@ -564,11 +575,13 @@
 
             async with adapter:
                 # Test connection
                 test_result = await adapter.test_connection()
                 if not test_result.success:
-                    logger.warning(f"Service {service.name} connection failed: {test_result.message}")
+                    logger.warning(
+                        f"Service {service.name} connection failed: {test_result.message}"
+                    )
                     return suggestions
 
                 # Get existing mappings to avoid duplicates
                 existing_mappings_result = await db.execute(
                     select(UserMapping).where(UserMapping.service_config_id == service.id)
@@ -581,11 +594,11 @@
                 # Get service users if adapter supports it
                 service_users = await self._get_service_users(adapter)
 
                 # Compare Authentik users with service users
                 for authentik_user in authentik_users:
-                    central_user_id = authentik_user.get('username')
+                    central_user_id = authentik_user.get("username")
                     if not central_user_id:
                         continue
 
                     # Skip if mapping already exists
                     if central_user_id in existing_mappings:
@@ -612,16 +625,16 @@
 
         Returns:
             List of users from the service
         """
         try:
-            if hasattr(adapter, 'get_users'):
+            if hasattr(adapter, "get_users"):
                 users = await adapter.get_users()
                 if isinstance(users, list):
                     return users
-                elif isinstance(users, dict) and 'users' in users:
-                    return users['users']
+                elif isinstance(users, dict) and "users" in users:
+                    return users["users"]
 
             # If no user enumeration is available, return empty list
             return []
 
         except Exception as e:
@@ -645,11 +658,13 @@
 
             async with adapter:
                 # Test connection
                 test_result = await adapter.test_connection()
                 if not test_result.success:
-                    logger.warning(f"Service {service.name} connection failed: {test_result.message}")
+                    logger.warning(
+                        f"Service {service.name} connection failed: {test_result.message}"
+                    )
                     return []
 
                 return await self._get_service_users(adapter)
 
         except Exception as e:
@@ -661,11 +676,11 @@
         db: AsyncSession,
         service_1: ServiceConfig,
         users_1: List[Dict[str, Any]],
         service_2: ServiceConfig,
         users_2: List[Dict[str, Any]],
-        already_matched_users: Dict[str, Dict[str, Any]] = None
+        already_matched_users: Dict[str, Dict[str, Any]] = None,
     ) -> Tuple[List[UserSuggestion], Dict[str, Dict[str, Any]]]:
         """Compare users between two services to find potential mappings.
 
         Args:
             db: Database session
@@ -685,21 +700,21 @@
         # Get existing mappings to avoid duplicates
         existing_mappings_1 = await self._get_existing_mappings(db, service_1.id)
         existing_mappings_2 = await self._get_existing_mappings(db, service_2.id)
 
         for user_1 in users_1:
-            user_1_id = str(user_1.get('id', user_1.get('user_id', user_1.get('username'))))
+            user_1_id = str(user_1.get("id", user_1.get("user_id", user_1.get("username"))))
 
             # Skip if this user already has a mapping
             if user_1_id in existing_mappings_1:
                 continue
 
             best_match_data = None
             best_score = 0.0
 
             for user_2 in users_2:
-                user_2_id = str(user_2.get('id', user_2.get('user_id', user_2.get('username'))))
+                user_2_id = str(user_2.get("id", user_2.get("user_id", user_2.get("username"))))
 
                 # Skip if this user already has a mapping
                 if user_2_id in existing_mappings_2:
                     continue
 
@@ -707,90 +722,102 @@
                 score, matching_attrs = self._calculate_user_match_score(user_1, user_2)
 
                 if score > best_score and score >= self.min_confidence_score:
                     best_score = score
                     best_match_data = {
-                        'score': score,
-                        'matching_attrs': matching_attrs,
-                        'user_1': user_1,
-                        'user_2': user_2,
-                        'user_1_id': user_1_id,
-                        'user_2_id': user_2_id
+                        "score": score,
+                        "matching_attrs": matching_attrs,
+                        "user_1": user_1,
+                        "user_2": user_2,
+                        "user_1_id": user_1_id,
+                        "user_2_id": user_2_id,
                     }
 
             # Create suggestions for the best match found
             if best_match_data and best_score >= self.min_confidence_score:
                 data = best_match_data
 
                 # Use the more reliable identifier as central_user_id
                 # Prefer email, then username, then ID
                 central_user_id = (
-                    data['user_1'].get('email') or data['user_2'].get('email') or
-                    data['user_1'].get('username') or data['user_1'].get('login') or
-                    data['user_2'].get('username') or data['user_2'].get('login') or
-                    str(data['user_1_id']) or str(data['user_2_id'])
+                    data["user_1"].get("email")
+                    or data["user_2"].get("email")
+                    or data["user_1"].get("username")
+                    or data["user_1"].get("login")
+                    or data["user_2"].get("username")
+                    or data["user_2"].get("login")
+                    or str(data["user_1_id"])
+                    or str(data["user_2_id"])
                 )
 
                 # Debug logging
-                logger.info(f"Found match: central_user_id={central_user_id}, "
-                          f"user_1({service_1.name})={data['user_1'].get('username')}, "
-                          f"user_2({service_2.name})={data['user_2'].get('username')}, "
-                          f"score={data['score']}")
+                logger.info(
+                    f"Found match: central_user_id={central_user_id}, "
+                    f"user_1({service_1.name})={data['user_1'].get('username')}, "
+                    f"user_2({service_2.name})={data['user_2'].get('username')}, "
+                    f"score={data['score']}"
+                )
 
                 # Track which services we've already created suggestions for this user
                 if central_user_id not in already_matched_users:
-                    already_matched_users[central_user_id] = {'service_ids': set()}
+                    already_matched_users[central_user_id] = {"service_ids": set()}
 
                 # Create suggestion for service_1 only if not already matched
-                if service_1.id not in already_matched_users[central_user_id]['service_ids']:
+                if service_1.id not in already_matched_users[central_user_id]["service_ids"]:
                     suggestion_1 = UserSuggestion(
                         central_user_id=central_user_id,
                         service_config_id=service_1.id,
-                        service_user_id=str(data['user_1_id']),
-                        service_username=data['user_1'].get('username', data['user_1'].get('login')),
-                        service_email=data['user_1'].get('email'),
-                        confidence_score=data['score'],
-                        matching_attributes=data['matching_attrs'],
-                        role=self._determine_user_role_from_service_user(data['user_1']),
+                        service_user_id=str(data["user_1_id"]),
+                        service_username=data["user_1"].get(
+                            "username", data["user_1"].get("login")
+                        ),
+                        service_email=data["user_1"].get("email"),
+                        confidence_score=data["score"],
+                        matching_attributes=data["matching_attrs"],
+                        role=self._determine_user_role_from_service_user(data["user_1"]),
                         metadata={
-                            'detection_method': 'cross_service_comparison',
-                            'source_service': service_2.name,
-                            'target_service': service_1.name,
-                            'source_user': data['user_2'],
-                            'target_user': data['user_1'],
-                            'detected_at': datetime.utcnow().isoformat()
-                        }
+                            "detection_method": "cross_service_comparison",
+                            "source_service": service_2.name,
+                            "target_service": service_1.name,
+                            "source_user": data["user_2"],
+                            "target_user": data["user_1"],
+                            "detected_at": datetime.utcnow().isoformat(),
+                        },
                     )
                     suggestions.append(suggestion_1)
-                    already_matched_users[central_user_id]['service_ids'].add(service_1.id)
+                    already_matched_users[central_user_id]["service_ids"].add(service_1.id)
 
                 # Create suggestion for service_2 only if not already matched
-                if service_2.id not in already_matched_users[central_user_id]['service_ids']:
+                if service_2.id not in already_matched_users[central_user_id]["service_ids"]:
                     suggestion_2 = UserSuggestion(
                         central_user_id=central_user_id,
                         service_config_id=service_2.id,
-                        service_user_id=str(data['user_2_id']),
-                        service_username=data['user_2'].get('username', data['user_2'].get('login')),
-                        service_email=data['user_2'].get('email'),
-                        confidence_score=data['score'],
-                        matching_attributes=data['matching_attrs'],
-                        role=self._determine_user_role_from_service_user(data['user_2']),
+                        service_user_id=str(data["user_2_id"]),
+                        service_username=data["user_2"].get(
+                            "username", data["user_2"].get("login")
+                        ),
+                        service_email=data["user_2"].get("email"),
+                        confidence_score=data["score"],
+                        matching_attributes=data["matching_attrs"],
+                        role=self._determine_user_role_from_service_user(data["user_2"]),
                         metadata={
-                            'detection_method': 'cross_service_comparison',
-                            'source_service': service_1.name,
-                            'target_service': service_2.name,
-                            'source_user': data['user_1'],
-                            'target_user': data['user_2'],
-                            'detected_at': datetime.utcnow().isoformat()
-                        }
+                            "detection_method": "cross_service_comparison",
+                            "source_service": service_1.name,
+                            "target_service": service_2.name,
+                            "source_user": data["user_1"],
+                            "target_user": data["user_2"],
+                            "detected_at": datetime.utcnow().isoformat(),
+                        },
                     )
                     suggestions.append(suggestion_2)
-                    already_matched_users[central_user_id]['service_ids'].add(service_2.id)
+                    already_matched_users[central_user_id]["service_ids"].add(service_2.id)
 
         return suggestions, already_matched_users
 
-    async def _get_existing_mappings(self, db: AsyncSession, service_id: str) -> Dict[str, UserMapping]:
+    async def _get_existing_mappings(
+        self, db: AsyncSession, service_id: str
+    ) -> Dict[str, UserMapping]:
         """Get existing mappings for a service.
 
         Args:
             db: Database session
             service_id: Service ID
@@ -801,37 +828,33 @@
         result = await db.execute(
             select(UserMapping).where(UserMapping.service_config_id == service_id)
         )
         mappings = result.scalars().all()
 
-        return {
-            mapping.service_user_id: mapping
-            for mapping in mappings
-            if mapping.service_user_id
-        }
+        return {mapping.service_user_id: mapping for mapping in mappings if mapping.service_user_id}
 
     def _determine_user_role_from_service_user(self, service_user: Dict[str, Any]) -> str:
         """Determine user role from service user data.
 
         Args:
             service_user: User data from service
 
         Returns:
             String representing the user role
         """
-        if service_user.get('is_superuser') or service_user.get('is_admin'):
-            return 'admin'
-        elif service_user.get('is_staff') or service_user.get('is_moderator'):
-            return 'moderator'
+        if service_user.get("is_superuser") or service_user.get("is_admin"):
+            return "admin"
+        elif service_user.get("is_staff") or service_user.get("is_moderator"):
+            return "moderator"
         else:
-            return 'user'
+            return "user"
 
     async def _find_best_user_match(
         self,
         authentik_user: Dict[str, Any],
         service_users: List[Dict[str, Any]],
-        service: ServiceConfig
+        service: ServiceConfig,
     ) -> Optional[UserSuggestion]:
         """Find the best matching user in a service for an Authentik user.
 
         Args:
             authentik_user: User data from Authentik
@@ -843,46 +866,42 @@
         """
         if not service_users:
             # If we can't enumerate users, create a suggestion based on Authentik data
             return self._create_suggestion_from_authentik(authentik_user, service)
 
-        authentik_username = authentik_user.get('username', '').lower()
-        authentik_user.get('email', '').lower()
-        authentik_user.get('name', '').lower()
+        authentik_username = authentik_user.get("username", "").lower()
+        authentik_user.get("email", "").lower()
+        authentik_user.get("name", "").lower()
 
         best_match = None
         best_score = 0.0
 
         for service_user in service_users:
-            score, matching_attrs = self._calculate_user_match_score(
-                authentik_user, service_user
-            )
+            score, matching_attrs = self._calculate_user_match_score(authentik_user, service_user)
 
             if score > best_score and score >= self.min_confidence_score:
                 best_score = score
                 best_match = UserSuggestion(
                     central_user_id=authentik_username,
                     service_config_id=service.id,
-                    service_user_id=str(service_user.get('id', service_user.get('user_id'))),
-                    service_username=service_user.get('username', service_user.get('login')),
-                    service_email=service_user.get('email'),
+                    service_user_id=str(service_user.get("id", service_user.get("user_id"))),
+                    service_username=service_user.get("username", service_user.get("login")),
+                    service_email=service_user.get("email"),
                     confidence_score=score,
                     matching_attributes=matching_attrs,
                     role=self._determine_user_role(authentik_user),
                     metadata={
-                        'detection_method': 'user_enumeration',
-                        'service_user_data': service_user,
-                        'detected_at': datetime.utcnow().isoformat()
-                    }
+                        "detection_method": "user_enumeration",
+                        "service_user_data": service_user,
+                        "detected_at": datetime.utcnow().isoformat(),
+                    },
                 )
 
         return best_match
 
     def _create_suggestion_from_authentik(
-        self,
-        authentik_user: Dict[str, Any],
-        service: ServiceConfig
+        self, authentik_user: Dict[str, Any], service: ServiceConfig
     ) -> UserSuggestion:
         """Create a user suggestion based only on Authentik data.
 
         Args:
             authentik_user: User data from Authentik
@@ -890,28 +909,26 @@
 
         Returns:
             UserSuggestion with medium confidence
         """
         return UserSuggestion(
-            central_user_id=authentik_user.get('username'),
+            central_user_id=authentik_user.get("username"),
             service_config_id=service.id,
-            service_username=authentik_user.get('username'),
-            service_email=authentik_user.get('email'),
+            service_username=authentik_user.get("username"),
+            service_email=authentik_user.get("email"),
             confidence_score=0.6,  # Medium confidence since we can't verify
-            matching_attributes=['username', 'email'],
+            matching_attributes=["username", "email"],
             role=self._determine_user_role(authentik_user),
             metadata={
-                'detection_method': 'authentik_only',
-                'note': 'Service does not support user enumeration',
-                'detected_at': datetime.utcnow().isoformat()
-            }
+                "detection_method": "authentik_only",
+                "note": "Service does not support user enumeration",
+                "detected_at": datetime.utcnow().isoformat(),
+            },
         )
 
     def _calculate_user_match_score(
-        self,
-        user_1: Dict[str, Any],
-        user_2: Dict[str, Any]
+        self, user_1: Dict[str, Any], user_2: Dict[str, Any]
     ) -> Tuple[float, List[str]]:
         """Calculate match score between two users from different services.
 
         Args:
             user_1: User from first service
@@ -922,79 +939,98 @@
         """
         score = 0.0
         matching_attrs = []
 
         # Get IDs for exact ID matching (highest priority)
-        user_1_id = user_1.get('id', user_1.get('user_id'))
-        user_2_id = user_2.get('id', user_2.get('user_id'))
+        user_1_id = user_1.get("id", user_1.get("user_id"))
+        user_2_id = user_2.get("id", user_2.get("user_id"))
 
         # Get usernames - handle different field names across services
-        user_1_username = str(user_1.get('username', user_1.get('login', ''))).lower() if user_1.get('username', user_1.get('login')) else ''
-        user_2_username = str(user_2.get('username', user_2.get('login', ''))).lower() if user_2.get('username', user_2.get('login')) else ''
+        user_1_username = (
+            str(user_1.get("username", user_1.get("login", ""))).lower()
+            if user_1.get("username", user_1.get("login"))
+            else ""
+        )
+        user_2_username = (
+            str(user_2.get("username", user_2.get("login", ""))).lower()
+            if user_2.get("username", user_2.get("login"))
+            else ""
+        )
 
         # Get emails
-        user_1_email = str(user_1.get('email', '')).lower() if user_1.get('email') else ''
-        user_2_email = str(user_2.get('email', '')).lower() if user_2.get('email') else ''
+        user_1_email = str(user_1.get("email", "")).lower() if user_1.get("email") else ""
+        user_2_email = str(user_2.get("email", "")).lower() if user_2.get("email") else ""
 
         # Get display names / friendly names (separate from username)
-        user_1_friendly = str(user_1.get('friendly_name', user_1.get('name', ''))).lower() if user_1.get('friendly_name', user_1.get('name')) else ''
-        user_2_friendly = str(user_2.get('friendly_name', user_2.get('name', ''))).lower() if user_2.get('friendly_name', user_2.get('name')) else ''
+        user_1_friendly = (
+            str(user_1.get("friendly_name", user_1.get("name", ""))).lower()
+            if user_1.get("friendly_name", user_1.get("name"))
+            else ""
+        )
+        user_2_friendly = (
+            str(user_2.get("friendly_name", user_2.get("name", ""))).lower()
+            if user_2.get("friendly_name", user_2.get("name"))
+            else ""
+        )
 
         # 1. Exact ID match (highest weight) - very reliable for Plex/Tautulli
-        if user_1_id is not None and user_2_id is not None and user_1_id == user_2_id and user_1_id != 0:
+        if (
+            user_1_id is not None
+            and user_2_id is not None
+            and user_1_id == user_2_id
+            and user_1_id != 0
+        ):
             score += 0.8
-            matching_attrs.append('id_exact')
+            matching_attrs.append("id_exact")
 
         # 2. Exact username match (high weight)
         if user_1_username and user_2_username and user_1_username == user_2_username:
             score += 0.5
-            matching_attrs.append('username_exact')
+            matching_attrs.append("username_exact")
 
         # 3. Exact email match (high weight)
         if user_1_email and user_2_email and user_1_email == user_2_email:
             score += 0.5
-            matching_attrs.append('email_exact')
+            matching_attrs.append("email_exact")
 
         # 4. Exact friendly_name match (medium weight) - useful for Plex/Tautulli
         if user_1_friendly and user_2_friendly and user_1_friendly == user_2_friendly:
             score += 0.4
-            matching_attrs.append('friendly_name_exact')
+            matching_attrs.append("friendly_name_exact")
 
         # 5. Username matches friendly_name (cross-field matching)
         if user_1_username and user_2_friendly and user_1_username == user_2_friendly:
             score += 0.4
-            matching_attrs.append('username_friendly_match')
+            matching_attrs.append("username_friendly_match")
         elif user_2_username and user_1_friendly and user_2_username == user_1_friendly:
             score += 0.4
-            matching_attrs.append('username_friendly_match')
+            matching_attrs.append("username_friendly_match")
 
         # 6. Fuzzy username match
         if user_1_username and user_2_username and user_1_username != user_2_username:
             username_similarity = difflib.SequenceMatcher(
                 None, user_1_username, user_2_username
             ).ratio()
             if username_similarity >= self.fuzzy_match_threshold:
                 score += 0.3 * username_similarity
-                matching_attrs.append('username_fuzzy')
+                matching_attrs.append("username_fuzzy")
 
         # 7. Fuzzy email match (if different from exact)
         if user_1_email and user_2_email and user_1_email != user_2_email:
-            email_similarity = difflib.SequenceMatcher(
-                None, user_1_email, user_2_email
-            ).ratio()
+            email_similarity = difflib.SequenceMatcher(None, user_1_email, user_2_email).ratio()
             if email_similarity >= self.fuzzy_match_threshold:
                 score += 0.3 * email_similarity
-                matching_attrs.append('email_fuzzy')
+                matching_attrs.append("email_fuzzy")
 
         # 8. Fuzzy friendly_name match
         if user_1_friendly and user_2_friendly and user_1_friendly != user_2_friendly:
             name_similarity = difflib.SequenceMatcher(
                 None, user_1_friendly, user_2_friendly
             ).ratio()
             if name_similarity >= self.fuzzy_match_threshold:
                 score += 0.2 * name_similarity
-                matching_attrs.append('name_fuzzy')
+                matching_attrs.append("name_fuzzy")
 
         return min(score, 1.0), matching_attrs
 
     def _determine_user_role(self, authentik_user: Dict[str, Any]) -> str:
         """Determine user role based on Authentik user data.
@@ -1003,22 +1039,22 @@
             authentik_user: User data from Authentik
 
         Returns:
             String representing the user role
         """
-        if authentik_user.get('is_superuser'):
-            return 'admin'
-        elif authentik_user.get('is_staff'):
-            return 'moderator'
+        if authentik_user.get("is_superuser"):
+            return "admin"
+        elif authentik_user.get("is_staff"):
+            return "moderator"
         else:
-            return 'user'
+            return "user"
 
     async def create_mappings_from_suggestions(
         self,
         db: AsyncSession,
         suggestions: List[Dict[str, Any]],
-        auto_approve_high_confidence: bool = False
+        auto_approve_high_confidence: bool = False,
     ) -> Dict[str, Any]:
         """Create user mappings from approved suggestions.
 
         Args:
             db: Database session
@@ -1033,36 +1069,39 @@
         results = {
             "total_suggestions": len(suggestions),
             "created_mappings": 0,
             "skipped_mappings": 0,
             "errors": [],
-            "created_mapping_ids": []
+            "created_mapping_ids": [],
         }
 
         for suggestion_data in suggestions:
             try:
                 logger.info(f"Processing suggestion: {suggestion_data}")
 
                 # Extract and validate required fields
-                central_user_id = suggestion_data.get('central_user_id')
-                service_config_id = suggestion_data.get('service_config_id')
-                service_user_id = suggestion_data.get('service_user_id')
-
-                logger.info(f"Extracted fields - central_user_id: {central_user_id}, service_config_id: {service_config_id}, service_user_id: {service_user_id}")
+                central_user_id = suggestion_data.get("central_user_id")
+                service_config_id = suggestion_data.get("service_config_id")
+                service_user_id = suggestion_data.get("service_user_id")
+
+                logger.info(
+                    f"Extracted fields - central_user_id: {central_user_id}, service_config_id: {service_config_id}, service_user_id: {service_user_id}"
+                )
 
                 if not central_user_id or not service_config_id:
                     error_msg = f"Missing required fields: central_user_id={central_user_id}, service_config_id={service_config_id}"
                     logger.error(error_msg)
                     raise ValueError(error_msg)
 
                 # Check if mapping already exists
                 from sqlalchemy import and_, select
+
                 existing_result = await db.execute(
                     select(UserMapping).where(
                         and_(
                             UserMapping.central_user_id == central_user_id,
-                            UserMapping.service_config_id == service_config_id
+                            UserMapping.service_config_id == service_config_id,
                         )
                     )
                 )
                 existing_mapping = existing_result.scalar_one_or_none()
                 if existing_mapping:
@@ -1076,42 +1115,44 @@
                 if service_user_id is not None:
                     service_user_id = str(service_user_id)
 
                 # Determine role from suggestion
                 role_mapping = {
-                    'admin': UserRole.ADMIN,
-                    'user': UserRole.USER,
-                    'moderator': UserRole.MODERATOR,
-                    'viewer': UserRole.VIEWER
+                    "admin": UserRole.ADMIN,
+                    "user": UserRole.USER,
+                    "moderator": UserRole.MODERATOR,
+                    "viewer": UserRole.VIEWER,
                 }
-                role_str = suggestion_data.get('role', 'user').lower()
+                role_str = suggestion_data.get("role", "user").lower()
                 role = role_mapping.get(role_str, UserRole.USER)
 
                 # Extract service_username from multiple possible sources
-                metadata = suggestion_data.get('metadata', {})
-                target_user = metadata.get('target_user', {})
-                source_user = metadata.get('source_user', {})
+                metadata = suggestion_data.get("metadata", {})
+                target_user = metadata.get("target_user", {})
+                source_user = metadata.get("source_user", {})
 
                 service_username = (
-                    suggestion_data.get('service_username') or
-                    target_user.get('username') or
-                    target_user.get('login') or
-                    target_user.get('name') or
-                    target_user.get('friendly_name') or
-                    source_user.get('username') or
-                    source_user.get('name') or
-                    central_user_id or
-                    f"user_{service_user_id}"
+                    suggestion_data.get("service_username")
+                    or target_user.get("username")
+                    or target_user.get("login")
+                    or target_user.get("name")
+                    or target_user.get("friendly_name")
+                    or source_user.get("username")
+                    or source_user.get("name")
+                    or central_user_id
+                    or f"user_{service_user_id}"
                 )
 
                 service_email = (
-                    suggestion_data.get('service_email') or
-                    target_user.get('email') or
-                    source_user.get('email')
-                )
-
-                logger.info(f"About to create mapping with role: {role}, service_username: {service_username}")
+                    suggestion_data.get("service_email")
+                    or target_user.get("email")
+                    or source_user.get("email")
+                )
+
+                logger.info(
+                    f"About to create mapping with role: {role}, service_username: {service_username}"
+                )
 
                 # Create UserMapping from suggestion - always ACTIVE (no more pending status per user request)
                 # Ensure we have a valid central_username
                 central_username = service_username
 
@@ -1126,22 +1167,24 @@
                     service_username=service_username,
                     service_email=service_email,
                     role=role,
                     status=MappingStatus.ACTIVE,  # Always active as requested by user
                     sync_enabled=True,
-                    metadata=metadata
+                    metadata=metadata,
                 )
 
                 db.add(mapping)
                 await db.flush()  # Get the ID
 
                 results["created_mappings"] += 1
                 results["created_mapping_ids"].append(str(mapping.id))
                 logger.info(f"Created mapping {mapping.id} for user {central_user_id}")
 
             except Exception as e:
-                error_msg = f"Error creating mapping for {suggestion_data.get('central_user_id')}: {str(e)}"
+                error_msg = (
+                    f"Error creating mapping for {suggestion_data.get('central_user_id')}: {str(e)}"
+                )
                 logger.error(error_msg)
                 results["errors"].append(error_msg)
                 results["skipped_mappings"] += 1
 
         # Commit all changes
would reformat /home/jeremie/Documents/Developpement/mcparr/src/backend/src/services/user_mapper.py

Oh no!   
93 files would be reformatted, 11 files would be left unchanged.
