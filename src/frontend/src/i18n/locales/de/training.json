{
  "title": "KI-Training",
  "subtitle": "KI-Modelltraining und Feinabstimmung",
  "refresh": "Aktualisieren",

  "help": {
    "category": "KI-Training"
  },

  "tabs": {
    "overview": "Übersicht",
    "overviewShort": "Stats",
    "overviewFull": "Gesamtübersicht",
    "sessions": "Sitzungen",
    "sessionsFull": "Trainingssitzungen",
    "prompts": "Prompts",
    "promptsFull": "Trainings-Prompts",
    "models": "Modelle",
    "modelsFull": "Ollama-Modelle",
    "workers": "Worker",
    "workersFull": "GPU-Worker"
  },

  "sessions": {
    "title": "Trainingssitzungen",
    "newSession": "Neue Sitzung",
    "newSessionTitle": "Neue Trainingssitzung",
    "count": "{{count}} Sitzung",
    "count_plural": "{{count}} Sitzungen",
    "name": "Name",
    "nameRequired": "Name *",
    "baseModel": "Basismodell",
    "outputModel": "Ausgabemodell",
    "trainingType": "Trainingstyp",
    "backend": "Backend",
    "dataset": "Datensatz",
    "prompts": "Prompts",
    "epochs": "Epochen",
    "steps": "Schritte",
    "progress": "Fortschritt",
    "status": "Status",
    "actions": "Aktionen",
    "start": "Starten",
    "cancel": "Abbrechen",
    "pause": "Pausieren",
    "resume": "Fortsetzen",
    "delete": "Löschen",
    "duplicate": "Duplizieren",
    "viewDetails": "Details anzeigen",
    "details": "Details",
    "viewLogs": "Protokolle anzeigen",
    "logs": "Protokolle",
    "managePrompts": "Prompts verwalten",
    "managePromptsCount": "Prompts verwalten ({{count}})",
    "createdAt": "Erstellt",
    "startedAt": "Gestartet",
    "completedAt": "Abgeschlossen",
    "loss": "Loss",
    "gpuMemory": "GPU-Speicher",
    "noSessions": "Keine Trainingssitzungen",
    "noSessionsHint": "Erstellen Sie eine neue Sitzung, um zu beginnen",
    "confirmDelete": "Möchten Sie diese Sitzung wirklich löschen?",
    "addPromptsBeforeStart": "Fügen Sie Prompts hinzu, bevor Sie starten",
    "description": "Beschreibung",
    "descriptionPlaceholder": "Optionale Beschreibung...",
    "trainingMethod": "Trainingsmethode",
    "modelfileMethod": "Modelfile (schnell)",
    "modelfileDescription": "Erstellt ein Ollama-Modell mit integrierten Beispielen. Keine GPU erforderlich.",
    "unslothMethod": "GPU-Fine-Tuning (Unsloth)",
    "unslothDescription": "LoRA-Fine-Tuning auf entferntem GPU-Worker. Bessere Ergebnisse.",
    "recommended": "Empfohlen",
    "gpuRequired": "GPU erforderlich",
    "selectOllamaModel": "Ollama-Modell auswählen",
    "selectModel": "Modell auswählen",
    "trainedModels": "Trainierte Modelle (inkrementelles Training)",
    "huggingfaceModels": "HuggingFace-Modelle (neues Training)",
    "incrementalTraining": "Inkrementelles Training: Neue Prompts werden zum vorhandenen Wissen hinzugefügt",
    "optimizedModels": "4-Bit-optimierte Modelle für GTX 1080 Ti (11GB VRAM)",
    "overwriteExisting": "Vorhandenes Modell überschreiben",
    "overwriteDescription": "Falls ein Modell mit demselben Namen bereits in Ollama existiert, wird es ersetzt. Andernfalls tritt ein Fehler auf, wenn der Name bereits vergeben ist.",
    "trainingWorker": "Trainings-Worker",
    "configureWorkerHint": "Konfigurieren Sie einen Worker in den Einstellungen, um das Training zu aktivieren.",
    "gpuAvailable": "GPU: {{name}}",
    "cpuOnly": "Nur CPU",
    "offline": "Offline",
    "busy": "Beschäftigt",
    "batchSize": "Batch Size",
    "learningRate": "Learning Rate",
    "sessionPlaceholder": "Meine Trainingssitzung",
    "step1": "1. Konfiguration",
    "step2": "2. Prompt-Auswahl",
    "next": "Weiter",
    "back": "Zurück",
    "promptsForTraining": "{{count}} Prompt für das Training",
    "promptsForTraining_plural": "{{count}} Prompts für das Training",
    "selectedCount": "{{count}} ausgewählt",
    "selectedCount_plural": "{{count}} ausgewählt",
    "selectedOfTotal": "{{selected}} ausgewählt / {{total}}",
    "selectedOfTotal_plural": "{{selected}} ausgewählt / {{total}}",
    "selectAll": "Alle auswählen",
    "selectNone": "Alle abwählen",
    "allServices": "Alle Dienste",
    "promptsSelection": "Prompt-Auswahl",
    "promptsWillBeUsed": "{{count}} Prompt wird für das Training verwendet",
    "promptsWillBeUsed_plural": "{{count}} Prompts werden für das Training verwendet",
    "selectedOfTotalDisplayed": "{{selected}} ausgewählt / {{displayed}} angezeigt",
    "selectedOfTotalDisplayed_plural": "{{selected}} ausgewählt / {{displayed}} angezeigt",
    "help": {
      "title": "Trainingssitzungen",
      "overview": "Übersicht",
      "overviewContent": "Die Registerkarte Sitzungen ermöglicht die Erstellung und Verwaltung von KI-Modell-Trainingssitzungen. Jede Sitzung trainiert ein Basismodell mit Ihren benutzerdefinierten Prompts.",
      "lifecycle": "Lebenszyklus",
      "lifecycleContent": "Eine Sitzung durchläuft mehrere Phasen:\n• Ausstehend: Konfiguration abgeschlossen, startbereit\n• Läuft: aktives Training mit sichtbarem Fortschritt\n• Abgeschlossen: trainiertes Modell in Ollama verfügbar\n• Fehlgeschlagen: Fehler während des Trainings (Protokolle prüfen)",
      "actions": "Verfügbare Aktionen",
      "actionsContent": "Für jede Sitzung:\n• Starten: startet das Training auf einem GPU-Worker\n• Details anzeigen: Metriken, Hyperparameter, Fortschritt\n• Protokolle anzeigen: detaillierte Trainingsprotokolle\n• Duplizieren: erstellt eine Kopie der Sitzung\n• Löschen: entfernt die Sitzung und ihre Daten",
      "creation": "Sitzungserstellung",
      "creationContent": "Um eine Sitzung zu erstellen:\n1. Wählen Sie einen Namen und ein Basismodell\n2. Wählen Sie die Methode (schnelles Modelfile oder GPU-Fine-Tuning)\n3. Konfigurieren Sie Hyperparameter (Epochen, Batch Size, Learning Rate)\n4. Wählen Sie Trainings-Prompts aus"
    }
  },

  "prompts": {
    "title": "Trainings-Prompts",
    "total": "{{count}} Prompt",
    "total_plural": "{{count}} Prompts",
    "validated": "validiert",
    "enabled": "aktiviert",
    "category": "Kategorie",
    "difficulty": "Schwierigkeit",
    "source": "Quelle",
    "format": "Format",
    "tags": "Tags",
    "timesUsed": "Verwendung",
    "timesUsedCount": "{{count}} Verwendungen",
    "validationScore": "Bewertung",
    "actions": "Aktionen",
    "edit": "Bearbeiten",
    "delete": "Löschen",
    "validate": "Validieren",
    "enable": "Aktivieren",
    "disable": "Deaktivieren",
    "cancel": "Abbrechen",
    "search": "Suchen...",
    "noPrompts": "Keine Trainings-Prompts",
    "noPromptsFound": "Keine Prompts gefunden",
    "noPromptsHint": "Fügen Sie Prompts hinzu, um Ihre Modelle zu trainieren",
    "perPage": "Pro Seite",
    "addPrompt": "Prompt hinzufügen",
    "createPrompt": "Prompt erstellen",
    "newPrompt": "Neuer Trainings-Prompt",
    "editPrompt": "Prompt bearbeiten",
    "save": "Speichern",
    "saving": "Wird gespeichert...",
    "create": "Prompt erstellen",
    "creating": "Wird erstellt...",
    "createMultiple": "Erstellen ({{count}} Prompts)",
    "saveMultiple": "Speichern ({{count}})",
    "searchPlaceholder": "Suchen...",
    "deleteAll": "Alle Prompts löschen und Homelab-Prompts neu laden",
    "confirmDelete": "Möchten Sie diesen Prompt wirklich löschen?",
    "selectAtLeastOne": "Wählen Sie mindestens einen Dienst aus",
    "resetPrompts": "Prompts zurücksetzen",
    "import": "Importieren",
    "export": "Exportieren",
    "new": "Neu",
    "allServicesCount": "Alle Dienste ({{count}})",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Systemanweisungen für das Modell...",
    "userInput": "Benutzereingabe",
    "userInputRequired": "Benutzereingabe *",
    "userInputPlaceholder": "Frage oder Anfrage des Benutzers...",
    "expectedOutput": "Erwartete Ausgabe",
    "expectedOutputRequired": "Erwartete Ausgabe *",
    "expectedOutputPlaceholder": "Erwartete Antwort des Modells...",
    "useToolCalling": "Tool Calling verwenden",
    "toolCallingHint": "(lehrt das Modell, Tools aufzurufen UND die Ergebnisse zu verwenden)",
    "toolCall": "Tool Call (Werkzeugaufruf)",
    "toolName": "Tool-Name",
    "toolNameRequired": "Tool-Name *",
    "toolNamePlaceholder": "z.B.: system_get_health",
    "toolArguments": "Argumente (JSON)",
    "toolArgumentsPlaceholder": "z.B.: {\"service\": \"ollama\"}",
    "toolResponse": "Tool-Antwort (JSON)",
    "toolResponseRequired": "Tool-Antwort (JSON) *",
    "toolResponsePlaceholder": "{\"status\": \"healthy\", \"version\": \"0.1.0\", \"services\": [...]}",
    "toolResponseHint": "Realistische Antwort, die das Tool zurückgeben würde (wird für das Training verwendet)",
    "assistantResponse": "Endgültige Assistentenantwort",
    "assistantResponseRequired": "Endgültige Assistentenantwort *",
    "assistantResponsePlaceholder": "Das System ist fehlerfrei. Ollama Version 0.1.0 ist betriebsbereit mit 3 aktiven Diensten...",
    "assistantResponseHint": "Wie der Assistent die Tool-Daten zusammenfassen und präsentieren soll",
    "description": "Beschreibung",
    "descriptionPlaceholder": "Beschreibung des Prompts",
    "importSuccess": "Prompts erfolgreich importiert",
    "confirmResetAll": "Dies wird ALLE vorhandenen Prompts löschen und durch die Standard-Prompts ersetzen. Fortfahren?",
    "help": {
      "title": "Trainings-Prompts",
      "overview": "Übersicht",
      "overviewContent": "Die Registerkarte Prompts verwaltet die Trainingsdaten für Ihre KI-Modelle. Jeder Prompt ist ein Konversationsbeispiel, das das Modell lernt zu reproduzieren.",
      "structure": "Prompt-Struktur",
      "structureContent": "Ein Prompt enthält:\n• Benutzereingabe: Frage oder Anfrage\n• Erwartete Ausgabe: ideale Modellantwort\n• Tool Call (optional): Tool-Aufruf mit Argumenten\n• Tool Response: Tool-Ergebnis\n• Finale Antwort: Datensynthese",
      "management": "Verwaltung",
      "managementContent": "Verfügbare Aktionen:\n• Neu: Prompt manuell erstellen\n• Reset: Standard-Homelab-Prompts neu laden\n• Import/Export: als JSON sichern oder wiederherstellen\n• Validieren: Prompt als geprüft markieren",
      "filtering": "Filterung",
      "filteringContent": "Filtern Sie Prompts nach Dienst (Plex, Radarr, Sonarr, etc.) oder suchen Sie nach Text. Badges zeigen Dienst, Schwierigkeit und Validierungsstatus an."
    }
  },

  "models": {
    "title": "Ollama-Modelle",
    "status": "Ollama-Status",
    "version": "Version",
    "modelCount": "Modelle",
    "modelCountValue": "{{count}} Modelle",
    "totalSize": "Gesamtgröße",
    "runningModels": "Laufende Modelle",
    "name": "Name",
    "model": "Modell",
    "family": "Familie",
    "size": "Größe",
    "parameterSize": "Parameter",
    "quantization": "Quantisierung",
    "modified": "Geändert",
    "actions": "Aktionen",
    "pull": "Herunterladen",
    "delete": "Löschen",
    "load": "Modell laden",
    "unload": "Modell entladen",
    "noModels": "Keine Modelle installiert",
    "noModelsFound": "Keine Modelle gefunden",
    "loading": "Wird geladen...",
    "ollamaOffline": "Ollama ist nicht verfügbar",
    "searchPlaceholder": "Nach einem Modell suchen...",
    "confirmDelete": "Möchten Sie dieses Modell wirklich löschen?",
    "confirmQuestion": "Bestätigen?",
    "loadedInMemory": "Im Speicher geladen",
    "loaded": "Geladen",
    "help": {
      "title": "Ollama-Modelle",
      "overview": "Übersicht",
      "overviewContent": "Die Registerkarte Modelle zeigt alle auf Ihrem Ollama-Server installierten LLM-Modelle an. Sie können deren Größe, Familie und Ladestatus einsehen.",
      "management": "Modellverwaltung",
      "managementContent": "Verfügbare Aktionen für jedes Modell:\n• Laden: lädt das Modell in den GPU-Speicher zur sofortigen Nutzung\n• Entladen: gibt den vom Modell belegten GPU-Speicher frei\n• Löschen: entfernt das Modell dauerhaft vom Server",
      "status": "Status",
      "statusContent": "Ein Modell kann sein:\n• Geladen (grün): im GPU-Speicher, einsatzbereit\n• Nicht geladen: auf Festplatte, muss vor der Nutzung geladen werden\n• Das Badge zeigt an, ob das Modell derzeit im Speicher ist",
      "info": "Informationen",
      "infoContent": "Für jedes Modell:\n• Familie: Modelltyp (llama, mistral, etc.)\n• Parameter: Anzahl der Parameter (7B, 13B, etc.)\n• Quantisierung: Komprimierungsstufe (Q4, Q8, etc.)\n• Größe: belegter Speicherplatz"
    }
  },

  "workers": {
    "title": "Trainings-Worker",
    "subtitle": "GPU-Worker für die Feinabstimmung von LLM-Modellen",
    "count": "{{count}} Worker",
    "count_plural": "{{count}} Worker",
    "name": "Name",
    "url": "URL",
    "status": "Status",
    "gpuAvailable": "GPU verfügbar",
    "gpuCount": "GPU-Anzahl",
    "gpuCountLabel": "{{count}} GPU",
    "gpuCountLabel_plural": "{{count}} GPUs",
    "gpuNames": "GPUs",
    "vram": "{{size}} GB VRAM",
    "currentJob": "Aktueller Auftrag",
    "actions": "Aktionen",
    "test": "Testen",
    "testing": "Wird getestet...",
    "edit": "Bearbeiten",
    "delete": "Löschen",
    "enable": "Aktivieren",
    "disable": "Deaktivieren",
    "noWorkers": "Keine Worker konfiguriert",
    "noWorkersHint": "Fügen Sie einen GPU-Worker hinzu, um Fine-Tuning zu aktivieren",
    "loading": "Worker werden geladen...",
    "addWorker": "Worker hinzufügen",
    "refreshAll": "Alle aktualisieren",
    "refresh": "Aktualisieren",
    "retry": "Erneut versuchen",
    "confirmDelete": "Möchten Sie diesen Worker wirklich löschen?",
    "deleteWorker": "Worker löschen",
    "deleteConfirmMessage": "Möchten Sie \"{{name}}\" wirklich löschen? Diese Aktion kann nicht rückgängig gemacht werden.",
    "cancel": "Abbrechen",
    "jobs": "Aufträge",
    "trainingTime": "Trainingszeit",
    "version": "Version",
    "metrics": "Metriken",
    "hideMetrics": "Metriken ausblenden",
    "noMetrics": "Keine Metriken verfügbar",
    "cpu": "CPU",
    "ram": "RAM",
    "gpu": "GPU",
    "vramUsage": "VRAM",
    "gpuTemp": "GPU-Temp.",
    "power": "Leistung",
    "online": "Online",
    "offline": "Offline",
    "training": "Training",
    "error": "Fehler",
    "unknown": "Unbekannt",
    "editWorker": "Worker bearbeiten",
    "addTrainingWorker": "Trainings-Worker hinzufügen",
    "formSubtitle": "Konfigurieren Sie einen GPU-Worker für die Feinabstimmung von Modellen",
    "namePlaceholder": "KI-PC-Worker",
    "description": "Beschreibung",
    "descriptionPlaceholder": "GPU-Worker für LLM-Training",
    "workerUrl": "Worker-URL *",
    "workerUrlPlaceholder": "http://192.168.1.100:8080",
    "workerUrlHint": "URL der Trainings-Worker-API (Docker-Container)",
    "apiKey": "API-Schlüssel (optional)",
    "apiKeyPlaceholder": "Optionaler API-Schlüssel für die Authentifizierung",
    "ollamaService": "Ollama-Dienst (für den Modellimport)",
    "ollamaServiceHint": "Wählen Sie den Ollama-Server aus, auf den das trainierte Modell importiert werden soll",
    "useWorkerDefault": "Worker-Standardwert verwenden",
    "workerEnabled": "Worker aktiviert",
    "saving": "Wird gespeichert...",
    "saveChanges": "Änderungen speichern",
    "failedToLoad": "Fehler beim Laden der Worker",
    "failedToSave": "Fehler beim Speichern des Workers",
    "failedToDelete": "Fehler beim Löschen des Workers",
    "testFailed": "Test fehlgeschlagen",
    "help": {
      "title": "GPU-Trainings-Worker",
      "overview": "Übersicht",
      "overviewContent": "Die Registerkarte Worker ermöglicht die Verwaltung von Remote-GPU-Workern für das Fine-Tuning von LLM-Modellen. Jeder Worker führt Trainingssitzungen auf seiner GPU aus.",
      "configuration": "Konfiguration",
      "configurationContent": "Um einen Worker hinzuzufügen:\n• Geben Sie die URL des training-worker Docker-Containers an\n• Optional einen API-Schlüssel für die Authentifizierung hinzufügen\n• Wählen Sie den Ziel-Ollama-Server für den Modellimport",
      "status": "Worker-Status",
      "statusContent": "Ein Worker kann verschiedene Status haben:\n• Online: verfügbar für Training\n• Training: Sitzung läuft\n• Offline: nicht erreichbar\n• Fehler: Verbindungsproblem",
      "metrics": "Metriken",
      "metricsContent": "Für jeden Online-Worker:\n• CPU/RAM-Auslastung\n• GPU- und VRAM-Auslastung\n• Temperatur und Stromverbrauch\n• Abgeschlossene Jobs und Gesamttrainingszeit"
    }
  },

  "status": {
    "pending": "Ausstehend",
    "preparing": "Wird vorbereitet",
    "running": "Läuft",
    "completed": "Abgeschlossen",
    "failed": "Fehlgeschlagen",
    "cancelled": "Abgebrochen",
    "paused": "Pausiert",
    "healthy": "Fehlerfrei",
    "unhealthy": "Fehlerhaft",
    "offline": "Offline",
    "notConfigured": "Nicht konfiguriert"
  },

  "difficulty": {
    "label": "Schwierigkeit",
    "basic": "Grundlegend",
    "intermediate": "Mittel",
    "advanced": "Fortgeschritten",
    "expert": "Experte"
  },

  "phases": {
    "preparing": "Wird vorbereitet",
    "downloading": "Modell wird heruntergeladen",
    "training": "Training",
    "exporting": "GGUF wird exportiert",
    "importing": "Zu Ollama importieren",
    "completed": "Abgeschlossen",
    "inProgress": "In Bearbeitung"
  },

  "form": {
    "nameRequired": "Name *",
    "namePlaceholder": "Prompt-Name",
    "toolNameRequired": "Tool-Name *",
    "servicesRequired": "Zugehörige Dienste *",
    "loadingAdapters": "Adapter werden geladen...",
    "jsonValidationError": "Tool-Aufruf-Argumente müssen gültiges JSON sein",
    "jsonResponseError": "Tool-Antwort muss gültiges JSON sein"
  },

  "errors": {
    "importFailed": "Fehler beim Importieren der Prompts",
    "exportFailed": "Fehler beim Exportieren der Prompts",
    "loadHomelabFailed": "Fehler beim Laden der Homelab-Prompts",
    "error": "Fehler",
    "loadingLogs": "Fehler beim Laden der Protokolle",
    "connectionFailed": "Verbindung fehlgeschlagen"
  },

  "overview": {
    "subtitle": "Echtzeit-Statistiken und Monitoring",
    "activeTraining": "Training läuft",
    "noData": "Keine Daten",
    "noWorkersConfigured": "Keine Worker konfiguriert",
    "addWorker": "Einen Worker hinzufügen",
    "connected": "Verbunden",
    "notConfigured": "Nicht konfiguriert",
    "ollamaNotConfigured": "Ollama nicht konfiguriert",
    "configure": "Konfigurieren",
    "promptsByService": "Prompts nach Dienst",
    "viewAll": "Alle anzeigen",
    "noPrompts": "Keine Prompts",
    "recentSessions": "Letzte Sitzungen",
    "lossEvolution": "Verlustentwicklung (letzte 10)",
    "noSessions": "Keine Sitzungen",
    "manage": "Verwalten",
    "models": "Modelle",
    "active": "Aktiv",
    "totalGB": "GB Gesamt",
    "inProgress": "In Bearbeitung",
    "online": "Online",
    "offline": "Offline",
    "busy": "Beschäftigt",
    "jobs": "Aufträge",
    "successRate": "Erfolgsrate",
    "completed": "abgeschlossen",
    "configured": "konfiguriert",
    "trainingWorkers": "Trainings-Worker",
    "ollamaServer": "Ollama-Server",
    "viewLiveLogs": "Live-Protokolle anzeigen",
    "viewLogs": "Protokolle anzeigen",
    "live": "Live",
    "lossDecreasing": "Abnehmend",
    "lossIncreasing": "Zunehmend",
    "lossStable": "Stabil",
    "speed": "Geschwindigkeit",
    "health": "Zustand",
    "utilization": "Auslastung",
    "temp": "Temp.",
    "power": "Leistung",
    "help": {
      "title": "KI-Training Statistiken",
      "overview": "Übersicht",
      "overviewContent": "Die Registerkarte Statistiken zeigt ein Echtzeit-Dashboard des KI-Trainings. Überwachen Sie aktive Sitzungen, Loss-Metriken, Fortschritt und GPU-Worker-Status.",
      "cards": "Statistik-Karten",
      "cardsContent": "Karten zeigen wichtige Metriken:\n• Sitzungen: gesamt und aktiv\n• Prompts: gesamt und validiert\n• Erfolgsrate: erfolgreich abgeschlossene Sitzungen\n• Worker: online GPU-Worker",
      "activeSessions": "Aktive Sitzungen",
      "activeSessionsContent": "Echtzeit-Trainingsfortschritt anzeigen:\n• Fortschritt (Epochen, Schritte)\n• Metriken (Loss, Learning Rate)\n• GPU-Auslastung (Speicher, Temperatur)\n• Phasenpipeline (Vorbereitung, Download, Training)",
      "workers": "Worker und Ollama",
      "workersContent": "Status der Trainingsressourcen:\n• GPU-Worker: Verfügbarkeit und Auslastung\n• Ollama-Server: verfügbare und laufende Modelle\n• WebSocket-Verbindungsstatus für Echtzeit-Updates"
    }
  },

  "logs": {
    "title": "Sitzungsprotokolle",
    "loading": "Wird geladen...",
    "error": "Fehler beim Laden der Protokolle",
    "noLogs": "Keine Protokolle für diese Sitzung verfügbar",
    "logsNote": "Protokolle werden am Ende des Trainings gespeichert",
    "refresh": "Aktualisieren",
    "download": "Herunterladen",
    "close": "Schließen",
    "goToEnd": "Zum Ende springen",
    "lines": "Zeilen",
    "disableAutoRefresh": "Automatische Aktualisierung deaktivieren",
    "enableAutoRefresh": "Automatische Aktualisierung aktivieren"
  },

  "details": {
    "title": "Sitzungsdetails",
    "name": "Name",
    "status": "Status",
    "baseModel": "Basismodell",
    "outputModel": "Ausgabemodell",
    "timing": "Zeitplan",
    "start": "Start",
    "end": "Ende",
    "duration": "Dauer",
    "progress": "Fortschritt",
    "epochs": "Epochen",
    "steps": "Schritte",
    "progressPercent": "Fortschritt",
    "prompts": "Prompts",
    "metrics": "Metriken",
    "initialLoss": "Anfangsverlust",
    "finalLoss": "Endverlust",
    "improvement": "Verbesserung",
    "minLoss": "Min. Verlust",
    "maxLoss": "Max. Verlust",
    "trend": "Trend",
    "trendDecreasing": "Abnehmend",
    "trendIncreasing": "Zunehmend",
    "trendStable": "Stabil",
    "lossEvolution": "Verlustentwicklung",
    "notEnoughData": "Nicht genügend Daten zur Anzeige des Diagramms",
    "error": "Fehler",
    "hyperparameters": "Hyperparameter",
    "close": "Schließen"
  }
}
