{
  "title": "AI Training",
  "subtitle": "AI model training and fine-tuning",
  "refresh": "Refresh",

  "devWarning": {
    "title": "Feature under development",
    "description": "This section is currently under development and not yet functional. AI training features will be available in a future release."
  },

  "help": {
    "category": "AI Training"
  },

  "tabs": {
    "overview": "Overview",
    "overviewShort": "Stats",
    "overviewFull": "General overview",
    "sessions": "Sessions",
    "sessionsFull": "Training sessions",
    "prompts": "Prompts",
    "promptsFull": "Training prompts",
    "models": "Models",
    "modelsFull": "Ollama models",
    "workers": "Workers",
    "workersFull": "GPU workers"
  },

  "sessions": {
    "title": "Training Sessions",
    "newSession": "New session",
    "newSessionTitle": "New training session",
    "count": "{{count}} session",
    "count_plural": "{{count}} sessions",
    "name": "Name",
    "nameRequired": "Name *",
    "baseModel": "Base model",
    "outputModel": "Output model",
    "trainingType": "Training type",
    "backend": "Backend",
    "dataset": "Dataset",
    "prompts": "prompts",
    "epochs": "Epochs",
    "steps": "Steps",
    "progress": "Progress",
    "status": "Status",
    "actions": "Actions",
    "start": "Start",
    "cancel": "Cancel",
    "pause": "Pause",
    "resume": "Resume",
    "delete": "Delete",
    "duplicate": "Duplicate",
    "viewDetails": "View details",
    "details": "Details",
    "viewLogs": "View logs",
    "logs": "Logs",
    "managePrompts": "Manage prompts",
    "managePromptsCount": "Manage prompts ({{count}})",
    "createdAt": "Created",
    "startedAt": "Started",
    "completedAt": "Completed",
    "loss": "Loss",
    "gpuMemory": "GPU Memory",
    "noSessions": "No training sessions",
    "noSessionsHint": "Create a new session to get started",
    "confirmDelete": "Are you sure you want to delete this session?",
    "addPromptsBeforeStart": "Add prompts before starting",
    "description": "Description",
    "descriptionPlaceholder": "Optional description...",
    "trainingMethod": "Training method",
    "modelfileMethod": "Modelfile (fast)",
    "modelfileDescription": "Creates an Ollama model with embedded examples. No GPU required.",
    "unslothMethod": "GPU Fine-tuning (Unsloth)",
    "unslothDescription": "LoRA fine-tuning on remote GPU worker. Better results.",
    "recommended": "Recommended",
    "gpuRequired": "GPU required",
    "selectOllamaModel": "Select an Ollama model",
    "selectModel": "Select a model",
    "trainedModels": "Trained models (incremental training)",
    "huggingfaceModels": "HuggingFace models (new training)",
    "incrementalTraining": "Incremental training: new prompts will be added to existing knowledge",
    "optimizedModels": "4-bit optimized models for GTX 1080 Ti (11GB VRAM)",
    "overwriteExisting": "Overwrite existing model",
    "overwriteDescription": "If a model with the same name already exists in Ollama, it will be replaced. Otherwise, an error will occur if the name is already taken.",
    "trainingWorker": "Training worker",
    "configureWorkerHint": "Configure a worker in settings to enable training.",
    "gpuAvailable": "GPU: {{name}}",
    "cpuOnly": "CPU only",
    "offline": "Offline",
    "busy": "Busy",
    "batchSize": "Batch size",
    "learningRate": "Learning rate",
    "sessionPlaceholder": "My training session",
    "step1": "1. Configuration",
    "step2": "2. Prompt selection",
    "next": "Next",
    "back": "Back",
    "promptsForTraining": "{{count}} prompt for training",
    "promptsForTraining_plural": "{{count}} prompts for training",
    "selectedCount": "{{count}} selected",
    "selectedCount_plural": "{{count}} selected",
    "selectedOfTotal": "{{selected}} selected / {{total}}",
    "selectedOfTotal_plural": "{{selected}} selected / {{total}}",
    "selectAll": "Select all",
    "selectNone": "Deselect all",
    "allServices": "All services",
    "promptsSelection": "Prompt selection",
    "promptsWillBeUsed": "{{count}} prompt will be used for training",
    "promptsWillBeUsed_plural": "{{count}} prompts will be used for training",
    "selectedOfTotalDisplayed": "{{selected}} selected / {{displayed}} displayed",
    "selectedOfTotalDisplayed_plural": "{{selected}} selected / {{displayed}} displayed",
    "help": {
      "title": "Training Sessions",
      "overview": "Overview",
      "overviewContent": "The Sessions tab allows you to create and manage AI model training sessions. Each session trains a base model with your custom prompts.",
      "lifecycle": "Lifecycle",
      "lifecycleContent": "A session goes through several phases:\n• Pending: configuration complete, ready to start\n• Running: active training with visible progress\n• Completed: trained model available in Ollama\n• Failed: error during training (check logs)",
      "actions": "Available Actions",
      "actionsContent": "For each session:\n• Start: launches training on a GPU worker\n• View details: metrics, hyperparameters, progress\n• View logs: detailed training logs\n• Duplicate: creates a copy of the session\n• Delete: removes the session and its data",
      "creation": "Session Creation",
      "creationContent": "To create a session:\n1. Choose a name and base model\n2. Select the method (quick Modelfile or GPU fine-tuning)\n3. Configure hyperparameters (epochs, batch size, learning rate)\n4. Select training prompts"
    }
  },

  "prompts": {
    "title": "Training Prompts",
    "total": "{{count}} prompt",
    "total_plural": "{{count}} prompts",
    "validated": "validated",
    "enabled": "enabled",
    "category": "Category",
    "difficulty": "Difficulty",
    "source": "Source",
    "format": "Format",
    "tags": "Tags",
    "timesUsed": "Usage",
    "timesUsedCount": "{{count}} uses",
    "validationScore": "Score",
    "actions": "Actions",
    "edit": "Edit",
    "delete": "Delete",
    "validate": "Validate",
    "enable": "Enable",
    "disable": "Disable",
    "cancel": "Cancel",
    "search": "Search...",
    "noPrompts": "No training prompts",
    "noPromptsFound": "No prompts found",
    "noPromptsHint": "Add prompts to train your models",
    "perPage": "Per page",
    "addPrompt": "Add prompt",
    "createPrompt": "Create prompt",
    "newPrompt": "New training prompt",
    "editPrompt": "Edit prompt",
    "save": "Save",
    "saving": "Saving...",
    "create": "Create prompt",
    "creating": "Creating...",
    "createMultiple": "Create ({{count}} prompts)",
    "saveMultiple": "Save ({{count}})",
    "searchPlaceholder": "Search...",
    "deleteAll": "Delete all prompts and reload homelab prompts",
    "confirmDelete": "Are you sure you want to delete this prompt?",
    "selectAtLeastOne": "Select at least one service",
    "resetPrompts": "Reset Prompts",
    "import": "Import",
    "export": "Export",
    "new": "New",
    "allServicesCount": "All services ({{count}})",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "System instructions for the model...",
    "userInput": "User input",
    "userInputRequired": "User input *",
    "userInputPlaceholder": "User question or request...",
    "expectedOutput": "Expected output",
    "expectedOutputRequired": "Expected output *",
    "expectedOutputPlaceholder": "Expected model response...",
    "useToolCalling": "Use Tool Calling",
    "toolCallingHint": "(teaches the model to call tools AND use the results)",
    "toolCall": "Tool Call",
    "toolName": "Tool name",
    "toolNameRequired": "Tool name *",
    "toolNamePlaceholder": "e.g.: system_get_health",
    "toolArguments": "Arguments (JSON)",
    "toolArgumentsPlaceholder": "e.g.: {\"service\": \"ollama\"}",
    "toolResponse": "Tool Response (JSON)",
    "toolResponseRequired": "Tool Response (JSON) *",
    "toolResponsePlaceholder": "{\"status\": \"healthy\", \"version\": \"0.1.0\", \"services\": [...]}",
    "toolResponseHint": "Realistic response the tool would return (used for training)",
    "assistantResponse": "Final assistant response",
    "assistantResponseRequired": "Final assistant response *",
    "assistantResponsePlaceholder": "The system is healthy. Ollama version 0.1.0 is operational with 3 active services...",
    "assistantResponseHint": "How the assistant should synthesize and present the tool data",
    "description": "Description",
    "descriptionPlaceholder": "Prompt description",
    "importSuccess": "Prompts imported successfully",
    "confirmResetAll": "This will delete ALL existing prompts and replace them with the default prompts. Continue?",
    "help": {
      "title": "Training Prompts",
      "overview": "Overview",
      "overviewContent": "The Prompts tab manages training data for your AI models. Each prompt is a conversation example that the model learns to reproduce.",
      "structure": "Prompt Structure",
      "structureContent": "A prompt contains:\n• User input: question or request\n• Expected output: ideal model response\n• Tool Call (optional): tool invocation with arguments\n• Tool Response: tool result\n• Final response: data synthesis",
      "management": "Management",
      "managementContent": "Available actions:\n• New: create a prompt manually\n• Reset: reload default homelab prompts\n• Import/Export: backup or restore as JSON\n• Validate: mark a prompt as verified",
      "filtering": "Filtering",
      "filteringContent": "Filter prompts by service (Plex, Radarr, Sonarr, etc.) or search by text. Badges indicate service, difficulty and validation status."
    }
  },

  "models": {
    "title": "Ollama Models",
    "status": "Ollama Status",
    "version": "Version",
    "modelCount": "Models",
    "modelCountValue": "{{count}} models",
    "totalSize": "Total size",
    "runningModels": "Running models",
    "name": "Name",
    "model": "Model",
    "family": "Family",
    "size": "Size",
    "parameterSize": "Parameters",
    "quantization": "Quantization",
    "modified": "Modified",
    "actions": "Actions",
    "pull": "Download",
    "delete": "Delete",
    "load": "Load model",
    "unload": "Unload model",
    "noModels": "No models installed",
    "noModelsFound": "No models found",
    "loading": "Loading...",
    "ollamaOffline": "Ollama is not available",
    "searchPlaceholder": "Search for a model...",
    "confirmDelete": "Are you sure you want to delete this model?",
    "confirmQuestion": "Confirm?",
    "loadedInMemory": "Loaded in memory",
    "loaded": "Loaded",
    "help": {
      "title": "Ollama Models",
      "overview": "Overview",
      "overviewContent": "The Models tab displays all LLM models installed on your Ollama server. You can see their size, family and loading status.",
      "management": "Model Management",
      "managementContent": "Available actions for each model:\n• Load: loads the model into GPU memory for immediate use\n• Unload: frees GPU memory occupied by the model\n• Delete: permanently removes the model from the server",
      "status": "Statuses",
      "statusContent": "A model can be:\n• Loaded (green): in GPU memory, ready for use\n• Not loaded: on disk, must be loaded before use\n• The badge indicates if the model is currently in memory",
      "info": "Information",
      "infoContent": "For each model:\n• Family: model type (llama, mistral, etc.)\n• Parameters: number of parameters (7B, 13B, etc.)\n• Quantization: compression level (Q4, Q8, etc.)\n• Size: disk space used"
    }
  },

  "workers": {
    "title": "Training Workers",
    "subtitle": "GPU workers for fine-tuning LLM models",
    "count": "{{count}} worker",
    "count_plural": "{{count}} workers",
    "name": "Name",
    "url": "URL",
    "status": "Status",
    "gpuAvailable": "GPU available",
    "gpuCount": "GPU count",
    "gpuCountLabel": "{{count}} GPU",
    "gpuCountLabel_plural": "{{count}} GPUs",
    "gpuNames": "GPUs",
    "vram": "{{size}} GB VRAM",
    "currentJob": "Current job",
    "actions": "Actions",
    "test": "Test",
    "testing": "Testing...",
    "edit": "Edit",
    "delete": "Delete",
    "enable": "Enable",
    "disable": "Disable",
    "noWorkers": "No workers configured",
    "noWorkersHint": "Add a GPU worker to enable fine-tuning capabilities",
    "loading": "Loading workers...",
    "addWorker": "Add Worker",
    "refreshAll": "Refresh All",
    "refresh": "Refresh",
    "retry": "Retry",
    "confirmDelete": "Are you sure you want to delete this worker?",
    "deleteWorker": "Delete Worker",
    "deleteConfirmMessage": "Are you sure you want to delete \"{{name}}\"? This action cannot be undone.",
    "cancel": "Cancel",
    "jobs": "Jobs",
    "trainingTime": "Training time",
    "version": "Version",
    "metrics": "Metrics",
    "hideMetrics": "Hide Metrics",
    "noMetrics": "No metrics available",
    "cpu": "CPU",
    "ram": "RAM",
    "gpu": "GPU",
    "vramUsage": "VRAM",
    "gpuTemp": "GPU Temp",
    "power": "Power",
    "online": "Online",
    "offline": "Offline",
    "training": "Training",
    "error": "Error",
    "unknown": "Unknown",
    "editWorker": "Edit Worker",
    "addTrainingWorker": "Add Training Worker",
    "formSubtitle": "Configure a GPU training worker for fine-tuning models",
    "namePlaceholder": "AI PC Worker",
    "description": "Description",
    "descriptionPlaceholder": "GPU worker for LLM training",
    "workerUrl": "Worker URL *",
    "workerUrlPlaceholder": "http://192.168.1.100:8080",
    "workerUrlHint": "URL of the training worker API (Docker container)",
    "apiKey": "API Key (optional)",
    "apiKeyPlaceholder": "Optional API key for authentication",
    "ollamaService": "Ollama Service (for model import)",
    "ollamaServiceHint": "Select which Ollama server to import the trained model to",
    "useWorkerDefault": "Use worker default",
    "workerEnabled": "Worker enabled",
    "saving": "Saving...",
    "saveChanges": "Save Changes",
    "failedToLoad": "Failed to load workers",
    "failedToSave": "Failed to save worker",
    "failedToDelete": "Failed to delete worker",
    "testFailed": "Test failed",
    "help": {
      "title": "GPU Training Workers",
      "overview": "Overview",
      "overviewContent": "The Workers tab allows you to manage remote GPU workers used for LLM model fine-tuning. Each worker runs training sessions on its GPU.",
      "configuration": "Configuration",
      "configurationContent": "To add a worker:\n• Specify the training-worker Docker container URL\n• Optionally add an API key for authentication\n• Select the destination Ollama server for model import",
      "status": "Worker States",
      "statusContent": "A worker can have several states:\n• Online: available for training\n• Training: session in progress\n• Offline: unreachable\n• Error: connection issue",
      "metrics": "Metrics",
      "metricsContent": "For each online worker:\n• CPU/RAM usage\n• GPU and VRAM usage\n• Temperature and power consumption\n• Completed jobs and total training time"
    }
  },

  "status": {
    "pending": "Pending",
    "preparing": "Preparing",
    "running": "Running",
    "completed": "Completed",
    "failed": "Failed",
    "cancelled": "Cancelled",
    "paused": "Paused",
    "healthy": "Healthy",
    "unhealthy": "Unhealthy",
    "offline": "Offline",
    "notConfigured": "Not configured"
  },

  "difficulty": {
    "label": "Difficulty",
    "basic": "Basic",
    "intermediate": "Intermediate",
    "advanced": "Advanced",
    "expert": "Expert"
  },

  "phases": {
    "preparing": "Preparing",
    "downloading": "Downloading model",
    "training": "Training",
    "exporting": "Exporting GGUF",
    "importing": "Importing to Ollama",
    "completed": "Completed",
    "inProgress": "In progress"
  },

  "form": {
    "nameRequired": "Name *",
    "namePlaceholder": "Prompt name",
    "toolNameRequired": "Tool name *",
    "servicesRequired": "Related services *",
    "loadingAdapters": "Loading adapters...",
    "jsonValidationError": "Tool call arguments must be valid JSON",
    "jsonResponseError": "Tool response must be valid JSON"
  },

  "errors": {
    "importFailed": "Error importing prompts",
    "exportFailed": "Error exporting prompts",
    "loadHomelabFailed": "Error loading homelab prompts",
    "error": "Error",
    "loadingLogs": "Error loading logs",
    "connectionFailed": "Connection failed"
  },

  "overview": {
    "subtitle": "Real-time statistics and monitoring",
    "activeTraining": "Training in progress",
    "noData": "No data",
    "noWorkersConfigured": "No workers configured",
    "addWorker": "Add a worker",
    "connected": "Connected",
    "notConfigured": "Not configured",
    "ollamaNotConfigured": "Ollama not configured",
    "configure": "Configure",
    "promptsByService": "Prompts by service",
    "viewAll": "View all",
    "noPrompts": "No prompts",
    "recentSessions": "Recent sessions",
    "lossEvolution": "Loss evolution (last 10)",
    "noSessions": "No sessions",
    "manage": "Manage",
    "models": "Models",
    "active": "Active",
    "totalGB": "GB Total",
    "inProgress": "In progress",
    "online": "Online",
    "offline": "Offline",
    "busy": "Busy",
    "jobs": "jobs",
    "successRate": "Success rate",
    "completed": "completed",
    "configured": "configured",
    "trainingWorkers": "Training Workers",
    "ollamaServer": "Ollama Server",
    "viewLiveLogs": "View live logs",
    "viewLogs": "View logs",
    "live": "Live",
    "lossDecreasing": "Decreasing",
    "lossIncreasing": "Increasing",
    "lossStable": "Stable",
    "speed": "Speed",
    "health": "Health",
    "utilization": "Utilization",
    "temp": "Temp",
    "power": "Power",
    "help": {
      "title": "AI Training Statistics",
      "overview": "Overview",
      "overviewContent": "The Statistics tab displays a real-time dashboard of AI training. Monitor active sessions, loss metrics, progress, and GPU worker status.",
      "cards": "Statistics Cards",
      "cardsContent": "Cards display key metrics:\n• Sessions: total and active\n• Prompts: total and validated\n• Success rate: successfully completed sessions\n• Workers: online GPU workers",
      "activeSessions": "Active Sessions",
      "activeSessionsContent": "View real-time training progress:\n• Progress (epochs, steps)\n• Metrics (loss, learning rate)\n• GPU usage (memory, temperature)\n• Phase pipeline (preparing, downloading, training)",
      "workers": "Workers and Ollama",
      "workersContent": "Training resources status:\n• GPU Workers: availability and load\n• Ollama Server: available and running models\n• WebSocket connection status for real-time updates"
    }
  },

  "logs": {
    "title": "Session logs",
    "loading": "Loading...",
    "error": "Error loading logs",
    "noLogs": "No logs available for this session",
    "logsNote": "Logs are saved at the end of training",
    "refresh": "Refresh",
    "download": "Download",
    "close": "Close",
    "goToEnd": "Go to end",
    "lines": "lines",
    "disableAutoRefresh": "Disable auto refresh",
    "enableAutoRefresh": "Enable auto refresh"
  },

  "details": {
    "title": "Session details",
    "name": "Name",
    "status": "Status",
    "baseModel": "Base model",
    "outputModel": "Output model",
    "timing": "Timing",
    "start": "Start",
    "end": "End",
    "duration": "Duration",
    "progress": "Progress",
    "epochs": "Epochs",
    "steps": "Steps",
    "progressPercent": "Progress",
    "prompts": "Prompts",
    "metrics": "Metrics",
    "initialLoss": "Initial loss",
    "finalLoss": "Final loss",
    "improvement": "Improvement",
    "minLoss": "Min loss",
    "maxLoss": "Max loss",
    "trend": "Trend",
    "trendDecreasing": "Decreasing",
    "trendIncreasing": "Increasing",
    "trendStable": "Stable",
    "lossEvolution": "Loss evolution",
    "notEnoughData": "Not enough data to display chart",
    "error": "Error",
    "hyperparameters": "Hyperparameters",
    "close": "Close"
  }
}
