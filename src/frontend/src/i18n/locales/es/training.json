{
  "title": "Entrenamiento IA",
  "subtitle": "Entrenamiento y ajuste fino de modelos de IA",
  "refresh": "Actualizar",

  "help": {
    "category": "Entrenamiento IA"
  },

  "tabs": {
    "overview": "Resumen",
    "overviewShort": "Estadísticas",
    "overviewFull": "Vista general",
    "sessions": "Sesiones",
    "sessionsFull": "Sesiones de entrenamiento",
    "prompts": "Prompts",
    "promptsFull": "Prompts de entrenamiento",
    "models": "Modelos",
    "modelsFull": "Modelos Ollama",
    "workers": "Workers",
    "workersFull": "Workers GPU"
  },

  "sessions": {
    "title": "Sesiones de Entrenamiento",
    "newSession": "Nueva sesión",
    "newSessionTitle": "Nueva sesión de entrenamiento",
    "count": "{{count}} sesión",
    "count_plural": "{{count}} sesiones",
    "name": "Nombre",
    "nameRequired": "Nombre *",
    "baseModel": "Modelo base",
    "outputModel": "Modelo de salida",
    "trainingType": "Tipo de entrenamiento",
    "backend": "Backend",
    "dataset": "Conjunto de datos",
    "prompts": "prompts",
    "epochs": "Epochs",
    "steps": "Steps",
    "progress": "Progreso",
    "status": "Estado",
    "actions": "Acciones",
    "start": "Iniciar",
    "cancel": "Cancelar",
    "pause": "Pausar",
    "resume": "Reanudar",
    "delete": "Eliminar",
    "duplicate": "Duplicar",
    "viewDetails": "Ver detalles",
    "details": "Detalles",
    "viewLogs": "Ver registros",
    "logs": "Registros",
    "managePrompts": "Gestionar prompts",
    "managePromptsCount": "Gestionar prompts ({{count}})",
    "createdAt": "Creado el",
    "startedAt": "Iniciado el",
    "completedAt": "Completado el",
    "loss": "Loss",
    "gpuMemory": "Memoria GPU",
    "noSessions": "Sin sesiones de entrenamiento",
    "noSessionsHint": "Cree una nueva sesión para comenzar",
    "confirmDelete": "¿Está seguro de que desea eliminar esta sesión?",
    "addPromptsBeforeStart": "Añada prompts antes de iniciar",
    "description": "Descripción",
    "descriptionPlaceholder": "Descripción opcional...",
    "trainingMethod": "Método de entrenamiento",
    "modelfileMethod": "Modelfile (rápido)",
    "modelfileDescription": "Crea un modelo Ollama con los ejemplos integrados. No requiere GPU.",
    "unslothMethod": "Fine-tuning GPU (Unsloth)",
    "unslothDescription": "Fine-tuning LoRA en worker GPU remoto. Mejores resultados.",
    "recommended": "Recomendado",
    "gpuRequired": "Requiere GPU",
    "selectOllamaModel": "Seleccionar un modelo Ollama",
    "selectModel": "Seleccionar un modelo",
    "trainedModels": "Modelos entrenados (entrenamiento incremental)",
    "huggingfaceModels": "Modelos HuggingFace (nuevo entrenamiento)",
    "incrementalTraining": "Entrenamiento incremental: los nuevos prompts se añadirán al conocimiento existente",
    "optimizedModels": "Modelos optimizados 4-bit para GTX 1080 Ti (11GB VRAM)",
    "overwriteExisting": "Sobrescribir el modelo existente",
    "overwriteDescription": "Si un modelo con el mismo nombre ya existe en Ollama, será reemplazado. De lo contrario, se producirá un error si el nombre ya está en uso.",
    "trainingWorker": "Worker de entrenamiento",
    "configureWorkerHint": "Configure un worker en los ajustes para activar el entrenamiento.",
    "gpuAvailable": "GPU: {{name}}",
    "cpuOnly": "Solo CPU",
    "offline": "Sin conexión",
    "busy": "Ocupado",
    "batchSize": "Batch size",
    "learningRate": "Learning rate",
    "sessionPlaceholder": "Mi sesión de entrenamiento",
    "step1": "1. Configuración",
    "step2": "2. Selección de prompts",
    "next": "Siguiente",
    "back": "Atrás",
    "promptsForTraining": "{{count}} prompt para el entrenamiento",
    "promptsForTraining_plural": "{{count}} prompts para el entrenamiento",
    "selectedCount": "{{count}} seleccionado",
    "selectedCount_plural": "{{count}} seleccionados",
    "selectedOfTotal": "{{selected}} seleccionado / {{total}}",
    "selectedOfTotal_plural": "{{selected}} seleccionados / {{total}}",
    "selectAll": "Seleccionar todo",
    "selectNone": "Deseleccionar todo",
    "allServices": "Todos los servicios",
    "promptsSelection": "Selección de prompts",
    "promptsWillBeUsed": "{{count}} prompt será utilizado para el entrenamiento",
    "promptsWillBeUsed_plural": "{{count}} prompts serán utilizados para el entrenamiento",
    "selectedOfTotalDisplayed": "{{selected}} seleccionado / {{displayed}} mostrado",
    "selectedOfTotalDisplayed_plural": "{{selected}} seleccionados / {{displayed}} mostrados",
    "help": {
      "title": "Sesiones de Entrenamiento",
      "overview": "Resumen",
      "overviewContent": "La pestaña Sesiones permite crear y gestionar sesiones de entrenamiento de modelos de IA. Cada sesión entrena un modelo base con sus prompts personalizados.",
      "lifecycle": "Ciclo de vida",
      "lifecycleContent": "Una sesión pasa por varias fases:\n• Pendiente: configuración completada, lista para iniciar\n• En ejecución: entrenamiento activo con progreso visible\n• Completada: modelo entrenado disponible en Ollama\n• Fallida: error durante el entrenamiento (consulte los registros)",
      "actions": "Acciones disponibles",
      "actionsContent": "Para cada sesión:\n• Iniciar: lanza el entrenamiento en un worker GPU\n• Ver detalles: métricas, hiperparámetros, progreso\n• Ver registros: registros detallados del entrenamiento\n• Duplicar: crea una copia de la sesión\n• Eliminar: elimina la sesión y sus datos",
      "creation": "Creación de sesión",
      "creationContent": "Para crear una sesión:\n1. Elija un nombre y modelo base\n2. Seleccione el método (Modelfile rápido o fine-tuning GPU)\n3. Configure los hiperparámetros (epochs, batch size, learning rate)\n4. Seleccione los prompts de entrenamiento"
    }
  },

  "prompts": {
    "title": "Prompts de Entrenamiento",
    "total": "{{count}} prompt",
    "total_plural": "{{count}} prompts",
    "validated": "validados",
    "enabled": "activados",
    "category": "Categoría",
    "difficulty": "Dificultad",
    "source": "Fuente",
    "format": "Formato",
    "tags": "Etiquetas",
    "timesUsed": "Usos",
    "timesUsedCount": "{{count}} usos",
    "validationScore": "Puntuación",
    "actions": "Acciones",
    "edit": "Editar",
    "delete": "Eliminar",
    "validate": "Validar",
    "enable": "Activar",
    "disable": "Desactivar",
    "cancel": "Cancelar",
    "search": "Buscar...",
    "noPrompts": "Sin prompts de entrenamiento",
    "noPromptsFound": "No se encontraron prompts",
    "noPromptsHint": "Añada prompts para entrenar sus modelos",
    "perPage": "Por página",
    "addPrompt": "Añadir prompt",
    "createPrompt": "Crear prompt",
    "newPrompt": "Nuevo prompt de entrenamiento",
    "editPrompt": "Editar prompt",
    "save": "Guardar",
    "saving": "Guardando...",
    "create": "Crear prompt",
    "creating": "Creando...",
    "createMultiple": "Crear ({{count}} prompts)",
    "saveMultiple": "Guardar ({{count}})",
    "searchPlaceholder": "Buscar...",
    "deleteAll": "Eliminar todos los prompts y recargar prompts de homelab",
    "confirmDelete": "¿Está seguro de que desea eliminar este prompt?",
    "selectAtLeastOne": "Seleccione al menos un servicio",
    "resetPrompts": "Restablecer Prompts",
    "import": "Importar",
    "export": "Exportar",
    "new": "Nuevo",
    "allServicesCount": "Todos los servicios ({{count}})",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Instrucciones del sistema para el modelo...",
    "userInput": "Entrada del usuario",
    "userInputRequired": "Entrada del usuario *",
    "userInputPlaceholder": "Pregunta o solicitud del usuario...",
    "expectedOutput": "Salida esperada",
    "expectedOutputRequired": "Salida esperada *",
    "expectedOutputPlaceholder": "Respuesta esperada del modelo...",
    "useToolCalling": "Utilizar Tool Calling",
    "toolCallingHint": "(enseña al modelo a llamar herramientas Y utilizar los resultados)",
    "toolCall": "Tool Call (Llamada de herramienta)",
    "toolName": "Nombre del tool",
    "toolNameRequired": "Nombre del tool *",
    "toolNamePlaceholder": "ej: system_get_health",
    "toolArguments": "Argumentos (JSON)",
    "toolArgumentsPlaceholder": "ej: {\"service\": \"ollama\"}",
    "toolResponse": "Respuesta del Tool (JSON)",
    "toolResponseRequired": "Respuesta del Tool (JSON) *",
    "toolResponsePlaceholder": "{\"status\": \"healthy\", \"version\": \"0.1.0\", \"services\": [...]}",
    "toolResponseHint": "Respuesta realista que el tool devolvería (utilizada para el entrenamiento)",
    "assistantResponse": "Respuesta final del asistente",
    "assistantResponseRequired": "Respuesta final del asistente *",
    "assistantResponsePlaceholder": "El sistema está en buen estado. Ollama versión 0.1.0 está operativo con 3 servicios activos...",
    "assistantResponseHint": "Cómo el asistente debe sintetizar y presentar los datos del tool",
    "description": "Descripción",
    "descriptionPlaceholder": "Descripción del prompt",
    "importSuccess": "Prompts importados con éxito",
    "confirmResetAll": "Esto eliminará TODOS los prompts existentes y los reemplazará por los prompts predeterminados. ¿Continuar?",
    "help": {
      "title": "Prompts de Entrenamiento",
      "overview": "Descripción general",
      "overviewContent": "La pestaña Prompts gestiona los datos de entrenamiento para sus modelos de IA. Cada prompt es un ejemplo de conversación que el modelo aprende a reproducir.",
      "structure": "Estructura del prompt",
      "structureContent": "Un prompt contiene:\n• Entrada del usuario: pregunta o solicitud\n• Salida esperada: respuesta ideal del modelo\n• Tool Call (opcional): invocación de herramienta con argumentos\n• Tool Response: resultado de la herramienta\n• Respuesta final: síntesis de datos",
      "management": "Gestión",
      "managementContent": "Acciones disponibles:\n• Nuevo: crear un prompt manualmente\n• Reset: recargar prompts homelab predeterminados\n• Importar/Exportar: guardar o restaurar como JSON\n• Validar: marcar un prompt como verificado",
      "filtering": "Filtrado",
      "filteringContent": "Filtre prompts por servicio (Plex, Radarr, Sonarr, etc.) o busque por texto. Las insignias indican servicio, dificultad y estado de validación."
    }
  },

  "models": {
    "title": "Modelos Ollama",
    "status": "Estado de Ollama",
    "version": "Versión",
    "modelCount": "Modelos",
    "modelCountValue": "{{count}} modelos",
    "totalSize": "Tamaño total",
    "runningModels": "Modelos en ejecución",
    "name": "Nombre",
    "model": "Modelo",
    "family": "Familia",
    "size": "Tamaño",
    "parameterSize": "Parámetros",
    "quantization": "Quantization",
    "modified": "Modificado",
    "actions": "Acciones",
    "pull": "Descargar",
    "delete": "Eliminar",
    "load": "Cargar modelo",
    "unload": "Descargar modelo",
    "noModels": "Sin modelos instalados",
    "noModelsFound": "No se encontraron modelos",
    "loading": "Cargando...",
    "ollamaOffline": "Ollama no está disponible",
    "searchPlaceholder": "Buscar un modelo...",
    "confirmDelete": "¿Está seguro de que desea eliminar este modelo?",
    "confirmQuestion": "¿Confirmar?",
    "loadedInMemory": "Cargado en memoria",
    "loaded": "Cargado",
    "help": {
      "title": "Modelos Ollama",
      "overview": "Descripción general",
      "overviewContent": "La pestaña Modelos muestra todos los modelos LLM instalados en su servidor Ollama. Puede ver su tamaño, familia y estado de carga.",
      "management": "Gestión de modelos",
      "managementContent": "Acciones disponibles para cada modelo:\n• Cargar: carga el modelo en la memoria GPU para uso inmediato\n• Descargar: libera la memoria GPU ocupada por el modelo\n• Eliminar: elimina permanentemente el modelo del servidor",
      "status": "Estados",
      "statusContent": "Un modelo puede estar:\n• Cargado (verde): en memoria GPU, listo para usar\n• No cargado: en disco, debe cargarse antes de usar\n• La insignia indica si el modelo está actualmente en memoria",
      "info": "Información",
      "infoContent": "Para cada modelo:\n• Familia: tipo de modelo (llama, mistral, etc.)\n• Parámetros: número de parámetros (7B, 13B, etc.)\n• Cuantización: nivel de compresión (Q4, Q8, etc.)\n• Tamaño: espacio en disco utilizado"
    }
  },

  "workers": {
    "title": "Workers de Entrenamiento",
    "subtitle": "Workers GPU para el ajuste fino de modelos LLM",
    "count": "{{count}} worker",
    "count_plural": "{{count}} workers",
    "name": "Nombre",
    "url": "URL",
    "status": "Estado",
    "gpuAvailable": "GPU disponible",
    "gpuCount": "Cantidad de GPU",
    "gpuCountLabel": "{{count}} GPU",
    "gpuCountLabel_plural": "{{count}} GPU",
    "gpuNames": "GPU",
    "vram": "{{size}} GB VRAM",
    "currentJob": "Trabajo actual",
    "actions": "Acciones",
    "test": "Probar",
    "testing": "Probando...",
    "edit": "Editar",
    "delete": "Eliminar",
    "enable": "Activar",
    "disable": "Desactivar",
    "noWorkers": "Sin workers configurados",
    "noWorkersHint": "Añada un worker GPU para activar el ajuste fino",
    "loading": "Cargando workers...",
    "addWorker": "Añadir worker",
    "refreshAll": "Actualizar todo",
    "refresh": "Actualizar",
    "retry": "Reintentar",
    "confirmDelete": "¿Está seguro de que desea eliminar este worker?",
    "deleteWorker": "Eliminar worker",
    "deleteConfirmMessage": "¿Está seguro de que desea eliminar \"{{name}}\"? Esta acción es irreversible.",
    "cancel": "Cancelar",
    "jobs": "Trabajos",
    "trainingTime": "Tiempo de entrenamiento",
    "version": "Versión",
    "metrics": "Métricas",
    "hideMetrics": "Ocultar métricas",
    "noMetrics": "Sin métricas disponibles",
    "cpu": "CPU",
    "ram": "RAM",
    "gpu": "GPU",
    "vramUsage": "VRAM",
    "gpuTemp": "Temp GPU",
    "power": "Power",
    "online": "En línea",
    "offline": "Sin conexión",
    "training": "Entrenando",
    "error": "Error",
    "unknown": "Desconocido",
    "editWorker": "Editar worker",
    "addTrainingWorker": "Añadir Training Worker",
    "formSubtitle": "Configurar un worker GPU para el ajuste fino de modelos",
    "namePlaceholder": "IA PC Worker",
    "description": "Descripción",
    "descriptionPlaceholder": "Worker GPU para entrenamiento LLM",
    "workerUrl": "URL del Worker *",
    "workerUrlPlaceholder": "http://192.168.1.100:8080",
    "workerUrlHint": "URL de la API del training worker (contenedor Docker)",
    "apiKey": "Clave API (opcional)",
    "apiKeyPlaceholder": "Clave API opcional para la autenticación",
    "ollamaService": "Servicio Ollama (para la importación del modelo)",
    "ollamaServiceHint": "Seleccione el servidor Ollama donde importar el modelo entrenado",
    "useWorkerDefault": "Utilizar el valor predeterminado del worker",
    "workerEnabled": "Worker activado",
    "saving": "Guardando...",
    "saveChanges": "Guardar cambios",
    "failedToLoad": "Error al cargar los workers",
    "failedToSave": "Error al guardar el worker",
    "failedToDelete": "Error al eliminar el worker",
    "testFailed": "Prueba fallida",
    "help": {
      "title": "Workers GPU de Entrenamiento",
      "overview": "Descripción general",
      "overviewContent": "La pestaña Workers permite gestionar workers GPU remotos utilizados para el ajuste fino de modelos LLM. Cada worker ejecuta sesiones de entrenamiento en su GPU.",
      "configuration": "Configuración",
      "configurationContent": "Para añadir un worker:\n• Especifique la URL del contenedor Docker training-worker\n• Opcionalmente añada una clave API para autenticación\n• Seleccione el servidor Ollama de destino para la importación del modelo",
      "status": "Estados del worker",
      "statusContent": "Un worker puede tener varios estados:\n• En línea: disponible para entrenamiento\n• Entrenando: sesión en curso\n• Sin conexión: no accesible\n• Error: problema de conexión",
      "metrics": "Métricas",
      "metricsContent": "Para cada worker en línea:\n• Uso de CPU/RAM\n• Uso de GPU y VRAM\n• Temperatura y consumo de energía\n• Trabajos completados y tiempo total de entrenamiento"
    }
  },

  "status": {
    "pending": "Pendiente",
    "preparing": "Preparando",
    "running": "En ejecución",
    "completed": "Completado",
    "failed": "Fallido",
    "cancelled": "Cancelado",
    "paused": "Pausado",
    "healthy": "Saludable",
    "unhealthy": "No saludable",
    "offline": "Sin conexión",
    "notConfigured": "No configurado"
  },

  "difficulty": {
    "label": "Dificultad",
    "basic": "Básico",
    "intermediate": "Intermedio",
    "advanced": "Avanzado",
    "expert": "Experto"
  },

  "phases": {
    "preparing": "Preparando",
    "downloading": "Descargando modelo",
    "training": "Entrenando",
    "exporting": "Exportando GGUF",
    "importing": "Importando a Ollama",
    "completed": "Completado",
    "inProgress": "En progreso"
  },

  "form": {
    "nameRequired": "Nombre *",
    "namePlaceholder": "Nombre del prompt",
    "toolNameRequired": "Nombre del tool *",
    "servicesRequired": "Servicios relacionados *",
    "loadingAdapters": "Cargando adaptadores...",
    "jsonValidationError": "Los argumentos del tool call deben ser un JSON válido",
    "jsonResponseError": "La respuesta del tool debe ser un JSON válido"
  },

  "errors": {
    "importFailed": "Error al importar prompts",
    "exportFailed": "Error al exportar prompts",
    "loadHomelabFailed": "Error al cargar prompts de homelab",
    "error": "Error",
    "loadingLogs": "Error al cargar registros",
    "connectionFailed": "Conexión fallida"
  },

  "overview": {
    "subtitle": "Estadísticas y monitoreo en tiempo real",
    "activeTraining": "Entrenamiento en progreso",
    "noData": "Sin datos",
    "noWorkersConfigured": "Sin workers configurados",
    "addWorker": "Añadir worker",
    "connected": "Conectado",
    "notConfigured": "No configurado",
    "ollamaNotConfigured": "Ollama no configurado",
    "configure": "Configurar",
    "promptsByService": "Prompts por servicio",
    "viewAll": "Ver todos",
    "noPrompts": "Sin prompts",
    "recentSessions": "Sesiones recientes",
    "lossEvolution": "Evolución del Loss (últimas 10)",
    "noSessions": "Sin sesiones",
    "manage": "Gestionar",
    "models": "Modelos",
    "active": "Activos",
    "totalGB": "GB Total",
    "inProgress": "En progreso",
    "online": "En línea",
    "offline": "Sin conexión",
    "busy": "Ocupado",
    "jobs": "trabajos",
    "successRate": "Tasa de éxito",
    "completed": "completadas",
    "configured": "configurados",
    "trainingWorkers": "Training Workers",
    "ollamaServer": "Ollama Server",
    "viewLiveLogs": "Ver registros en vivo",
    "viewLogs": "Ver registros",
    "live": "En vivo",
    "lossDecreasing": "Decreciente",
    "lossIncreasing": "Creciente",
    "lossStable": "Estable",
    "speed": "Velocidad",
    "health": "Salud",
    "utilization": "Utilización",
    "temp": "Temp",
    "power": "Potencia",
    "help": {
      "title": "Estadísticas de Entrenamiento IA",
      "overview": "Resumen",
      "overviewContent": "La pestaña Estadísticas muestra un panel de control en tiempo real del entrenamiento de IA. Supervise las sesiones activas, las métricas de loss, el progreso y el estado de los workers GPU.",
      "cards": "Tarjetas de estadísticas",
      "cardsContent": "Las tarjetas muestran métricas clave:\n• Sesiones: total y activas\n• Prompts: total y validados\n• Tasa de éxito: sesiones completadas con éxito\n• Workers: workers GPU en línea",
      "activeSessions": "Sesiones activas",
      "activeSessionsContent": "Ver el progreso del entrenamiento en tiempo real:\n• Progreso (epochs, steps)\n• Métricas (loss, learning rate)\n• Uso de GPU (memoria, temperatura)\n• Pipeline de fases (preparación, descarga, entrenamiento)",
      "workers": "Workers y Ollama",
      "workersContent": "Estado de los recursos de entrenamiento:\n• Workers GPU: disponibilidad y carga\n• Servidor Ollama: modelos disponibles y en ejecución\n• Estado de conexión WebSocket para actualizaciones en tiempo real"
    }
  },

  "logs": {
    "title": "Registros de sesión",
    "loading": "Cargando...",
    "error": "Error al cargar registros",
    "noLogs": "Sin registros disponibles para esta sesión",
    "logsNote": "Los registros se guardan al finalizar el entrenamiento",
    "refresh": "Actualizar",
    "download": "Descargar",
    "close": "Cerrar",
    "goToEnd": "Ir al final",
    "lines": "líneas",
    "disableAutoRefresh": "Desactivar actualización automática",
    "enableAutoRefresh": "Activar actualización automática"
  },

  "details": {
    "title": "Detalles de sesión",
    "name": "Nombre",
    "status": "Estado",
    "baseModel": "Modelo base",
    "outputModel": "Modelo de salida",
    "timing": "Temporización",
    "start": "Inicio",
    "end": "Fin",
    "duration": "Duración",
    "progress": "Progreso",
    "epochs": "Epochs",
    "steps": "Steps",
    "progressPercent": "Progreso",
    "prompts": "Prompts",
    "metrics": "Métricas",
    "initialLoss": "Loss inicial",
    "finalLoss": "Loss final",
    "improvement": "Mejora",
    "minLoss": "Loss mínimo",
    "maxLoss": "Loss máximo",
    "trend": "Tendencia",
    "trendDecreasing": "Decreciente",
    "trendIncreasing": "Creciente",
    "trendStable": "Estable",
    "lossEvolution": "Evolución del Loss",
    "notEnoughData": "No hay suficientes datos para mostrar el gráfico",
    "error": "Error",
    "hyperparameters": "Hiperparámetros",
    "close": "Cerrar"
  }
}
