{
  "title": "AI Training",
  "subtitle": "Entraînement et fine-tuning de modèles IA",
  "refresh": "Actualiser",

  "devWarning": {
    "title": "Fonctionnalité en cours de développement",
    "description": "Cette section est actuellement en développement et n'est pas encore fonctionnelle. Les fonctionnalités d'entraînement IA seront disponibles dans une prochaine version."
  },

  "help": {
    "category": "IA Training"
  },

  "tabs": {
    "overview": "Vue d'ensemble",
    "overviewShort": "Stats",
    "overviewFull": "Vue générale",
    "sessions": "Sessions",
    "sessionsFull": "Sessions d'entraînement",
    "prompts": "Prompts",
    "promptsFull": "Prompts d'entraînement",
    "models": "Modèles",
    "modelsFull": "Modèles Ollama",
    "workers": "Workers",
    "workersFull": "Workers GPU"
  },

  "sessions": {
    "title": "Sessions d'Entraînement",
    "newSession": "Nouvelle session",
    "newSessionTitle": "Nouvelle session d'entraînement",
    "count": "{{count}} session",
    "count_plural": "{{count}} sessions",
    "name": "Nom",
    "nameRequired": "Nom *",
    "baseModel": "Modèle de base",
    "outputModel": "Modèle de sortie",
    "trainingType": "Type d'entraînement",
    "backend": "Backend",
    "dataset": "Dataset",
    "prompts": "prompts",
    "epochs": "Epochs",
    "steps": "Steps",
    "progress": "Progression",
    "status": "Statut",
    "actions": "Actions",
    "start": "Démarrer",
    "cancel": "Annuler",
    "pause": "Pause",
    "resume": "Reprendre",
    "delete": "Supprimer",
    "duplicate": "Dupliquer",
    "viewDetails": "Voir les détails",
    "details": "Détails",
    "viewLogs": "Voir les logs",
    "logs": "Logs",
    "managePrompts": "Gérer les prompts",
    "managePromptsCount": "Gérer les prompts ({{count}})",
    "createdAt": "Créé le",
    "startedAt": "Démarré le",
    "completedAt": "Terminé le",
    "loss": "Loss",
    "gpuMemory": "Mémoire GPU",
    "noSessions": "Aucune session d'entraînement",
    "noSessionsHint": "Créez une nouvelle session pour commencer",
    "confirmDelete": "Êtes-vous sûr de vouloir supprimer cette session ?",
    "addPromptsBeforeStart": "Ajoutez des prompts avant de démarrer",
    "description": "Description",
    "descriptionPlaceholder": "Description optionnelle...",
    "trainingMethod": "Méthode d'entraînement",
    "modelfileMethod": "Modelfile (rapide)",
    "modelfileDescription": "Crée un modèle Ollama avec les exemples intégrés. Pas de GPU requis.",
    "unslothMethod": "Fine-tuning GPU (Unsloth)",
    "unslothDescription": "Fine-tuning LoRA sur worker GPU distant. Meilleurs résultats.",
    "recommended": "Recommandé",
    "gpuRequired": "GPU requis",
    "selectOllamaModel": "Sélectionner un modèle Ollama",
    "selectModel": "Sélectionner un modèle",
    "trainedModels": "Modèles entraînés (entraînement incrémental)",
    "huggingfaceModels": "Modèles HuggingFace (nouvel entraînement)",
    "incrementalTraining": "Entraînement incrémental : les nouveaux prompts s'ajouteront aux connaissances existantes",
    "optimizedModels": "Modèles optimisés 4-bit pour GTX 1080 Ti (11GB VRAM)",
    "overwriteExisting": "Écraser le modèle existant",
    "overwriteDescription": "Si un modèle avec le même nom existe déjà dans Ollama, il sera remplacé. Sinon, une erreur se produira si le nom est déjà pris.",
    "trainingWorker": "Worker d'entraînement",
    "configureWorkerHint": "Configurez un worker dans les paramètres pour activer l'entraînement.",
    "gpuAvailable": "GPU: {{name}}",
    "cpuOnly": "CPU only",
    "offline": "Hors ligne",
    "busy": "Occupé",
    "batchSize": "Batch size",
    "learningRate": "Learning rate",
    "sessionPlaceholder": "Ma session d'entraînement",
    "step1": "1. Configuration",
    "step2": "2. Sélection des prompts",
    "next": "Suivant",
    "back": "Retour",
    "promptsForTraining": "{{count}} prompt pour l'entraînement",
    "promptsForTraining_plural": "{{count}} prompts pour l'entraînement",
    "selectedCount": "{{count}} sélectionné",
    "selectedCount_plural": "{{count}} sélectionnés",
    "selectedOfTotal": "{{selected}} sélectionné / {{total}}",
    "selectedOfTotal_plural": "{{selected}} sélectionnés / {{total}}",
    "selectAll": "Tout sélectionner",
    "selectNone": "Tout désélectionner",
    "allServices": "Tous les services",
    "promptsSelection": "Sélection des prompts",
    "promptsWillBeUsed": "{{count}} prompt sera utilisé pour l'entraînement",
    "promptsWillBeUsed_plural": "{{count}} prompts seront utilisés pour l'entraînement",
    "selectedOfTotalDisplayed": "{{selected}} sélectionné / {{displayed}} affiché",
    "selectedOfTotalDisplayed_plural": "{{selected}} sélectionnés / {{displayed}} affichés",
    "help": {
      "title": "Sessions d'Entraînement",
      "overview": "Vue d'ensemble",
      "overviewContent": "L'onglet Sessions permet de créer et gérer les sessions d'entraînement de modèles IA. Chaque session entraîne un modèle de base avec vos prompts personnalisés.",
      "lifecycle": "Cycle de vie",
      "lifecycleContent": "Une session passe par plusieurs phases :\n• En attente : configuration terminée, prête à démarrer\n• En cours : entraînement actif avec progression visible\n• Terminée : modèle entraîné disponible dans Ollama\n• Échouée : erreur durant l'entraînement (consultez les logs)",
      "actions": "Actions disponibles",
      "actionsContent": "Pour chaque session :\n• Démarrer : lance l'entraînement sur un worker GPU\n• Voir les détails : métriques, hyperparamètres, progression\n• Voir les logs : logs détaillés de l'entraînement\n• Dupliquer : crée une copie de la session\n• Supprimer : supprime la session et ses données",
      "creation": "Création de session",
      "creationContent": "Pour créer une session :\n1. Choisissez un nom et un modèle de base\n2. Sélectionnez la méthode (Modelfile rapide ou GPU fine-tuning)\n3. Configurez les hyperparamètres (epochs, batch size, learning rate)\n4. Sélectionnez les prompts d'entraînement"
    }
  },

  "prompts": {
    "title": "Prompts d'Entraînement",
    "total": "{{count}} prompt",
    "total_plural": "{{count}} prompts",
    "validated": "validés",
    "enabled": "activés",
    "category": "Catégorie",
    "difficulty": "Difficulté",
    "source": "Source",
    "format": "Format",
    "tags": "Tags",
    "timesUsed": "Utilisations",
    "timesUsedCount": "{{count}} utilisations",
    "validationScore": "Score",
    "actions": "Actions",
    "edit": "Modifier",
    "delete": "Supprimer",
    "validate": "Valider",
    "enable": "Activer",
    "disable": "Désactiver",
    "cancel": "Annuler",
    "search": "Rechercher...",
    "noPrompts": "Aucun prompt d'entraînement",
    "noPromptsFound": "Aucun prompt trouvé",
    "noPromptsHint": "Ajoutez des prompts pour entraîner vos modèles",
    "perPage": "Par page",
    "addPrompt": "Ajouter un prompt",
    "createPrompt": "Créer un prompt",
    "newPrompt": "Nouveau prompt d'entraînement",
    "editPrompt": "Modifier le prompt",
    "save": "Enregistrer",
    "saving": "Enregistrement...",
    "create": "Créer le prompt",
    "creating": "Création...",
    "createMultiple": "Créer ({{count}} prompts)",
    "saveMultiple": "Enregistrer ({{count}})",
    "searchPlaceholder": "Rechercher...",
    "deleteAll": "Supprimer tous les prompts et recharger les prompts homelab",
    "confirmDelete": "Êtes-vous sûr de vouloir supprimer ce prompt ?",
    "selectAtLeastOne": "Sélectionnez au moins un service",
    "resetPrompts": "Reset Prompts",
    "import": "Importer",
    "export": "Exporter",
    "new": "Nouveau",
    "allServicesCount": "Tous les services ({{count}})",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Instructions système pour le modèle...",
    "userInput": "Input utilisateur",
    "userInputRequired": "Input utilisateur *",
    "userInputPlaceholder": "Question ou demande de l'utilisateur...",
    "expectedOutput": "Sortie attendue",
    "expectedOutputRequired": "Sortie attendue *",
    "expectedOutputPlaceholder": "Réponse attendue du modèle...",
    "useToolCalling": "Utiliser Tool Calling",
    "toolCallingHint": "(apprend au modèle à appeler des outils ET utiliser les résultats)",
    "toolCall": "Tool Call (Appel d'outil)",
    "toolName": "Nom du tool",
    "toolNameRequired": "Nom du tool *",
    "toolNamePlaceholder": "ex: system_get_health",
    "toolArguments": "Arguments (JSON)",
    "toolArgumentsPlaceholder": "ex: {\"service\": \"ollama\"}",
    "toolResponse": "Réponse du Tool (JSON)",
    "toolResponseRequired": "Réponse du Tool (JSON) *",
    "toolResponsePlaceholder": "{\"status\": \"healthy\", \"version\": \"0.1.0\", \"services\": [...]}",
    "toolResponseHint": "Réponse réaliste que le tool retournerait (utilisée pour l'entraînement)",
    "assistantResponse": "Réponse finale de l'assistant",
    "assistantResponseRequired": "Réponse finale de l'assistant *",
    "assistantResponsePlaceholder": "Le système est en bonne santé. Ollama version 0.1.0 est opérationnel avec 3 services actifs...",
    "assistantResponseHint": "Comment l'assistant doit synthétiser et présenter les données du tool",
    "description": "Description",
    "descriptionPlaceholder": "Description du prompt",
    "importSuccess": "Prompts importés avec succès",
    "confirmResetAll": "Ceci va supprimer TOUS les prompts existants et les remplacer par les prompts par défaut. Continuer ?",
    "help": {
      "title": "Prompts d'Entraînement",
      "overview": "Vue d'ensemble",
      "overviewContent": "L'onglet Prompts gère les données d'entraînement pour vos modèles IA. Chaque prompt est un exemple de conversation que le modèle apprend à reproduire.",
      "structure": "Structure d'un prompt",
      "structureContent": "Un prompt contient :\n• Input utilisateur : question ou demande\n• Sortie attendue : réponse idéale du modèle\n• Tool Call (optionnel) : appel d'outil avec arguments\n• Tool Response : résultat de l'outil\n• Réponse finale : synthèse des données",
      "management": "Gestion",
      "managementContent": "Actions disponibles :\n• Nouveau : créer un prompt manuellement\n• Reset : recharger les prompts homelab par défaut\n• Import/Export : sauvegarder ou restaurer en JSON\n• Valider : marquer un prompt comme vérifié",
      "filtering": "Filtrage",
      "filteringContent": "Filtrez les prompts par service (Plex, Radarr, Sonarr, etc.) ou recherchez par texte. Les badges indiquent le service, la difficulté et le statut de validation."
    }
  },

  "models": {
    "title": "Modèles Ollama",
    "status": "Statut Ollama",
    "version": "Version",
    "modelCount": "Modèles",
    "modelCountValue": "{{count}} modèles",
    "totalSize": "Taille totale",
    "runningModels": "Modèles en cours",
    "name": "Nom",
    "model": "Modèle",
    "family": "Famille",
    "size": "Taille",
    "parameterSize": "Paramètres",
    "quantization": "Quantization",
    "modified": "Modifié",
    "actions": "Actions",
    "pull": "Télécharger",
    "delete": "Supprimer",
    "load": "Charger le modèle",
    "unload": "Décharger le modèle",
    "noModels": "Aucun modèle installé",
    "noModelsFound": "Aucun modèle trouvé",
    "loading": "Chargement...",
    "ollamaOffline": "Ollama n'est pas disponible",
    "searchPlaceholder": "Rechercher un modèle...",
    "confirmDelete": "Êtes-vous sûr de vouloir supprimer ce modèle ?",
    "confirmQuestion": "Confirmer ?",
    "loadedInMemory": "Chargé en mémoire",
    "loaded": "Chargé",
    "help": {
      "title": "Modèles Ollama",
      "overview": "Vue d'ensemble",
      "overviewContent": "L'onglet Modèles affiche tous les modèles LLM installés sur votre serveur Ollama. Vous pouvez voir leur taille, famille et statut de chargement.",
      "management": "Gestion des modèles",
      "managementContent": "Actions disponibles pour chaque modèle :\n• Charger : charge le modèle en mémoire GPU pour une utilisation immédiate\n• Décharger : libère la mémoire GPU occupée par le modèle\n• Supprimer : supprime définitivement le modèle du serveur",
      "status": "Statuts",
      "statusContent": "Un modèle peut être :\n• Chargé (vert) : en mémoire GPU, prêt à l'utilisation\n• Non chargé : sur disque, doit être chargé avant utilisation\n• Le badge indique si le modèle est actuellement en mémoire",
      "info": "Informations",
      "infoContent": "Pour chaque modèle :\n• Famille : type de modèle (llama, mistral, etc.)\n• Paramètres : nombre de paramètres (7B, 13B, etc.)\n• Quantization : niveau de compression (Q4, Q8, etc.)\n• Taille : espace disque occupé"
    }
  },

  "workers": {
    "title": "Workers d'Entraînement",
    "subtitle": "Workers GPU pour le fine-tuning de modèles LLM",
    "count": "{{count}} worker",
    "count_plural": "{{count}} workers",
    "name": "Nom",
    "url": "URL",
    "status": "Statut",
    "gpuAvailable": "GPU disponible",
    "gpuCount": "Nombre de GPU",
    "gpuCountLabel": "{{count}} GPU",
    "gpuCountLabel_plural": "{{count}} GPU",
    "gpuNames": "GPU",
    "vram": "{{size}} GB VRAM",
    "currentJob": "Job actuel",
    "actions": "Actions",
    "test": "Tester",
    "testing": "Test...",
    "edit": "Modifier",
    "delete": "Supprimer",
    "enable": "Activer",
    "disable": "Désactiver",
    "noWorkers": "Aucun worker configuré",
    "noWorkersHint": "Ajoutez un worker GPU pour activer le fine-tuning",
    "loading": "Chargement des workers...",
    "addWorker": "Ajouter un worker",
    "refreshAll": "Actualiser tout",
    "refresh": "Actualiser",
    "retry": "Réessayer",
    "confirmDelete": "Êtes-vous sûr de vouloir supprimer ce worker ?",
    "deleteWorker": "Supprimer le worker",
    "deleteConfirmMessage": "Êtes-vous sûr de vouloir supprimer \"{{name}}\" ? Cette action est irréversible.",
    "cancel": "Annuler",
    "jobs": "Jobs",
    "trainingTime": "Temps d'entraînement",
    "version": "Version",
    "metrics": "Métriques",
    "hideMetrics": "Masquer les métriques",
    "noMetrics": "Aucune métrique disponible",
    "cpu": "CPU",
    "ram": "RAM",
    "gpu": "GPU",
    "vramUsage": "VRAM",
    "gpuTemp": "Temp GPU",
    "power": "Power",
    "online": "En ligne",
    "offline": "Hors ligne",
    "training": "Entraînement",
    "error": "Erreur",
    "unknown": "Inconnu",
    "editWorker": "Modifier le worker",
    "addTrainingWorker": "Ajouter un Training Worker",
    "formSubtitle": "Configurer un worker GPU pour le fine-tuning de modèles",
    "namePlaceholder": "IA PC Worker",
    "description": "Description",
    "descriptionPlaceholder": "Worker GPU pour l'entraînement LLM",
    "workerUrl": "URL du Worker *",
    "workerUrlPlaceholder": "http://192.168.1.100:8080",
    "workerUrlHint": "URL de l'API du training worker (conteneur Docker)",
    "apiKey": "Clé API (optionnel)",
    "apiKeyPlaceholder": "Clé API optionnelle pour l'authentification",
    "ollamaService": "Service Ollama (pour l'import du modèle)",
    "ollamaServiceHint": "Sélectionnez le serveur Ollama où importer le modèle entraîné",
    "useWorkerDefault": "Utiliser la valeur par défaut du worker",
    "workerEnabled": "Worker activé",
    "saving": "Enregistrement...",
    "saveChanges": "Enregistrer les modifications",
    "failedToLoad": "Échec du chargement des workers",
    "failedToSave": "Échec de l'enregistrement du worker",
    "failedToDelete": "Échec de la suppression du worker",
    "testFailed": "Test échoué",
    "help": {
      "title": "Workers d'Entraînement GPU",
      "overview": "Vue d'ensemble",
      "overviewContent": "L'onglet Workers permet de gérer les workers GPU distants utilisés pour le fine-tuning de modèles LLM. Chaque worker exécute les sessions d'entraînement sur son GPU.",
      "configuration": "Configuration",
      "configurationContent": "Pour ajouter un worker :\n• Spécifiez l'URL du conteneur Docker training-worker\n• Optionnellement, ajoutez une clé API pour l'authentification\n• Sélectionnez le serveur Ollama de destination pour l'import du modèle",
      "status": "États du worker",
      "statusContent": "Un worker peut avoir plusieurs états :\n• En ligne : disponible pour l'entraînement\n• Entraînement : session en cours\n• Hors ligne : non joignable\n• Erreur : problème de connexion",
      "metrics": "Métriques",
      "metricsContent": "Pour chaque worker en ligne :\n• Utilisation CPU/RAM\n• Utilisation GPU et VRAM\n• Température et consommation\n• Jobs complétés et temps d'entraînement total"
    }
  },

  "status": {
    "pending": "En attente",
    "preparing": "Préparation",
    "running": "En cours",
    "completed": "Terminé",
    "failed": "Échoué",
    "cancelled": "Annulé",
    "paused": "En pause",
    "healthy": "Sain",
    "unhealthy": "Défaillant",
    "offline": "Hors ligne",
    "notConfigured": "Non configuré"
  },

  "difficulty": {
    "label": "Difficulté",
    "basic": "Basique",
    "intermediate": "Intermédiaire",
    "advanced": "Avancé",
    "expert": "Expert"
  },

  "phases": {
    "preparing": "Préparation",
    "downloading": "Téléchargement modèle",
    "training": "Entraînement",
    "exporting": "Export GGUF",
    "importing": "Import Ollama",
    "completed": "Terminé",
    "inProgress": "En cours"
  },

  "form": {
    "nameRequired": "Nom *",
    "namePlaceholder": "Nom du prompt",
    "toolNameRequired": "Nom du tool *",
    "servicesRequired": "Services concernés *",
    "loadingAdapters": "Chargement des adaptateurs...",
    "jsonValidationError": "Les arguments du tool call doivent être un JSON valide",
    "jsonResponseError": "La réponse du tool doit être un JSON valide"
  },

  "errors": {
    "importFailed": "Erreur lors de l'import des prompts",
    "exportFailed": "Erreur lors de l'export des prompts",
    "loadHomelabFailed": "Erreur lors du chargement des prompts homelab",
    "error": "Erreur",
    "loadingLogs": "Erreur lors du chargement des logs",
    "connectionFailed": "Connexion échouée"
  },

  "overview": {
    "subtitle": "Statistiques et monitoring en temps réel",
    "activeTraining": "Entraînement en cours",
    "noData": "Aucune donnée",
    "noWorkersConfigured": "Aucun worker configuré",
    "addWorker": "Ajouter un worker",
    "connected": "Connecté",
    "notConfigured": "Non configuré",
    "ollamaNotConfigured": "Ollama non configuré",
    "configure": "Configurer",
    "promptsByService": "Prompts par service",
    "viewAll": "Voir tout",
    "noPrompts": "Aucun prompt",
    "recentSessions": "Sessions récentes",
    "lossEvolution": "Évolution du Loss (10 dernières)",
    "noSessions": "Aucune session",
    "manage": "Gérer",
    "models": "Modèles",
    "active": "Actifs",
    "totalGB": "GB Total",
    "inProgress": "En cours",
    "online": "En ligne",
    "offline": "Hors ligne",
    "busy": "Occupé",
    "jobs": "jobs",
    "successRate": "Taux de succès",
    "completed": "complétées",
    "configured": "configurés",
    "trainingWorkers": "Training Workers",
    "ollamaServer": "Ollama Server",
    "viewLiveLogs": "Voir les logs en direct",
    "viewLogs": "Voir les logs",
    "live": "Live",
    "lossDecreasing": "En baisse",
    "lossIncreasing": "En hausse",
    "lossStable": "Stable",
    "speed": "Vitesse",
    "health": "Santé",
    "utilization": "Utilisation",
    "temp": "Temp",
    "power": "Power",
    "help": {
      "title": "Statistiques IA Training",
      "overview": "Vue d'ensemble",
      "overviewContent": "L'onglet Statistiques affiche un tableau de bord temps réel de l'entraînement IA. Suivez les sessions actives, les métriques de loss, la progression et l'état des workers GPU.",
      "cards": "Cartes de statistiques",
      "cardsContent": "Les cartes affichent les métriques clés :\n• Sessions : total et actives\n• Prompts : total et validés\n• Taux de succès : sessions terminées avec succès\n• Workers : workers GPU en ligne",
      "activeSessions": "Sessions actives",
      "activeSessionsContent": "Visualisez en temps réel les entraînements en cours :\n• Progression (epochs, steps)\n• Métriques (loss, learning rate)\n• Utilisation GPU (mémoire, température)\n• Pipeline de phases (préparation, téléchargement, entraînement)",
      "workers": "Workers et Ollama",
      "workersContent": "État des ressources d'entraînement :\n• Workers GPU : disponibilité et charge\n• Ollama Server : modèles disponibles et en cours d'exécution\n• Statut de connexion WebSocket pour les mises à jour temps réel"
    }
  },

  "logs": {
    "title": "Logs de la session",
    "loading": "Chargement...",
    "error": "Erreur lors du chargement des logs",
    "noLogs": "Aucun log disponible pour cette session",
    "logsNote": "Les logs sont enregistrés à la fin de l'entraînement",
    "refresh": "Rafraîchir",
    "download": "Télécharger",
    "close": "Fermer",
    "goToEnd": "Aller à la fin",
    "lines": "lignes",
    "disableAutoRefresh": "Désactiver le rafraîchissement automatique",
    "enableAutoRefresh": "Activer le rafraîchissement automatique"
  },

  "details": {
    "title": "Détails de la session",
    "name": "Nom",
    "status": "Status",
    "baseModel": "Modèle de base",
    "outputModel": "Modèle de sortie",
    "timing": "Timing",
    "start": "Début",
    "end": "Fin",
    "duration": "Durée",
    "progress": "Progression",
    "epochs": "Epochs",
    "steps": "Steps",
    "progressPercent": "Progrès",
    "prompts": "Prompts",
    "metrics": "Métriques",
    "initialLoss": "Loss initial",
    "finalLoss": "Loss final",
    "improvement": "Amélioration",
    "minLoss": "Loss min",
    "maxLoss": "Loss max",
    "trend": "Tendance",
    "trendDecreasing": "En baisse",
    "trendIncreasing": "En hausse",
    "trendStable": "Stable",
    "lossEvolution": "Évolution du Loss",
    "notEnoughData": "Pas assez de données pour afficher le graphique",
    "error": "Erreur",
    "hyperparameters": "Hyperparamètres",
    "close": "Fermer"
  }
}
