{
  "title": "Addestramento IA",
  "subtitle": "Addestramento e ottimizzazione dei modelli IA",
  "refresh": "Aggiorna",

  "help": {
    "category": "Addestramento IA"
  },

  "tabs": {
    "overview": "Panoramica",
    "overviewShort": "Statistiche",
    "overviewFull": "Vista generale",
    "sessions": "Sessioni",
    "sessionsFull": "Sessioni di addestramento",
    "prompts": "Prompt",
    "promptsFull": "Prompt di addestramento",
    "models": "Modelli",
    "modelsFull": "Modelli Ollama",
    "workers": "Worker",
    "workersFull": "Worker GPU"
  },

  "sessions": {
    "title": "Sessioni di Addestramento",
    "newSession": "Nuova sessione",
    "newSessionTitle": "Nuova sessione di addestramento",
    "count": "{{count}} sessione",
    "count_plural": "{{count}} sessioni",
    "name": "Nome",
    "nameRequired": "Nome *",
    "baseModel": "Modello base",
    "outputModel": "Modello di output",
    "trainingType": "Tipo di addestramento",
    "backend": "Backend",
    "dataset": "Dataset",
    "prompts": "prompt",
    "epochs": "Epoche",
    "steps": "Passi",
    "progress": "Avanzamento",
    "status": "Stato",
    "actions": "Azioni",
    "start": "Avvia",
    "cancel": "Annulla",
    "pause": "Pausa",
    "resume": "Riprendi",
    "delete": "Elimina",
    "duplicate": "Duplica",
    "viewDetails": "Visualizza dettagli",
    "details": "Dettagli",
    "viewLogs": "Visualizza log",
    "logs": "Log",
    "managePrompts": "Gestisci prompt",
    "managePromptsCount": "Gestisci prompt ({{count}})",
    "createdAt": "Creato il",
    "startedAt": "Avviato il",
    "completedAt": "Completato il",
    "loss": "Loss",
    "gpuMemory": "Memoria GPU",
    "noSessions": "Nessuna sessione di addestramento",
    "noSessionsHint": "Crei una nuova sessione per iniziare",
    "confirmDelete": "È sicuro di voler eliminare questa sessione?",
    "addPromptsBeforeStart": "Aggiunga dei prompt prima di avviare",
    "description": "Descrizione",
    "descriptionPlaceholder": "Descrizione opzionale...",
    "trainingMethod": "Metodo di addestramento",
    "modelfileMethod": "Modelfile (rapido)",
    "modelfileDescription": "Crea un modello Ollama con gli esempi integrati. GPU non richiesta.",
    "unslothMethod": "Fine-tuning GPU (Unsloth)",
    "unslothDescription": "Fine-tuning LoRA su worker GPU remoto. Migliori risultati.",
    "recommended": "Consigliato",
    "gpuRequired": "GPU richiesta",
    "selectOllamaModel": "Selezionare un modello Ollama",
    "selectModel": "Selezionare un modello",
    "trainedModels": "Modelli addestrati (addestramento incrementale)",
    "huggingfaceModels": "Modelli HuggingFace (nuovo addestramento)",
    "incrementalTraining": "Addestramento incrementale: i nuovi prompt si aggiungeranno alle conoscenze esistenti",
    "optimizedModels": "Modelli ottimizzati 4-bit per GTX 1080 Ti (11GB VRAM)",
    "overwriteExisting": "Sovrascrivi il modello esistente",
    "overwriteDescription": "Se un modello con lo stesso nome esiste già in Ollama, verrà sostituito. Altrimenti, si verificherà un errore se il nome è già utilizzato.",
    "trainingWorker": "Worker di addestramento",
    "configureWorkerHint": "Configuri un worker nelle impostazioni per abilitare l'addestramento.",
    "gpuAvailable": "GPU: {{name}}",
    "cpuOnly": "Solo CPU",
    "offline": "Offline",
    "busy": "Occupato",
    "batchSize": "Batch size",
    "learningRate": "Learning rate",
    "sessionPlaceholder": "La mia sessione di addestramento",
    "step1": "1. Configurazione",
    "step2": "2. Selezione dei prompt",
    "next": "Avanti",
    "back": "Indietro",
    "promptsForTraining": "{{count}} prompt per l'addestramento",
    "promptsForTraining_plural": "{{count}} prompt per l'addestramento",
    "selectedCount": "{{count}} selezionato",
    "selectedCount_plural": "{{count}} selezionati",
    "selectedOfTotal": "{{selected}} selezionato / {{total}}",
    "selectedOfTotal_plural": "{{selected}} selezionati / {{total}}",
    "selectAll": "Seleziona tutto",
    "selectNone": "Deseleziona tutto",
    "allServices": "Tutti i servizi",
    "promptsSelection": "Selezione dei prompt",
    "promptsWillBeUsed": "{{count}} prompt verrà utilizzato per l'addestramento",
    "promptsWillBeUsed_plural": "{{count}} prompt verranno utilizzati per l'addestramento",
    "selectedOfTotalDisplayed": "{{selected}} selezionato / {{displayed}} visualizzato",
    "selectedOfTotalDisplayed_plural": "{{selected}} selezionati / {{displayed}} visualizzati",
    "help": {
      "title": "Sessioni di Addestramento",
      "overview": "Panoramica",
      "overviewContent": "La scheda Sessioni consente di creare e gestire sessioni di addestramento di modelli IA. Ogni sessione addestra un modello base con i propri prompt personalizzati.",
      "lifecycle": "Ciclo di vita",
      "lifecycleContent": "Una sessione attraversa diverse fasi:\n• In attesa: configurazione completata, pronta per l'avvio\n• In esecuzione: addestramento attivo con avanzamento visibile\n• Completata: modello addestrato disponibile in Ollama\n• Fallita: errore durante l'addestramento (controllare i log)",
      "actions": "Azioni disponibili",
      "actionsContent": "Per ogni sessione:\n• Avvia: lancia l'addestramento su un worker GPU\n• Visualizza dettagli: metriche, iperparametri, avanzamento\n• Visualizza log: log dettagliati dell'addestramento\n• Duplica: crea una copia della sessione\n• Elimina: rimuove la sessione e i suoi dati",
      "creation": "Creazione sessione",
      "creationContent": "Per creare una sessione:\n1. Scegli un nome e un modello base\n2. Seleziona il metodo (Modelfile rapido o fine-tuning GPU)\n3. Configura gli iperparametri (epoche, batch size, learning rate)\n4. Seleziona i prompt di addestramento"
    }
  },

  "prompts": {
    "title": "Prompt di Addestramento",
    "total": "{{count}} prompt",
    "total_plural": "{{count}} prompt",
    "validated": "validati",
    "enabled": "abilitati",
    "category": "Categoria",
    "difficulty": "Difficoltà",
    "source": "Origine",
    "format": "Formato",
    "tags": "Tag",
    "timesUsed": "Utilizzi",
    "timesUsedCount": "{{count}} utilizzi",
    "validationScore": "Punteggio",
    "actions": "Azioni",
    "edit": "Modifica",
    "delete": "Elimina",
    "validate": "Valida",
    "enable": "Abilita",
    "disable": "Disabilita",
    "cancel": "Annulla",
    "search": "Cerca...",
    "noPrompts": "Nessun prompt di addestramento",
    "noPromptsFound": "Nessun prompt trovato",
    "noPromptsHint": "Aggiunga dei prompt per addestrare i Suoi modelli",
    "perPage": "Per pagina",
    "addPrompt": "Aggiungi prompt",
    "createPrompt": "Crea prompt",
    "newPrompt": "Nuovo prompt di addestramento",
    "editPrompt": "Modifica prompt",
    "save": "Salva",
    "saving": "Salvataggio...",
    "create": "Crea prompt",
    "creating": "Creazione...",
    "createMultiple": "Crea ({{count}} prompt)",
    "saveMultiple": "Salva ({{count}})",
    "searchPlaceholder": "Cerca...",
    "deleteAll": "Elimina tutti i prompt e ricarica i prompt homelab",
    "confirmDelete": "È sicuro di voler eliminare questo prompt?",
    "selectAtLeastOne": "Selezioni almeno un servizio",
    "resetPrompts": "Reset Prompts",
    "import": "Importa",
    "export": "Esporta",
    "new": "Nuovo",
    "allServicesCount": "Tutti i servizi ({{count}})",
    "systemPrompt": "System Prompt",
    "systemPromptPlaceholder": "Istruzioni di sistema per il modello...",
    "userInput": "Input utente",
    "userInputRequired": "Input utente *",
    "userInputPlaceholder": "Domanda o richiesta dell'utente...",
    "expectedOutput": "Output atteso",
    "expectedOutputRequired": "Output atteso *",
    "expectedOutputPlaceholder": "Risposta attesa dal modello...",
    "useToolCalling": "Utilizza Tool Calling",
    "toolCallingHint": "(insegna al modello a chiamare strumenti E utilizzare i risultati)",
    "toolCall": "Tool Call (Chiamata strumento)",
    "toolName": "Nome del tool",
    "toolNameRequired": "Nome del tool *",
    "toolNamePlaceholder": "es: system_get_health",
    "toolArguments": "Argomenti (JSON)",
    "toolArgumentsPlaceholder": "es: {\"service\": \"ollama\"}",
    "toolResponse": "Risposta del Tool (JSON)",
    "toolResponseRequired": "Risposta del Tool (JSON) *",
    "toolResponsePlaceholder": "{\"status\": \"healthy\", \"version\": \"0.1.0\", \"services\": [...]}",
    "toolResponseHint": "Risposta realistica che il tool restituirebbe (utilizzata per l'addestramento)",
    "assistantResponse": "Risposta finale dell'assistente",
    "assistantResponseRequired": "Risposta finale dell'assistente *",
    "assistantResponsePlaceholder": "Il sistema è in buona salute. Ollama versione 0.1.0 è operativo con 3 servizi attivi...",
    "assistantResponseHint": "Come l'assistente deve sintetizzare e presentare i dati del tool",
    "description": "Descrizione",
    "descriptionPlaceholder": "Descrizione del prompt",
    "importSuccess": "Prompt importati con successo",
    "confirmResetAll": "Questa operazione eliminerà TUTTI i prompt esistenti e li sostituirà con i prompt predefiniti. Continuare?",
    "help": {
      "title": "Prompt di Addestramento",
      "overview": "Panoramica",
      "overviewContent": "La scheda Prompt gestisce i dati di addestramento per i tuoi modelli IA. Ogni prompt è un esempio di conversazione che il modello impara a riprodurre.",
      "structure": "Struttura del prompt",
      "structureContent": "Un prompt contiene:\n• Input utente: domanda o richiesta\n• Output atteso: risposta ideale del modello\n• Tool Call (opzionale): chiamata dello strumento con argomenti\n• Tool Response: risultato dello strumento\n• Risposta finale: sintesi dei dati",
      "management": "Gestione",
      "managementContent": "Azioni disponibili:\n• Nuovo: crea un prompt manualmente\n• Reset: ricarica i prompt homelab predefiniti\n• Importa/Esporta: salva o ripristina come JSON\n• Valida: contrassegna un prompt come verificato",
      "filtering": "Filtraggio",
      "filteringContent": "Filtra i prompt per servizio (Plex, Radarr, Sonarr, ecc.) o cerca per testo. I badge indicano servizio, difficoltà e stato di validazione."
    }
  },

  "models": {
    "title": "Modelli Ollama",
    "status": "Stato Ollama",
    "version": "Versione",
    "modelCount": "Modelli",
    "modelCountValue": "{{count}} modelli",
    "totalSize": "Dimensione totale",
    "runningModels": "Modelli in esecuzione",
    "name": "Nome",
    "model": "Modello",
    "family": "Famiglia",
    "size": "Dimensione",
    "parameterSize": "Parametri",
    "quantization": "Quantizzazione",
    "modified": "Modificato",
    "actions": "Azioni",
    "pull": "Scarica",
    "delete": "Elimina",
    "load": "Carica modello",
    "unload": "Scarica modello",
    "noModels": "Nessun modello installato",
    "noModelsFound": "Nessun modello trovato",
    "loading": "Caricamento...",
    "ollamaOffline": "Ollama non è disponibile",
    "searchPlaceholder": "Cerca un modello...",
    "confirmDelete": "È sicuro di voler eliminare questo modello?",
    "confirmQuestion": "Confermare?",
    "loadedInMemory": "Caricato in memoria",
    "loaded": "Caricato",
    "help": {
      "title": "Modelli Ollama",
      "overview": "Panoramica",
      "overviewContent": "La scheda Modelli mostra tutti i modelli LLM installati sul server Ollama. È possibile vedere la loro dimensione, famiglia e stato di caricamento.",
      "management": "Gestione modelli",
      "managementContent": "Azioni disponibili per ogni modello:\n• Carica: carica il modello nella memoria GPU per l'uso immediato\n• Scarica: libera la memoria GPU occupata dal modello\n• Elimina: rimuove permanentemente il modello dal server",
      "status": "Stati",
      "statusContent": "Un modello può essere:\n• Caricato (verde): in memoria GPU, pronto all'uso\n• Non caricato: su disco, deve essere caricato prima dell'uso\n• Il badge indica se il modello è attualmente in memoria",
      "info": "Informazioni",
      "infoContent": "Per ogni modello:\n• Famiglia: tipo di modello (llama, mistral, etc.)\n• Parametri: numero di parametri (7B, 13B, etc.)\n• Quantizzazione: livello di compressione (Q4, Q8, etc.)\n• Dimensione: spazio su disco occupato"
    }
  },

  "workers": {
    "title": "Worker di Addestramento",
    "subtitle": "Worker GPU per il fine-tuning dei modelli LLM",
    "count": "{{count}} worker",
    "count_plural": "{{count}} worker",
    "name": "Nome",
    "url": "URL",
    "status": "Stato",
    "gpuAvailable": "GPU disponibile",
    "gpuCount": "Numero GPU",
    "gpuCountLabel": "{{count}} GPU",
    "gpuCountLabel_plural": "{{count}} GPU",
    "gpuNames": "GPU",
    "vram": "{{size}} GB VRAM",
    "currentJob": "Job corrente",
    "actions": "Azioni",
    "test": "Test",
    "testing": "Test...",
    "edit": "Modifica",
    "delete": "Elimina",
    "enable": "Abilita",
    "disable": "Disabilita",
    "noWorkers": "Nessun worker configurato",
    "noWorkersHint": "Aggiunga un worker GPU per abilitare il fine-tuning",
    "loading": "Caricamento worker...",
    "addWorker": "Aggiungi worker",
    "refreshAll": "Aggiorna tutto",
    "refresh": "Aggiorna",
    "retry": "Riprova",
    "confirmDelete": "È sicuro di voler eliminare questo worker?",
    "deleteWorker": "Elimina worker",
    "deleteConfirmMessage": "È sicuro di voler eliminare \"{{name}}\"? Questa azione è irreversibile.",
    "cancel": "Annulla",
    "jobs": "Job",
    "trainingTime": "Tempo di addestramento",
    "version": "Versione",
    "metrics": "Metriche",
    "hideMetrics": "Nascondi metriche",
    "noMetrics": "Nessuna metrica disponibile",
    "cpu": "CPU",
    "ram": "RAM",
    "gpu": "GPU",
    "vramUsage": "VRAM",
    "gpuTemp": "Temp GPU",
    "power": "Potenza",
    "online": "Online",
    "offline": "Offline",
    "training": "Addestramento",
    "error": "Errore",
    "unknown": "Sconosciuto",
    "editWorker": "Modifica worker",
    "addTrainingWorker": "Aggiungi Training Worker",
    "formSubtitle": "Configuri un worker GPU per il fine-tuning dei modelli",
    "namePlaceholder": "Worker PC IA",
    "description": "Descrizione",
    "descriptionPlaceholder": "Worker GPU per l'addestramento LLM",
    "workerUrl": "URL del Worker *",
    "workerUrlPlaceholder": "http://192.168.1.100:8080",
    "workerUrlHint": "URL dell'API del training worker (container Docker)",
    "apiKey": "Chiave API (opzionale)",
    "apiKeyPlaceholder": "Chiave API opzionale per l'autenticazione",
    "ollamaService": "Servizio Ollama (per l'importazione del modello)",
    "ollamaServiceHint": "Selezioni il server Ollama dove importare il modello addestrato",
    "useWorkerDefault": "Utilizza il valore predefinito del worker",
    "workerEnabled": "Worker abilitato",
    "saving": "Salvataggio...",
    "saveChanges": "Salva le modifiche",
    "failedToLoad": "Caricamento worker fallito",
    "failedToSave": "Salvataggio worker fallito",
    "failedToDelete": "Eliminazione worker fallita",
    "testFailed": "Test fallito",
    "help": {
      "title": "Worker GPU di Addestramento",
      "overview": "Panoramica",
      "overviewContent": "La scheda Worker permette di gestire i worker GPU remoti utilizzati per il fine-tuning dei modelli LLM. Ogni worker esegue sessioni di addestramento sulla sua GPU.",
      "configuration": "Configurazione",
      "configurationContent": "Per aggiungere un worker:\n• Specificare l'URL del container Docker training-worker\n• Opzionalmente aggiungere una chiave API per l'autenticazione\n• Selezionare il server Ollama di destinazione per l'importazione del modello",
      "status": "Stati del worker",
      "statusContent": "Un worker può avere diversi stati:\n• Online: disponibile per l'addestramento\n• Addestramento: sessione in corso\n• Offline: non raggiungibile\n• Errore: problema di connessione",
      "metrics": "Metriche",
      "metricsContent": "Per ogni worker online:\n• Utilizzo CPU/RAM\n• Utilizzo GPU e VRAM\n• Temperatura e consumo energetico\n• Lavori completati e tempo totale di addestramento"
    }
  },

  "status": {
    "pending": "In attesa",
    "preparing": "Preparazione",
    "running": "In esecuzione",
    "completed": "Completato",
    "failed": "Fallito",
    "cancelled": "Annullato",
    "paused": "In pausa",
    "healthy": "Funzionante",
    "unhealthy": "Non funzionante",
    "offline": "Offline",
    "notConfigured": "Non configurato"
  },

  "difficulty": {
    "label": "Difficoltà",
    "basic": "Base",
    "intermediate": "Intermedio",
    "advanced": "Avanzato",
    "expert": "Esperto"
  },

  "phases": {
    "preparing": "Preparazione",
    "downloading": "Download modello",
    "training": "Addestramento",
    "exporting": "Esportazione GGUF",
    "importing": "Importazione in Ollama",
    "completed": "Completato",
    "inProgress": "In corso"
  },

  "form": {
    "nameRequired": "Nome *",
    "namePlaceholder": "Nome del prompt",
    "toolNameRequired": "Nome del tool *",
    "servicesRequired": "Servizi correlati *",
    "loadingAdapters": "Caricamento adapter...",
    "jsonValidationError": "Gli argomenti del tool call devono essere un JSON valido",
    "jsonResponseError": "La risposta del tool deve essere un JSON valido"
  },

  "errors": {
    "importFailed": "Errore durante l'importazione dei prompt",
    "exportFailed": "Errore durante l'esportazione dei prompt",
    "loadHomelabFailed": "Errore durante il caricamento dei prompt homelab",
    "error": "Errore",
    "loadingLogs": "Errore durante il caricamento dei log",
    "connectionFailed": "Connessione fallita"
  },

  "overview": {
    "subtitle": "Statistiche e monitoraggio in tempo reale",
    "activeTraining": "Addestramento in corso",
    "noData": "Nessun dato",
    "noWorkersConfigured": "Nessun worker configurato",
    "addWorker": "Aggiungi un worker",
    "connected": "Connesso",
    "notConfigured": "Non configurato",
    "ollamaNotConfigured": "Ollama non configurato",
    "configure": "Configura",
    "promptsByService": "Prompt per servizio",
    "viewAll": "Visualizza tutto",
    "noPrompts": "Nessun prompt",
    "recentSessions": "Sessioni recenti",
    "lossEvolution": "Evoluzione del Loss (ultime 10)",
    "noSessions": "Nessuna sessione",
    "manage": "Gestisci",
    "models": "Modelli",
    "active": "Attivi",
    "totalGB": "GB totali",
    "inProgress": "In corso",
    "online": "Online",
    "offline": "Offline",
    "busy": "Occupato",
    "jobs": "job",
    "successRate": "Tasso di successo",
    "completed": "completate",
    "configured": "configurati",
    "trainingWorkers": "Worker di Addestramento",
    "ollamaServer": "Server Ollama",
    "viewLiveLogs": "Visualizza log in tempo reale",
    "viewLogs": "Visualizza log",
    "live": "Live",
    "lossDecreasing": "In diminuzione",
    "lossIncreasing": "In aumento",
    "lossStable": "Stabile",
    "speed": "Velocità",
    "health": "Salute",
    "utilization": "Utilizzo",
    "temp": "Temp",
    "power": "Potenza",
    "help": {
      "title": "Statistiche Addestramento IA",
      "overview": "Panoramica",
      "overviewContent": "La scheda Statistiche mostra una dashboard in tempo reale dell'addestramento IA. Monitora le sessioni attive, le metriche di loss, l'avanzamento e lo stato dei worker GPU.",
      "cards": "Schede statistiche",
      "cardsContent": "Le schede mostrano metriche chiave:\n• Sessioni: totali e attive\n• Prompt: totali e validati\n• Tasso di successo: sessioni completate con successo\n• Worker: worker GPU online",
      "activeSessions": "Sessioni attive",
      "activeSessionsContent": "Visualizza l'avanzamento dell'addestramento in tempo reale:\n• Avanzamento (epoche, passi)\n• Metriche (loss, learning rate)\n• Utilizzo GPU (memoria, temperatura)\n• Pipeline delle fasi (preparazione, download, addestramento)",
      "workers": "Worker e Ollama",
      "workersContent": "Stato delle risorse di addestramento:\n• Worker GPU: disponibilità e carico\n• Server Ollama: modelli disponibili e in esecuzione\n• Stato della connessione WebSocket per aggiornamenti in tempo reale"
    }
  },

  "logs": {
    "title": "Log della sessione",
    "loading": "Caricamento...",
    "error": "Errore durante il caricamento dei log",
    "noLogs": "Nessun log disponibile per questa sessione",
    "logsNote": "I log vengono salvati alla fine dell'addestramento",
    "refresh": "Aggiorna",
    "download": "Scarica",
    "close": "Chiudi",
    "goToEnd": "Vai alla fine",
    "lines": "righe",
    "disableAutoRefresh": "Disabilita aggiornamento automatico",
    "enableAutoRefresh": "Abilita aggiornamento automatico"
  },

  "details": {
    "title": "Dettagli della sessione",
    "name": "Nome",
    "status": "Stato",
    "baseModel": "Modello base",
    "outputModel": "Modello di output",
    "timing": "Tempistiche",
    "start": "Inizio",
    "end": "Fine",
    "duration": "Durata",
    "progress": "Avanzamento",
    "epochs": "Epoche",
    "steps": "Passi",
    "progressPercent": "Avanzamento",
    "prompts": "Prompt",
    "metrics": "Metriche",
    "initialLoss": "Loss iniziale",
    "finalLoss": "Loss finale",
    "improvement": "Miglioramento",
    "minLoss": "Loss minima",
    "maxLoss": "Loss massima",
    "trend": "Tendenza",
    "trendDecreasing": "In diminuzione",
    "trendIncreasing": "In aumento",
    "trendStable": "Stabile",
    "lossEvolution": "Evoluzione del Loss",
    "notEnoughData": "Dati insufficienti per visualizzare il grafico",
    "error": "Errore",
    "hyperparameters": "Iperparametri",
    "close": "Chiudi"
  }
}
